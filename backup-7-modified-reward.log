2018-04-20 00:09:43,744 (dqn_main.py:61) DEBUG: ">>>> RUNNING data_file=7_17.npy,reuse_weights=None,test=False<<<<"
2018-04-20 00:09:44,064 (tf_logging.py:160) Level 1: "Registering Batch (<function _BatchGrad at 0x7f16fc834378>) in gradient."
2018-04-20 00:09:44,064 (tf_logging.py:160) Level 1: "Registering Unbatch (<function _UnbatchGrad at 0x7f16fc834e18>) in gradient."
2018-04-20 00:09:44,067 (tf_logging.py:160) Level 1: "Registering ZeroInitializer (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,081 (tf_logging.py:160) Level 1: "Registering SparseFeatureCross (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,083 (tf_logging.py:160) Level 1: "Registering SparseFeatureCrossV2 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,085 (tf_logging.py:160) Level 1: "Registering SparseFeatureCross (None) in gradient."
2018-04-20 00:09:44,086 (tf_logging.py:160) Level 1: "Registering SparseFeatureCrossV2 (None) in gradient."
2018-04-20 00:09:44,089 (tf_logging.py:160) Level 1: "Registering GDNLowerBound (<function GDN._lower_bound_grad at 0x7f16f81de6a8>) in gradient."
2018-04-20 00:09:44,105 (tf_logging.py:160) Level 1: "Registering ObtainNext (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,113 (tf_logging.py:160) Level 1: "Registering hparams ((<class 'tensorflow.contrib.training.python.training.hparam_pb2.HParamDef'>, <function HParams.to_proto at 0x7f16f02c1620>, <function HParams.from_proto at 0x7f16f02c16a8>)) in proto functions."
2018-04-20 00:09:44,119 (tf_logging.py:160) Level 1: "Registering GRUBlockCell (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,121 (tf_logging.py:160) Level 1: "Registering GRUBlockCellGrad (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,122 (tf_logging.py:160) Level 1: "Registering GRUBlockCell (<function _GRUBlockCellGrad at 0x7f16f0259b70>) in gradient."
2018-04-20 00:09:44,124 (tf_logging.py:160) Level 1: "Registering BlockLSTM (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,125 (tf_logging.py:160) Level 1: "Registering BlockLSTMGrad (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,125 (tf_logging.py:160) Level 1: "Registering LSTMBlockCell (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,126 (tf_logging.py:160) Level 1: "Registering LSTMBlockCellGrad (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,128 (tf_logging.py:160) Level 1: "Registering LSTMBlockCell (<function _LSTMBlockCellGrad at 0x7f16f0221d90>) in gradient."
2018-04-20 00:09:44,129 (tf_logging.py:160) Level 1: "Registering BlockLSTM (<function _BlockLSTMGrad at 0x7f16f0221e18>) in gradient."
2018-04-20 00:09:44,132 (tf_logging.py:160) Level 1: "Registering KMC2ChainInitialization (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,133 (tf_logging.py:160) Level 1: "Registering KmeansPlusPlusInitialization (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,134 (tf_logging.py:160) Level 1: "Registering NearestNeighbors (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,137 (tf_logging.py:160) Level 1: "Registering MaskedMatmul (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,138 (tf_logging.py:160) Level 1: "Registering WALSComputePartialLhsAndRhs (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,148 (tf_logging.py:160) Level 1: "Registering ConfigureDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,149 (tf_logging.py:160) Level 1: "Registering CrossReplicaSum (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,149 (tf_logging.py:160) Level 1: "Registering InfeedDequeue (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,150 (tf_logging.py:160) Level 1: "Registering InfeedDequeueTuple (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,150 (tf_logging.py:160) Level 1: "Registering InfeedEnqueue (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,151 (tf_logging.py:160) Level 1: "Registering InfeedEnqueueTuple (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,151 (tf_logging.py:160) Level 1: "Registering OutfeedDequeue (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,151 (tf_logging.py:160) Level 1: "Registering OutfeedDequeueTuple (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,152 (tf_logging.py:160) Level 1: "Registering OutfeedEnqueue (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,152 (tf_logging.py:160) Level 1: "Registering OutfeedEnqueueTuple (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,153 (tf_logging.py:160) Level 1: "Registering ShutdownDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,153 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingActivations (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,154 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingEnqueueSparseBatch (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,154 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingLoadAdagradParameters (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,155 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingLoadGradientDescentParameters (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,155 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingReceiveActivations (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,156 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingRetrieveAdagradParameters (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,157 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingRetrieveGradientDescentParameters (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,157 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingSendGradients (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,158 (tf_logging.py:160) Level 1: "Registering TPUReplicate (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,158 (tf_logging.py:160) Level 1: "Registering TPUReplicateMetadata (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,159 (tf_logging.py:160) Level 1: "Registering TPUReplicatedInput (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,159 (tf_logging.py:160) Level 1: "Registering TPUReplicatedOutput (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,163 (tf_logging.py:160) Level 1: "Registering _ConfigureDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,164 (tf_logging.py:160) Level 1: "Registering _WaitForDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,165 (tf_logging.py:160) Level 1: "Registering _SetGlobalTPUArray (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,165 (tf_logging.py:160) Level 1: "Registering _ShutdownDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,166 (tf_logging.py:160) Level 1: "Registering _InitializeHostForDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,166 (tf_logging.py:160) Level 1: "Registering _DisconnectHostFromDistributedTPUSystem (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,168 (tf_logging.py:160) Level 1: "Registering CrossReplicaSum (<function _cross_replica_sum_grad at 0x7f16f00da400>) in gradient."
2018-04-20 00:09:44,172 (tf_logging.py:160) Level 1: "Registering CloseSummaryWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,173 (tf_logging.py:160) Level 1: "Registering CreateSummaryDbWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,174 (tf_logging.py:160) Level 1: "Registering CreateSummaryFileWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,175 (tf_logging.py:160) Level 1: "Registering FlushSummaryWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,175 (tf_logging.py:160) Level 1: "Registering ImportEvent (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,176 (tf_logging.py:160) Level 1: "Registering SummaryWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,177 (tf_logging.py:160) Level 1: "Registering WriteAudioSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,177 (tf_logging.py:160) Level 1: "Registering WriteGraphSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,178 (tf_logging.py:160) Level 1: "Registering WriteHistogramSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,179 (tf_logging.py:160) Level 1: "Registering WriteImageSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,179 (tf_logging.py:160) Level 1: "Registering WriteScalarSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,180 (tf_logging.py:160) Level 1: "Registering WriteSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,207 (tf_logging.py:160) Level 1: "Registering BigQueryReader (None) in gradient."
2018-04-20 00:09:44,220 (tf_logging.py:160) Level 1: "Registering RangeDecode (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,221 (tf_logging.py:160) Level 1: "Registering RangeEncode (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,273 (tf_logging.py:160) Level 1: "Registering CudnnRNN (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,274 (tf_logging.py:160) Level 1: "Registering CudnnRNNBackprop (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,275 (tf_logging.py:160) Level 1: "Registering CudnnRNNCanonicalToParams (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,275 (tf_logging.py:160) Level 1: "Registering CudnnRNNParamsSize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,276 (tf_logging.py:160) Level 1: "Registering CudnnRNNParamsToCanonical (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,282 (tf_logging.py:160) Level 1: "Registering CudnnRNN (<function _cudnn_rnn_backward at 0x7f16e14d46a8>) in gradient."
2018-04-20 00:09:44,283 (tf_logging.py:160) Level 1: "Registering CudnnRNNParamsSize (<function call_cpp_shape_fn at 0x7f1767fa7840>) in shape functions."
2018-04-20 00:09:44,283 (tf_logging.py:160) Level 1: "Registering CudnnRNNParamsToCanonical (<function call_cpp_shape_fn at 0x7f1767fa7840>) in shape functions."
2018-04-20 00:09:44,283 (tf_logging.py:160) Level 1: "Registering CudnnRNNCanonicalToParams (<function call_cpp_shape_fn at 0x7f1767fa7840>) in shape functions."
2018-04-20 00:09:44,284 (tf_logging.py:160) Level 1: "Registering CudnnRNN (<function call_cpp_shape_fn at 0x7f1767fa7840>) in shape functions."
2018-04-20 00:09:44,284 (tf_logging.py:160) Level 1: "Registering CudnnRNNBackprop (<function call_cpp_shape_fn at 0x7f1767fa7840>) in shape functions."
2018-04-20 00:09:44,312 (tf_logging.py:160) Level 1: "Registering AdjustHsvInYiq (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,315 (tf_logging.py:160) Level 1: "Registering BipartiteMatch (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,315 (tf_logging.py:160) Level 1: "Registering ImageConnectedComponents (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,316 (tf_logging.py:160) Level 1: "Registering ImageProjectiveTransform (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,318 (tf_logging.py:160) Level 1: "Registering ImageConnectedComponents (<function call_cpp_shape_fn at 0x7f1767fa7840>) in shape functions."
2018-04-20 00:09:44,319 (tf_logging.py:160) Level 1: "Registering ImageProjectiveTransform (<function call_cpp_shape_fn at 0x7f1767fa7840>) in shape functions."
2018-04-20 00:09:44,319 (tf_logging.py:160) Level 1: "Registering ImageProjectiveTransform (<function _image_projective_transform_grad at 0x7f16e0df4b70>) in gradient."
2018-04-20 00:09:44,319 (tf_logging.py:160) Level 1: "Registering BipartiteMatch (None) in gradient."
2018-04-20 00:09:44,320 (tf_logging.py:160) Level 1: "Registering ImageConnectedComponents (None) in gradient."
2018-04-20 00:09:44,320 (tf_logging.py:160) Level 1: "Registering SingleImageRandomDotStereograms (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,325 (tf_logging.py:160) Level 1: "Registering SingleImageRandomDotStereograms (None) in gradient."
2018-04-20 00:09:44,355 (tf_logging.py:160) Level 1: "Registering BytesInUse (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,355 (tf_logging.py:160) Level 1: "Registering BytesLimit (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,356 (tf_logging.py:160) Level 1: "Registering MaxBytesInUse (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,360 (tf_logging.py:160) Level 1: "Registering NcclAllReduce (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,360 (tf_logging.py:160) Level 1: "Registering NcclBroadcast (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,361 (tf_logging.py:160) Level 1: "Registering NcclReduce (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,363 (tf_logging.py:160) Level 1: "Registering _NcclReduceSend (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,363 (tf_logging.py:160) Level 1: "Registering _NcclReduceRecv (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,364 (tf_logging.py:160) Level 1: "Registering _NcclBroadcastSend (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,364 (tf_logging.py:160) Level 1: "Registering _NcclBroadcastRecv (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,364 (tf_logging.py:160) Level 1: "Registering NcclAllReduce (<function _all_sum_grad at 0x7f16e04a8950>) in gradient."
2018-04-20 00:09:44,365 (tf_logging.py:160) Level 1: "Registering NcclReduce (<function _reduce_sum_grad at 0x7f16e04a8bf8>) in gradient."
2018-04-20 00:09:44,365 (tf_logging.py:160) Level 1: "Registering NcclBroadcast (<function _broadcast_grad at 0x7f16e04a8d90>) in gradient."
2018-04-20 00:09:44,366 (tf_logging.py:160) Level 1: "Registering PeriodicResample (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,373 (tf_logging.py:160) Level 1: "Registering FoldFusedBatchNormGrad (<function _FoldFusedBatchNormGrad at 0x7f16e01ed048>) in gradient."
2018-04-20 00:09:44,377 (tf_logging.py:160) Level 1: "Registering Resampler (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,378 (tf_logging.py:160) Level 1: "Registering ResamplerGrad (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,380 (tf_logging.py:160) Level 1: "Registering Resampler (<function _resampler_grad at 0x7f16e0195c80>) in gradient."
2018-04-20 00:09:44,381 (tf_logging.py:160) Level 1: "Registering ResamplerGrad (None) in gradient."
2018-04-20 00:09:44,385 (tf_logging.py:160) Level 1: "Registering GatherTree (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,394 (tf_logging.py:160) Level 1: "Registering StatelessRandomNormal (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,395 (tf_logging.py:160) Level 1: "Registering StatelessRandomUniform (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,395 (tf_logging.py:160) Level 1: "Registering StatelessTruncatedNormal (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,396 (tf_logging.py:160) Level 1: "Registering StatelessRandomNormal (None) in gradient."
2018-04-20 00:09:44,396 (tf_logging.py:160) Level 1: "Registering StatelessRandomUniform (None) in gradient."
2018-04-20 00:09:44,397 (tf_logging.py:160) Level 1: "Registering StatelessTruncatedNormal (None) in gradient."
2018-04-20 00:09:44,402 (tf_logging.py:160) Level 1: "Registering ReinterpretStringToFloat (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,403 (tf_logging.py:160) Level 1: "Registering ScatterAddNdim (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,410 (tf_logging.py:160) Level 1: "Registering CreateTreeVariable (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,411 (tf_logging.py:160) Level 1: "Registering DecisionTreeResourceHandleOp (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,411 (tf_logging.py:160) Level 1: "Registering FeatureUsageCounts (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,412 (tf_logging.py:160) Level 1: "Registering TraverseTreeV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,413 (tf_logging.py:160) Level 1: "Registering TreeDeserialize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,413 (tf_logging.py:160) Level 1: "Registering TreeIsInitializedOp (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,414 (tf_logging.py:160) Level 1: "Registering TreePredictionsV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,415 (tf_logging.py:160) Level 1: "Registering TreeSerialize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,416 (tf_logging.py:160) Level 1: "Registering TreeSize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,416 (tf_logging.py:160) Level 1: "Registering UpdateModelV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,420 (tf_logging.py:160) Level 1: "Registering TreeVariable (None) in gradient."
2018-04-20 00:09:44,421 (tf_logging.py:160) Level 1: "Registering TreeSerialize (None) in gradient."
2018-04-20 00:09:44,421 (tf_logging.py:160) Level 1: "Registering TreeDeserialize (None) in gradient."
2018-04-20 00:09:44,422 (tf_logging.py:160) Level 1: "Registering TreeSize (None) in gradient."
2018-04-20 00:09:44,422 (tf_logging.py:160) Level 1: "Registering TreePredictionsV4 (None) in gradient."
2018-04-20 00:09:44,423 (tf_logging.py:160) Level 1: "Registering FeatureUsageCounts (None) in gradient."
2018-04-20 00:09:44,424 (tf_logging.py:160) Level 1: "Registering CreateFertileStatsVariable (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,425 (tf_logging.py:160) Level 1: "Registering FertileStatsDeserialize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,425 (tf_logging.py:160) Level 1: "Registering FertileStatsIsInitializedOp (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,426 (tf_logging.py:160) Level 1: "Registering FertileStatsResourceHandleOp (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,427 (tf_logging.py:160) Level 1: "Registering FertileStatsSerialize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,427 (tf_logging.py:160) Level 1: "Registering FinalizeTree (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,428 (tf_logging.py:160) Level 1: "Registering GrowTreeV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,429 (tf_logging.py:160) Level 1: "Registering ProcessInputV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,457 (tf_logging.py:160) Level 1: "Registering FertileStatsVariable (None) in gradient."
2018-04-20 00:09:44,467 (tf_logging.py:160) Level 1: "Registering FertileStatsSerialize (None) in gradient."
2018-04-20 00:09:44,468 (tf_logging.py:160) Level 1: "Registering FertileStatsDeserialize (None) in gradient."
2018-04-20 00:09:44,468 (tf_logging.py:160) Level 1: "Registering GrowTreeV4 (None) in gradient."
2018-04-20 00:09:44,469 (tf_logging.py:160) Level 1: "Registering ProcessInputV4 (None) in gradient."
2018-04-20 00:09:44,469 (tf_logging.py:160) Level 1: "Registering FinalizeTree (None) in gradient."
2018-04-20 00:09:44,489 (tf_logging.py:160) Level 1: "Registering FunctionBufferingResource (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,493 (tf_logging.py:160) Level 1: "Registering FunctionBufferingResourceGetNext (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,519 (tf_logging.py:160) Level 1: "Registering RemoteFusedGraphExecute (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,522 (tf_logging.py:160) Level 1: "Registering RemoteFusedGraphExecute (None) in gradient."
2018-04-20 00:09:44,538 (tf_logging.py:160) Level 1: "Created variable q/Conv/weights:0 with shape (1, 1, 2, 8) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f16f81d5510>"
2018-04-20 00:09:44,542 (tf_logging.py:160) Level 1: "Created variable q/Conv/biases:0 with shape (8,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16f81d9208>"
2018-04-20 00:09:44,552 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/weights:0 with shape (3, 3, 8, 12) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f16f81d5510>"
2018-04-20 00:09:44,557 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/biases:0 with shape (12,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16f81d9208>"
2018-04-20 00:09:44,565 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/weights:0 with shape (3, 3, 12, 16) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f16f81d5510>"
2018-04-20 00:09:44,569 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/biases:0 with shape (16,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16f81d9208>"
2018-04-20 00:09:44,582 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/weights:0 with shape (576, 128) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f16f81de2f0>"
2018-04-20 00:09:44,586 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/biases:0 with shape (128,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16f81d95f8>"
2018-04-20 00:09:44,593 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/weights:0 with shape (128, 5) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f16f81de2f0>"
2018-04-20 00:09:44,597 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/biases:0 with shape (5,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16f81d95f8>"
2018-04-20 00:09:44,605 (tf_logging.py:160) Level 1: "Created variable target_q/Conv/weights:0 with shape (1, 1, 2, 8) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f16f81d5510>"
2018-04-20 00:09:44,609 (tf_logging.py:160) Level 1: "Created variable target_q/Conv/biases:0 with shape (8,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16f81d9208>"
2018-04-20 00:09:44,616 (tf_logging.py:160) Level 1: "Created variable target_q/Conv_1/weights:0 with shape (3, 3, 8, 12) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f16f81d5510>"
2018-04-20 00:09:44,620 (tf_logging.py:160) Level 1: "Created variable target_q/Conv_1/biases:0 with shape (12,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16f81d9208>"
2018-04-20 00:09:44,626 (tf_logging.py:160) Level 1: "Created variable target_q/Conv_2/weights:0 with shape (3, 3, 12, 16) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f16f81d5510>"
2018-04-20 00:09:44,631 (tf_logging.py:160) Level 1: "Created variable target_q/Conv_2/biases:0 with shape (16,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16f81d9208>"
2018-04-20 00:09:44,640 (tf_logging.py:160) Level 1: "Created variable target_q/fully_connected/weights:0 with shape (576, 128) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f16f81de2f0>"
2018-04-20 00:09:44,644 (tf_logging.py:160) Level 1: "Created variable target_q/fully_connected/biases:0 with shape (128,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16f81d95f8>"
2018-04-20 00:09:44,650 (tf_logging.py:160) Level 1: "Created variable target_q/fully_connected_1/weights:0 with shape (128, 5) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f16f81de2f0>"
2018-04-20 00:09:44,653 (tf_logging.py:160) Level 1: "Created variable target_q/fully_connected_1/biases:0 with shape (5,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16f81d95f8>"
2018-04-20 00:09:44,675 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/value'"
2018-04-20 00:09:44,676 (tf_logging.py:160) Level 1: "  in  --> gradients/Fill:0"
2018-04-20 00:09:44,676 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/value_grad/tuple/control_dependency:0, gradients/mean_squared_error/value_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,682 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/div'"
2018-04-20 00:09:44,682 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/value_grad/tuple/control_dependency:0"
2018-04-20 00:09:44,682 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/div_grad/tuple/control_dependency:0, gradients/mean_squared_error/div_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,684 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/Sum_1'"
2018-04-20 00:09:44,685 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/div_grad/tuple/control_dependency:0"
2018-04-20 00:09:44,685 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/Sum_1_grad/Tile:0"
2018-04-20 00:09:44,688 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/Select'"
2018-04-20 00:09:44,688 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/div_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,689 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/Select_grad/tuple/control_dependency:0, gradients/mean_squared_error/Select_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,693 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/Sum'"
2018-04-20 00:09:44,693 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/Sum_1_grad/Tile:0"
2018-04-20 00:09:44,693 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/Sum_grad/Tile:0"
2018-04-20 00:09:44,700 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/Mul'"
2018-04-20 00:09:44,701 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/Sum_grad/Tile:0"
2018-04-20 00:09:44,701 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/Mul_grad/tuple/control_dependency:0, gradients/mean_squared_error/Mul_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,704 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/num_present'"
2018-04-20 00:09:44,704 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/Select_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,704 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/num_present_grad/Tile:0"
2018-04-20 00:09:44,710 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/num_present/broadcast_weights'"
2018-04-20 00:09:44,711 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/num_present_grad/Tile:0"
2018-04-20 00:09:44,711 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/num_present/broadcast_weights_grad/tuple/control_dependency:0, gradients/mean_squared_error/num_present/broadcast_weights_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,712 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/num_present/broadcast_weights/ones_like'"
2018-04-20 00:09:44,713 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/num_present/broadcast_weights_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,713 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/num_present/broadcast_weights/ones_like_grad/Sum:0"
2018-04-20 00:09:44,719 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/SquaredDifference'"
2018-04-20 00:09:44,720 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/Mul_grad/tuple/control_dependency:0"
2018-04-20 00:09:44,720 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/SquaredDifference_grad/tuple/control_dependency:0, gradients/mean_squared_error/SquaredDifference_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,727 (tf_logging.py:160) Level 1: "Gradient for 'Sum'"
2018-04-20 00:09:44,728 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/SquaredDifference_grad/tuple/control_dependency:0"
2018-04-20 00:09:44,728 (tf_logging.py:160) Level 1: "  out --> gradients/Sum_grad/Tile:0"
2018-04-20 00:09:44,734 (tf_logging.py:160) Level 1: "Gradient for 'mul'"
2018-04-20 00:09:44,734 (tf_logging.py:160) Level 1: "  in  --> gradients/Sum_grad/Tile:0"
2018-04-20 00:09:44,734 (tf_logging.py:160) Level 1: "  out --> gradients/mul_grad/tuple/control_dependency:0, gradients/mul_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,736 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected_1/BiasAdd'"
2018-04-20 00:09:44,736 (tf_logging.py:160) Level 1: "  in  --> gradients/mul_grad/tuple/control_dependency:0"
2018-04-20 00:09:44,737 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency:0, gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,739 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected_1/MatMul'"
2018-04-20 00:09:44,739 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 00:09:44,740 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency:0, gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,740 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected_1/biases/read'"
2018-04-20 00:09:44,740 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,741 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,741 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/Relu'"
2018-04-20 00:09:44,742 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency:0"
2018-04-20 00:09:44,742 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/Relu_grad/ReluGrad:0"
2018-04-20 00:09:44,742 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected_1/weights/read'"
2018-04-20 00:09:44,743 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,743 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,745 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/BiasAdd'"
2018-04-20 00:09:44,745 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/Relu_grad/ReluGrad:0"
2018-04-20 00:09:44,745 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency:0, gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,748 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/MatMul'"
2018-04-20 00:09:44,748 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 00:09:44,748 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/MatMul_grad/tuple/control_dependency:0, gradients/q/fully_connected/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,749 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/biases/read'"
2018-04-20 00:09:44,749 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,749 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,750 (tf_logging.py:160) Level 1: "Gradient for 'q/Flatten/flatten/Reshape'"
2018-04-20 00:09:44,750 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/MatMul_grad/tuple/control_dependency:0"
2018-04-20 00:09:44,750 (tf_logging.py:160) Level 1: "  out --> gradients/q/Flatten/flatten/Reshape_grad/Reshape:0"
2018-04-20 00:09:44,751 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/weights/read'"
2018-04-20 00:09:44,751 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,751 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,752 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/Relu'"
2018-04-20 00:09:44,752 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Flatten/flatten/Reshape_grad/Reshape:0"
2018-04-20 00:09:44,752 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/Relu_grad/ReluGrad:0"
2018-04-20 00:09:44,754 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/BiasAdd'"
2018-04-20 00:09:44,754 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/Relu_grad/ReluGrad:0"
2018-04-20 00:09:44,754 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency:0, gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,758 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/Conv2D'"
2018-04-20 00:09:44,758 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 00:09:44,758 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency:0, gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,758 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/biases/read'"
2018-04-20 00:09:44,758 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,759 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,759 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/Relu'"
2018-04-20 00:09:44,759 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency:0"
2018-04-20 00:09:44,759 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/Relu_grad/ReluGrad:0"
2018-04-20 00:09:44,760 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/weights/read'"
2018-04-20 00:09:44,760 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,760 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,761 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/BiasAdd'"
2018-04-20 00:09:44,761 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/Relu_grad/ReluGrad:0"
2018-04-20 00:09:44,762 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency:0, gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,765 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/Conv2D'"
2018-04-20 00:09:44,765 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 00:09:44,765 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency:0, gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,766 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/biases/read'"
2018-04-20 00:09:44,766 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,766 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,767 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/Relu'"
2018-04-20 00:09:44,767 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency:0"
2018-04-20 00:09:44,767 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/Relu_grad/ReluGrad:0"
2018-04-20 00:09:44,767 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/weights/read'"
2018-04-20 00:09:44,767 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,767 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,769 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/BiasAdd'"
2018-04-20 00:09:44,769 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv/Relu_grad/ReluGrad:0"
2018-04-20 00:09:44,769 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/BiasAdd_grad/tuple/control_dependency:0, gradients/q/Conv/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,773 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/Conv2D'"
2018-04-20 00:09:44,773 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 00:09:44,773 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/Conv2D_grad/tuple/control_dependency:0, gradients/q/Conv/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,774 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/biases/read'"
2018-04-20 00:09:44,774 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,774 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,774 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/weights/read'"
2018-04-20 00:09:44,774 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,775 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,858 (tf_logging.py:126) WARNING: "From /home/syedeqbal/.local/lib/python3.5/site-packages/tensorflow/python/ops/clip_ops.py:113: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead"
2018-04-20 00:09:44,889 (tf_logging.py:160) Level 1: "Created variable q/Conv/weights/Adam:0 with shape (1, 1, 2, 8) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16befed358>"
2018-04-20 00:09:44,891 (tf_logging.py:160) Level 1: "Created variable q/Conv/weights/Adam_1:0 with shape (1, 1, 2, 8) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16befed358>"
2018-04-20 00:09:44,894 (tf_logging.py:160) Level 1: "Created variable q/Conv/biases/Adam:0 with shape (8,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16befed358>"
2018-04-20 00:09:44,897 (tf_logging.py:160) Level 1: "Created variable q/Conv/biases/Adam_1:0 with shape (8,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16befed358>"
2018-04-20 00:09:44,899 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/weights/Adam:0 with shape (3, 3, 8, 12) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16befed358>"
2018-04-20 00:09:44,902 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/weights/Adam_1:0 with shape (3, 3, 8, 12) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16befed358>"
2018-04-20 00:09:44,905 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/biases/Adam:0 with shape (12,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16befed358>"
2018-04-20 00:09:44,907 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/biases/Adam_1:0 with shape (12,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16befed358>"
2018-04-20 00:09:44,910 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/weights/Adam:0 with shape (3, 3, 12, 16) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16befed358>"
2018-04-20 00:09:44,913 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/weights/Adam_1:0 with shape (3, 3, 12, 16) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16bf01cf28>"
2018-04-20 00:09:44,916 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/biases/Adam:0 with shape (16,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16bf01cf28>"
2018-04-20 00:09:44,918 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/biases/Adam_1:0 with shape (16,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16bf01cf28>"
2018-04-20 00:09:44,921 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/weights/Adam:0 with shape (576, 128) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16bf01cf28>"
2018-04-20 00:09:44,924 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/weights/Adam_1:0 with shape (576, 128) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16bf01cf28>"
2018-04-20 00:09:44,926 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/biases/Adam:0 with shape (128,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16bf01cf28>"
2018-04-20 00:09:44,929 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/biases/Adam_1:0 with shape (128,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16bf01cf28>"
2018-04-20 00:09:44,932 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/weights/Adam:0 with shape (128, 5) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16bf01cf28>"
2018-04-20 00:09:44,935 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/weights/Adam_1:0 with shape (128, 5) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16bf01cf28>"
2018-04-20 00:09:44,938 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/biases/Adam:0 with shape (5,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16bf01cf28>"
2018-04-20 00:09:44,941 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/biases/Adam_1:0 with shape (5,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16bf01cf28>"
2018-04-20 00:09:45,102 (dqn_agent.py:161) DEBUG: "var_name: q/Conv/weights:0, var_value [[[[-0.45437422  0.09241241 -0.4031417   0.20321494 -0.16378003
    -0.14166075 -0.6734322   0.43192756]
   [ 0.54498637  0.03903526  0.5607197  -0.48249277  0.35027182
    -0.5211806  -0.7130368   0.5883169 ]]]]: "
2018-04-20 00:09:45,109 (dqn_agent.py:161) DEBUG: "var_name: q/Conv/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 00:09:45,129 (dqn_agent.py:161) DEBUG: "var_name: q/Conv_1/weights:0, var_value [[[[-0.01466241  0.05850556 -0.02121381  0.12007976  0.17141369
    -0.02536257  0.10543251  0.04181224  0.09713131  0.1067071
     0.08750033  0.13686469]
   [-0.13607019  0.14534569 -0.07360096 -0.08263129  0.10095194
     0.17122132 -0.17606041  0.08580339 -0.1452238   0.00371042
    -0.1557769  -0.09631909]
   [ 0.08883604  0.18050572 -0.04877298 -0.03218353 -0.05961033
    -0.06289382  0.11775747 -0.00884241 -0.00773033 -0.05212864
    -0.16727336  0.12815186]
   [ 0.11595932  0.16943693  0.13994163  0.1036067   0.04620007
    -0.1540871   0.0192927   0.12014189 -0.09592968 -0.15637033
    -0.05390354  0.17530632]
   [-0.07557636  0.08791155  0.1331468   0.01842286  0.06721978
     0.17661545 -0.00288388  0.03301768 -0.12310915  0.05204898
    -0.06071501 -0.14016119]
   [-0.11692846 -0.16908447  0.11855218 -0.02288641 -0.17366879
     0.1013779   0.1591393   0.01173401 -0.13761348 -0.03117806
    -0.1557847  -0.00268583]
   [-0.17106453  0.16602117  0.025399   -0.03741346  0.14993021
    -0.17943686 -0.021634   -0.08604149  0.00401068  0.16467047
    -0.0994057  -0.13315158]
   [-0.14518179  0.10588831 -0.14631498  0.12457117 -0.01658358
    -0.10606639 -0.15731038  0.01483493 -0.00218403 -0.1075109
    -0.17891935 -0.07590918]]

  [[-0.01333256  0.1740242   0.07614797 -0.05813996 -0.17304093
     0.12749454  0.17430508 -0.15049408 -0.12419246  0.04585683
    -0.08201022  0.16711304]
   [ 0.03648023  0.02337807 -0.12276632  0.08584508 -0.0518266
    -0.00043355 -0.1442396  -0.11551877  0.1594108   0.12146437
    -0.07694382  0.1417476 ]
   [ 0.15309837  0.14997703 -0.0314606  -0.16766238  0.03715721
     0.09037656 -0.16108304 -0.16444837  0.01136026  0.11861974
    -0.05405244  0.11663139]
   [ 0.13407314 -0.15358482  0.04635908  0.07625258  0.1136378
    -0.12670888 -0.01294258 -0.17408831  0.06679799  0.13880342
     0.15530473 -0.0765616 ]
   [-0.1327855   0.12211311 -0.15656626 -0.06900856 -0.11279089
     0.03097981 -0.10999297 -0.02160509 -0.01772265  0.12285644
    -0.10395113 -0.10794454]
   [-0.01922117  0.11961403  0.05933566  0.06834012  0.07574412
    -0.17862383 -0.01404008  0.14127192 -0.09762575  0.17321154
     0.09610689 -0.01100537]
   [-0.05330914  0.13111311 -0.04512776 -0.11598005 -0.01563795
    -0.14568633 -0.17443912 -0.07030447  0.14984336  0.05552343
     0.03977296 -0.05611438]
   [-0.13787618 -0.16749157 -0.09924342  0.12353513  0.09741321
    -0.08098002 -0.00868562  0.07680324  0.00490603  0.00120288
    -0.03632802  0.02839328]]

  [[ 0.04877546 -0.03812329  0.06513944  0.12940246 -0.10367812
    -0.13032344  0.01147853  0.16639602  0.15375596 -0.058024
     0.18119892 -0.15170655]
   [ 0.13204837  0.10922822 -0.1737666   0.13117331  0.00372839
    -0.06782135  0.16924846 -0.14124072  0.00763774 -0.15902525
    -0.07066088 -0.02490115]
   [-0.12640604  0.03605348  0.13907462  0.12396351 -0.05497976
     0.09312224 -0.15864168  0.07145956 -0.0708081   0.14016694
     0.01189519 -0.13005361]
   [-0.15416576 -0.06358641  0.03356549 -0.02790079 -0.06227248
     0.18057421  0.14865828 -0.13827774  0.1314114   0.15134072
     0.13974035 -0.05316563]
   [-0.1423928  -0.03416494 -0.12294888 -0.00292815 -0.08575132
    -0.05901742 -0.08555344  0.16854623  0.13293344  0.17930493
     0.04580817 -0.03104937]
   [ 0.10880136  0.00361566 -0.10198963 -0.09792419 -0.1515167
     0.13225156  0.02701871  0.12189987  0.15916237 -0.08133247
     0.04811221  0.01869866]
   [-0.07182685  0.03867745  0.18253401  0.01392335  0.1608679
     0.07485074 -0.10170095 -0.0306329   0.13777822 -0.1663074
    -0.11913121 -0.11220273]
   [ 0.03737789  0.17200816  0.03748028  0.1132786   0.04067257
     0.11394405  0.08071089  0.1346007  -0.11249515  0.02093334
     0.01518773  0.15978548]]]


 [[[-0.09711798  0.12095186 -0.18033461  0.07197481 -0.12435444
    -0.16174373 -0.17205203 -0.03097586 -0.17449313 -0.14949012
     0.16603026  0.13275442]
   [-0.10304103 -0.13372284  0.16245231 -0.03266169  0.10227737
     0.14526805 -0.07895361 -0.12290309  0.06942195 -0.00308286
    -0.00142889  0.01682882]
   [-0.16460398  0.18009877  0.04248498 -0.09288578 -0.08978438
     0.17851126 -0.02766979 -0.12828812 -0.08642367  0.03198847
     0.14432576 -0.10928519]
   [-0.04919243  0.04991871  0.07239917  0.18044013  0.13450849
     0.17717206 -0.02298875 -0.08162159  0.07165939 -0.05454685
    -0.04493006 -0.1249651 ]
   [ 0.0137057   0.11937758  0.07023516  0.00343958 -0.09185728
    -0.05500509 -0.1392392  -0.02637157 -0.10415751  0.11168638
    -0.0851353   0.01113935]
   [-0.04140042 -0.07588407 -0.16345003  0.08287257  0.05111828
     0.09552804 -0.01822284  0.18026441 -0.02794705  0.11909673
     0.04235153 -0.0785642 ]
   [ 0.07920724 -0.00274529  0.06485868 -0.03334846  0.06625217
     0.13307175 -0.17441075  0.05304432 -0.09459343 -0.11465428
    -0.13867776  0.02053772]
   [ 0.08871722  0.13296005 -0.16012724 -0.02379934 -0.1343044
     0.04384091 -0.086555    0.09754524 -0.16061054 -0.0963366
     0.10912845  0.12435153]]

  [[-0.04925089  0.00873929  0.14807117  0.1325534  -0.12621722
    -0.03693655  0.06350462 -0.11509524 -0.06725591 -0.0896571
     0.11077985  0.02153628]
   [-0.12957017 -0.079065   -0.05105133 -0.1692932   0.08707368
     0.04464199 -0.09839739  0.05348392 -0.14870363  0.09071094
    -0.08592553  0.01773654]
   [-0.18215217 -0.10857836 -0.17412184 -0.11928429 -0.11099514
    -0.07311845  0.15416324  0.05049147  0.06907451  0.16530386
     0.15430179 -0.00327104]
   [ 0.11380634  0.04600358  0.04465801 -0.0428791  -0.1160073
    -0.15509698  0.09838989  0.08397385  0.07401916  0.15863878
     0.17510185 -0.019881  ]
   [ 0.10233834  0.03508291 -0.12254889 -0.09592233  0.17196506
    -0.13716243 -0.06233124  0.09376338 -0.1497557  -0.0764348
     0.03716417 -0.17782633]
   [ 0.1710994   0.10975549  0.13816503 -0.00569904  0.1750032
     0.14428678 -0.05615011 -0.0253364   0.05387467 -0.07739335
    -0.13125327  0.1331723 ]
   [-0.04720381 -0.03753473  0.03489865  0.02259028 -0.14662257
     0.09675616  0.08911821  0.17121378  0.04895672 -0.02772637
    -0.0867928  -0.01295024]
   [ 0.00947301 -0.01002309 -0.00651051 -0.07714523 -0.08588622
     0.06352738  0.15263718 -0.0196307  -0.15290502  0.14769417
     0.09335217 -0.07713292]]

  [[ 0.07333118 -0.03735948  0.01542309  0.03733228  0.05957991
     0.02390721  0.02595608  0.0621644  -0.07231329  0.12799668
    -0.03680509  0.17074442]
   [-0.10140085  0.06354627 -0.13662246  0.08991715 -0.07954012
    -0.02399558 -0.01637429 -0.07357197  0.00909196  0.14505047
    -0.14007545 -0.07018145]
   [-0.08556115  0.07365611  0.16732678 -0.05895931  0.07251701
     0.11456421 -0.13488247 -0.08253618 -0.15309507 -0.00558078
     0.11341459 -0.07041386]
   [ 0.11344743 -0.10803007 -0.07666746 -0.14819688  0.1439592
    -0.04249112  0.05444121 -0.09240205  0.04306436 -0.03621688
    -0.01520254 -0.04023832]
   [-0.0823188  -0.15016177  0.08762142 -0.00075614  0.06591508
     0.12297022 -0.11480093 -0.09847195  0.11489156 -0.04070631
    -0.08099412 -0.04146218]
   [-0.15724744 -0.14397404 -0.11141437  0.17407519  0.09058154
     0.06041719 -0.07250638  0.0198715   0.14399496 -0.03132552
     0.08252391 -0.18137144]
   [ 0.07579848  0.09563783 -0.03113016 -0.01049717 -0.03869787
    -0.1402896   0.05172879  0.16654548 -0.02835602 -0.02578184
     0.17120874 -0.06828938]
   [-0.06846897  0.07873088 -0.08821677  0.14310127  0.16859818
     0.05140898 -0.0893107   0.12624368 -0.02682288  0.04080437
     0.0106688   0.08510935]]]


 [[[-0.10897526  0.13367662  0.15619364 -0.06999423 -0.02717434
    -0.11035156 -0.10835454  0.15969238 -0.08526637  0.14704192
    -0.09030451  0.17456818]
   [ 0.16563424  0.06151494 -0.16206598  0.08341992  0.04689771
     0.054217   -0.13138294  0.17479184 -0.03726193 -0.04269153
     0.11002967 -0.06969532]
   [-0.08868501  0.07564074  0.14892909  0.12079281 -0.09101778
     0.07109585 -0.05553997 -0.11530644  0.03784631 -0.01577654
    -0.07192009 -0.15675117]
   [-0.0735314  -0.1652137   0.02120845  0.0183654   0.17537561
     0.15261787  0.0069741   0.14271334  0.0050263   0.0354698
     0.09023002  0.06579477]
   [-0.06095969  0.05041076  0.01524849  0.00169246 -0.1525096
     0.12067726  0.11791995  0.03120604  0.09408206 -0.02889447
    -0.12880825  0.15582225]
   [-0.127826   -0.1494274  -0.03031504  0.00710647  0.01140636
    -0.05398986  0.01549983 -0.04401264  0.15839073  0.0254239
     0.04430681  0.10316274]
   [-0.04401442 -0.08693401 -0.04611614 -0.15874441 -0.02085574
     0.12584922 -0.07778938  0.07651812  0.01063828  0.14573783
    -0.017022   -0.0256664 ]
   [-0.04349761  0.10638207  0.1078729   0.1765739  -0.06204543
     0.14214712  0.11837754 -0.01438841 -0.07388486  0.08071905
    -0.14853379  0.06661451]]

  [[ 0.07779527 -0.11770336  0.10445264  0.10759658 -0.03735299
     0.01196928  0.14848569  0.13723698 -0.00261371 -0.01220721
    -0.02871208  0.12323365]
   [-0.06835105  0.16196147  0.14300656  0.02209666 -0.0643042
    -0.09489992  0.15379405 -0.13700852  0.13039896  0.10075757
    -0.14659409  0.09277135]
   [-0.05200654  0.00612023 -0.06426646 -0.075417    0.03244644
     0.0147413   0.04503044 -0.09471135  0.13704303 -0.11523192
    -0.07149107 -0.05435149]
   [ 0.08963063  0.02480608 -0.05215319  0.02542682 -0.15885001
    -0.17714758  0.01799679 -0.02272409  0.0497079  -0.1736505
    -0.02113354  0.04501721]
   [-0.07498924  0.01818036  0.04811095  0.13194507  0.03520149
    -0.14354797  0.1643706  -0.14866398 -0.13641517  0.14522159
     0.06691878  0.06758699]
   [-0.01079722 -0.07063206  0.00471407  0.16985306 -0.14888489
     0.11848301  0.16788247 -0.12660371 -0.01320224  0.14040408
     0.16058648  0.06816941]
   [-0.10741661 -0.02724394 -0.0822233   0.08925724  0.09258765
     0.06231165  0.0498044  -0.13713339 -0.13286063  0.17867482
    -0.05096972 -0.00895812]
   [ 0.02829708 -0.08036517  0.04478677 -0.16197905 -0.0109954
    -0.07474104 -0.14697593  0.02370255  0.0876936   0.01851954
     0.09659082 -0.0992752 ]]

  [[ 0.07054719  0.03664042  0.17328823  0.1551832  -0.02233982
    -0.1800142   0.02474132 -0.06799451  0.06863508  0.09027073
    -0.00181633 -0.07467387]
   [-0.01741277 -0.004581   -0.12157645 -0.01688723  0.11161086
    -0.02841021 -0.09768213 -0.04028572  0.01998416  0.00660427
    -0.17724048 -0.14708376]
   [ 0.04511471 -0.15401018 -0.01555946 -0.03063032 -0.11404274
     0.1064834  -0.08018744  0.02472408 -0.07646235 -0.10636378
    -0.148667    0.07533795]
   [ 0.04659531 -0.02630559  0.14988288 -0.02543582 -0.0281446
    -0.05474138 -0.04716301  0.15032604  0.15306407 -0.02251659
    -0.12148735 -0.12412669]
   [ 0.13318762  0.18038425  0.02371864  0.12804452  0.18000343
    -0.02104762  0.04726039 -0.15654784 -0.09428968  0.14436075
    -0.01856154 -0.08612794]
   [-0.0541607  -0.09237941  0.06004162 -0.13420218 -0.11275276
    -0.09002075  0.14222795  0.06486289  0.06487805  0.03626904
     0.11652446 -0.10532191]
   [-0.06088612 -0.02427961 -0.07980164 -0.0209693   0.05309759
    -0.09637764  0.02788343 -0.1616983   0.07265839 -0.0316944
    -0.06968196 -0.06994962]
   [-0.13647963  0.09382018  0.05407822  0.13661614  0.16818133
    -0.1110708   0.02397725 -0.12108409  0.07832575  0.03426287
    -0.11895713  0.04951768]]]]: "
2018-04-20 00:09:45,177 (dqn_agent.py:161) DEBUG: "var_name: q/Conv_1/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 00:09:45,195 (dqn_agent.py:161) DEBUG: "var_name: q/Conv_2/weights:0, var_value [[[[-0.0797774   0.01873627  0.1385109  ...  0.01415014  0.05313519
    -0.11567675]
   [ 0.0371282  -0.01852378 -0.01220277 ...  0.07838745 -0.15200189
    -0.02942897]
   [-0.11219987  0.02653207  0.13914661 ... -0.02268051  0.01884557
    -0.10662605]
   ...
   [-0.01931754  0.10785471 -0.0738834  ...  0.05605897 -0.02745824
    -0.14945176]
   [-0.00934859  0.06111154 -0.06048029 ... -0.01047826  0.08065607
    -0.01911066]
   [ 0.0869908  -0.03158921  0.07200363 ... -0.00325014  0.10848556
    -0.11243635]]

  [[ 0.10402112 -0.08505578  0.03061622 ... -0.14676416 -0.09480286
     0.11201669]
   [ 0.01366302  0.0022932  -0.01384506 ... -0.02880698 -0.08913184
    -0.11579804]
   [-0.09752969 -0.06275689  0.12859626 ...  0.08642426  0.10306172
    -0.09605898]
   ...
   [-0.03521162  0.0527986   0.02938788 ...  0.03956902 -0.11750452
    -0.11807732]
   [-0.10061806 -0.05139725 -0.05516935 ...  0.05418053 -0.08568631
    -0.0906323 ]
   [ 0.03504129  0.02396856 -0.08887803 ... -0.03232042 -0.00468104
     0.07404447]]

  [[ 0.1541829  -0.1045125  -0.11529106 ... -0.10019596 -0.14190017
    -0.07995395]
   [ 0.02162334  0.00685629  0.0875206  ... -0.01866394  0.06448419
     0.10108863]
   [ 0.11919345  0.14987867 -0.06624336 ... -0.08187944 -0.11034374
     0.0748125 ]
   ...
   [-0.13684542 -0.05107023 -0.0037633  ...  0.06076154 -0.14174308
     0.0386741 ]
   [ 0.14700033  0.08633758 -0.15287624 ... -0.13077605 -0.00711119
     0.05512314]
   [ 0.12159131  0.05729982  0.08275715 ...  0.0526921   0.14226906
    -0.06211813]]]


 [[[-0.01202865 -0.00967431  0.02385871 ...  0.02471659  0.04241538
    -0.01958933]
   [ 0.12125929  0.01211418  0.13327138 ... -0.12111421  0.10108043
    -0.10277212]
   [ 0.0984657  -0.0080872   0.11509134 ...  0.08291644 -0.01644051
     0.11152099]
   ...
   [ 0.03221072  0.13378079 -0.06361223 ...  0.12784235 -0.10977568
    -0.05360178]
   [-0.10839099 -0.13388881 -0.02110647 ... -0.09940819 -0.04715988
    -0.00712647]
   [ 0.06567498 -0.03493702 -0.01443522 ...  0.15022798  0.00903827
     0.10069202]]

  [[ 0.07153139 -0.13819873 -0.04929683 ...  0.11265786  0.08069491
    -0.12779906]
   [ 0.12745853  0.00370216 -0.02454191 ...  0.09623154  0.0001775
     0.04350774]
   [ 0.07256651  0.05599676  0.14617844 ... -0.01220372  0.14148615
    -0.07017564]
   ...
   [-0.13294595  0.05087757 -0.00388417 ... -0.08877664 -0.11591922
    -0.07819052]
   [ 0.11482559 -0.04780306  0.14269985 ... -0.02060565 -0.05782322
    -0.10979146]
   [-0.08152399 -0.12382263 -0.06542066 ...  0.12074052 -0.12256813
    -0.14660501]]

  [[ 0.05660661  0.04520389  0.05418664 ...  0.13390882  0.09029326
     0.12069909]
   [ 0.07769762  0.02919297  0.10366435 ... -0.02221252  0.14408077
     0.07060909]
   [ 0.0815248  -0.13238297  0.11402886 ... -0.13921385 -0.09824571
    -0.11210467]
   ...
   [-0.038612   -0.07993986  0.09361216 ... -0.13619772  0.12755702
     0.13634567]
   [ 0.02829695  0.0308069  -0.13810375 ... -0.01558612 -0.09937266
     0.03809218]
   [-0.07015412 -0.05846588 -0.120064   ...  0.13161443 -0.05718276
    -0.10728085]]]


 [[[ 0.030435   -0.06333458  0.02243446 ...  0.13593231 -0.13051705
    -0.02433604]
   [-0.02924481  0.01935621  0.12169908 ... -0.0406849  -0.12146281
     0.14411007]
   [ 0.07565585 -0.05887306 -0.12136301 ... -0.07856981 -0.02397165
     0.02643587]
   ...
   [ 0.1533375   0.04228702 -0.09097724 ...  0.10271607  0.13476925
    -0.02679199]
   [ 0.03572099  0.04462653 -0.02515885 ...  0.02842607 -0.1516429
     0.0448923 ]
   [ 0.00234838 -0.03872756  0.11498405 ... -0.03516199 -0.04284337
     0.07417628]]

  [[-0.06454548  0.0776455   0.03432643 ...  0.08143765 -0.04530789
     0.01492421]
   [-0.12865528  0.02481234 -0.11718009 ... -0.04410365  0.00359632
     0.04930131]
   [ 0.12103857  0.03000383 -0.08107848 ... -0.03966247  0.145406
     0.05948658]
   ...
   [-0.12647136  0.02175365 -0.02808857 ...  0.13086133  0.02426165
    -0.02675097]
   [-0.13547882  0.09986694 -0.0996836  ... -0.03389531 -0.07216095
     0.13954224]
   [-0.04688683  0.04190913  0.12469019 ... -0.11713892  0.05286431
    -0.03286828]]

  [[ 0.13387235  0.00517166 -0.06660926 ...  0.14508961 -0.11595403
    -0.08661048]
   [-0.08677559  0.11258914  0.06776421 ... -0.05621794 -0.01255502
     0.12493841]
   [-0.10320002 -0.13903755  0.03457987 ...  0.02658622 -0.03870077
     0.00746298]
   ...
   [-0.12197867 -0.10988932 -0.07672408 ...  0.01115187  0.02591468
    -0.13302387]
   [-0.15196793 -0.02575892  0.10223298 ...  0.09138496  0.04587485
    -0.08367073]
   [ 0.04596645 -0.00647435  0.02616249 ...  0.02018991  0.00734271
     0.15340148]]]]: "
2018-04-20 00:09:45,208 (dqn_agent.py:161) DEBUG: "var_name: q/Conv_2/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 00:09:45,221 (dqn_agent.py:161) DEBUG: "var_name: q/fully_connected/weights:0, var_value [[-0.06105846  0.02842958 -0.06607082 ...  0.08143545  0.02440361
  -0.00027925]
 [-0.01322457  0.04913994 -0.07371138 ... -0.00715099  0.05188406
  -0.08400482]
 [ 0.0208477   0.06453959  0.03748194 ... -0.08069795  0.08146083
  -0.0542092 ]
 ...
 [-0.05078364 -0.06910589 -0.07922482 ...  0.00789656  0.04588784
   0.06274114]
 [-0.08737447  0.08850712 -0.0916521  ... -0.04621189  0.02897456
  -0.02463267]
 [-0.08712668  0.0145384   0.02659321 ... -0.08777002 -0.0797758
  -0.09084145]]: "
2018-04-20 00:09:45,238 (dqn_agent.py:161) DEBUG: "var_name: q/fully_connected/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 00:09:45,260 (dqn_agent.py:161) DEBUG: "var_name: q/fully_connected_1/weights:0, var_value [[-1.33332372e-01 -1.21349141e-01 -5.98904490e-03  9.78068113e-02
  -1.72639668e-01]
 [ 2.19879001e-02  1.17726624e-01  5.87365031e-02 -1.50980830e-01
   1.43375307e-01]
 [-3.88857126e-02 -1.21027328e-01  5.75172305e-02 -1.40003175e-01
   1.91109031e-01]
 [-1.64104626e-01 -1.37330830e-01  7.63312280e-02 -4.93871868e-02
   1.40498400e-01]
 [-6.21345341e-02 -2.12296918e-01  1.88643992e-01 -1.62010074e-01
   2.89283544e-02]
 [ 7.92510211e-02  6.57981932e-02  8.34364593e-02  1.93149596e-01
  -5.63380271e-02]
 [ 8.33594501e-02  1.30414516e-02 -1.72245502e-03 -2.02637374e-01
  -3.33143026e-02]
 [-1.03909835e-01 -1.39290273e-01  9.87536311e-02  7.15075135e-02
   1.76905304e-01]
 [ 1.52604789e-01 -1.41019076e-02  1.11094624e-01 -6.31067157e-02
   1.23259515e-01]
 [ 2.49368399e-02 -4.09058183e-02  9.59849358e-02 -1.94948867e-01
   1.39712423e-01]
 [ 2.74312943e-02  2.62325555e-02  1.07461601e-01 -2.02591240e-01
   2.20338255e-02]
 [ 1.25593185e-01  5.53655922e-02  1.29744053e-01  3.81451845e-03
   1.52154148e-01]
 [-4.18858975e-02  1.42774522e-01  1.27843171e-02  1.15700305e-01
   8.67719054e-02]
 [-3.30982208e-02 -2.43003517e-02  1.51905507e-01  7.35116303e-02
   2.28226185e-04]
 [ 2.11443812e-01  1.20608777e-01 -1.78808883e-01 -2.39927620e-02
   1.83877409e-01]
 [ 3.56259942e-03 -1.89073563e-01  1.82523966e-01 -1.20623223e-01
  -1.48555189e-02]
 [ 1.20509446e-01  1.11306667e-01 -5.10512292e-03 -3.31417173e-02
  -9.28477272e-02]
 [-1.40883401e-01  2.00892031e-01 -1.62269041e-01  1.05588526e-01
  -3.88249755e-04]
 [ 1.83306038e-02 -1.13561690e-01  4.76567447e-02  2.08044112e-01
   2.57307142e-02]
 [-4.58348244e-02 -1.89173222e-01 -1.69141382e-01  1.63844138e-01
  -1.06254801e-01]
 [ 1.69571042e-02  1.90918118e-01 -4.01447564e-02  1.58081055e-01
   3.56156081e-02]
 [-1.26972407e-01 -1.17496997e-02  1.40221298e-01 -1.63462922e-01
  -1.27168477e-01]
 [-1.33166790e-01 -7.77329803e-02 -4.70646024e-02 -5.45788556e-02
   7.29191005e-02]
 [ 1.58559740e-01 -2.13138312e-02  7.36537576e-03  1.61597759e-01
   1.71119511e-01]
 [-6.78443909e-03 -1.45141169e-01 -1.38303190e-02 -5.31578064e-03
   3.53223532e-02]
 [ 4.64116037e-02  1.79639637e-01  1.42013669e-01  3.87872756e-02
  -7.78463632e-02]
 [-1.25575006e-01 -1.79828703e-01 -2.10043862e-01 -2.00302690e-01
  -1.76701576e-01]
 [-1.25143468e-01  9.25613642e-02  8.50352645e-02  1.86021179e-01
   8.28426182e-02]
 [ 2.03106403e-01 -1.26479864e-02 -1.94376245e-01  3.41293365e-02
   4.27161753e-02]
 [-1.91581905e-01 -6.36603087e-02 -1.67869419e-01  1.46228194e-01
   1.24100477e-01]
 [ 3.45172435e-02  7.85651505e-02  8.66160691e-02  7.83444047e-02
  -3.56978476e-02]
 [-1.83149099e-01  4.07444835e-02  1.18230343e-01 -1.06956519e-01
   6.45250678e-02]
 [ 1.66767716e-01 -1.19897857e-01 -4.49884832e-02 -1.47899061e-01
   1.28830642e-01]
 [-1.30647019e-01  1.52333468e-01  6.11083806e-02  5.36487997e-02
  -9.23249274e-02]
 [-8.76322091e-02  1.70817107e-01 -7.91828930e-02  8.18712413e-02
   1.22866154e-01]
 [-1.55784488e-01  9.03639495e-02  1.61848694e-01 -1.07190721e-01
  -1.45900160e-01]
 [-6.51546270e-02 -5.38187623e-02 -2.56687403e-03 -1.45303980e-01
   1.80245012e-01]
 [-2.10296005e-01  1.65432751e-01 -1.96618468e-01 -4.83155251e-04
  -1.97427124e-01]
 [ 1.44576877e-02  2.10917145e-01  5.70272207e-02  1.49710089e-01
  -1.44896537e-01]
 [ 1.72353417e-01 -1.22898862e-01 -1.07862204e-01  7.61069357e-02
  -1.64051145e-01]
 [ 2.54404992e-02 -3.45092416e-02  1.22068584e-01 -4.28612232e-02
   5.47040403e-02]
 [-7.95610696e-02  5.46818972e-02  4.17655706e-02 -1.28726810e-02
  -1.42941996e-01]
 [ 1.31037205e-01 -8.53326917e-03  1.52641445e-01 -2.08379090e-01
  -6.94002509e-02]
 [-4.83085662e-02  1.05872273e-01  1.96069390e-01 -7.71625340e-03
   3.70381325e-02]
 [-8.26944411e-02  1.81950063e-01  1.04183048e-01  1.86633199e-01
   1.09252572e-01]
 [-8.32722485e-02  2.21315175e-02  1.10602826e-02  1.12895221e-01
  -8.20102096e-02]
 [ 1.59277260e-01  1.74249232e-01  1.44925863e-01  2.00162113e-01
   9.39865112e-02]
 [-1.73819810e-02 -1.66694582e-01 -1.82291821e-01 -5.25571257e-02
  -1.95269167e-01]
 [ 2.10287333e-01 -5.10967821e-02 -1.80516496e-01 -1.15478694e-01
   1.39438659e-01]
 [-3.89538705e-02 -2.62869895e-02 -1.35155961e-01 -8.16502124e-02
  -1.04703464e-01]
 [ 6.32601082e-02  1.79905772e-01  2.08012551e-01 -1.13431491e-01
   1.73217356e-01]
 [-5.87642193e-02  1.56381488e-01 -1.13846228e-01 -1.28444701e-01
  -4.73091453e-02]
 [ 3.96845639e-02  8.60593915e-02 -1.79569587e-01 -1.95884392e-01
  -5.57826608e-02]
 [ 1.54591978e-01 -1.92236260e-01 -3.72524559e-03 -1.16627149e-01
   1.81555867e-01]
 [-2.44139880e-02  3.47475410e-02  2.02982575e-01 -7.77329355e-02
   1.61969751e-01]
 [-2.71016806e-02  1.52809560e-01 -1.67976022e-02 -8.15618485e-02
   1.84121370e-01]
 [ 6.86028600e-03 -1.21316321e-01  4.07213569e-02  1.51968658e-01
   1.35954291e-01]
 [-1.17039412e-01 -8.46014768e-02  4.84654903e-02  1.69804543e-02
   4.88846898e-02]
 [ 4.18361723e-02 -1.78853959e-01 -1.45407289e-01 -1.25650868e-01
   1.17502093e-01]
 [-2.06809878e-01 -8.18790495e-02  5.74409068e-02 -1.80485308e-01
   1.30008459e-02]
 [ 1.05592281e-01  2.04155952e-01  9.08307433e-02  3.57435793e-02
  -1.28867894e-01]
 [ 1.47449464e-01 -1.95517704e-01  2.64264494e-02 -1.46879628e-01
  -9.44144651e-02]
 [-7.73212314e-02  1.50754929e-01  1.16665930e-01  8.31313133e-02
  -1.51184201e-01]
 [ 7.02056289e-02 -3.86433452e-02 -2.00528488e-01 -1.67933837e-01
  -6.42767549e-03]
 [-9.73364711e-02  1.68140709e-01  1.46741629e-01 -4.84089404e-02
   1.64870650e-01]
 [-1.96861371e-01 -3.66970152e-02 -2.90136337e-02 -1.72180921e-01
  -1.18585385e-01]
 [ 1.56324774e-01 -1.72880769e-01 -1.79759443e-01  2.02931434e-01
   2.05285013e-01]
 [-1.14409700e-01 -6.00090325e-02 -6.00715727e-02 -1.48965329e-01
  -6.92888945e-02]
 [-7.44006932e-02  8.93048346e-02  1.00024372e-01  1.93319649e-01
   2.11270094e-01]
 [-2.13102847e-02 -1.57896727e-01 -1.83345631e-01 -7.51146674e-03
  -1.38531625e-02]
 [ 2.19836384e-02  1.52192324e-01 -5.66162914e-02  2.17455924e-02
  -6.32507354e-02]
 [-1.75569370e-01  1.75910234e-01 -1.22227125e-01 -1.01274356e-01
   5.80603778e-02]
 [ 4.43098247e-02  5.88109195e-02  2.02916294e-01 -1.05794795e-01
  -6.80513084e-02]
 [-1.26083687e-01  1.56830668e-01 -5.63588440e-02  4.55490649e-02
   1.47138834e-02]
 [ 8.71114433e-02  3.84750366e-02 -1.47621244e-01 -1.96559876e-01
  -1.48402765e-01]
 [ 1.37743682e-01 -8.18346441e-02 -1.76512688e-01 -1.57841012e-01
  -1.42260045e-01]
 [-1.95939839e-03  5.35142124e-02 -1.31175667e-02  1.77288383e-01
   1.00596696e-01]
 [ 2.02702492e-01 -1.70870826e-01 -1.89399689e-01 -1.96021214e-01
  -1.11866273e-01]
 [ 5.80630004e-02  6.27471805e-02  1.08344853e-01 -1.05071068e-02
  -1.03693604e-02]
 [ 5.66751361e-02 -8.86138529e-02 -1.07130565e-01  9.31333303e-02
   6.72780573e-02]
 [ 2.83122063e-06  1.89666450e-02 -8.52186829e-02 -1.19457550e-01
  -1.03126593e-01]
 [-1.10526860e-01 -1.05703190e-01  1.77719027e-01 -1.15153342e-02
  -1.06111541e-01]
 [ 1.04258657e-01  6.74642920e-02 -1.85029387e-01 -8.57597589e-02
   3.71636599e-02]
 [-7.52004534e-02  1.67274922e-01  4.62332666e-02 -1.41756773e-01
   1.65151030e-01]
 [ 2.56775022e-02 -1.75179645e-01 -1.96602911e-01  4.48317528e-02
   1.57505721e-01]
 [-7.31959343e-02 -2.08361015e-01 -1.62833571e-01 -2.67283171e-02
  -1.27656490e-01]
 [ 6.40900731e-02 -1.70506120e-01  6.44489527e-02  1.06842071e-01
   1.33804083e-01]
 [ 3.87928784e-02 -7.65558630e-02  1.96308583e-01 -2.05414906e-01
   1.08516216e-01]
 [-8.95004570e-02  9.48854685e-02 -1.34641975e-01 -3.70140672e-02
   1.27068937e-01]
 [ 7.14562237e-02 -1.33513927e-01  7.49334693e-02  1.65760338e-01
  -7.71780759e-02]
 [ 4.13779914e-02  2.11308092e-01 -1.88402444e-01  1.29697889e-01
  -1.62390530e-01]
 [-8.18880647e-02 -9.55564901e-02  7.28605986e-02 -1.60114616e-02
   1.19657516e-01]
 [ 1.29042089e-01  1.25617534e-01 -1.48041159e-01 -1.77534938e-01
  -1.14387773e-01]
 [-7.82036334e-02  1.44397676e-01 -7.22879171e-02  2.08964586e-01
   8.45837593e-03]
 [-1.74476475e-01 -3.87125164e-02  1.30463243e-01 -1.62515491e-02
  -5.79580814e-02]
 [-9.36988816e-02 -3.44815403e-02  4.77618575e-02 -6.10817373e-02
  -1.52989239e-01]
 [-1.39445081e-01  1.81519777e-01  3.26515287e-02  7.57436454e-03
   1.85713232e-01]
 [ 1.19170129e-01 -7.29819387e-02 -1.92039177e-01 -9.55184102e-02
  -1.90760478e-01]
 [ 3.02956700e-02 -1.46895796e-02 -9.13210437e-02  8.34646225e-02
  -4.54191267e-02]
 [-8.38156044e-02 -5.32496274e-02  1.15667015e-01 -5.57486862e-02
  -5.41878194e-02]
 [ 1.50856614e-01 -1.75100341e-01 -1.18969433e-01 -9.78152677e-02
  -6.72666430e-02]
 [ 1.42697603e-01 -3.07936668e-02 -4.56988513e-02  1.10326022e-01
   1.67318612e-01]
 [-2.04904377e-02 -8.31899047e-02  4.74621356e-02  1.21553570e-01
   1.75197929e-01]
 [-2.57045329e-02  1.64978117e-01 -1.25101775e-01 -1.60598904e-01
  -1.42539710e-01]
 [ 1.89972311e-01  7.19270706e-02  2.01232076e-01 -5.36444038e-02
  -2.05520287e-01]
 [-7.36287981e-02 -1.83466449e-01  1.89967155e-02 -8.38266015e-02
   1.08603150e-01]
 [-1.69596985e-01  1.80198848e-02 -1.18377253e-01 -3.07594240e-03
   6.10244572e-02]
 [ 1.34180099e-01  7.04799294e-02 -9.25011039e-02  1.23018324e-01
  -7.09713995e-03]
 [ 1.52822375e-01 -7.20094144e-03  1.81729376e-01 -1.33396089e-01
   4.68405783e-02]
 [-9.41604078e-02  6.97126985e-02  8.21819305e-02  8.86453986e-02
  -1.93376839e-03]
 [ 1.47830695e-01 -2.05642134e-02  4.93700802e-03 -1.73537299e-01
  -6.39557391e-02]
 [-6.12229109e-04 -1.02399617e-01 -1.80691212e-01  9.89547074e-02
   4.43066657e-02]
 [-6.52963221e-02  3.80224586e-02  7.80207813e-02 -1.41674191e-01
   9.97964740e-02]
 [ 1.21713787e-01  7.33523071e-02  1.05053544e-01  2.16308832e-02
   1.32878900e-01]
 [-5.92103601e-03  2.03366190e-01  7.00026453e-02  9.40120816e-02
   1.29161954e-01]
 [-2.51051635e-02  1.53929323e-01 -3.58356386e-02 -4.51561511e-02
  -1.56033233e-01]
 [-1.96996436e-01 -1.58153310e-01  1.48793966e-01 -1.00975931e-01
  -1.05046041e-01]
 [ 6.47329986e-02 -1.06125318e-01  7.41723180e-02  9.74582136e-02
   2.55825967e-02]
 [-2.42102593e-02 -9.21168998e-02  1.16180867e-01 -1.86484620e-01
   2.13188976e-02]
 [-1.86951011e-01 -7.34149516e-02 -7.33887255e-02  1.31130129e-01
   2.72764862e-02]
 [ 1.47147447e-01 -1.83533430e-02 -8.10547173e-03 -1.66236803e-01
  -1.35311171e-01]
 [ 6.97261095e-02  1.21982634e-01 -1.16987303e-01 -1.33938432e-01
   2.19946355e-02]
 [ 1.41777039e-01 -1.88485950e-01 -6.29267395e-02 -1.16352379e-01
  -8.35455954e-02]
 [-5.08670360e-02 -2.76563317e-02 -3.30282897e-02 -2.07740784e-01
   1.70364022e-01]
 [ 1.50674433e-02  1.58690661e-02 -1.78512082e-01  5.01784980e-02
  -2.02114224e-01]
 [-1.93267643e-01 -6.17783368e-02 -2.07096592e-01 -5.04980683e-02
  -9.29170027e-02]
 [-2.36701965e-02  1.18253976e-02  1.02882981e-01 -1.89824909e-01
  -1.48974508e-02]
 [-2.05038399e-01  1.69189543e-01 -9.32534039e-02  6.71012104e-02
   1.25466853e-01]]: "
2018-04-20 00:09:45,269 (dqn_agent.py:161) DEBUG: "var_name: q/fully_connected_1/biases:0, var_value [0. 0. 0. 0. 0.]: "
2018-04-20 00:09:45,277 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv/weights:0, var_value [[[[-0.45437422  0.09241241 -0.4031417   0.20321494 -0.16378003
    -0.14166075 -0.6734322   0.43192756]
   [ 0.54498637  0.03903526  0.5607197  -0.48249277  0.35027182
    -0.5211806  -0.7130368   0.5883169 ]]]]: "
2018-04-20 00:09:45,285 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 00:09:45,305 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv_1/weights:0, var_value [[[[-0.01466241  0.05850556 -0.02121381  0.12007976  0.17141369
    -0.02536257  0.10543251  0.04181224  0.09713131  0.1067071
     0.08750033  0.13686469]
   [-0.13607019  0.14534569 -0.07360096 -0.08263129  0.10095194
     0.17122132 -0.17606041  0.08580339 -0.1452238   0.00371042
    -0.1557769  -0.09631909]
   [ 0.08883604  0.18050572 -0.04877298 -0.03218353 -0.05961033
    -0.06289382  0.11775747 -0.00884241 -0.00773033 -0.05212864
    -0.16727336  0.12815186]
   [ 0.11595932  0.16943693  0.13994163  0.1036067   0.04620007
    -0.1540871   0.0192927   0.12014189 -0.09592968 -0.15637033
    -0.05390354  0.17530632]
   [-0.07557636  0.08791155  0.1331468   0.01842286  0.06721978
     0.17661545 -0.00288388  0.03301768 -0.12310915  0.05204898
    -0.06071501 -0.14016119]
   [-0.11692846 -0.16908447  0.11855218 -0.02288641 -0.17366879
     0.1013779   0.1591393   0.01173401 -0.13761348 -0.03117806
    -0.1557847  -0.00268583]
   [-0.17106453  0.16602117  0.025399   -0.03741346  0.14993021
    -0.17943686 -0.021634   -0.08604149  0.00401068  0.16467047
    -0.0994057  -0.13315158]
   [-0.14518179  0.10588831 -0.14631498  0.12457117 -0.01658358
    -0.10606639 -0.15731038  0.01483493 -0.00218403 -0.1075109
    -0.17891935 -0.07590918]]

  [[-0.01333256  0.1740242   0.07614797 -0.05813996 -0.17304093
     0.12749454  0.17430508 -0.15049408 -0.12419246  0.04585683
    -0.08201022  0.16711304]
   [ 0.03648023  0.02337807 -0.12276632  0.08584508 -0.0518266
    -0.00043355 -0.1442396  -0.11551877  0.1594108   0.12146437
    -0.07694382  0.1417476 ]
   [ 0.15309837  0.14997703 -0.0314606  -0.16766238  0.03715721
     0.09037656 -0.16108304 -0.16444837  0.01136026  0.11861974
    -0.05405244  0.11663139]
   [ 0.13407314 -0.15358482  0.04635908  0.07625258  0.1136378
    -0.12670888 -0.01294258 -0.17408831  0.06679799  0.13880342
     0.15530473 -0.0765616 ]
   [-0.1327855   0.12211311 -0.15656626 -0.06900856 -0.11279089
     0.03097981 -0.10999297 -0.02160509 -0.01772265  0.12285644
    -0.10395113 -0.10794454]
   [-0.01922117  0.11961403  0.05933566  0.06834012  0.07574412
    -0.17862383 -0.01404008  0.14127192 -0.09762575  0.17321154
     0.09610689 -0.01100537]
   [-0.05330914  0.13111311 -0.04512776 -0.11598005 -0.01563795
    -0.14568633 -0.17443912 -0.07030447  0.14984336  0.05552343
     0.03977296 -0.05611438]
   [-0.13787618 -0.16749157 -0.09924342  0.12353513  0.09741321
    -0.08098002 -0.00868562  0.07680324  0.00490603  0.00120288
    -0.03632802  0.02839328]]

  [[ 0.04877546 -0.03812329  0.06513944  0.12940246 -0.10367812
    -0.13032344  0.01147853  0.16639602  0.15375596 -0.058024
     0.18119892 -0.15170655]
   [ 0.13204837  0.10922822 -0.1737666   0.13117331  0.00372839
    -0.06782135  0.16924846 -0.14124072  0.00763774 -0.15902525
    -0.07066088 -0.02490115]
   [-0.12640604  0.03605348  0.13907462  0.12396351 -0.05497976
     0.09312224 -0.15864168  0.07145956 -0.0708081   0.14016694
     0.01189519 -0.13005361]
   [-0.15416576 -0.06358641  0.03356549 -0.02790079 -0.06227248
     0.18057421  0.14865828 -0.13827774  0.1314114   0.15134072
     0.13974035 -0.05316563]
   [-0.1423928  -0.03416494 -0.12294888 -0.00292815 -0.08575132
    -0.05901742 -0.08555344  0.16854623  0.13293344  0.17930493
     0.04580817 -0.03104937]
   [ 0.10880136  0.00361566 -0.10198963 -0.09792419 -0.1515167
     0.13225156  0.02701871  0.12189987  0.15916237 -0.08133247
     0.04811221  0.01869866]
   [-0.07182685  0.03867745  0.18253401  0.01392335  0.1608679
     0.07485074 -0.10170095 -0.0306329   0.13777822 -0.1663074
    -0.11913121 -0.11220273]
   [ 0.03737789  0.17200816  0.03748028  0.1132786   0.04067257
     0.11394405  0.08071089  0.1346007  -0.11249515  0.02093334
     0.01518773  0.15978548]]]


 [[[-0.09711798  0.12095186 -0.18033461  0.07197481 -0.12435444
    -0.16174373 -0.17205203 -0.03097586 -0.17449313 -0.14949012
     0.16603026  0.13275442]
   [-0.10304103 -0.13372284  0.16245231 -0.03266169  0.10227737
     0.14526805 -0.07895361 -0.12290309  0.06942195 -0.00308286
    -0.00142889  0.01682882]
   [-0.16460398  0.18009877  0.04248498 -0.09288578 -0.08978438
     0.17851126 -0.02766979 -0.12828812 -0.08642367  0.03198847
     0.14432576 -0.10928519]
   [-0.04919243  0.04991871  0.07239917  0.18044013  0.13450849
     0.17717206 -0.02298875 -0.08162159  0.07165939 -0.05454685
    -0.04493006 -0.1249651 ]
   [ 0.0137057   0.11937758  0.07023516  0.00343958 -0.09185728
    -0.05500509 -0.1392392  -0.02637157 -0.10415751  0.11168638
    -0.0851353   0.01113935]
   [-0.04140042 -0.07588407 -0.16345003  0.08287257  0.05111828
     0.09552804 -0.01822284  0.18026441 -0.02794705  0.11909673
     0.04235153 -0.0785642 ]
   [ 0.07920724 -0.00274529  0.06485868 -0.03334846  0.06625217
     0.13307175 -0.17441075  0.05304432 -0.09459343 -0.11465428
    -0.13867776  0.02053772]
   [ 0.08871722  0.13296005 -0.16012724 -0.02379934 -0.1343044
     0.04384091 -0.086555    0.09754524 -0.16061054 -0.0963366
     0.10912845  0.12435153]]

  [[-0.04925089  0.00873929  0.14807117  0.1325534  -0.12621722
    -0.03693655  0.06350462 -0.11509524 -0.06725591 -0.0896571
     0.11077985  0.02153628]
   [-0.12957017 -0.079065   -0.05105133 -0.1692932   0.08707368
     0.04464199 -0.09839739  0.05348392 -0.14870363  0.09071094
    -0.08592553  0.01773654]
   [-0.18215217 -0.10857836 -0.17412184 -0.11928429 -0.11099514
    -0.07311845  0.15416324  0.05049147  0.06907451  0.16530386
     0.15430179 -0.00327104]
   [ 0.11380634  0.04600358  0.04465801 -0.0428791  -0.1160073
    -0.15509698  0.09838989  0.08397385  0.07401916  0.15863878
     0.17510185 -0.019881  ]
   [ 0.10233834  0.03508291 -0.12254889 -0.09592233  0.17196506
    -0.13716243 -0.06233124  0.09376338 -0.1497557  -0.0764348
     0.03716417 -0.17782633]
   [ 0.1710994   0.10975549  0.13816503 -0.00569904  0.1750032
     0.14428678 -0.05615011 -0.0253364   0.05387467 -0.07739335
    -0.13125327  0.1331723 ]
   [-0.04720381 -0.03753473  0.03489865  0.02259028 -0.14662257
     0.09675616  0.08911821  0.17121378  0.04895672 -0.02772637
    -0.0867928  -0.01295024]
   [ 0.00947301 -0.01002309 -0.00651051 -0.07714523 -0.08588622
     0.06352738  0.15263718 -0.0196307  -0.15290502  0.14769417
     0.09335217 -0.07713292]]

  [[ 0.07333118 -0.03735948  0.01542309  0.03733228  0.05957991
     0.02390721  0.02595608  0.0621644  -0.07231329  0.12799668
    -0.03680509  0.17074442]
   [-0.10140085  0.06354627 -0.13662246  0.08991715 -0.07954012
    -0.02399558 -0.01637429 -0.07357197  0.00909196  0.14505047
    -0.14007545 -0.07018145]
   [-0.08556115  0.07365611  0.16732678 -0.05895931  0.07251701
     0.11456421 -0.13488247 -0.08253618 -0.15309507 -0.00558078
     0.11341459 -0.07041386]
   [ 0.11344743 -0.10803007 -0.07666746 -0.14819688  0.1439592
    -0.04249112  0.05444121 -0.09240205  0.04306436 -0.03621688
    -0.01520254 -0.04023832]
   [-0.0823188  -0.15016177  0.08762142 -0.00075614  0.06591508
     0.12297022 -0.11480093 -0.09847195  0.11489156 -0.04070631
    -0.08099412 -0.04146218]
   [-0.15724744 -0.14397404 -0.11141437  0.17407519  0.09058154
     0.06041719 -0.07250638  0.0198715   0.14399496 -0.03132552
     0.08252391 -0.18137144]
   [ 0.07579848  0.09563783 -0.03113016 -0.01049717 -0.03869787
    -0.1402896   0.05172879  0.16654548 -0.02835602 -0.02578184
     0.17120874 -0.06828938]
   [-0.06846897  0.07873088 -0.08821677  0.14310127  0.16859818
     0.05140898 -0.0893107   0.12624368 -0.02682288  0.04080437
     0.0106688   0.08510935]]]


 [[[-0.10897526  0.13367662  0.15619364 -0.06999423 -0.02717434
    -0.11035156 -0.10835454  0.15969238 -0.08526637  0.14704192
    -0.09030451  0.17456818]
   [ 0.16563424  0.06151494 -0.16206598  0.08341992  0.04689771
     0.054217   -0.13138294  0.17479184 -0.03726193 -0.04269153
     0.11002967 -0.06969532]
   [-0.08868501  0.07564074  0.14892909  0.12079281 -0.09101778
     0.07109585 -0.05553997 -0.11530644  0.03784631 -0.01577654
    -0.07192009 -0.15675117]
   [-0.0735314  -0.1652137   0.02120845  0.0183654   0.17537561
     0.15261787  0.0069741   0.14271334  0.0050263   0.0354698
     0.09023002  0.06579477]
   [-0.06095969  0.05041076  0.01524849  0.00169246 -0.1525096
     0.12067726  0.11791995  0.03120604  0.09408206 -0.02889447
    -0.12880825  0.15582225]
   [-0.127826   -0.1494274  -0.03031504  0.00710647  0.01140636
    -0.05398986  0.01549983 -0.04401264  0.15839073  0.0254239
     0.04430681  0.10316274]
   [-0.04401442 -0.08693401 -0.04611614 -0.15874441 -0.02085574
     0.12584922 -0.07778938  0.07651812  0.01063828  0.14573783
    -0.017022   -0.0256664 ]
   [-0.04349761  0.10638207  0.1078729   0.1765739  -0.06204543
     0.14214712  0.11837754 -0.01438841 -0.07388486  0.08071905
    -0.14853379  0.06661451]]

  [[ 0.07779527 -0.11770336  0.10445264  0.10759658 -0.03735299
     0.01196928  0.14848569  0.13723698 -0.00261371 -0.01220721
    -0.02871208  0.12323365]
   [-0.06835105  0.16196147  0.14300656  0.02209666 -0.0643042
    -0.09489992  0.15379405 -0.13700852  0.13039896  0.10075757
    -0.14659409  0.09277135]
   [-0.05200654  0.00612023 -0.06426646 -0.075417    0.03244644
     0.0147413   0.04503044 -0.09471135  0.13704303 -0.11523192
    -0.07149107 -0.05435149]
   [ 0.08963063  0.02480608 -0.05215319  0.02542682 -0.15885001
    -0.17714758  0.01799679 -0.02272409  0.0497079  -0.1736505
    -0.02113354  0.04501721]
   [-0.07498924  0.01818036  0.04811095  0.13194507  0.03520149
    -0.14354797  0.1643706  -0.14866398 -0.13641517  0.14522159
     0.06691878  0.06758699]
   [-0.01079722 -0.07063206  0.00471407  0.16985306 -0.14888489
     0.11848301  0.16788247 -0.12660371 -0.01320224  0.14040408
     0.16058648  0.06816941]
   [-0.10741661 -0.02724394 -0.0822233   0.08925724  0.09258765
     0.06231165  0.0498044  -0.13713339 -0.13286063  0.17867482
    -0.05096972 -0.00895812]
   [ 0.02829708 -0.08036517  0.04478677 -0.16197905 -0.0109954
    -0.07474104 -0.14697593  0.02370255  0.0876936   0.01851954
     0.09659082 -0.0992752 ]]

  [[ 0.07054719  0.03664042  0.17328823  0.1551832  -0.02233982
    -0.1800142   0.02474132 -0.06799451  0.06863508  0.09027073
    -0.00181633 -0.07467387]
   [-0.01741277 -0.004581   -0.12157645 -0.01688723  0.11161086
    -0.02841021 -0.09768213 -0.04028572  0.01998416  0.00660427
    -0.17724048 -0.14708376]
   [ 0.04511471 -0.15401018 -0.01555946 -0.03063032 -0.11404274
     0.1064834  -0.08018744  0.02472408 -0.07646235 -0.10636378
    -0.148667    0.07533795]
   [ 0.04659531 -0.02630559  0.14988288 -0.02543582 -0.0281446
    -0.05474138 -0.04716301  0.15032604  0.15306407 -0.02251659
    -0.12148735 -0.12412669]
   [ 0.13318762  0.18038425  0.02371864  0.12804452  0.18000343
    -0.02104762  0.04726039 -0.15654784 -0.09428968  0.14436075
    -0.01856154 -0.08612794]
   [-0.0541607  -0.09237941  0.06004162 -0.13420218 -0.11275276
    -0.09002075  0.14222795  0.06486289  0.06487805  0.03626904
     0.11652446 -0.10532191]
   [-0.06088612 -0.02427961 -0.07980164 -0.0209693   0.05309759
    -0.09637764  0.02788343 -0.1616983   0.07265839 -0.0316944
    -0.06968196 -0.06994962]
   [-0.13647963  0.09382018  0.05407822  0.13661614  0.16818133
    -0.1110708   0.02397725 -0.12108409  0.07832575  0.03426287
    -0.11895713  0.04951768]]]]: "
2018-04-20 00:09:45,312 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv_1/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 00:09:45,324 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv_2/weights:0, var_value [[[[-0.0797774   0.01873627  0.1385109  ...  0.01415014  0.05313519
    -0.11567675]
   [ 0.0371282  -0.01852378 -0.01220277 ...  0.07838745 -0.15200189
    -0.02942897]
   [-0.11219987  0.02653207  0.13914661 ... -0.02268051  0.01884557
    -0.10662605]
   ...
   [-0.01931754  0.10785471 -0.0738834  ...  0.05605897 -0.02745824
    -0.14945176]
   [-0.00934859  0.06111154 -0.06048029 ... -0.01047826  0.08065607
    -0.01911066]
   [ 0.0869908  -0.03158921  0.07200363 ... -0.00325014  0.10848556
    -0.11243635]]

  [[ 0.10402112 -0.08505578  0.03061622 ... -0.14676416 -0.09480286
     0.11201669]
   [ 0.01366302  0.0022932  -0.01384506 ... -0.02880698 -0.08913184
    -0.11579804]
   [-0.09752969 -0.06275689  0.12859626 ...  0.08642426  0.10306172
    -0.09605898]
   ...
   [-0.03521162  0.0527986   0.02938788 ...  0.03956902 -0.11750452
    -0.11807732]
   [-0.10061806 -0.05139725 -0.05516935 ...  0.05418053 -0.08568631
    -0.0906323 ]
   [ 0.03504129  0.02396856 -0.08887803 ... -0.03232042 -0.00468104
     0.07404447]]

  [[ 0.1541829  -0.1045125  -0.11529106 ... -0.10019596 -0.14190017
    -0.07995395]
   [ 0.02162334  0.00685629  0.0875206  ... -0.01866394  0.06448419
     0.10108863]
   [ 0.11919345  0.14987867 -0.06624336 ... -0.08187944 -0.11034374
     0.0748125 ]
   ...
   [-0.13684542 -0.05107023 -0.0037633  ...  0.06076154 -0.14174308
     0.0386741 ]
   [ 0.14700033  0.08633758 -0.15287624 ... -0.13077605 -0.00711119
     0.05512314]
   [ 0.12159131  0.05729982  0.08275715 ...  0.0526921   0.14226906
    -0.06211813]]]


 [[[-0.01202865 -0.00967431  0.02385871 ...  0.02471659  0.04241538
    -0.01958933]
   [ 0.12125929  0.01211418  0.13327138 ... -0.12111421  0.10108043
    -0.10277212]
   [ 0.0984657  -0.0080872   0.11509134 ...  0.08291644 -0.01644051
     0.11152099]
   ...
   [ 0.03221072  0.13378079 -0.06361223 ...  0.12784235 -0.10977568
    -0.05360178]
   [-0.10839099 -0.13388881 -0.02110647 ... -0.09940819 -0.04715988
    -0.00712647]
   [ 0.06567498 -0.03493702 -0.01443522 ...  0.15022798  0.00903827
     0.10069202]]

  [[ 0.07153139 -0.13819873 -0.04929683 ...  0.11265786  0.08069491
    -0.12779906]
   [ 0.12745853  0.00370216 -0.02454191 ...  0.09623154  0.0001775
     0.04350774]
   [ 0.07256651  0.05599676  0.14617844 ... -0.01220372  0.14148615
    -0.07017564]
   ...
   [-0.13294595  0.05087757 -0.00388417 ... -0.08877664 -0.11591922
    -0.07819052]
   [ 0.11482559 -0.04780306  0.14269985 ... -0.02060565 -0.05782322
    -0.10979146]
   [-0.08152399 -0.12382263 -0.06542066 ...  0.12074052 -0.12256813
    -0.14660501]]

  [[ 0.05660661  0.04520389  0.05418664 ...  0.13390882  0.09029326
     0.12069909]
   [ 0.07769762  0.02919297  0.10366435 ... -0.02221252  0.14408077
     0.07060909]
   [ 0.0815248  -0.13238297  0.11402886 ... -0.13921385 -0.09824571
    -0.11210467]
   ...
   [-0.038612   -0.07993986  0.09361216 ... -0.13619772  0.12755702
     0.13634567]
   [ 0.02829695  0.0308069  -0.13810375 ... -0.01558612 -0.09937266
     0.03809218]
   [-0.07015412 -0.05846588 -0.120064   ...  0.13161443 -0.05718276
    -0.10728085]]]


 [[[ 0.030435   -0.06333458  0.02243446 ...  0.13593231 -0.13051705
    -0.02433604]
   [-0.02924481  0.01935621  0.12169908 ... -0.0406849  -0.12146281
     0.14411007]
   [ 0.07565585 -0.05887306 -0.12136301 ... -0.07856981 -0.02397165
     0.02643587]
   ...
   [ 0.1533375   0.04228702 -0.09097724 ...  0.10271607  0.13476925
    -0.02679199]
   [ 0.03572099  0.04462653 -0.02515885 ...  0.02842607 -0.1516429
     0.0448923 ]
   [ 0.00234838 -0.03872756  0.11498405 ... -0.03516199 -0.04284337
     0.07417628]]

  [[-0.06454548  0.0776455   0.03432643 ...  0.08143765 -0.04530789
     0.01492421]
   [-0.12865528  0.02481234 -0.11718009 ... -0.04410365  0.00359632
     0.04930131]
   [ 0.12103857  0.03000383 -0.08107848 ... -0.03966247  0.145406
     0.05948658]
   ...
   [-0.12647136  0.02175365 -0.02808857 ...  0.13086133  0.02426165
    -0.02675097]
   [-0.13547882  0.09986694 -0.0996836  ... -0.03389531 -0.07216095
     0.13954224]
   [-0.04688683  0.04190913  0.12469019 ... -0.11713892  0.05286431
    -0.03286828]]

  [[ 0.13387235  0.00517166 -0.06660926 ...  0.14508961 -0.11595403
    -0.08661048]
   [-0.08677559  0.11258914  0.06776421 ... -0.05621794 -0.01255502
     0.12493841]
   [-0.10320002 -0.13903755  0.03457987 ...  0.02658622 -0.03870077
     0.00746298]
   ...
   [-0.12197867 -0.10988932 -0.07672408 ...  0.01115187  0.02591468
    -0.13302387]
   [-0.15196793 -0.02575892  0.10223298 ...  0.09138496  0.04587485
    -0.08367073]
   [ 0.04596645 -0.00647435  0.02616249 ...  0.02018991  0.00734271
     0.15340148]]]]: "
2018-04-20 00:09:45,330 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv_2/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 00:09:45,334 (dqn_agent.py:161) DEBUG: "var_name: target_q/fully_connected/weights:0, var_value [[-0.06105846  0.02842958 -0.06607082 ...  0.08143545  0.02440361
  -0.00027925]
 [-0.01322457  0.04913994 -0.07371138 ... -0.00715099  0.05188406
  -0.08400482]
 [ 0.0208477   0.06453959  0.03748194 ... -0.08069795  0.08146083
  -0.0542092 ]
 ...
 [-0.05078364 -0.06910589 -0.07922482 ...  0.00789656  0.04588784
   0.06274114]
 [-0.08737447  0.08850712 -0.0916521  ... -0.04621189  0.02897456
  -0.02463267]
 [-0.08712668  0.0145384   0.02659321 ... -0.08777002 -0.0797758
  -0.09084145]]: "
2018-04-20 00:09:45,340 (dqn_agent.py:161) DEBUG: "var_name: target_q/fully_connected/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 00:09:45,348 (dqn_agent.py:161) DEBUG: "var_name: target_q/fully_connected_1/weights:0, var_value [[-1.33332372e-01 -1.21349141e-01 -5.98904490e-03  9.78068113e-02
  -1.72639668e-01]
 [ 2.19879001e-02  1.17726624e-01  5.87365031e-02 -1.50980830e-01
   1.43375307e-01]
 [-3.88857126e-02 -1.21027328e-01  5.75172305e-02 -1.40003175e-01
   1.91109031e-01]
 [-1.64104626e-01 -1.37330830e-01  7.63312280e-02 -4.93871868e-02
   1.40498400e-01]
 [-6.21345341e-02 -2.12296918e-01  1.88643992e-01 -1.62010074e-01
   2.89283544e-02]
 [ 7.92510211e-02  6.57981932e-02  8.34364593e-02  1.93149596e-01
  -5.63380271e-02]
 [ 8.33594501e-02  1.30414516e-02 -1.72245502e-03 -2.02637374e-01
  -3.33143026e-02]
 [-1.03909835e-01 -1.39290273e-01  9.87536311e-02  7.15075135e-02
   1.76905304e-01]
 [ 1.52604789e-01 -1.41019076e-02  1.11094624e-01 -6.31067157e-02
   1.23259515e-01]
 [ 2.49368399e-02 -4.09058183e-02  9.59849358e-02 -1.94948867e-01
   1.39712423e-01]
 [ 2.74312943e-02  2.62325555e-02  1.07461601e-01 -2.02591240e-01
   2.20338255e-02]
 [ 1.25593185e-01  5.53655922e-02  1.29744053e-01  3.81451845e-03
   1.52154148e-01]
 [-4.18858975e-02  1.42774522e-01  1.27843171e-02  1.15700305e-01
   8.67719054e-02]
 [-3.30982208e-02 -2.43003517e-02  1.51905507e-01  7.35116303e-02
   2.28226185e-04]
 [ 2.11443812e-01  1.20608777e-01 -1.78808883e-01 -2.39927620e-02
   1.83877409e-01]
 [ 3.56259942e-03 -1.89073563e-01  1.82523966e-01 -1.20623223e-01
  -1.48555189e-02]
 [ 1.20509446e-01  1.11306667e-01 -5.10512292e-03 -3.31417173e-02
  -9.28477272e-02]
 [-1.40883401e-01  2.00892031e-01 -1.62269041e-01  1.05588526e-01
  -3.88249755e-04]
 [ 1.83306038e-02 -1.13561690e-01  4.76567447e-02  2.08044112e-01
   2.57307142e-02]
 [-4.58348244e-02 -1.89173222e-01 -1.69141382e-01  1.63844138e-01
  -1.06254801e-01]
 [ 1.69571042e-02  1.90918118e-01 -4.01447564e-02  1.58081055e-01
   3.56156081e-02]
 [-1.26972407e-01 -1.17496997e-02  1.40221298e-01 -1.63462922e-01
  -1.27168477e-01]
 [-1.33166790e-01 -7.77329803e-02 -4.70646024e-02 -5.45788556e-02
   7.29191005e-02]
 [ 1.58559740e-01 -2.13138312e-02  7.36537576e-03  1.61597759e-01
   1.71119511e-01]
 [-6.78443909e-03 -1.45141169e-01 -1.38303190e-02 -5.31578064e-03
   3.53223532e-02]
 [ 4.64116037e-02  1.79639637e-01  1.42013669e-01  3.87872756e-02
  -7.78463632e-02]
 [-1.25575006e-01 -1.79828703e-01 -2.10043862e-01 -2.00302690e-01
  -1.76701576e-01]
 [-1.25143468e-01  9.25613642e-02  8.50352645e-02  1.86021179e-01
   8.28426182e-02]
 [ 2.03106403e-01 -1.26479864e-02 -1.94376245e-01  3.41293365e-02
   4.27161753e-02]
 [-1.91581905e-01 -6.36603087e-02 -1.67869419e-01  1.46228194e-01
   1.24100477e-01]
 [ 3.45172435e-02  7.85651505e-02  8.66160691e-02  7.83444047e-02
  -3.56978476e-02]
 [-1.83149099e-01  4.07444835e-02  1.18230343e-01 -1.06956519e-01
   6.45250678e-02]
 [ 1.66767716e-01 -1.19897857e-01 -4.49884832e-02 -1.47899061e-01
   1.28830642e-01]
 [-1.30647019e-01  1.52333468e-01  6.11083806e-02  5.36487997e-02
  -9.23249274e-02]
 [-8.76322091e-02  1.70817107e-01 -7.91828930e-02  8.18712413e-02
   1.22866154e-01]
 [-1.55784488e-01  9.03639495e-02  1.61848694e-01 -1.07190721e-01
  -1.45900160e-01]
 [-6.51546270e-02 -5.38187623e-02 -2.56687403e-03 -1.45303980e-01
   1.80245012e-01]
 [-2.10296005e-01  1.65432751e-01 -1.96618468e-01 -4.83155251e-04
  -1.97427124e-01]
 [ 1.44576877e-02  2.10917145e-01  5.70272207e-02  1.49710089e-01
  -1.44896537e-01]
 [ 1.72353417e-01 -1.22898862e-01 -1.07862204e-01  7.61069357e-02
  -1.64051145e-01]
 [ 2.54404992e-02 -3.45092416e-02  1.22068584e-01 -4.28612232e-02
   5.47040403e-02]
 [-7.95610696e-02  5.46818972e-02  4.17655706e-02 -1.28726810e-02
  -1.42941996e-01]
 [ 1.31037205e-01 -8.53326917e-03  1.52641445e-01 -2.08379090e-01
  -6.94002509e-02]
 [-4.83085662e-02  1.05872273e-01  1.96069390e-01 -7.71625340e-03
   3.70381325e-02]
 [-8.26944411e-02  1.81950063e-01  1.04183048e-01  1.86633199e-01
   1.09252572e-01]
 [-8.32722485e-02  2.21315175e-02  1.10602826e-02  1.12895221e-01
  -8.20102096e-02]
 [ 1.59277260e-01  1.74249232e-01  1.44925863e-01  2.00162113e-01
   9.39865112e-02]
 [-1.73819810e-02 -1.66694582e-01 -1.82291821e-01 -5.25571257e-02
  -1.95269167e-01]
 [ 2.10287333e-01 -5.10967821e-02 -1.80516496e-01 -1.15478694e-01
   1.39438659e-01]
 [-3.89538705e-02 -2.62869895e-02 -1.35155961e-01 -8.16502124e-02
  -1.04703464e-01]
 [ 6.32601082e-02  1.79905772e-01  2.08012551e-01 -1.13431491e-01
   1.73217356e-01]
 [-5.87642193e-02  1.56381488e-01 -1.13846228e-01 -1.28444701e-01
  -4.73091453e-02]
 [ 3.96845639e-02  8.60593915e-02 -1.79569587e-01 -1.95884392e-01
  -5.57826608e-02]
 [ 1.54591978e-01 -1.92236260e-01 -3.72524559e-03 -1.16627149e-01
   1.81555867e-01]
 [-2.44139880e-02  3.47475410e-02  2.02982575e-01 -7.77329355e-02
   1.61969751e-01]
 [-2.71016806e-02  1.52809560e-01 -1.67976022e-02 -8.15618485e-02
   1.84121370e-01]
 [ 6.86028600e-03 -1.21316321e-01  4.07213569e-02  1.51968658e-01
   1.35954291e-01]
 [-1.17039412e-01 -8.46014768e-02  4.84654903e-02  1.69804543e-02
   4.88846898e-02]
 [ 4.18361723e-02 -1.78853959e-01 -1.45407289e-01 -1.25650868e-01
   1.17502093e-01]
 [-2.06809878e-01 -8.18790495e-02  5.74409068e-02 -1.80485308e-01
   1.30008459e-02]
 [ 1.05592281e-01  2.04155952e-01  9.08307433e-02  3.57435793e-02
  -1.28867894e-01]
 [ 1.47449464e-01 -1.95517704e-01  2.64264494e-02 -1.46879628e-01
  -9.44144651e-02]
 [-7.73212314e-02  1.50754929e-01  1.16665930e-01  8.31313133e-02
  -1.51184201e-01]
 [ 7.02056289e-02 -3.86433452e-02 -2.00528488e-01 -1.67933837e-01
  -6.42767549e-03]
 [-9.73364711e-02  1.68140709e-01  1.46741629e-01 -4.84089404e-02
   1.64870650e-01]
 [-1.96861371e-01 -3.66970152e-02 -2.90136337e-02 -1.72180921e-01
  -1.18585385e-01]
 [ 1.56324774e-01 -1.72880769e-01 -1.79759443e-01  2.02931434e-01
   2.05285013e-01]
 [-1.14409700e-01 -6.00090325e-02 -6.00715727e-02 -1.48965329e-01
  -6.92888945e-02]
 [-7.44006932e-02  8.93048346e-02  1.00024372e-01  1.93319649e-01
   2.11270094e-01]
 [-2.13102847e-02 -1.57896727e-01 -1.83345631e-01 -7.51146674e-03
  -1.38531625e-02]
 [ 2.19836384e-02  1.52192324e-01 -5.66162914e-02  2.17455924e-02
  -6.32507354e-02]
 [-1.75569370e-01  1.75910234e-01 -1.22227125e-01 -1.01274356e-01
   5.80603778e-02]
 [ 4.43098247e-02  5.88109195e-02  2.02916294e-01 -1.05794795e-01
  -6.80513084e-02]
 [-1.26083687e-01  1.56830668e-01 -5.63588440e-02  4.55490649e-02
   1.47138834e-02]
 [ 8.71114433e-02  3.84750366e-02 -1.47621244e-01 -1.96559876e-01
  -1.48402765e-01]
 [ 1.37743682e-01 -8.18346441e-02 -1.76512688e-01 -1.57841012e-01
  -1.42260045e-01]
 [-1.95939839e-03  5.35142124e-02 -1.31175667e-02  1.77288383e-01
   1.00596696e-01]
 [ 2.02702492e-01 -1.70870826e-01 -1.89399689e-01 -1.96021214e-01
  -1.11866273e-01]
 [ 5.80630004e-02  6.27471805e-02  1.08344853e-01 -1.05071068e-02
  -1.03693604e-02]
 [ 5.66751361e-02 -8.86138529e-02 -1.07130565e-01  9.31333303e-02
   6.72780573e-02]
 [ 2.83122063e-06  1.89666450e-02 -8.52186829e-02 -1.19457550e-01
  -1.03126593e-01]
 [-1.10526860e-01 -1.05703190e-01  1.77719027e-01 -1.15153342e-02
  -1.06111541e-01]
 [ 1.04258657e-01  6.74642920e-02 -1.85029387e-01 -8.57597589e-02
   3.71636599e-02]
 [-7.52004534e-02  1.67274922e-01  4.62332666e-02 -1.41756773e-01
   1.65151030e-01]
 [ 2.56775022e-02 -1.75179645e-01 -1.96602911e-01  4.48317528e-02
   1.57505721e-01]
 [-7.31959343e-02 -2.08361015e-01 -1.62833571e-01 -2.67283171e-02
  -1.27656490e-01]
 [ 6.40900731e-02 -1.70506120e-01  6.44489527e-02  1.06842071e-01
   1.33804083e-01]
 [ 3.87928784e-02 -7.65558630e-02  1.96308583e-01 -2.05414906e-01
   1.08516216e-01]
 [-8.95004570e-02  9.48854685e-02 -1.34641975e-01 -3.70140672e-02
   1.27068937e-01]
 [ 7.14562237e-02 -1.33513927e-01  7.49334693e-02  1.65760338e-01
  -7.71780759e-02]
 [ 4.13779914e-02  2.11308092e-01 -1.88402444e-01  1.29697889e-01
  -1.62390530e-01]
 [-8.18880647e-02 -9.55564901e-02  7.28605986e-02 -1.60114616e-02
   1.19657516e-01]
 [ 1.29042089e-01  1.25617534e-01 -1.48041159e-01 -1.77534938e-01
  -1.14387773e-01]
 [-7.82036334e-02  1.44397676e-01 -7.22879171e-02  2.08964586e-01
   8.45837593e-03]
 [-1.74476475e-01 -3.87125164e-02  1.30463243e-01 -1.62515491e-02
  -5.79580814e-02]
 [-9.36988816e-02 -3.44815403e-02  4.77618575e-02 -6.10817373e-02
  -1.52989239e-01]
 [-1.39445081e-01  1.81519777e-01  3.26515287e-02  7.57436454e-03
   1.85713232e-01]
 [ 1.19170129e-01 -7.29819387e-02 -1.92039177e-01 -9.55184102e-02
  -1.90760478e-01]
 [ 3.02956700e-02 -1.46895796e-02 -9.13210437e-02  8.34646225e-02
  -4.54191267e-02]
 [-8.38156044e-02 -5.32496274e-02  1.15667015e-01 -5.57486862e-02
  -5.41878194e-02]
 [ 1.50856614e-01 -1.75100341e-01 -1.18969433e-01 -9.78152677e-02
  -6.72666430e-02]
 [ 1.42697603e-01 -3.07936668e-02 -4.56988513e-02  1.10326022e-01
   1.67318612e-01]
 [-2.04904377e-02 -8.31899047e-02  4.74621356e-02  1.21553570e-01
   1.75197929e-01]
 [-2.57045329e-02  1.64978117e-01 -1.25101775e-01 -1.60598904e-01
  -1.42539710e-01]
 [ 1.89972311e-01  7.19270706e-02  2.01232076e-01 -5.36444038e-02
  -2.05520287e-01]
 [-7.36287981e-02 -1.83466449e-01  1.89967155e-02 -8.38266015e-02
   1.08603150e-01]
 [-1.69596985e-01  1.80198848e-02 -1.18377253e-01 -3.07594240e-03
   6.10244572e-02]
 [ 1.34180099e-01  7.04799294e-02 -9.25011039e-02  1.23018324e-01
  -7.09713995e-03]
 [ 1.52822375e-01 -7.20094144e-03  1.81729376e-01 -1.33396089e-01
   4.68405783e-02]
 [-9.41604078e-02  6.97126985e-02  8.21819305e-02  8.86453986e-02
  -1.93376839e-03]
 [ 1.47830695e-01 -2.05642134e-02  4.93700802e-03 -1.73537299e-01
  -6.39557391e-02]
 [-6.12229109e-04 -1.02399617e-01 -1.80691212e-01  9.89547074e-02
   4.43066657e-02]
 [-6.52963221e-02  3.80224586e-02  7.80207813e-02 -1.41674191e-01
   9.97964740e-02]
 [ 1.21713787e-01  7.33523071e-02  1.05053544e-01  2.16308832e-02
   1.32878900e-01]
 [-5.92103601e-03  2.03366190e-01  7.00026453e-02  9.40120816e-02
   1.29161954e-01]
 [-2.51051635e-02  1.53929323e-01 -3.58356386e-02 -4.51561511e-02
  -1.56033233e-01]
 [-1.96996436e-01 -1.58153310e-01  1.48793966e-01 -1.00975931e-01
  -1.05046041e-01]
 [ 6.47329986e-02 -1.06125318e-01  7.41723180e-02  9.74582136e-02
   2.55825967e-02]
 [-2.42102593e-02 -9.21168998e-02  1.16180867e-01 -1.86484620e-01
   2.13188976e-02]
 [-1.86951011e-01 -7.34149516e-02 -7.33887255e-02  1.31130129e-01
   2.72764862e-02]
 [ 1.47147447e-01 -1.83533430e-02 -8.10547173e-03 -1.66236803e-01
  -1.35311171e-01]
 [ 6.97261095e-02  1.21982634e-01 -1.16987303e-01 -1.33938432e-01
   2.19946355e-02]
 [ 1.41777039e-01 -1.88485950e-01 -6.29267395e-02 -1.16352379e-01
  -8.35455954e-02]
 [-5.08670360e-02 -2.76563317e-02 -3.30282897e-02 -2.07740784e-01
   1.70364022e-01]
 [ 1.50674433e-02  1.58690661e-02 -1.78512082e-01  5.01784980e-02
  -2.02114224e-01]
 [-1.93267643e-01 -6.17783368e-02 -2.07096592e-01 -5.04980683e-02
  -9.29170027e-02]
 [-2.36701965e-02  1.18253976e-02  1.02882981e-01 -1.89824909e-01
  -1.48974508e-02]
 [-2.05038399e-01  1.69189543e-01 -9.32534039e-02  6.71012104e-02
   1.25466853e-01]]: "
2018-04-20 00:09:45,352 (dqn_agent.py:161) DEBUG: "var_name: target_q/fully_connected_1/biases:0, var_value [0. 0. 0. 0. 0.]: "
2018-04-20 00:09:53,036 (dqn_main.py:212) DEBUG: "Episode 10000, mean reward over last 10000 episodes: -1.3475400000000002"
2018-04-20 00:09:53,036 (dqn_main.py:213) DEBUG: "Epsilon: 0.9954253000001506"
2018-04-20 00:09:53,036 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -1.1, done: True"
2018-04-20 00:09:53,036 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 00:10:43,232 (dqn_main.py:212) DEBUG: "Episode 20000, mean reward over last 10000 episodes: -1.3297800000000002"
2018-04-20 00:10:43,233 (dqn_main.py:213) DEBUG: "Epsilon: 0.9440236000018429"
2018-04-20 00:10:43,233 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -2.3, done: True"
2018-04-20 00:10:43,233 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 00:11:40,850 (dqn_main.py:212) DEBUG: "Episode 30000, mean reward over last 10000 episodes: -1.3363"
2018-04-20 00:11:40,851 (dqn_main.py:213) DEBUG: "Epsilon: 0.8856793000037638"
2018-04-20 00:11:40,851 (dqn_main.py:214) DEBUG: "RL steps: [(2, 4)], reward: -1.4, done: True"
2018-04-20 00:11:40,851 (dqn_main.py:215) DEBUG: "Steps: 1, coords: 40"
2018-04-20 00:12:49,393 (dqn_main.py:212) DEBUG: "Episode 40000, mean reward over last 10000 episodes: -1.30247"
2018-04-20 00:12:49,393 (dqn_main.py:213) DEBUG: "Epsilon: 0.820430200005912"
2018-04-20 00:12:49,393 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -1.9, done: True"
2018-04-20 00:12:49,393 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 00:14:21,475 (dqn_main.py:212) DEBUG: "Episode 50000, mean reward over last 10000 episodes: -1.22463"
2018-04-20 00:14:21,476 (dqn_main.py:213) DEBUG: "Epsilon: 0.7419610000084955"
2018-04-20 00:14:21,476 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -1.5, done: True"
2018-04-20 00:14:21,476 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 00:16:17,414 (dqn_main.py:212) DEBUG: "Episode 60000, mean reward over last 10000 episodes: -1.05072"
2018-04-20 00:16:17,414 (dqn_main.py:213) DEBUG: "Epsilon: 0.6470974000116188"
2018-04-20 00:16:17,414 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -1.5, done: True"
2018-04-20 00:16:17,415 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 00:19:04,223 (dqn_main.py:212) DEBUG: "Episode 70000, mean reward over last 10000 episodes: -0.7993600000000002"
2018-04-20 00:19:04,223 (dqn_main.py:213) DEBUG: "Epsilon: 0.5217031000157472"
2018-04-20 00:19:04,223 (dqn_main.py:214) DEBUG: "RL steps: [(3, 1), (2, 2), (2, 4), (4, 6), (5, 5), (2, 5)], reward: -1.3000000000000003, done: True"
2018-04-20 00:19:04,224 (dqn_main.py:215) DEBUG: "Steps: 6, coords: 40"
2018-04-20 00:23:11,931 (dqn_main.py:212) DEBUG: "Episode 80000, mean reward over last 10000 episodes: -0.7009900000000001"
2018-04-20 00:23:11,932 (dqn_main.py:213) DEBUG: "Epsilon: 0.34840540001210246"
2018-04-20 00:23:11,932 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (2, 2), (4, 5), (2, 7), (2, 6)], reward: -0.3000000000000006, done: True"
2018-04-20 00:23:11,932 (dqn_main.py:215) DEBUG: "Steps: 5, coords: 40"
2018-04-20 00:39:24,811 (dqn_main.py:212) DEBUG: "Episode 90000, mean reward over last 10000 episodes: -1.228019999999999"
2018-04-20 00:39:24,812 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 00:39:24,812 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (2, 2), (2, 4), (2, 5), (3, 5), (3, 6), (4, 6), (4, 8), (4, 7), (5, 7), (6, 5), (6, 6), (5, 5), (4, 5)], reward: -7.399999999999963, done: True"
2018-04-20 00:39:24,812 (dqn_main.py:215) DEBUG: "Steps: 14, coords: 40"
2018-04-20 01:04:04,376 (dqn_main.py:212) DEBUG: "Episode 100000, mean reward over last 10000 episodes: -0.17340999999999343"
2018-04-20 01:04:04,376 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 01:04:04,376 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (2, 2), (2, 3), (2, 4), (3, 3), (3, 4), (4, 4), (4, 6), (4, 5), (3, 5), (6, 5), (3, 6), (2, 7), (5, 6)], reward: -3.7999999999999985, done: True"
2018-04-20 01:04:04,377 (dqn_main.py:215) DEBUG: "Steps: 14, coords: 40"
2018-04-20 01:25:01,515 (dqn_main.py:212) DEBUG: "Episode 110000, mean reward over last 10000 episodes: 7.013570000000007"
2018-04-20 01:25:01,515 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 01:25:01,515 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 2)], reward: 0.30000000000000004, done: True"
2018-04-20 01:25:01,515 (dqn_main.py:215) DEBUG: "Steps: 2, coords: 40"
2018-04-20 01:44:04,370 (dqn_main.py:212) DEBUG: "Episode 120000, mean reward over last 10000 episodes: 11.08757999999999"
2018-04-20 01:44:04,370 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 01:44:04,370 (dqn_main.py:214) DEBUG: "RL steps: [(3, 1), (2, 1), (2, 2), (3, 2), (3, 3)], reward: 3.1999999999999993, done: True"
2018-04-20 01:44:04,370 (dqn_main.py:215) DEBUG: "Steps: 5, coords: 40"
2018-04-20 02:01:45,884 (dqn_main.py:212) DEBUG: "Episode 130000, mean reward over last 10000 episodes: 12.980129999999987"
2018-04-20 02:01:45,884 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 02:01:45,884 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -1.0, done: True"
2018-04-20 02:01:45,884 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 02:25:23,984 (dqn_main.py:212) DEBUG: "Episode 140000, mean reward over last 10000 episodes: 10.55693999999998"
2018-04-20 02:25:23,984 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 02:25:23,984 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (2, 2), (3, 2), (3, 1), (3, 3), (2, 3), (2, 4), (3, 4), (4, 4), (4, 5), (3, 5), (2, 5), (2, 7), (2, 6), (3, 6), (4, 6), (5, 7), (6, 7), (6, 6), (5, 6), (5, 5), (6, 5), (7, 5), (7, 4), (8, 4), (8, 5), (6, 4), (8, 6), (7, 7), (4, 8), (4, 7)], reward: 15.299999999999898, done: True"
2018-04-20 02:25:23,984 (dqn_main.py:215) DEBUG: "Steps: 31, coords: 40"
2018-04-20 02:45:49,996 (dqn_main.py:212) DEBUG: "Episode 150000, mean reward over last 10000 episodes: 13.71269999999998"
2018-04-20 02:45:49,996 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 02:45:49,996 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (2, 2), (3, 1), (3, 2), (3, 3), (2, 3), (2, 4), (3, 4), (4, 4), (4, 5), (3, 5), (2, 5), (2, 6), (2, 7), (3, 6), (4, 6), (4, 7), (5, 7), (6, 7), (6, 6), (5, 6), (5, 5), (6, 5), (6, 4), (7, 4), (7, 5), (8, 5), (8, 6), (9, 5), (9, 4)], reward: 25.099999999999987, done: True"
2018-04-20 02:45:49,996 (dqn_main.py:215) DEBUG: "Steps: 30, coords: 40"
2018-04-20 03:04:12,281 (dqn_main.py:212) DEBUG: "Episode 160000, mean reward over last 10000 episodes: 16.84200999999998"
2018-04-20 03:04:12,281 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 03:04:12,282 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (2, 3), (2, 4), (3, 4), (3, 3), (4, 4), (4, 5), (3, 5), (2, 5), (2, 6), (3, 6), (4, 6), (4, 7), (5, 7), (6, 7), (6, 6), (5, 6), (5, 5), (6, 5), (6, 4), (7, 4)], reward: 19.9, done: True"
2018-04-20 03:04:12,282 (dqn_main.py:215) DEBUG: "Steps: 24, coords: 40"
2018-04-20 03:21:52,607 (dqn_main.py:212) DEBUG: "Episode 170000, mean reward over last 10000 episodes: 18.04867999999998"
2018-04-20 03:21:52,608 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 03:21:52,608 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (3, 3), (2, 3), (2, 2), (2, 4), (3, 4), (4, 4), (4, 5), (3, 5), (2, 5), (2, 6), (3, 6), (4, 6), (4, 7), (5, 7)], reward: 14.000000000000005, done: True"
2018-04-20 03:21:52,608 (dqn_main.py:215) DEBUG: "Steps: 17, coords: 40"
2018-04-20 03:39:16,556 (dqn_main.py:212) DEBUG: "Episode 180000, mean reward over last 10000 episodes: 18.124399999999984"
2018-04-20 03:39:16,557 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 03:39:16,557 (dqn_main.py:214) DEBUG: "RL steps: [(3, 1), (2, 1), (2, 2), (2, 3), (3, 2), (3, 3), (2, 4), (3, 4), (4, 4), (4, 5), (3, 5), (2, 5), (2, 6), (3, 6), (4, 6), (4, 7)], reward: 12.100000000000005, done: True"
2018-04-20 03:39:16,557 (dqn_main.py:215) DEBUG: "Steps: 16, coords: 40"
2018-04-20 03:56:18,055 (dqn_main.py:212) DEBUG: "Episode 190000, mean reward over last 10000 episodes: 18.75642999999998"
2018-04-20 03:56:18,055 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 03:56:18,055 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 2), (3, 1), (2, 2), (2, 3), (3, 3), (3, 4), (2, 4), (4, 4), (4, 5), (3, 5), (2, 5), (2, 6), (2, 7), (3, 6), (4, 6), (4, 7), (5, 7), (6, 6), (6, 7), (5, 6), (5, 5), (6, 5), (6, 4), (7, 4), (7, 5), (8, 6), (8, 5), (9, 5), (8, 4), (9, 4), (9, 3), (8, 3), (7, 3), (7, 6), (7, 7), (3, 7), (3, 8), (4, 8), (5, 8)], reward: 32.89999999999994, done: True"
2018-04-20 03:56:18,055 (dqn_main.py:215) DEBUG: "Steps: 40, coords: 40"
2018-04-20 03:56:18,463 (tsp_computer.py:36) DEBUG: "tour"
2018-04-20 03:56:18,463 (dqn_main.py:217) DEBUG: "tsp_cost 42"
2018-04-20 04:13:02,974 (dqn_main.py:212) DEBUG: "Episode 200000, mean reward over last 10000 episodes: 18.693169999999984"
2018-04-20 04:13:02,974 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 04:13:02,974 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (2, 3), (3, 3), (2, 4), (3, 4), (4, 4), (4, 5), (3, 5), (2, 5), (2, 6), (2, 7), (3, 6), (4, 6), (4, 7), (4, 8), (5, 7), (6, 7), (6, 6), (5, 6), (5, 5), (6, 5), (6, 4), (7, 4), (7, 5), (8, 5), (8, 6), (9, 5), (9, 4), (9, 3), (8, 3), (7, 3), (8, 4), (7, 6), (7, 7), (3, 7), (3, 8), (5, 8)], reward: 33.59999999999996, done: True"
2018-04-20 04:13:02,974 (dqn_main.py:215) DEBUG: "Steps: 40, coords: 40"
2018-04-20 04:13:03,344 (tsp_computer.py:36) DEBUG: "tour"
2018-04-20 04:13:03,345 (dqn_main.py:217) DEBUG: "tsp_cost 42"
2018-04-20 04:30:11,462 (dqn_main.py:212) DEBUG: "Episode 210000, mean reward over last 10000 episodes: 19.04100999999998"
2018-04-20 04:30:11,463 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 04:30:11,463 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (2, 2), (3, 1), (3, 2), (3, 3), (2, 3), (2, 4), (3, 4), (4, 4), (4, 5), (3, 5), (2, 5)], reward: 9.3, done: True"
2018-04-20 04:30:11,463 (dqn_main.py:215) DEBUG: "Steps: 12, coords: 40"
2018-04-20 04:47:10,335 (dqn_main.py:212) DEBUG: "Episode 220000, mean reward over last 10000 episodes: 18.512449999999987"
2018-04-20 04:47:10,336 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 04:47:10,336 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (2, 2), (3, 2), (3, 3), (2, 3), (2, 4), (3, 4), (4, 4), (4, 5), (3, 5), (2, 5), (2, 6), (2, 7), (3, 6), (4, 6), (4, 7)], reward: 13.900000000000004, done: True"
2018-04-20 04:47:10,336 (dqn_main.py:215) DEBUG: "Steps: 17, coords: 40"
2018-04-20 05:04:03,982 (dqn_main.py:212) DEBUG: "Episode 230000, mean reward over last 10000 episodes: 18.875109999999985"
2018-04-20 05:04:03,983 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 05:04:03,983 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (2, 2), (3, 2), (3, 1), (3, 3), (2, 3), (2, 4), (3, 4), (3, 5), (4, 5), (4, 4), (2, 5), (2, 6), (2, 7), (3, 6), (4, 6), (4, 7), (5, 7), (6, 7), (6, 6), (5, 6), (5, 5), (6, 5), (6, 4), (7, 4), (7, 5), (8, 5), (8, 4), (8, 6)], reward: 22.19999999999999, done: True"
2018-04-20 05:04:03,983 (dqn_main.py:215) DEBUG: "Steps: 29, coords: 40"
2018-04-20 05:21:00,731 (dqn_main.py:212) DEBUG: "Episode 240000, mean reward over last 10000 episodes: 18.641769999999983"
2018-04-20 05:21:00,731 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 05:21:00,731 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (2, 3), (3, 3), (2, 4), (3, 4), (4, 4), (4, 5), (3, 5), (2, 5), (2, 6), (3, 6), (4, 6), (2, 7), (4, 7), (5, 7), (6, 7), (6, 6), (5, 6), (5, 5), (6, 5), (6, 4), (8, 4), (7, 5), (8, 6), (8, 5), (9, 5), (9, 4), (9, 3), (8, 3), (7, 3), (7, 4), (7, 6), (7, 7), (3, 7), (3, 8), (4, 8), (5, 8)], reward: 32.89999999999995, done: True"
2018-04-20 05:21:00,731 (dqn_main.py:215) DEBUG: "Steps: 40, coords: 40"
2018-04-20 05:21:00,923 (tsp_computer.py:36) DEBUG: "tour"
2018-04-20 05:21:00,923 (dqn_main.py:217) DEBUG: "tsp_cost 42"
2018-04-20 05:38:31,965 (dqn_main.py:212) DEBUG: "Episode 250000, mean reward over last 10000 episodes: 17.833379999999988"
2018-04-20 05:38:31,965 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 05:38:31,965 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (2, 2), (3, 2), (3, 3), (2, 3), (2, 4), (3, 4), (4, 4), (4, 5), (3, 5), (2, 5), (2, 7), (2, 6), (3, 6), (4, 6), (4, 7), (5, 7), (6, 7), (6, 6), (5, 6), (5, 5), (6, 5), (6, 4), (7, 4), (7, 5), (8, 5), (8, 6), (9, 5)], reward: 24.19999999999999, done: True"
2018-04-20 05:38:31,965 (dqn_main.py:215) DEBUG: "Steps: 29, coords: 40"
2018-04-20 05:55:14,569 (dqn_main.py:212) DEBUG: "Episode 260000, mean reward over last 10000 episodes: 18.95280999999998"
2018-04-20 05:55:14,569 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 05:55:14,569 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (2, 2), (3, 2), (3, 3), (2, 3), (2, 4), (3, 4), (4, 4), (4, 5), (3, 5), (2, 5), (2, 6), (2, 7), (3, 6), (4, 6), (4, 8), (4, 7), (5, 7), (6, 7), (6, 6), (5, 6), (5, 5), (6, 5), (6, 4), (7, 4), (7, 5), (8, 6), (8, 5), (9, 5), (9, 4), (9, 3), (8, 3), (8, 4), (7, 3), (7, 6), (7, 7), (3, 7), (3, 8), (5, 8)], reward: 33.299999999999955, done: True"
2018-04-20 05:55:14,570 (dqn_main.py:215) DEBUG: "Steps: 40, coords: 40"
2018-04-20 05:55:14,778 (tsp_computer.py:36) DEBUG: "tour"
2018-04-20 05:55:14,778 (dqn_main.py:217) DEBUG: "tsp_cost 42"
2018-04-20 06:12:06,151 (dqn_main.py:212) DEBUG: "Episode 270000, mean reward over last 10000 episodes: 19.24135999999998"
2018-04-20 06:12:06,151 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 06:12:06,151 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (3, 3), (2, 3), (2, 2), (2, 4), (3, 4), (4, 4), (4, 5), (4, 6), (3, 5), (2, 5), (2, 6), (2, 7), (3, 6), (4, 7), (3, 7), (5, 7), (5, 6), (5, 5), (6, 5), (6, 6), (6, 7), (6, 4), (7, 4), (7, 5), (8, 6), (8, 5), (9, 5), (9, 4), (9, 3), (8, 3), (8, 4), (7, 3), (7, 6), (7, 7), (4, 8), (3, 8), (5, 8)], reward: 33.89999999999996, done: True"
2018-04-20 06:12:06,151 (dqn_main.py:215) DEBUG: "Steps: 40, coords: 40"
2018-04-20 06:12:06,397 (tsp_computer.py:36) DEBUG: "tour"
2018-04-20 06:12:06,397 (dqn_main.py:217) DEBUG: "tsp_cost 42"
2018-04-20 06:28:54,043 (dqn_main.py:212) DEBUG: "Episode 280000, mean reward over last 10000 episodes: 19.04627999999998"
2018-04-20 06:28:54,043 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 06:28:54,043 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (2, 2), (3, 2), (3, 3), (2, 3), (3, 4), (2, 4), (4, 4), (4, 5), (3, 5), (2, 5), (2, 6), (3, 6), (4, 6), (4, 8), (4, 7), (5, 7), (6, 7), (6, 6), (5, 6), (5, 5), (6, 5), (6, 4), (7, 4), (7, 5), (8, 5), (8, 6), (9, 5), (9, 4), (9, 3), (8, 3), (8, 4), (7, 3), (7, 6), (7, 7), (3, 7), (2, 7), (3, 8), (5, 8)], reward: 33.59999999999996, done: True"
2018-04-20 06:28:54,043 (dqn_main.py:215) DEBUG: "Steps: 40, coords: 40"
2018-04-20 06:28:54,200 (tsp_computer.py:36) DEBUG: "tour"
2018-04-20 06:28:54,200 (dqn_main.py:217) DEBUG: "tsp_cost 42"
2018-04-20 06:45:55,671 (dqn_main.py:212) DEBUG: "Episode 290000, mean reward over last 10000 episodes: 19.165009999999985"
2018-04-20 06:45:55,671 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 06:45:55,671 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (3, 3), (2, 2), (2, 3), (2, 4), (3, 4), (4, 4), (4, 5), (3, 5), (2, 5), (2, 6), (3, 6), (4, 6), (5, 7), (4, 8), (4, 7), (5, 6), (6, 7), (6, 6), (5, 5), (6, 5), (6, 4), (7, 4), (7, 5), (8, 5), (8, 6), (9, 4), (9, 5), (9, 3), (8, 3), (7, 3)], reward: 26.29999999999998, done: True"
2018-04-20 06:45:55,671 (dqn_main.py:215) DEBUG: "Steps: 33, coords: 40"
2018-04-20 07:02:13,457 (dqn_main.py:212) DEBUG: "Episode 300000, mean reward over last 10000 episodes: 19.10059999999998"
2018-04-20 07:02:13,457 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 07:02:13,457 (dqn_main.py:214) DEBUG: "RL steps: [(2, 2), (2, 1), (3, 1), (3, 2), (3, 3), (2, 3), (2, 4), (3, 4), (4, 4), (4, 5), (3, 5), (2, 5), (2, 6), (3, 6), (4, 6), (4, 7), (5, 7), (6, 7), (6, 6), (5, 6), (5, 5), (6, 5), (6, 4), (7, 4), (7, 5), (8, 5), (8, 6), (9, 5), (9, 4), (9, 3), (8, 3), (7, 3), (8, 4), (7, 6), (7, 7), (3, 7), (2, 7), (3, 8), (4, 8), (5, 8)], reward: 34.39999999999996, done: True"
2018-04-20 07:02:13,457 (dqn_main.py:215) DEBUG: "Steps: 40, coords: 40"
2018-04-20 07:02:13,724 (tsp_computer.py:36) DEBUG: "tour"
2018-04-20 07:02:13,724 (dqn_main.py:217) DEBUG: "tsp_cost 42"
2018-04-20 07:19:07,479 (dqn_main.py:212) DEBUG: "Episode 310000, mean reward over last 10000 episodes: 19.244629999999983"
2018-04-20 07:19:07,479 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 07:19:07,479 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (2, 3), (3, 3), (3, 4), (2, 4), (4, 4), (4, 5), (3, 5), (2, 5), (2, 6), (2, 7), (3, 7), (3, 6), (4, 6), (4, 7), (5, 7), (6, 7), (6, 6), (5, 6), (5, 5), (6, 5), (6, 4), (7, 4), (7, 5), (8, 6), (8, 5), (9, 5), (8, 4), (9, 4), (9, 3), (8, 3), (7, 3), (7, 6), (7, 7), (4, 8), (3, 8), (5, 8)], reward: 33.899999999999956, done: True"
2018-04-20 07:19:07,479 (dqn_main.py:215) DEBUG: "Steps: 40, coords: 40"
2018-04-20 07:19:07,725 (tsp_computer.py:36) DEBUG: "tour"
2018-04-20 07:19:07,726 (dqn_main.py:217) DEBUG: "tsp_cost 42"
2018-04-20 07:36:15,257 (dqn_main.py:212) DEBUG: "Episode 320000, mean reward over last 10000 episodes: 19.45722999999998"
2018-04-20 07:36:15,258 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 07:36:15,258 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (2, 2), (3, 2), (3, 3), (2, 3), (2, 4), (3, 4), (4, 4), (4, 6), (4, 5), (3, 5), (2, 5), (2, 6), (2, 7), (3, 7), (3, 6), (4, 7), (5, 7), (6, 7), (6, 6), (5, 6), (5, 5), (6, 5), (6, 4), (7, 4), (7, 5), (7, 6), (8, 6), (8, 5), (9, 5), (9, 4), (9, 3), (8, 3), (8, 4), (7, 3), (7, 7), (4, 8), (3, 8), (5, 8)], reward: 33.899999999999956, done: True"
2018-04-20 07:36:15,258 (dqn_main.py:215) DEBUG: "Steps: 40, coords: 40"
2018-04-20 07:36:15,487 (tsp_computer.py:36) DEBUG: "tour"
2018-04-20 07:36:15,487 (dqn_main.py:217) DEBUG: "tsp_cost 42"
2018-04-20 07:53:28,232 (dqn_main.py:212) DEBUG: "Episode 330000, mean reward over last 10000 episodes: 19.303489999999986"
2018-04-20 07:53:28,232 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 07:53:28,232 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (2, 3), (2, 4), (3, 4), (3, 3), (4, 4), (4, 5), (4, 6), (3, 6), (3, 5), (2, 5), (2, 6), (2, 7), (3, 7), (4, 7), (5, 7), (6, 7), (6, 6), (5, 6), (5, 5), (6, 5), (6, 4), (7, 4), (7, 5), (8, 6), (8, 5), (9, 5), (9, 4), (9, 3), (8, 3), (8, 4), (7, 3), (7, 6), (7, 7), (4, 8), (3, 8), (5, 8)], reward: 33.49999999999996, done: True"
2018-04-20 07:53:28,232 (dqn_main.py:215) DEBUG: "Steps: 40, coords: 40"
2018-04-20 07:53:28,410 (tsp_computer.py:36) DEBUG: "tour"
2018-04-20 07:53:28,410 (dqn_main.py:217) DEBUG: "tsp_cost 42"
2018-04-20 08:10:36,592 (dqn_main.py:212) DEBUG: "Episode 340000, mean reward over last 10000 episodes: 19.434649999999984"
2018-04-20 08:10:36,592 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 08:10:36,592 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (2, 4)], reward: 3.0999999999999996, done: True"
2018-04-20 08:10:36,592 (dqn_main.py:215) DEBUG: "Steps: 5, coords: 40"
2018-04-20 08:27:31,752 (dqn_main.py:212) DEBUG: "Episode 350000, mean reward over last 10000 episodes: 19.531119999999984"
2018-04-20 08:27:31,752 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 08:27:31,752 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2)], reward: 1.4, done: True"
2018-04-20 08:27:31,752 (dqn_main.py:215) DEBUG: "Steps: 3, coords: 40"
2018-04-20 08:44:37,591 (dqn_main.py:212) DEBUG: "Episode 360000, mean reward over last 10000 episodes: 19.642119999999984"
2018-04-20 08:44:37,591 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 08:44:37,591 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (3, 3), (2, 3), (2, 2), (2, 4), (2, 5), (3, 5), (3, 4), (4, 4), (4, 5), (4, 6), (3, 6), (2, 7), (2, 6), (3, 7), (4, 7), (5, 7), (6, 7), (6, 6), (5, 6), (5, 5), (6, 4), (6, 5), (7, 5), (8, 5), (8, 6), (9, 5), (9, 4), (9, 3), (8, 3), (7, 3), (7, 4), (8, 4)], reward: 28.49999999999998, done: True"
2018-04-20 08:44:37,591 (dqn_main.py:215) DEBUG: "Steps: 35, coords: 40"
2018-04-20 09:01:10,341 (dqn_main.py:212) DEBUG: "Episode 370000, mean reward over last 10000 episodes: 19.431319999999985"
2018-04-20 09:01:10,341 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 09:01:10,341 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (2, 2), (3, 2), (3, 3), (2, 3), (2, 4), (2, 5), (3, 5), (3, 4), (4, 4), (4, 5), (4, 6), (3, 6), (2, 6), (2, 7), (3, 7), (4, 7), (5, 7), (6, 7), (5, 6), (5, 5), (6, 6), (6, 5), (6, 4), (7, 4), (7, 5), (7, 6), (8, 6), (8, 5), (9, 5), (9, 4), (8, 4), (9, 3), (8, 3), (7, 3), (7, 7), (5, 8), (4, 8), (3, 8)], reward: 33.89999999999996, done: True"
2018-04-20 09:01:10,341 (dqn_main.py:215) DEBUG: "Steps: 40, coords: 40"
2018-04-20 09:01:10,661 (tsp_computer.py:36) DEBUG: "tour"
2018-04-20 09:01:10,661 (dqn_main.py:217) DEBUG: "tsp_cost 42"
2018-04-20 09:18:07,778 (dqn_main.py:212) DEBUG: "Episode 380000, mean reward over last 10000 episodes: 19.58122999999998"
2018-04-20 09:18:07,779 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 09:18:07,779 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (2, 4), (2, 3), (3, 3), (3, 4), (4, 4), (4, 5), (3, 5), (2, 5), (2, 6), (2, 7), (3, 7), (3, 6), (4, 6), (4, 7), (6, 7), (5, 7), (5, 6), (6, 6), (6, 5), (5, 5), (6, 4), (7, 4), (7, 5), (7, 6), (8, 6), (8, 5), (9, 5), (9, 4), (9, 3), (8, 3), (7, 3), (8, 4), (7, 7), (5, 8), (4, 8), (3, 8)], reward: 33.899999999999956, done: True"
2018-04-20 09:18:07,779 (dqn_main.py:215) DEBUG: "Steps: 40, coords: 40"
2018-04-20 09:18:08,087 (tsp_computer.py:36) DEBUG: "tour"
2018-04-20 09:18:08,087 (dqn_main.py:217) DEBUG: "tsp_cost 42"
2018-04-20 09:27:06,734 (dqn_main.py:61) DEBUG: ">>>> RUNNING data_file=7_17.npy,reuse_weights=None,test=True<<<<"
2018-04-20 09:28:51,955 (dqn_main.py:61) DEBUG: ">>>> RUNNING data_file=7_17.npy,reuse_weights=None,test=True<<<<"
2018-04-20 09:28:52,417 (tf_logging.py:160) Level 1: "Registering Batch (<function _BatchGrad at 0x7f2234134378>) in gradient."
2018-04-20 09:28:52,418 (tf_logging.py:160) Level 1: "Registering Unbatch (<function _UnbatchGrad at 0x7f2234134e18>) in gradient."
2018-04-20 09:28:52,424 (tf_logging.py:160) Level 1: "Registering ZeroInitializer (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,447 (tf_logging.py:160) Level 1: "Registering SparseFeatureCross (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,450 (tf_logging.py:160) Level 1: "Registering SparseFeatureCrossV2 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,456 (tf_logging.py:160) Level 1: "Registering SparseFeatureCross (None) in gradient."
2018-04-20 09:28:52,457 (tf_logging.py:160) Level 1: "Registering SparseFeatureCrossV2 (None) in gradient."
2018-04-20 09:28:52,464 (tf_logging.py:160) Level 1: "Registering GDNLowerBound (<function GDN._lower_bound_grad at 0x7f222c7d76a8>) in gradient."
2018-04-20 09:28:52,490 (tf_logging.py:160) Level 1: "Registering ObtainNext (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,505 (tf_logging.py:160) Level 1: "Registering hparams ((<class 'tensorflow.contrib.training.python.training.hparam_pb2.HParamDef'>, <function HParams.to_proto at 0x7f222c0fd620>, <function HParams.from_proto at 0x7f222c0fd6a8>)) in proto functions."
2018-04-20 09:28:52,515 (tf_logging.py:160) Level 1: "Registering GRUBlockCell (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,517 (tf_logging.py:160) Level 1: "Registering GRUBlockCellGrad (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,520 (tf_logging.py:160) Level 1: "Registering GRUBlockCell (<function _GRUBlockCellGrad at 0x7f222c096b70>) in gradient."
2018-04-20 09:28:52,522 (tf_logging.py:160) Level 1: "Registering BlockLSTM (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,523 (tf_logging.py:160) Level 1: "Registering BlockLSTMGrad (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,524 (tf_logging.py:160) Level 1: "Registering LSTMBlockCell (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,526 (tf_logging.py:160) Level 1: "Registering LSTMBlockCellGrad (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,529 (tf_logging.py:160) Level 1: "Registering LSTMBlockCell (<function _LSTMBlockCellGrad at 0x7f222c05fd90>) in gradient."
2018-04-20 09:28:52,530 (tf_logging.py:160) Level 1: "Registering BlockLSTM (<function _BlockLSTMGrad at 0x7f222c05fe18>) in gradient."
2018-04-20 09:28:52,535 (tf_logging.py:160) Level 1: "Registering KMC2ChainInitialization (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,537 (tf_logging.py:160) Level 1: "Registering KmeansPlusPlusInitialization (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,538 (tf_logging.py:160) Level 1: "Registering NearestNeighbors (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,542 (tf_logging.py:160) Level 1: "Registering MaskedMatmul (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,544 (tf_logging.py:160) Level 1: "Registering WALSComputePartialLhsAndRhs (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,563 (tf_logging.py:160) Level 1: "Registering ConfigureDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,565 (tf_logging.py:160) Level 1: "Registering CrossReplicaSum (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,566 (tf_logging.py:160) Level 1: "Registering InfeedDequeue (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,567 (tf_logging.py:160) Level 1: "Registering InfeedDequeueTuple (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,567 (tf_logging.py:160) Level 1: "Registering InfeedEnqueue (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,568 (tf_logging.py:160) Level 1: "Registering InfeedEnqueueTuple (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,569 (tf_logging.py:160) Level 1: "Registering OutfeedDequeue (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,569 (tf_logging.py:160) Level 1: "Registering OutfeedDequeueTuple (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,570 (tf_logging.py:160) Level 1: "Registering OutfeedEnqueue (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,571 (tf_logging.py:160) Level 1: "Registering OutfeedEnqueueTuple (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,571 (tf_logging.py:160) Level 1: "Registering ShutdownDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,572 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingActivations (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,572 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingEnqueueSparseBatch (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,573 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingLoadAdagradParameters (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,574 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingLoadGradientDescentParameters (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,575 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingReceiveActivations (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,576 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingRetrieveAdagradParameters (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,576 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingRetrieveGradientDescentParameters (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,577 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingSendGradients (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,577 (tf_logging.py:160) Level 1: "Registering TPUReplicate (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,582 (tf_logging.py:160) Level 1: "Registering TPUReplicateMetadata (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,583 (tf_logging.py:160) Level 1: "Registering TPUReplicatedInput (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,583 (tf_logging.py:160) Level 1: "Registering TPUReplicatedOutput (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,589 (tf_logging.py:160) Level 1: "Registering _ConfigureDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,590 (tf_logging.py:160) Level 1: "Registering _WaitForDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,591 (tf_logging.py:160) Level 1: "Registering _SetGlobalTPUArray (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,592 (tf_logging.py:160) Level 1: "Registering _ShutdownDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,592 (tf_logging.py:160) Level 1: "Registering _InitializeHostForDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,593 (tf_logging.py:160) Level 1: "Registering _DisconnectHostFromDistributedTPUSystem (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,595 (tf_logging.py:160) Level 1: "Registering CrossReplicaSum (<function _cross_replica_sum_grad at 0x7f2208116400>) in gradient."
2018-04-20 09:28:52,606 (tf_logging.py:160) Level 1: "Registering CloseSummaryWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,607 (tf_logging.py:160) Level 1: "Registering CreateSummaryDbWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,608 (tf_logging.py:160) Level 1: "Registering CreateSummaryFileWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,609 (tf_logging.py:160) Level 1: "Registering FlushSummaryWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,610 (tf_logging.py:160) Level 1: "Registering ImportEvent (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,610 (tf_logging.py:160) Level 1: "Registering SummaryWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,611 (tf_logging.py:160) Level 1: "Registering WriteAudioSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,612 (tf_logging.py:160) Level 1: "Registering WriteGraphSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,612 (tf_logging.py:160) Level 1: "Registering WriteHistogramSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,613 (tf_logging.py:160) Level 1: "Registering WriteImageSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,614 (tf_logging.py:160) Level 1: "Registering WriteScalarSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,614 (tf_logging.py:160) Level 1: "Registering WriteSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,637 (tf_logging.py:160) Level 1: "Registering BigQueryReader (None) in gradient."
2018-04-20 09:28:52,641 (tf_logging.py:160) Level 1: "Registering RangeDecode (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,642 (tf_logging.py:160) Level 1: "Registering RangeEncode (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,690 (tf_logging.py:160) Level 1: "Registering CudnnRNN (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,692 (tf_logging.py:160) Level 1: "Registering CudnnRNNBackprop (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,692 (tf_logging.py:160) Level 1: "Registering CudnnRNNCanonicalToParams (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,693 (tf_logging.py:160) Level 1: "Registering CudnnRNNParamsSize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,694 (tf_logging.py:160) Level 1: "Registering CudnnRNNParamsToCanonical (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,701 (tf_logging.py:160) Level 1: "Registering CudnnRNN (<function _cudnn_rnn_backward at 0x7f21e65d16a8>) in gradient."
2018-04-20 09:28:52,702 (tf_logging.py:160) Level 1: "Registering CudnnRNNParamsSize (<function call_cpp_shape_fn at 0x7f229f875840>) in shape functions."
2018-04-20 09:28:52,702 (tf_logging.py:160) Level 1: "Registering CudnnRNNParamsToCanonical (<function call_cpp_shape_fn at 0x7f229f875840>) in shape functions."
2018-04-20 09:28:52,702 (tf_logging.py:160) Level 1: "Registering CudnnRNNCanonicalToParams (<function call_cpp_shape_fn at 0x7f229f875840>) in shape functions."
2018-04-20 09:28:52,703 (tf_logging.py:160) Level 1: "Registering CudnnRNN (<function call_cpp_shape_fn at 0x7f229f875840>) in shape functions."
2018-04-20 09:28:52,703 (tf_logging.py:160) Level 1: "Registering CudnnRNNBackprop (<function call_cpp_shape_fn at 0x7f229f875840>) in shape functions."
2018-04-20 09:28:52,741 (tf_logging.py:160) Level 1: "Registering AdjustHsvInYiq (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,745 (tf_logging.py:160) Level 1: "Registering BipartiteMatch (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,745 (tf_logging.py:160) Level 1: "Registering ImageConnectedComponents (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,746 (tf_logging.py:160) Level 1: "Registering ImageProjectiveTransform (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,749 (tf_logging.py:160) Level 1: "Registering ImageConnectedComponents (<function call_cpp_shape_fn at 0x7f229f875840>) in shape functions."
2018-04-20 09:28:52,749 (tf_logging.py:160) Level 1: "Registering ImageProjectiveTransform (<function call_cpp_shape_fn at 0x7f229f875840>) in shape functions."
2018-04-20 09:28:52,749 (tf_logging.py:160) Level 1: "Registering ImageProjectiveTransform (<function _image_projective_transform_grad at 0x7f21e5ef4b70>) in gradient."
2018-04-20 09:28:52,749 (tf_logging.py:160) Level 1: "Registering BipartiteMatch (None) in gradient."
2018-04-20 09:28:52,750 (tf_logging.py:160) Level 1: "Registering ImageConnectedComponents (None) in gradient."
2018-04-20 09:28:52,750 (tf_logging.py:160) Level 1: "Registering SingleImageRandomDotStereograms (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,755 (tf_logging.py:160) Level 1: "Registering SingleImageRandomDotStereograms (None) in gradient."
2018-04-20 09:28:52,798 (tf_logging.py:160) Level 1: "Registering BytesInUse (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,798 (tf_logging.py:160) Level 1: "Registering BytesLimit (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,799 (tf_logging.py:160) Level 1: "Registering MaxBytesInUse (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,805 (tf_logging.py:160) Level 1: "Registering NcclAllReduce (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,805 (tf_logging.py:160) Level 1: "Registering NcclBroadcast (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,806 (tf_logging.py:160) Level 1: "Registering NcclReduce (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,808 (tf_logging.py:160) Level 1: "Registering _NcclReduceSend (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,809 (tf_logging.py:160) Level 1: "Registering _NcclReduceRecv (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,809 (tf_logging.py:160) Level 1: "Registering _NcclBroadcastSend (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,809 (tf_logging.py:160) Level 1: "Registering _NcclBroadcastRecv (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,809 (tf_logging.py:160) Level 1: "Registering NcclAllReduce (<function _all_sum_grad at 0x7f21e55a8950>) in gradient."
2018-04-20 09:28:52,810 (tf_logging.py:160) Level 1: "Registering NcclReduce (<function _reduce_sum_grad at 0x7f21e55a8bf8>) in gradient."
2018-04-20 09:28:52,810 (tf_logging.py:160) Level 1: "Registering NcclBroadcast (<function _broadcast_grad at 0x7f21e55a8d90>) in gradient."
2018-04-20 09:28:52,811 (tf_logging.py:160) Level 1: "Registering PeriodicResample (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,818 (tf_logging.py:160) Level 1: "Registering FoldFusedBatchNormGrad (<function _FoldFusedBatchNormGrad at 0x7f21e52ed048>) in gradient."
2018-04-20 09:28:52,821 (tf_logging.py:160) Level 1: "Registering Resampler (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,823 (tf_logging.py:160) Level 1: "Registering ResamplerGrad (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,825 (tf_logging.py:160) Level 1: "Registering Resampler (<function _resampler_grad at 0x7f21e501ac80>) in gradient."
2018-04-20 09:28:52,825 (tf_logging.py:160) Level 1: "Registering ResamplerGrad (None) in gradient."
2018-04-20 09:28:52,831 (tf_logging.py:160) Level 1: "Registering GatherTree (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,846 (tf_logging.py:160) Level 1: "Registering StatelessRandomNormal (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,847 (tf_logging.py:160) Level 1: "Registering StatelessRandomUniform (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,847 (tf_logging.py:160) Level 1: "Registering StatelessTruncatedNormal (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,848 (tf_logging.py:160) Level 1: "Registering StatelessRandomNormal (None) in gradient."
2018-04-20 09:28:52,848 (tf_logging.py:160) Level 1: "Registering StatelessRandomUniform (None) in gradient."
2018-04-20 09:28:52,849 (tf_logging.py:160) Level 1: "Registering StatelessTruncatedNormal (None) in gradient."
2018-04-20 09:28:52,859 (tf_logging.py:160) Level 1: "Registering ReinterpretStringToFloat (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,861 (tf_logging.py:160) Level 1: "Registering ScatterAddNdim (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,869 (tf_logging.py:160) Level 1: "Registering CreateTreeVariable (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,882 (tf_logging.py:160) Level 1: "Registering DecisionTreeResourceHandleOp (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,897 (tf_logging.py:160) Level 1: "Registering FeatureUsageCounts (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,898 (tf_logging.py:160) Level 1: "Registering TraverseTreeV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,898 (tf_logging.py:160) Level 1: "Registering TreeDeserialize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,899 (tf_logging.py:160) Level 1: "Registering TreeIsInitializedOp (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,899 (tf_logging.py:160) Level 1: "Registering TreePredictionsV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,900 (tf_logging.py:160) Level 1: "Registering TreeSerialize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,901 (tf_logging.py:160) Level 1: "Registering TreeSize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,901 (tf_logging.py:160) Level 1: "Registering UpdateModelV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,907 (tf_logging.py:160) Level 1: "Registering TreeVariable (None) in gradient."
2018-04-20 09:28:52,908 (tf_logging.py:160) Level 1: "Registering TreeSerialize (None) in gradient."
2018-04-20 09:28:52,908 (tf_logging.py:160) Level 1: "Registering TreeDeserialize (None) in gradient."
2018-04-20 09:28:52,908 (tf_logging.py:160) Level 1: "Registering TreeSize (None) in gradient."
2018-04-20 09:28:52,909 (tf_logging.py:160) Level 1: "Registering TreePredictionsV4 (None) in gradient."
2018-04-20 09:28:52,909 (tf_logging.py:160) Level 1: "Registering FeatureUsageCounts (None) in gradient."
2018-04-20 09:28:52,910 (tf_logging.py:160) Level 1: "Registering CreateFertileStatsVariable (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,912 (tf_logging.py:160) Level 1: "Registering FertileStatsDeserialize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,914 (tf_logging.py:160) Level 1: "Registering FertileStatsIsInitializedOp (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,915 (tf_logging.py:160) Level 1: "Registering FertileStatsResourceHandleOp (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,916 (tf_logging.py:160) Level 1: "Registering FertileStatsSerialize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,917 (tf_logging.py:160) Level 1: "Registering FinalizeTree (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,918 (tf_logging.py:160) Level 1: "Registering GrowTreeV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,919 (tf_logging.py:160) Level 1: "Registering ProcessInputV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,924 (tf_logging.py:160) Level 1: "Registering FertileStatsVariable (None) in gradient."
2018-04-20 09:28:52,927 (tf_logging.py:160) Level 1: "Registering FertileStatsSerialize (None) in gradient."
2018-04-20 09:28:52,928 (tf_logging.py:160) Level 1: "Registering FertileStatsDeserialize (None) in gradient."
2018-04-20 09:28:52,929 (tf_logging.py:160) Level 1: "Registering GrowTreeV4 (None) in gradient."
2018-04-20 09:28:52,930 (tf_logging.py:160) Level 1: "Registering ProcessInputV4 (None) in gradient."
2018-04-20 09:28:52,931 (tf_logging.py:160) Level 1: "Registering FinalizeTree (None) in gradient."
2018-04-20 09:28:52,966 (tf_logging.py:160) Level 1: "Registering FunctionBufferingResource (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,967 (tf_logging.py:160) Level 1: "Registering FunctionBufferingResourceGetNext (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,978 (tf_logging.py:160) Level 1: "Registering RemoteFusedGraphExecute (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,979 (tf_logging.py:160) Level 1: "Registering RemoteFusedGraphExecute (None) in gradient."
2018-04-20 09:28:52,990 (tf_logging.py:160) Level 1: "Created variable q/Conv/weights:0 with shape (1, 1, 2, 8) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f222c7ce510>"
2018-04-20 09:28:52,993 (tf_logging.py:160) Level 1: "Created variable q/Conv/biases:0 with shape (8,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f222c7d31d0>"
2018-04-20 09:28:53,001 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/weights:0 with shape (3, 3, 8, 12) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f222c7ce510>"
2018-04-20 09:28:53,005 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/biases:0 with shape (12,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f222c7d31d0>"
2018-04-20 09:28:53,012 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/weights:0 with shape (3, 3, 12, 16) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f222c7ce510>"
2018-04-20 09:28:53,016 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/biases:0 with shape (16,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f222c7d31d0>"
2018-04-20 09:28:53,027 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/weights:0 with shape (576, 128) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f222c7d72f0>"
2018-04-20 09:28:53,030 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/biases:0 with shape (128,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f222c7d35c0>"
2018-04-20 09:28:53,037 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/weights:0 with shape (128, 5) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f222c7d72f0>"
2018-04-20 09:28:53,040 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/biases:0 with shape (5,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f222c7d35c0>"
2018-04-20 09:28:53,047 (tf_logging.py:160) Level 1: "Created variable target_q/Conv/weights:0 with shape (1, 1, 2, 8) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f222c7ce510>"
2018-04-20 09:28:53,051 (tf_logging.py:160) Level 1: "Created variable target_q/Conv/biases:0 with shape (8,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f222c7d31d0>"
2018-04-20 09:28:53,058 (tf_logging.py:160) Level 1: "Created variable target_q/Conv_1/weights:0 with shape (3, 3, 8, 12) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f222c7ce510>"
2018-04-20 09:28:53,062 (tf_logging.py:160) Level 1: "Created variable target_q/Conv_1/biases:0 with shape (12,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f222c7d31d0>"
2018-04-20 09:28:53,069 (tf_logging.py:160) Level 1: "Created variable target_q/Conv_2/weights:0 with shape (3, 3, 12, 16) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f222c7ce510>"
2018-04-20 09:28:53,073 (tf_logging.py:160) Level 1: "Created variable target_q/Conv_2/biases:0 with shape (16,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f222c7d31d0>"
2018-04-20 09:28:53,085 (tf_logging.py:160) Level 1: "Created variable target_q/fully_connected/weights:0 with shape (576, 128) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f222c7d72f0>"
2018-04-20 09:28:53,089 (tf_logging.py:160) Level 1: "Created variable target_q/fully_connected/biases:0 with shape (128,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f222c7d35c0>"
2018-04-20 09:28:53,096 (tf_logging.py:160) Level 1: "Created variable target_q/fully_connected_1/weights:0 with shape (128, 5) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f222c7d72f0>"
2018-04-20 09:28:53,099 (tf_logging.py:160) Level 1: "Created variable target_q/fully_connected_1/biases:0 with shape (5,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f222c7d35c0>"
2018-04-20 09:28:53,130 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/value'"
2018-04-20 09:28:53,130 (tf_logging.py:160) Level 1: "  in  --> gradients/Fill:0"
2018-04-20 09:28:53,130 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/value_grad/tuple/control_dependency:0, gradients/mean_squared_error/value_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,137 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/div'"
2018-04-20 09:28:53,137 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/value_grad/tuple/control_dependency:0"
2018-04-20 09:28:53,137 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/div_grad/tuple/control_dependency:0, gradients/mean_squared_error/div_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,140 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/Sum_1'"
2018-04-20 09:28:53,140 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/div_grad/tuple/control_dependency:0"
2018-04-20 09:28:53,140 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/Sum_1_grad/Tile:0"
2018-04-20 09:28:53,144 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/Select'"
2018-04-20 09:28:53,144 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/div_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,144 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/Select_grad/tuple/control_dependency:0, gradients/mean_squared_error/Select_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,146 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/Sum'"
2018-04-20 09:28:53,147 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/Sum_1_grad/Tile:0"
2018-04-20 09:28:53,147 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/Sum_grad/Tile:0"
2018-04-20 09:28:53,153 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/Mul'"
2018-04-20 09:28:53,153 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/Sum_grad/Tile:0"
2018-04-20 09:28:53,154 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/Mul_grad/tuple/control_dependency:0, gradients/mean_squared_error/Mul_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,156 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/num_present'"
2018-04-20 09:28:53,156 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/Select_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,157 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/num_present_grad/Tile:0"
2018-04-20 09:28:53,163 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/num_present/broadcast_weights'"
2018-04-20 09:28:53,163 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/num_present_grad/Tile:0"
2018-04-20 09:28:53,163 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/num_present/broadcast_weights_grad/tuple/control_dependency:0, gradients/mean_squared_error/num_present/broadcast_weights_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,164 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/num_present/broadcast_weights/ones_like'"
2018-04-20 09:28:53,165 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/num_present/broadcast_weights_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,165 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/num_present/broadcast_weights/ones_like_grad/Sum:0"
2018-04-20 09:28:53,172 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/SquaredDifference'"
2018-04-20 09:28:53,172 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/Mul_grad/tuple/control_dependency:0"
2018-04-20 09:28:53,172 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/SquaredDifference_grad/tuple/control_dependency:0, gradients/mean_squared_error/SquaredDifference_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,180 (tf_logging.py:160) Level 1: "Gradient for 'Sum'"
2018-04-20 09:28:53,180 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/SquaredDifference_grad/tuple/control_dependency:0"
2018-04-20 09:28:53,181 (tf_logging.py:160) Level 1: "  out --> gradients/Sum_grad/Tile:0"
2018-04-20 09:28:53,186 (tf_logging.py:160) Level 1: "Gradient for 'mul'"
2018-04-20 09:28:53,187 (tf_logging.py:160) Level 1: "  in  --> gradients/Sum_grad/Tile:0"
2018-04-20 09:28:53,187 (tf_logging.py:160) Level 1: "  out --> gradients/mul_grad/tuple/control_dependency:0, gradients/mul_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,189 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected_1/BiasAdd'"
2018-04-20 09:28:53,189 (tf_logging.py:160) Level 1: "  in  --> gradients/mul_grad/tuple/control_dependency:0"
2018-04-20 09:28:53,189 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency:0, gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,192 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected_1/MatMul'"
2018-04-20 09:28:53,192 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 09:28:53,192 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency:0, gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,193 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected_1/biases/read'"
2018-04-20 09:28:53,193 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,193 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,193 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/Relu'"
2018-04-20 09:28:53,194 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency:0"
2018-04-20 09:28:53,194 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/Relu_grad/ReluGrad:0"
2018-04-20 09:28:53,194 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected_1/weights/read'"
2018-04-20 09:28:53,194 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,194 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,196 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/BiasAdd'"
2018-04-20 09:28:53,196 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/Relu_grad/ReluGrad:0"
2018-04-20 09:28:53,196 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency:0, gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,198 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/MatMul'"
2018-04-20 09:28:53,199 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 09:28:53,199 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/MatMul_grad/tuple/control_dependency:0, gradients/q/fully_connected/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,199 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/biases/read'"
2018-04-20 09:28:53,199 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,199 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,200 (tf_logging.py:160) Level 1: "Gradient for 'q/Flatten/flatten/Reshape'"
2018-04-20 09:28:53,200 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/MatMul_grad/tuple/control_dependency:0"
2018-04-20 09:28:53,200 (tf_logging.py:160) Level 1: "  out --> gradients/q/Flatten/flatten/Reshape_grad/Reshape:0"
2018-04-20 09:28:53,201 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/weights/read'"
2018-04-20 09:28:53,201 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,201 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,202 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/Relu'"
2018-04-20 09:28:53,202 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Flatten/flatten/Reshape_grad/Reshape:0"
2018-04-20 09:28:53,202 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/Relu_grad/ReluGrad:0"
2018-04-20 09:28:53,203 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/BiasAdd'"
2018-04-20 09:28:53,204 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/Relu_grad/ReluGrad:0"
2018-04-20 09:28:53,204 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency:0, gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,208 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/Conv2D'"
2018-04-20 09:28:53,208 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 09:28:53,208 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency:0, gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,208 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/biases/read'"
2018-04-20 09:28:53,208 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,208 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,209 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/Relu'"
2018-04-20 09:28:53,209 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency:0"
2018-04-20 09:28:53,209 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/Relu_grad/ReluGrad:0"
2018-04-20 09:28:53,209 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/weights/read'"
2018-04-20 09:28:53,209 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,210 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,211 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/BiasAdd'"
2018-04-20 09:28:53,212 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/Relu_grad/ReluGrad:0"
2018-04-20 09:28:53,212 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency:0, gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,216 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/Conv2D'"
2018-04-20 09:28:53,217 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 09:28:53,217 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency:0, gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,217 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/biases/read'"
2018-04-20 09:28:53,217 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,217 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,218 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/Relu'"
2018-04-20 09:28:53,218 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency:0"
2018-04-20 09:28:53,218 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/Relu_grad/ReluGrad:0"
2018-04-20 09:28:53,218 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/weights/read'"
2018-04-20 09:28:53,218 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,218 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,220 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/BiasAdd'"
2018-04-20 09:28:53,220 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv/Relu_grad/ReluGrad:0"
2018-04-20 09:28:53,220 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/BiasAdd_grad/tuple/control_dependency:0, gradients/q/Conv/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,224 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/Conv2D'"
2018-04-20 09:28:53,225 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 09:28:53,225 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/Conv2D_grad/tuple/control_dependency:0, gradients/q/Conv/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,225 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/biases/read'"
2018-04-20 09:28:53,225 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,225 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,225 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/weights/read'"
2018-04-20 09:28:53,225 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,226 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,300 (tf_logging.py:126) WARNING: "From /home/syedeqbal/.local/lib/python3.5/site-packages/tensorflow/python/ops/clip_ops.py:113: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead"
2018-04-20 09:28:53,332 (tf_logging.py:160) Level 1: "Created variable q/Conv/weights/Adam:0 with shape (1, 1, 2, 8) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f21c20f3320>"
2018-04-20 09:28:53,334 (tf_logging.py:160) Level 1: "Created variable q/Conv/weights/Adam_1:0 with shape (1, 1, 2, 8) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f21c20f3320>"
2018-04-20 09:28:53,337 (tf_logging.py:160) Level 1: "Created variable q/Conv/biases/Adam:0 with shape (8,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f21c20f3320>"
2018-04-20 09:28:53,340 (tf_logging.py:160) Level 1: "Created variable q/Conv/biases/Adam_1:0 with shape (8,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f21c20f3320>"
2018-04-20 09:28:53,343 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/weights/Adam:0 with shape (3, 3, 8, 12) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f21c20f3320>"
2018-04-20 09:28:53,346 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/weights/Adam_1:0 with shape (3, 3, 8, 12) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f21c20f3320>"
2018-04-20 09:28:53,348 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/biases/Adam:0 with shape (12,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f21c20f3320>"
2018-04-20 09:28:53,351 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/biases/Adam_1:0 with shape (12,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f21c20f3320>"
2018-04-20 09:28:53,354 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/weights/Adam:0 with shape (3, 3, 12, 16) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f21c20f3320>"
2018-04-20 09:28:53,356 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/weights/Adam_1:0 with shape (3, 3, 12, 16) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f21c20b0f28>"
2018-04-20 09:28:53,359 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/biases/Adam:0 with shape (16,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f21c20b0f28>"
2018-04-20 09:28:53,362 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/biases/Adam_1:0 with shape (16,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f21c20b0f28>"
2018-04-20 09:28:53,364 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/weights/Adam:0 with shape (576, 128) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f21c20b0f28>"
2018-04-20 09:28:53,367 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/weights/Adam_1:0 with shape (576, 128) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f21c20b0f28>"
2018-04-20 09:28:53,369 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/biases/Adam:0 with shape (128,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f21c20b0f28>"
2018-04-20 09:28:53,372 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/biases/Adam_1:0 with shape (128,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f21c20b0f28>"
2018-04-20 09:28:53,375 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/weights/Adam:0 with shape (128, 5) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f21c20b0f28>"
2018-04-20 09:28:53,377 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/weights/Adam_1:0 with shape (128, 5) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f21c20b0f28>"
2018-04-20 09:28:53,379 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/biases/Adam:0 with shape (5,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f21c20b0f28>"
2018-04-20 09:28:53,382 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/biases/Adam_1:0 with shape (5,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f21c20b0f28>"
2018-04-20 09:28:53,533 (dqn_agent.py:161) DEBUG: "var_name: q/Conv/weights:0, var_value [[[[ 0.07914811  0.4790275   0.7519878   0.30090177 -0.7116133
    -0.38285536 -0.17304963 -0.67449665]
   [-0.32940283  0.5482898  -0.11913466 -0.7408853  -0.11541724
    -0.28320834  0.5569451  -0.07108968]]]]: "
2018-04-20 09:28:53,537 (dqn_agent.py:161) DEBUG: "var_name: q/Conv/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 09:28:53,545 (dqn_agent.py:161) DEBUG: "var_name: q/Conv_1/weights:0, var_value [[[[ 4.59266603e-02 -1.72088891e-01 -1.48474574e-02  1.39961183e-01
    -1.24499992e-01 -9.86169055e-02  5.83966076e-02 -3.10574323e-02
    -4.71849591e-02 -9.68626142e-03  1.11561358e-01  5.80064952e-02]
   [-1.74712315e-01  1.12578809e-01  1.70844316e-01 -7.22567439e-02
     5.09893447e-02 -6.62921742e-02 -1.35316670e-01  1.18894547e-01
    -7.61907697e-02 -1.11978814e-01 -9.48175192e-02 -8.32724571e-03]
   [ 6.27263188e-02  8.97668898e-02 -1.30530566e-01  1.23129964e-01
    -1.24589927e-01 -4.29591984e-02  1.31127506e-01  4.46048081e-02
     5.72550297e-03  6.66925460e-02  8.24193358e-02  1.53374523e-01]
   [ 1.19814336e-01  4.28056270e-02  1.66132718e-01  1.52832717e-02
    -2.76231617e-02 -3.99370193e-02 -6.52910024e-02  1.55058354e-01
     1.56291813e-01 -2.81294882e-02 -1.82388917e-01 -1.13509603e-01]
   [ 5.75251132e-02 -1.09999195e-01 -1.36744991e-01  4.72179502e-02
     3.64765525e-03 -1.31609604e-01  2.25259364e-03  2.50491053e-02
    -6.33881316e-02  1.50839180e-01  1.14190042e-01  1.42353624e-01]
   [ 8.74959826e-02  2.17679292e-02 -4.60047871e-02  4.37177718e-02
    -1.20182216e-01  1.66270137e-02 -1.66230053e-01 -6.18038923e-02
     7.97687173e-02 -1.23784333e-01  1.09827369e-02  1.38401866e-01]
   [-1.49266422e-02  4.34265733e-02  1.29332721e-01  8.45234096e-03
     6.72231764e-02 -3.86303514e-02  1.83291733e-03 -9.60594043e-02
    -1.55982077e-02  2.40914226e-02 -1.01943530e-01  8.47566724e-02]
   [-1.06488183e-01  1.33211851e-01  2.57079750e-02 -2.43195593e-02
    -1.14360161e-01  1.72666192e-01  2.91829854e-02 -5.00739366e-02
     1.61852151e-01 -1.46439001e-01  1.79510683e-01 -1.39846697e-01]]

  [[ 1.72673851e-01  2.51529217e-02  1.15051717e-02 -1.43374726e-01
    -1.36862695e-01 -3.57176065e-02 -9.79878679e-02  2.95825303e-02
    -7.06764236e-02  1.50512487e-01 -4.54729944e-02 -1.61682144e-01]
   [-1.48730189e-01  1.60694629e-01  1.68279529e-01  2.79130638e-02
    -1.72764510e-01  1.77673280e-01 -1.46749169e-02  1.78631872e-01
    -1.70602039e-01 -2.39093006e-02  1.52031660e-01  7.89385140e-02]
   [-1.02264136e-02  9.62170064e-02 -5.22153974e-02  9.72304344e-02
     1.53782755e-01 -9.59211513e-02 -1.42036110e-01  7.42993057e-02
     4.21266556e-02  8.14753771e-02 -6.23330325e-02  5.48714101e-02]
   [-4.26714271e-02  1.68763787e-01 -1.37789384e-01 -1.26971886e-01
    -7.12006018e-02 -1.24533772e-01 -1.26656294e-01  4.72326577e-02
    -1.53898358e-01 -1.29698232e-01 -1.65449083e-03  9.38509405e-03]
   [-5.22648394e-02  7.24693537e-02 -5.65063953e-03  1.69194818e-01
    -9.89471227e-02 -4.44261283e-02  1.20224714e-01 -1.61533177e-01
    -9.98510867e-02  6.56803250e-02 -1.49763092e-01 -3.69788259e-02]
   [ 1.23640776e-01  1.14785969e-01  8.30202699e-02 -1.17309093e-02
     1.75392538e-01 -4.08211350e-02 -1.15941830e-01  8.18128884e-02
     1.15362734e-01 -2.01758593e-02 -1.12635054e-01 -1.00648321e-01]
   [-1.64424479e-01 -6.04204908e-02 -1.01013444e-01 -1.57799035e-01
     7.98922181e-02  9.28924382e-02  1.45952523e-01 -1.47205502e-01
    -4.47390527e-02  8.18745792e-02  1.21312439e-01 -8.92264247e-02]
   [ 1.31564677e-01 -9.42128971e-02  1.74615413e-01 -8.29721242e-02
     1.68625563e-01 -6.82979822e-03  1.00587428e-01  9.79534686e-02
    -9.08489749e-02 -4.79797572e-02  6.88457489e-02 -1.24556452e-01]]

  [[ 2.09542811e-02 -1.76576704e-01 -1.75516590e-01  1.53792888e-01
     5.94764352e-02 -1.17908955e-01  4.38780934e-02 -1.16823249e-01
     1.59227967e-01 -4.43907380e-02 -1.03770643e-02 -1.01199009e-01]
   [ 1.58088326e-01  9.51612294e-02 -3.39910388e-03  1.78934425e-01
    -1.56330496e-01  9.69698131e-02  1.24928504e-01  5.12717664e-02
    -1.31829023e-01  7.67928660e-02  5.32713532e-03 -2.81759799e-02]
   [ 1.32242084e-01 -2.21901685e-02  1.53149754e-01  6.62189126e-02
    -1.33845508e-01  1.46808833e-01  1.34788275e-01 -3.07158530e-02
     1.57297105e-02 -1.61284938e-01  1.41481370e-01  8.88178945e-02]
   [ 1.37166053e-01  7.25163519e-03  1.82257146e-02  1.01106375e-01
    -1.46806121e-01  7.49268532e-02 -1.12262405e-01 -8.03965479e-02
     8.99758637e-02  1.68902785e-01  8.05737078e-02 -1.53716922e-01]
   [-3.87430191e-06  1.55886561e-01 -1.53968483e-01  4.74248379e-02
     1.48850322e-01  9.80639458e-02  2.69348770e-02  1.29187196e-01
    -1.04294844e-01  5.72997183e-02 -1.03384912e-01  1.04157507e-01]
   [-3.08575928e-02 -1.78174868e-01 -1.52732000e-01  9.38374996e-02
     1.23474330e-01  5.52441478e-02 -1.77889764e-01  1.00657642e-01
    -1.37531906e-01  9.26029384e-02  9.69907939e-02 -2.03150511e-03]
   [ 1.03919923e-01  4.18893993e-03  6.23003840e-02  1.20164841e-01
    -5.60711473e-02 -3.42509151e-03  2.82454491e-02  9.55198705e-02
    -1.80768549e-01 -5.15434295e-02 -8.48628059e-02 -1.43701017e-01]
   [ 1.09497100e-01 -1.76315621e-01 -8.78376290e-02 -1.06290691e-01
    -1.77713335e-01 -3.94454896e-02 -8.83867517e-02  8.48598778e-03
    -9.84680429e-02 -1.74542964e-02 -7.20858574e-03  1.28679574e-01]]]


 [[[ 1.28606260e-02 -1.11839347e-01  1.78446263e-01  1.60450101e-01
    -1.22931167e-01  4.03821021e-02 -8.86781290e-02  4.64679003e-02
     1.59533948e-01 -1.85661018e-02  4.76158410e-02  1.59816533e-01]
   [ 1.14592135e-01 -3.25613171e-02  1.02412939e-01  1.78614378e-01
     1.61424309e-01 -2.00513154e-02  3.79820317e-02  3.60320657e-02
    -3.44310254e-02  6.52043819e-02 -2.49615759e-02 -6.52617514e-02]
   [ 7.00071156e-02 -8.65188316e-02  6.12260848e-02  1.46166623e-01
     5.68872392e-02 -3.95068973e-02  1.19807422e-01 -5.52808344e-02
     1.14707381e-01  4.55020815e-02  1.22642010e-01 -1.17365927e-01]
   [-1.81644708e-01  1.43975854e-01 -1.42608792e-01 -6.97683170e-02
     1.74225003e-01 -1.23612136e-01  4.15722728e-02 -4.14943993e-02
     1.71231061e-01  1.79012775e-01  1.68393940e-01 -1.55556113e-01]
   [-1.29081085e-01 -5.31472266e-03 -9.76994485e-02 -1.48799866e-02
    -4.37819362e-02  1.06984407e-01 -8.46678019e-02  6.73810095e-02
    -8.88119861e-02 -1.43700629e-01 -1.66791588e-01  5.36713898e-02]
   [-1.75354496e-01  1.38470829e-01  5.61376214e-02 -4.80189323e-02
     6.90983534e-02 -1.49500221e-02  1.03393614e-01  2.00432688e-02
    -1.60512343e-01  8.45625103e-02 -9.86327529e-02 -8.51325989e-02]
   [ 3.47246677e-02 -1.27928957e-01  3.90052348e-02  9.58932042e-02
    -9.02312472e-02 -1.05098784e-02  1.45444274e-01  2.19392180e-02
    -9.71539840e-02 -1.72861278e-01  8.16225111e-02 -4.66572493e-02]
   [-1.37085468e-01 -7.39390105e-02 -7.37784803e-02 -9.79664996e-02
     1.69566035e-01 -1.68275714e-01 -1.73885524e-01  9.83146727e-02
    -5.77553809e-02  1.36770874e-01 -1.71338812e-01  1.14945710e-01]]

  [[-1.02200180e-01 -8.54808763e-02  2.09976882e-02  1.76483124e-01
    -2.46948749e-02  6.84345961e-02  1.45440042e-01 -1.15988143e-01
     4.61251885e-02  1.36736155e-01 -4.15718406e-02 -3.48895639e-02]
   [-7.83773214e-02 -4.37892973e-02 -1.72850400e-01  1.09205306e-01
    -7.62047470e-02  9.95500386e-02 -1.67300001e-01 -1.40161797e-01
     4.44115847e-02 -7.95173049e-02  9.77259576e-02  6.59237802e-02]
   [ 1.22180581e-01  4.58921790e-02 -8.81682336e-02  8.87607038e-02
     1.87306106e-03 -1.22860476e-01  8.13596249e-02  5.36538512e-02
    -1.21953189e-02  1.81094140e-01 -2.48734653e-02  2.73757875e-02]
   [-6.70417473e-02 -9.75400209e-03  6.90546036e-02 -6.57290220e-05
     3.89454663e-02 -3.19474638e-02 -4.86744791e-02  4.34660912e-02
    -1.78270772e-01  1.57679737e-01  1.47491872e-01  3.11343968e-02]
   [ 1.68085605e-01  3.50283235e-02  1.56668156e-01 -6.75793290e-02
    -6.54479265e-02 -1.66074708e-01  1.48709089e-01  1.63217157e-01
    -1.07698597e-01 -4.47358340e-02 -7.77370557e-02  5.51681370e-02]
   [ 1.08388275e-01  1.31204963e-01  7.76115060e-02  1.02005243e-01
    -3.76685858e-02  6.04691952e-02 -1.05460025e-01 -6.43647462e-02
    -1.98711604e-02 -1.54201686e-03 -7.20002279e-02  4.67528850e-02]
   [ 7.62280822e-02  6.35936260e-02 -6.29071742e-02  4.29544002e-02
     1.17542863e-01  9.46930349e-02 -5.15767783e-02  4.67247218e-02
     1.53215140e-01  1.70972854e-01  4.20156568e-02 -1.27667263e-01]
   [-1.00742653e-01  5.63824326e-02  7.62930512e-03  8.20686817e-02
    -6.75128624e-02  2.11458206e-02  5.47942668e-02 -1.78667665e-01
    -5.19984365e-02  1.43111467e-01  5.68439662e-02 -5.82566634e-02]]

  [[ 6.52910024e-02  3.88919264e-02  1.56293601e-01 -5.79654500e-02
    -5.25534004e-02 -1.51155949e-01  7.13013709e-02 -3.91205400e-02
     1.64552271e-01  4.98473644e-03  1.15655333e-01  1.76461577e-01]
   [-7.70413727e-02 -9.89104286e-02 -1.39436483e-01 -1.05452687e-02
     9.18515325e-02 -1.58981636e-01 -7.53689855e-02  1.25269741e-02
    -1.69140071e-01 -1.64931148e-01  9.61601734e-02 -7.61459395e-02]
   [ 3.81103605e-02  1.55175328e-01 -1.01402074e-01 -1.71500608e-01
     1.55800700e-01  1.45497173e-01 -2.21505910e-02  1.14997149e-01
     9.81632471e-02 -1.25671476e-02  2.27606595e-02  1.38822883e-01]
   [ 8.14593136e-02  1.23865992e-01 -8.12770575e-02 -9.59374309e-02
    -1.03909969e-02  1.38591886e-01 -9.04690474e-02 -1.76978916e-01
     6.39621466e-02  1.16951436e-01  1.33817613e-01 -4.85350490e-02]
   [-6.42985851e-02 -1.14503540e-01 -1.49273306e-01  6.70658201e-02
    -1.15240313e-01  1.05984628e-01 -1.68339431e-01  6.25888109e-02
     8.41828883e-02  1.18337244e-01 -6.16042241e-02 -5.10894656e-02]
   [-1.03813283e-01 -1.73969269e-01  1.42139852e-01 -7.57478178e-02
    -2.05801129e-02  4.91224378e-02 -6.06351346e-02 -5.70891649e-02
     3.74096781e-02 -7.16233999e-02 -8.07693377e-02  1.01306140e-02]
   [-1.70468539e-02  9.37549174e-02  2.21922547e-02  3.11460942e-02
     6.40661418e-02 -4.77975756e-02  4.64781225e-02 -5.60601354e-02
     1.77811980e-01 -1.71505868e-01 -1.51334792e-01 -7.61548206e-02]
   [ 1.52543306e-01 -1.58861890e-01 -7.21160620e-02  4.08331454e-02
    -3.71688753e-02 -1.30136758e-01  6.75946176e-02  1.19643956e-02
    -1.81868404e-01  1.05541915e-01  2.93406844e-02 -4.08212692e-02]]]


 [[[-1.26051843e-01 -1.70084387e-01 -9.52820629e-02  1.30769521e-01
    -1.04875259e-01 -3.49074900e-02  7.44546950e-02  1.76120907e-01
    -1.45677984e-01 -1.57409281e-01  7.59648979e-02  7.47658610e-02]
   [ 1.65956259e-01  4.41375226e-02  3.59243304e-02 -7.29618296e-02
    -1.42369032e-01  9.90335643e-02 -3.81329954e-02 -6.60448819e-02
    -5.02698570e-02  7.66457915e-02  3.91039103e-02  2.00575441e-02]
   [ 7.39718378e-02 -1.78248867e-01 -4.46717143e-02  1.50459915e-01
    -1.24331236e-01  1.54924780e-01  1.13002002e-01  1.11056924e-01
     3.68026644e-02  1.04091257e-01 -7.09437802e-02 -5.79119995e-02]
   [-1.10180579e-01  1.56654567e-01  3.64961773e-02 -4.38162386e-02
    -5.18400818e-02 -4.87378091e-02  1.57480896e-01  3.45415026e-02
    -6.92495853e-02  1.66018069e-01  5.02528399e-02 -1.57147631e-01]
   [-1.11175224e-01 -6.81748912e-02 -4.95221615e-02 -7.11339116e-02
    -1.62811160e-01  8.68570805e-02 -9.64322686e-02 -1.23721570e-01
     1.13224864e-01 -1.78154767e-01  2.28995532e-02  1.60965860e-01]
   [ 1.73273623e-01 -1.42604917e-01  9.60727334e-02  7.41100311e-02
    -1.10245645e-02  9.16182995e-02 -3.04630399e-02  4.74387705e-02
    -6.29801750e-02 -8.76510218e-02 -1.31499857e-01 -2.49503404e-02]
   [-9.36283022e-02  1.39113128e-01 -5.57173043e-02 -4.20599282e-02
    -1.49229646e-01  6.66291267e-02 -1.13109134e-01  1.00668132e-01
    -1.28383011e-01  1.62950575e-01 -1.02640823e-01 -1.04010336e-01]
   [ 5.51230013e-02  1.36328906e-01  8.22690129e-02 -8.52608830e-02
    -7.75496662e-02 -2.23609358e-02 -6.74213171e-02  1.71216428e-02
     1.47710085e-01  1.52977854e-01  4.76944447e-03  1.19491100e-01]]

  [[ 1.97386146e-02  1.41787380e-01  1.48842096e-01 -1.79836601e-01
     6.08225316e-02 -1.59452587e-01 -8.96047801e-02 -7.63107836e-02
    -1.11123033e-01  9.58444476e-02  1.51126266e-01 -1.11307204e-01]
   [-1.88637972e-02  1.46871716e-01  6.01410717e-02  2.86610723e-02
     1.23184323e-01 -1.35057673e-01 -1.49379343e-01 -5.34864366e-02
    -3.29534262e-02  3.02254111e-02 -1.36238098e-01 -8.39818642e-02]
   [-1.94984972e-02 -1.01037651e-01 -1.80198714e-01  6.18741959e-02
    -3.82479131e-02  1.00545645e-01  3.71569395e-02  1.80864781e-01
     8.67847800e-02  1.69556111e-01 -1.50802314e-01 -1.26330003e-01]
   [ 1.50527000e-01  5.19312769e-02  1.17203027e-01  7.27529228e-02
    -4.61325943e-02  1.22542679e-03 -1.64538175e-02 -1.26455456e-01
    -1.22738481e-02 -3.42369080e-03 -1.32781357e-01 -9.28237513e-02]
   [-1.29109412e-01  1.16934955e-01 -6.06799126e-03  3.48960012e-02
     1.12979501e-01  4.91897762e-02  5.11793196e-02  4.26351279e-02
     1.33226126e-01  1.48976833e-01 -9.27268192e-02 -6.90789521e-03]
   [-1.23111546e-01 -1.71052814e-01  8.02772939e-02 -1.01912886e-01
    -2.86003500e-02  1.14549160e-01  4.26118821e-02  8.39364231e-02
    -3.22494805e-02 -7.89153874e-02 -1.32538334e-01 -1.29463747e-01]
   [ 1.46687120e-01  1.52506828e-01  9.26443636e-02  6.21414185e-02
    -1.72423720e-01 -6.23126999e-02  2.05010623e-02 -1.00300699e-01
    -1.53363794e-02  1.37828499e-01 -8.18656608e-02  1.51547343e-01]
   [ 1.38815999e-01 -7.20064938e-02 -5.25365025e-02  2.56573856e-02
     6.23481721e-02  2.25929767e-02 -1.10020570e-01 -4.29743379e-02
     3.30728740e-02 -2.43608803e-02 -9.76782069e-02 -8.40325356e-02]]

  [[-1.63036332e-01  1.25057250e-02  7.12753832e-03 -1.06795110e-01
     6.51193708e-02  1.22607529e-01  1.57663882e-01 -4.83435243e-02
     1.39397770e-01 -2.29231119e-02  1.37293845e-01 -1.18514135e-01]
   [ 7.97202885e-02 -3.46474499e-02 -1.49823725e-01  6.80226386e-02
    -1.16630763e-01 -2.42122710e-02  4.53294814e-03 -3.08151096e-02
    -5.27321249e-02 -3.81362438e-03 -1.13759786e-02 -8.65967050e-02]
   [ 1.80331796e-01  6.82802200e-02 -8.55085179e-02  5.56591004e-02
    -3.77566814e-02 -8.91078115e-02 -1.47222176e-01  1.29493445e-01
     1.69769377e-01 -1.67796969e-01 -1.57929957e-02  7.98244476e-02]
   [ 1.39167458e-01 -1.52052820e-01 -4.07072157e-02  9.21656489e-02
     1.02456957e-02 -1.76625893e-01 -1.39610946e-01 -1.55866221e-01
     1.40045702e-01 -3.42336595e-02  5.93219548e-02 -1.42839015e-01]
   [-5.18756956e-02  1.35763884e-01  9.81894135e-02 -1.33831456e-01
    -1.48827434e-01  5.15295416e-02 -1.05127551e-01  8.44017863e-02
     1.17250323e-01  1.12633914e-01  1.10680908e-02 -1.19379058e-01]
   [-1.38842523e-01 -4.17533964e-02 -8.26727748e-02 -5.91531023e-02
     1.12382501e-01 -8.16313401e-02  7.49033093e-02  2.87096202e-03
     1.17437840e-01  1.01735413e-01  1.44566804e-01  1.13771379e-01]
   [-1.16637640e-01  5.05429655e-02  7.48217106e-03  7.32546151e-02
     9.94349122e-02 -7.83396289e-02 -1.66305840e-01 -1.37253538e-01
     1.25993550e-01 -1.71555489e-01  9.11465883e-02  7.38407373e-02]
   [ 1.10166609e-01 -3.80566865e-02 -9.39138532e-02 -1.52244821e-01
    -1.51174814e-02 -1.33969262e-01  1.64696008e-01  2.71832049e-02
     1.63365245e-01 -6.29455298e-02  1.39455616e-01  3.91784757e-02]]]]: "
2018-04-20 09:28:53,548 (dqn_agent.py:161) DEBUG: "var_name: q/Conv_1/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 09:28:53,554 (dqn_agent.py:161) DEBUG: "var_name: q/Conv_2/weights:0, var_value [[[[-0.02920526  0.03114332  0.07556178 ...  0.08078215  0.03317054
     0.08133997]
   [ 0.06541389 -0.0714056  -0.12045061 ... -0.01010297 -0.04065978
    -0.04366763]
   [-0.10315385  0.09700729 -0.03924992 ... -0.11348377  0.14366092
     0.14392848]
   ...
   [ 0.14039032  0.11492862 -0.13838169 ...  0.12618656 -0.14563419
     0.0656838 ]
   [-0.11907725  0.11028333 -0.08764619 ...  0.01702762  0.03354317
    -0.03116849]
   [ 0.00041163 -0.08662196 -0.10274317 ...  0.07911474  0.10078789
    -0.03744234]]

  [[ 0.12377752 -0.10194632  0.05374162 ... -0.01728672  0.07922804
    -0.12383551]
   [ 0.04989144 -0.03849512 -0.09851025 ...  0.01318242  0.01081064
     0.14884894]
   [ 0.05687344 -0.0954612   0.02583839 ... -0.00986621  0.01287015
    -0.12618616]
   ...
   [-0.09302413  0.06463918 -0.02820335 ...  0.13729946  0.04159676
     0.10923503]
   [-0.03035811 -0.07867058 -0.02609675 ... -0.0538284   0.11970116
     0.08582166]
   [-0.12506635 -0.1361765   0.03656243 ... -0.14304249 -0.02295403
    -0.14778678]]

  [[ 0.073322    0.00066382  0.01132812 ... -0.03657614  0.07289805
    -0.15138987]
   [-0.12140965  0.05063708  0.09882168 ... -0.01612529 -0.05614009
     0.05685283]
   [-0.14226279 -0.12296318  0.07010618 ... -0.09440058  0.11210941
    -0.03090063]
   ...
   [ 0.08294705 -0.03542627 -0.09705739 ... -0.06138823  0.02672639
     0.15292941]
   [ 0.06306201  0.00099602 -0.03438902 ...  0.14358433  0.01500393
    -0.10632665]
   [-0.00780861  0.06028855 -0.01955938 ...  0.06119812  0.13792737
     0.0712768 ]]]


 [[[ 0.00138822 -0.14444543  0.05700496 ... -0.1420688   0.05771205
    -0.06127967]
   [-0.142923   -0.15150027 -0.1405664  ...  0.07226712  0.14594705
     0.08877878]
   [ 0.01995686  0.08113527  0.1394745  ... -0.05097167 -0.05327528
     0.06352206]
   ...
   [-0.02183338 -0.02164148  0.14560981 ... -0.08714315  0.11033224
    -0.14970969]
   [ 0.11455075 -0.11459181  0.14244781 ...  0.14594416 -0.11412099
    -0.00499496]
   [-0.13352413 -0.13583553  0.15286417 ... -0.0552082   0.08746991
     0.15323408]]

  [[-0.1106329  -0.0358509   0.02746415 ... -0.06078894  0.04966255
     0.12742223]
   [ 0.09369339 -0.02016181  0.13986747 ... -0.07942931  0.03955626
    -0.08520231]
   [ 0.12014051 -0.1433076  -0.02773224 ... -0.04497212 -0.12718649
     0.07232293]
   ...
   [-0.11415031  0.04120016 -0.13765298 ... -0.03793531  0.09867357
     0.13389201]
   [-0.01294461 -0.13478827 -0.15234767 ... -0.08313898  0.0497714
     0.11732294]
   [-0.11552845 -0.03007513  0.1164618  ... -0.06640126 -0.14707418
     0.05282299]]

  [[-0.05480959  0.12044753 -0.01254866 ...  0.1409223  -0.10205963
    -0.08372974]
   [-0.14350599 -0.05941768 -0.11675452 ...  0.10383911 -0.00428914
    -0.09363412]
   [-0.02692752  0.10505442  0.12645723 ... -0.07301025  0.04839116
    -0.07205761]
   ...
   [ 0.06215242  0.01079732  0.00747621 ...  0.06894314  0.05767238
    -0.0177819 ]
   [-0.01610197 -0.07911693 -0.12925336 ...  0.06165558 -0.15149781
    -0.08739956]
   [ 0.00354733 -0.10406735  0.10553958 ...  0.05455711 -0.08983726
     0.11769201]]]


 [[[-0.1408274   0.05439532  0.07556535 ... -0.03507796  0.117148
    -0.11513217]
   [-0.03333833  0.05693002 -0.148012   ...  0.08571839 -0.11009482
    -0.03143985]
   [ 0.0369008   0.04954611  0.10708191 ... -0.09012675  0.00994809
    -0.14538626]
   ...
   [ 0.05741754  0.02945384  0.08636624 ...  0.14660443 -0.05157582
    -0.0426112 ]
   [ 0.125059    0.05557431 -0.04478034 ... -0.0117159   0.06688198
     0.04059625]
   [ 0.05203255  0.11688437 -0.11579502 ...  0.15246804 -0.15327331
    -0.02917311]]

  [[ 0.04812337  0.14541169 -0.02299583 ... -0.04381828  0.04496065
    -0.13958545]
   [ 0.0849608   0.02151982  0.13751878 ... -0.09880394 -0.05738863
    -0.11465292]
   [-0.04540027 -0.11332532 -0.14562838 ...  0.0929032   0.1173936
    -0.03032213]
   ...
   [-0.12221383  0.09325005  0.07185365 ...  0.09368923  0.03340632
     0.04187126]
   [-0.00506829 -0.10702516 -0.03905097 ...  0.10690762  0.14002176
     0.05246884]
   [ 0.07353538 -0.13594535 -0.03012741 ...  0.12792723 -0.04081091
    -0.1098295 ]]

  [[-0.06634346  0.02977486  0.08566067 ...  0.09430404  0.08419526
     0.08522362]
   [-0.08819869 -0.12208249  0.07034218 ...  0.0912735  -0.08815738
    -0.08286659]
   [-0.11275759 -0.05685685  0.10075052 ...  0.04972965 -0.05060253
    -0.09544295]
   ...
   [ 0.04746078  0.14117186 -0.00307433 ... -0.00714736  0.10469718
    -0.11343591]
   [-0.13416338 -0.12214646  0.0910908  ...  0.00146876 -0.04203351
     0.01481386]
   [-0.13841763  0.02974628  0.05971453 ...  0.08685987  0.01862156
    -0.02834779]]]]: "
2018-04-20 09:28:53,558 (dqn_agent.py:161) DEBUG: "var_name: q/Conv_2/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 09:28:53,562 (dqn_agent.py:161) DEBUG: "var_name: q/fully_connected/weights:0, var_value [[ 0.08157042  0.06623418  0.06776739 ...  0.05644212  0.07899103
   0.05643616]
 [ 0.02209343 -0.05179443 -0.02903633 ... -0.00462473  0.0866315
  -0.02627775]
 [-0.00445791  0.01925971  0.06567714 ... -0.03357385  0.07819278
   0.04664712]
 ...
 [ 0.03009177 -0.06488372  0.06634163 ... -0.03944565 -0.04472656
  -0.07609192]
 [-0.06219979  0.05804006 -0.01590803 ... -0.06922067 -0.0525541
   0.08135106]
 [-0.01098281 -0.08562314 -0.07261136 ... -0.08409451 -0.01397916
   0.02504937]]: "
2018-04-20 09:28:53,567 (dqn_agent.py:161) DEBUG: "var_name: q/fully_connected/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 09:28:53,575 (dqn_agent.py:161) DEBUG: "var_name: q/fully_connected_1/weights:0, var_value [[-1.33299828e-01  1.40574872e-02 -7.08519369e-02  6.46952689e-02
   9.59742069e-02]
 [-1.93864018e-01 -1.61325574e-01 -1.27446860e-01  2.11798012e-01
   1.96384192e-01]
 [-1.62822932e-01  1.54100925e-01 -2.03218877e-01  1.86855614e-01
   1.69897169e-01]
 [-1.34735703e-02  2.58669257e-04 -1.90357491e-01 -5.68246841e-03
   1.00014180e-01]
 [ 1.13576621e-01  3.52445692e-02  7.04729557e-02  9.39109623e-02
   1.04788691e-01]
 [ 4.65270877e-03 -4.56783473e-02  7.44275749e-02 -1.56244859e-01
   1.06541067e-01]
 [-3.39077413e-03 -5.53624034e-02  4.70186770e-02  2.04944879e-01
   3.21537405e-02]
 [-1.39143586e-01 -4.10440117e-02  1.65419012e-01  6.88962936e-02
   2.32711583e-02]
 [ 5.16156852e-02 -9.28531587e-03 -1.47460848e-02 -1.29877895e-01
  -2.08430141e-01]
 [-1.24819465e-01  1.29220456e-01 -1.76744461e-01 -1.65693939e-01
  -1.23002976e-01]
 [ 6.32750988e-02 -2.04019532e-01 -7.52302706e-02 -1.38983667e-01
   1.94035828e-01]
 [ 1.88507468e-01  1.17310137e-01 -9.67103615e-02 -1.20085582e-01
  -1.75580502e-01]
 [-1.36453196e-01  7.53062963e-02  1.86333507e-01  1.99722469e-01
   9.47043896e-02]
 [-8.57917666e-02  5.19664586e-02  1.13683581e-01  5.64240515e-02
  -8.79084468e-02]
 [ 4.06257510e-02  9.89227593e-02 -1.17120229e-01  1.42862946e-01
  -1.49873540e-01]
 [-2.06193388e-01  1.60203159e-01  2.06621438e-01 -5.88385612e-02
  -2.09971458e-01]
 [-1.63450658e-01 -5.57343662e-03  9.87532139e-02 -2.03066349e-01
   8.07760060e-02]
 [-1.60088852e-01 -1.01498790e-01  1.21336877e-02 -1.74619406e-02
   2.85941362e-03]
 [-9.28267837e-04  8.98760557e-02  1.31628960e-01 -2.18663663e-02
   5.96837699e-02]
 [ 1.03134096e-01 -1.22160636e-01 -8.58860016e-02  1.08571261e-01
  -1.11071490e-01]
 [-2.78026909e-02 -8.59253556e-02  1.14764988e-01  1.48713738e-01
   6.38012588e-03]
 [-1.55442983e-01 -1.29066616e-01 -1.29093245e-01 -5.37588000e-02
  -1.58720776e-01]
 [ 3.96580696e-02 -1.59128532e-01  1.77198738e-01 -1.03527457e-02
   1.32669419e-01]
 [ 2.05792040e-02 -1.53549463e-01  1.95737988e-01  1.42226875e-01
  -1.13157481e-01]
 [-1.14196606e-01  2.57390738e-03 -8.75675902e-02 -1.34542868e-01
  -1.19291604e-01]
 [ 7.68667459e-02  1.88262939e-01  9.44095552e-02 -8.99212211e-02
   9.73729193e-02]
 [ 2.07806557e-01  9.33260620e-02 -1.29229918e-01 -2.04818681e-01
   1.22991323e-01]
 [-1.07458860e-01  1.29220963e-01  7.39139616e-02 -1.23778522e-01
  -1.63169667e-01]
 [-2.27470398e-02  1.63773537e-01 -1.00449942e-01 -2.06083298e-01
  -1.72836930e-02]
 [ 5.94137609e-02 -8.15672129e-02 -1.27406180e-01 -1.91571876e-01
   1.71176940e-02]
 [-2.06798315e-02  1.38266891e-01  1.38171643e-01  1.91700399e-01
  -1.25953898e-01]
 [-5.31684905e-02 -3.75389010e-02  1.16632581e-02  3.84386182e-02
  -1.37449086e-01]
 [-4.07289416e-02 -5.69811463e-02  1.52470797e-01 -1.85510069e-01
   1.42048717e-01]
 [-4.06951606e-02  1.38778806e-01 -1.85947388e-01  1.43138587e-01
   1.28177285e-01]
 [ 8.99710357e-02 -1.61721781e-01 -3.68046761e-02 -4.57380563e-02
   4.95254993e-04]
 [-1.53600708e-01  4.52516675e-02  1.27036512e-01 -1.16491184e-01
   6.57955110e-02]
 [-6.16139024e-02 -5.18214703e-03 -1.30937845e-01 -1.14585012e-01
  -1.75196454e-01]
 [-1.94620371e-01 -2.03980654e-02 -1.58955842e-01  7.26519227e-02
  -1.73306316e-02]
 [-1.75178438e-01 -1.42431408e-02 -1.09862112e-01  2.25317180e-02
  -1.12451665e-01]
 [-1.53357133e-01 -1.09710343e-01 -1.37862548e-01  9.25220251e-02
  -1.44818902e-01]
 [ 5.81429601e-02 -1.29831821e-01 -1.75121158e-01 -4.49038148e-02
  -1.95001125e-01]
 [ 8.79958272e-03  1.03748083e-01  4.46168482e-02  1.19810611e-01
  -1.67408451e-01]
 [-1.94066912e-02 -4.55603004e-02 -1.62356049e-02 -1.00090802e-01
   6.25995994e-02]
 [ 2.04512358e-01 -5.51346838e-02  1.40624315e-01  1.60176247e-01
   1.87169224e-01]
 [ 2.11744457e-01 -3.81401479e-02  1.10687912e-02  7.24288821e-02
   8.87269974e-02]
 [ 9.30531323e-02 -9.58742499e-02  8.00922811e-02  8.39873254e-02
   8.94822776e-02]
 [ 1.53533459e-01  4.07693386e-02  1.16920471e-01  2.10090339e-01
  -4.98117507e-02]
 [ 9.24170315e-02 -8.13147277e-02  1.51871681e-01  1.61630422e-01
  -1.76149949e-01]
 [-9.98161361e-02 -1.97957620e-01  1.79989189e-02 -1.77015126e-01
   8.34802687e-02]
 [-1.34091109e-01 -2.21316665e-02 -1.89185783e-01  8.82847607e-02
   1.84389651e-01]
 [-1.12051971e-01 -1.52146801e-01  4.71714139e-02 -3.92214954e-02
  -1.32929534e-01]
 [ 1.91508263e-01  1.34995282e-01 -1.17333218e-01 -7.69265443e-02
  -3.91703099e-02]
 [-3.90403569e-02  7.71655142e-02  5.80673218e-02 -1.23770416e-01
   1.80938691e-02]
 [-1.99991658e-01 -1.30604208e-03  1.33748442e-01 -1.33045971e-01
   2.50199437e-03]
 [-1.20283075e-01 -4.17659432e-02  1.09589458e-01  6.80515766e-02
   1.12798393e-01]
 [ 9.99173522e-03  1.14754200e-01 -9.14048031e-02 -1.89841866e-01
   1.61151230e-01]
 [ 1.82970345e-01  2.11820155e-02  1.56734735e-01 -1.18818730e-01
  -4.47130501e-02]
 [-2.41348147e-02 -8.86413530e-02  1.89207852e-01 -1.25272632e-01
  -1.41281784e-01]
 [-1.16354607e-01  3.20801586e-02  1.47045374e-01 -3.08876932e-02
   2.02019781e-01]
 [ 6.14875555e-03  1.27297550e-01  7.21142292e-02 -2.00974122e-01
   2.68503129e-02]
 [ 1.92973077e-01 -7.58328438e-02  1.37268245e-01 -2.03969091e-01
  -5.90929687e-02]
 [-1.08924322e-01 -8.94440934e-02  1.97469890e-02 -1.35631725e-01
   1.10527873e-01]
 [-1.77012652e-01 -6.18345439e-02  1.03068411e-01 -1.19194679e-01
  -9.90418568e-02]
 [-4.15264666e-02  1.14324659e-01  4.54396307e-02 -2.01209292e-01
   1.91397458e-01]
 [ 2.10495889e-01  6.39667809e-02 -5.37462980e-02  1.83368206e-01
  -3.50108743e-02]
 [ 4.06920314e-02 -1.85996920e-01  4.13198769e-03 -3.35038453e-02
   1.44174308e-01]
 [ 1.62238747e-01  1.37864232e-01 -1.39489084e-01  1.02697134e-01
  -4.73292023e-02]
 [-6.67312741e-03 -1.80796742e-01  6.88863099e-02  1.51217908e-01
  -1.14925765e-01]
 [ 1.24556690e-01  1.96774036e-01  1.98205948e-01  9.99077559e-02
  -1.86149955e-01]
 [-6.42117113e-02  2.07862675e-01  8.95886123e-02 -1.92947894e-01
  -2.04674050e-01]
 [ 9.47193205e-02 -1.13070838e-01 -2.06116155e-01 -1.32610172e-01
   1.85954273e-01]
 [ 2.10419506e-01 -1.63228869e-01 -1.71216086e-01 -1.24598525e-01
  -1.54693916e-01]
 [ 1.45468861e-01 -3.27154249e-02  6.93160295e-02 -1.47741169e-01
  -1.58869356e-01]
 [-8.43391120e-02 -1.80306643e-01 -6.53254986e-03  1.79963320e-01
  -1.87741444e-01]
 [-1.16624981e-02 -2.42316425e-02 -1.79944515e-01  3.52976471e-02
  -4.84511703e-02]
 [ 1.06213987e-02  8.93397629e-03 -3.82776856e-02  1.05401129e-02
  -1.55844748e-01]
 [-1.01029508e-01  2.61832327e-02  1.35792792e-01 -1.03135407e-01
   3.71879637e-02]
 [ 9.54458416e-02 -1.16168968e-01  9.37369466e-02 -2.79847383e-02
  -1.37182206e-01]
 [-9.76120532e-02  2.05598891e-01 -1.06868811e-01  1.27204329e-01
   1.49802685e-01]
 [ 6.70772195e-02  3.02013308e-02 -7.55790323e-02 -1.99647725e-01
   7.73878396e-03]
 [ 1.14767253e-01  1.54064566e-01 -2.55355239e-03  1.31901413e-01
   1.53072029e-01]
 [-7.74801970e-02 -2.08543062e-01  6.48558140e-02  5.96918166e-03
   7.84949660e-02]
 [ 7.50566423e-02  1.12952858e-01 -1.34281576e-01  1.47529095e-01
   1.90393686e-01]
 [ 1.45587295e-01 -1.93827972e-01  2.03819215e-01  1.61185920e-01
  -1.70694143e-01]
 [ 1.84947193e-01 -9.87321138e-04  5.78837097e-02 -6.76939487e-02
   3.25574428e-02]
 [-1.23953968e-02  8.64458382e-02 -9.21477899e-02  8.11449289e-02
   2.07048833e-01]
 [ 1.52090222e-01  2.08526313e-01  9.52346325e-02  8.56096148e-02
   1.51132792e-01]
 [-1.38095587e-01  1.89284980e-01 -4.76497412e-02 -1.70217991e-01
  -6.45513535e-02]
 [ 1.62907451e-01  4.16189432e-05  5.21859229e-02 -4.28136736e-02
   2.83536464e-02]
 [ 2.49941200e-02  1.79801911e-01  2.23825872e-02  6.37984574e-02
   1.90637261e-01]
 [-1.11613177e-01  1.85310453e-01 -1.19038001e-01  1.50295615e-01
   1.55494332e-01]
 [ 2.11143196e-02 -8.70250165e-03  1.28290564e-01 -1.97300270e-01
   7.28970468e-02]
 [-2.51718163e-02  4.16837633e-02 -6.66119307e-02 -2.66940296e-02
   2.17834711e-02]
 [-5.59258163e-02  1.05253756e-01 -1.91947311e-01 -1.46291807e-01
   1.85605377e-01]
 [ 1.36108756e-01 -5.71402609e-02 -1.96304917e-03  1.74542964e-02
  -2.02672616e-01]
 [ 1.66650534e-01  9.12436843e-02  1.09799713e-01  1.00556284e-01
  -1.52703524e-01]
 [ 1.37518495e-01  1.06106132e-01 -1.89798936e-01 -1.85306042e-01
   2.87944674e-02]
 [ 2.33644396e-02 -3.53551209e-02 -1.29313275e-01  1.14356220e-01
   2.65521407e-02]
 [ 9.87855792e-02  2.04345733e-02  1.13541901e-01  1.27106309e-02
   1.28202289e-01]
 [-1.48128241e-01 -9.52904820e-02  1.90396339e-01 -2.11362988e-02
   2.09120154e-01]
 [ 1.60200477e-01 -2.08531618e-01 -4.95258421e-02 -1.57291830e-01
   1.95052624e-01]
 [ 1.00021899e-01 -3.89390886e-02 -2.34838873e-02 -3.31031829e-02
  -9.69290733e-04]
 [ 1.43746346e-01  1.96992368e-01 -5.24681509e-02 -3.16498727e-02
   1.64927810e-01]
 [-1.34221464e-01 -1.73774242e-01 -2.01056719e-01  1.65233731e-01
  -2.07562268e-01]
 [-1.62036598e-01 -1.27658367e-01  1.42982304e-01 -6.27174973e-04
  -8.96266475e-02]
 [-7.97394216e-02  5.48231006e-02 -1.03361160e-01 -4.32671010e-02
   1.03646606e-01]
 [-3.39051634e-02 -1.68837503e-01  1.50081098e-01 -9.88376290e-02
   1.41394466e-01]
 [-1.70523748e-01  7.36922920e-02 -4.59634960e-02 -1.47729874e-01
   1.26590282e-01]
 [ 3.94977927e-02 -4.23553735e-02 -1.07438959e-01  2.37901062e-02
  -1.30911961e-01]
 [ 5.04257977e-02  1.79057568e-01  2.02911735e-01  6.06529117e-02
   1.26227140e-02]
 [-9.79978219e-02  1.75997287e-01  4.79388535e-02  9.06721652e-02
  -1.76444769e-01]
 [-1.59125388e-01 -1.74650669e-01 -1.27384454e-01 -1.90612704e-01
  -4.08250093e-02]
 [ 1.83052123e-01 -5.32934219e-02  2.10260600e-01 -1.80872694e-01
  -7.23566860e-02]
 [ 7.72516429e-02  1.53194070e-01  1.58892840e-01 -2.86635011e-02
  -1.10854596e-01]
 [-1.37804210e-01 -1.53750509e-01  2.10951388e-01  3.84791195e-02
  -3.72670144e-02]
 [-2.05008924e-01  1.65603966e-01  1.37905627e-02 -1.31051019e-01
  -1.87281847e-01]
 [ 7.60070980e-02 -9.38904956e-02 -3.21145505e-02  2.05786556e-01
  -1.60290658e-01]
 [ 1.50911659e-01 -6.85408711e-04  7.17292130e-02 -1.12558112e-01
   8.05796683e-03]
 [ 1.79141074e-01  6.64601624e-02 -6.92120194e-02 -5.89349717e-02
   1.05314732e-01]
 [-5.36694676e-02  1.74739271e-01  1.08442426e-01 -6.52989000e-02
  -1.82026416e-01]
 [-1.94738805e-03 -3.06461006e-02 -1.07189305e-01  5.62258661e-02
   1.22701526e-01]
 [ 7.05108047e-04 -1.84519559e-01  8.60762596e-02 -6.98125511e-02
  -3.19413096e-02]
 [-2.30425596e-03 -1.85792834e-01 -2.10975885e-01  8.40231776e-03
  -1.17462605e-01]
 [ 7.62175024e-02  4.20083404e-02  1.55216455e-01 -9.79003385e-02
  -1.64052919e-01]
 [ 9.70424414e-02  1.73741877e-01 -3.36237103e-02  6.78210557e-02
   1.83016956e-02]
 [-1.61673069e-01 -8.19951296e-04 -1.96342975e-01  3.94056737e-03
  -2.08351642e-01]
 [-1.43294185e-01 -1.36637330e-01  1.64014935e-01 -6.10820353e-02
   1.85837388e-01]
 [ 1.45880431e-02  1.55484349e-01 -1.23854734e-01  9.29306746e-02
  -5.54155707e-02]]: "
2018-04-20 09:28:53,578 (dqn_agent.py:161) DEBUG: "var_name: q/fully_connected_1/biases:0, var_value [0. 0. 0. 0. 0.]: "
2018-04-20 09:28:53,582 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv/weights:0, var_value [[[[ 0.07914811  0.4790275   0.7519878   0.30090177 -0.7116133
    -0.38285536 -0.17304963 -0.67449665]
   [-0.32940283  0.5482898  -0.11913466 -0.7408853  -0.11541724
    -0.28320834  0.5569451  -0.07108968]]]]: "
2018-04-20 09:28:53,586 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 09:28:53,595 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv_1/weights:0, var_value [[[[ 4.59266603e-02 -1.72088891e-01 -1.48474574e-02  1.39961183e-01
    -1.24499992e-01 -9.86169055e-02  5.83966076e-02 -3.10574323e-02
    -4.71849591e-02 -9.68626142e-03  1.11561358e-01  5.80064952e-02]
   [-1.74712315e-01  1.12578809e-01  1.70844316e-01 -7.22567439e-02
     5.09893447e-02 -6.62921742e-02 -1.35316670e-01  1.18894547e-01
    -7.61907697e-02 -1.11978814e-01 -9.48175192e-02 -8.32724571e-03]
   [ 6.27263188e-02  8.97668898e-02 -1.30530566e-01  1.23129964e-01
    -1.24589927e-01 -4.29591984e-02  1.31127506e-01  4.46048081e-02
     5.72550297e-03  6.66925460e-02  8.24193358e-02  1.53374523e-01]
   [ 1.19814336e-01  4.28056270e-02  1.66132718e-01  1.52832717e-02
    -2.76231617e-02 -3.99370193e-02 -6.52910024e-02  1.55058354e-01
     1.56291813e-01 -2.81294882e-02 -1.82388917e-01 -1.13509603e-01]
   [ 5.75251132e-02 -1.09999195e-01 -1.36744991e-01  4.72179502e-02
     3.64765525e-03 -1.31609604e-01  2.25259364e-03  2.50491053e-02
    -6.33881316e-02  1.50839180e-01  1.14190042e-01  1.42353624e-01]
   [ 8.74959826e-02  2.17679292e-02 -4.60047871e-02  4.37177718e-02
    -1.20182216e-01  1.66270137e-02 -1.66230053e-01 -6.18038923e-02
     7.97687173e-02 -1.23784333e-01  1.09827369e-02  1.38401866e-01]
   [-1.49266422e-02  4.34265733e-02  1.29332721e-01  8.45234096e-03
     6.72231764e-02 -3.86303514e-02  1.83291733e-03 -9.60594043e-02
    -1.55982077e-02  2.40914226e-02 -1.01943530e-01  8.47566724e-02]
   [-1.06488183e-01  1.33211851e-01  2.57079750e-02 -2.43195593e-02
    -1.14360161e-01  1.72666192e-01  2.91829854e-02 -5.00739366e-02
     1.61852151e-01 -1.46439001e-01  1.79510683e-01 -1.39846697e-01]]

  [[ 1.72673851e-01  2.51529217e-02  1.15051717e-02 -1.43374726e-01
    -1.36862695e-01 -3.57176065e-02 -9.79878679e-02  2.95825303e-02
    -7.06764236e-02  1.50512487e-01 -4.54729944e-02 -1.61682144e-01]
   [-1.48730189e-01  1.60694629e-01  1.68279529e-01  2.79130638e-02
    -1.72764510e-01  1.77673280e-01 -1.46749169e-02  1.78631872e-01
    -1.70602039e-01 -2.39093006e-02  1.52031660e-01  7.89385140e-02]
   [-1.02264136e-02  9.62170064e-02 -5.22153974e-02  9.72304344e-02
     1.53782755e-01 -9.59211513e-02 -1.42036110e-01  7.42993057e-02
     4.21266556e-02  8.14753771e-02 -6.23330325e-02  5.48714101e-02]
   [-4.26714271e-02  1.68763787e-01 -1.37789384e-01 -1.26971886e-01
    -7.12006018e-02 -1.24533772e-01 -1.26656294e-01  4.72326577e-02
    -1.53898358e-01 -1.29698232e-01 -1.65449083e-03  9.38509405e-03]
   [-5.22648394e-02  7.24693537e-02 -5.65063953e-03  1.69194818e-01
    -9.89471227e-02 -4.44261283e-02  1.20224714e-01 -1.61533177e-01
    -9.98510867e-02  6.56803250e-02 -1.49763092e-01 -3.69788259e-02]
   [ 1.23640776e-01  1.14785969e-01  8.30202699e-02 -1.17309093e-02
     1.75392538e-01 -4.08211350e-02 -1.15941830e-01  8.18128884e-02
     1.15362734e-01 -2.01758593e-02 -1.12635054e-01 -1.00648321e-01]
   [-1.64424479e-01 -6.04204908e-02 -1.01013444e-01 -1.57799035e-01
     7.98922181e-02  9.28924382e-02  1.45952523e-01 -1.47205502e-01
    -4.47390527e-02  8.18745792e-02  1.21312439e-01 -8.92264247e-02]
   [ 1.31564677e-01 -9.42128971e-02  1.74615413e-01 -8.29721242e-02
     1.68625563e-01 -6.82979822e-03  1.00587428e-01  9.79534686e-02
    -9.08489749e-02 -4.79797572e-02  6.88457489e-02 -1.24556452e-01]]

  [[ 2.09542811e-02 -1.76576704e-01 -1.75516590e-01  1.53792888e-01
     5.94764352e-02 -1.17908955e-01  4.38780934e-02 -1.16823249e-01
     1.59227967e-01 -4.43907380e-02 -1.03770643e-02 -1.01199009e-01]
   [ 1.58088326e-01  9.51612294e-02 -3.39910388e-03  1.78934425e-01
    -1.56330496e-01  9.69698131e-02  1.24928504e-01  5.12717664e-02
    -1.31829023e-01  7.67928660e-02  5.32713532e-03 -2.81759799e-02]
   [ 1.32242084e-01 -2.21901685e-02  1.53149754e-01  6.62189126e-02
    -1.33845508e-01  1.46808833e-01  1.34788275e-01 -3.07158530e-02
     1.57297105e-02 -1.61284938e-01  1.41481370e-01  8.88178945e-02]
   [ 1.37166053e-01  7.25163519e-03  1.82257146e-02  1.01106375e-01
    -1.46806121e-01  7.49268532e-02 -1.12262405e-01 -8.03965479e-02
     8.99758637e-02  1.68902785e-01  8.05737078e-02 -1.53716922e-01]
   [-3.87430191e-06  1.55886561e-01 -1.53968483e-01  4.74248379e-02
     1.48850322e-01  9.80639458e-02  2.69348770e-02  1.29187196e-01
    -1.04294844e-01  5.72997183e-02 -1.03384912e-01  1.04157507e-01]
   [-3.08575928e-02 -1.78174868e-01 -1.52732000e-01  9.38374996e-02
     1.23474330e-01  5.52441478e-02 -1.77889764e-01  1.00657642e-01
    -1.37531906e-01  9.26029384e-02  9.69907939e-02 -2.03150511e-03]
   [ 1.03919923e-01  4.18893993e-03  6.23003840e-02  1.20164841e-01
    -5.60711473e-02 -3.42509151e-03  2.82454491e-02  9.55198705e-02
    -1.80768549e-01 -5.15434295e-02 -8.48628059e-02 -1.43701017e-01]
   [ 1.09497100e-01 -1.76315621e-01 -8.78376290e-02 -1.06290691e-01
    -1.77713335e-01 -3.94454896e-02 -8.83867517e-02  8.48598778e-03
    -9.84680429e-02 -1.74542964e-02 -7.20858574e-03  1.28679574e-01]]]


 [[[ 1.28606260e-02 -1.11839347e-01  1.78446263e-01  1.60450101e-01
    -1.22931167e-01  4.03821021e-02 -8.86781290e-02  4.64679003e-02
     1.59533948e-01 -1.85661018e-02  4.76158410e-02  1.59816533e-01]
   [ 1.14592135e-01 -3.25613171e-02  1.02412939e-01  1.78614378e-01
     1.61424309e-01 -2.00513154e-02  3.79820317e-02  3.60320657e-02
    -3.44310254e-02  6.52043819e-02 -2.49615759e-02 -6.52617514e-02]
   [ 7.00071156e-02 -8.65188316e-02  6.12260848e-02  1.46166623e-01
     5.68872392e-02 -3.95068973e-02  1.19807422e-01 -5.52808344e-02
     1.14707381e-01  4.55020815e-02  1.22642010e-01 -1.17365927e-01]
   [-1.81644708e-01  1.43975854e-01 -1.42608792e-01 -6.97683170e-02
     1.74225003e-01 -1.23612136e-01  4.15722728e-02 -4.14943993e-02
     1.71231061e-01  1.79012775e-01  1.68393940e-01 -1.55556113e-01]
   [-1.29081085e-01 -5.31472266e-03 -9.76994485e-02 -1.48799866e-02
    -4.37819362e-02  1.06984407e-01 -8.46678019e-02  6.73810095e-02
    -8.88119861e-02 -1.43700629e-01 -1.66791588e-01  5.36713898e-02]
   [-1.75354496e-01  1.38470829e-01  5.61376214e-02 -4.80189323e-02
     6.90983534e-02 -1.49500221e-02  1.03393614e-01  2.00432688e-02
    -1.60512343e-01  8.45625103e-02 -9.86327529e-02 -8.51325989e-02]
   [ 3.47246677e-02 -1.27928957e-01  3.90052348e-02  9.58932042e-02
    -9.02312472e-02 -1.05098784e-02  1.45444274e-01  2.19392180e-02
    -9.71539840e-02 -1.72861278e-01  8.16225111e-02 -4.66572493e-02]
   [-1.37085468e-01 -7.39390105e-02 -7.37784803e-02 -9.79664996e-02
     1.69566035e-01 -1.68275714e-01 -1.73885524e-01  9.83146727e-02
    -5.77553809e-02  1.36770874e-01 -1.71338812e-01  1.14945710e-01]]

  [[-1.02200180e-01 -8.54808763e-02  2.09976882e-02  1.76483124e-01
    -2.46948749e-02  6.84345961e-02  1.45440042e-01 -1.15988143e-01
     4.61251885e-02  1.36736155e-01 -4.15718406e-02 -3.48895639e-02]
   [-7.83773214e-02 -4.37892973e-02 -1.72850400e-01  1.09205306e-01
    -7.62047470e-02  9.95500386e-02 -1.67300001e-01 -1.40161797e-01
     4.44115847e-02 -7.95173049e-02  9.77259576e-02  6.59237802e-02]
   [ 1.22180581e-01  4.58921790e-02 -8.81682336e-02  8.87607038e-02
     1.87306106e-03 -1.22860476e-01  8.13596249e-02  5.36538512e-02
    -1.21953189e-02  1.81094140e-01 -2.48734653e-02  2.73757875e-02]
   [-6.70417473e-02 -9.75400209e-03  6.90546036e-02 -6.57290220e-05
     3.89454663e-02 -3.19474638e-02 -4.86744791e-02  4.34660912e-02
    -1.78270772e-01  1.57679737e-01  1.47491872e-01  3.11343968e-02]
   [ 1.68085605e-01  3.50283235e-02  1.56668156e-01 -6.75793290e-02
    -6.54479265e-02 -1.66074708e-01  1.48709089e-01  1.63217157e-01
    -1.07698597e-01 -4.47358340e-02 -7.77370557e-02  5.51681370e-02]
   [ 1.08388275e-01  1.31204963e-01  7.76115060e-02  1.02005243e-01
    -3.76685858e-02  6.04691952e-02 -1.05460025e-01 -6.43647462e-02
    -1.98711604e-02 -1.54201686e-03 -7.20002279e-02  4.67528850e-02]
   [ 7.62280822e-02  6.35936260e-02 -6.29071742e-02  4.29544002e-02
     1.17542863e-01  9.46930349e-02 -5.15767783e-02  4.67247218e-02
     1.53215140e-01  1.70972854e-01  4.20156568e-02 -1.27667263e-01]
   [-1.00742653e-01  5.63824326e-02  7.62930512e-03  8.20686817e-02
    -6.75128624e-02  2.11458206e-02  5.47942668e-02 -1.78667665e-01
    -5.19984365e-02  1.43111467e-01  5.68439662e-02 -5.82566634e-02]]

  [[ 6.52910024e-02  3.88919264e-02  1.56293601e-01 -5.79654500e-02
    -5.25534004e-02 -1.51155949e-01  7.13013709e-02 -3.91205400e-02
     1.64552271e-01  4.98473644e-03  1.15655333e-01  1.76461577e-01]
   [-7.70413727e-02 -9.89104286e-02 -1.39436483e-01 -1.05452687e-02
     9.18515325e-02 -1.58981636e-01 -7.53689855e-02  1.25269741e-02
    -1.69140071e-01 -1.64931148e-01  9.61601734e-02 -7.61459395e-02]
   [ 3.81103605e-02  1.55175328e-01 -1.01402074e-01 -1.71500608e-01
     1.55800700e-01  1.45497173e-01 -2.21505910e-02  1.14997149e-01
     9.81632471e-02 -1.25671476e-02  2.27606595e-02  1.38822883e-01]
   [ 8.14593136e-02  1.23865992e-01 -8.12770575e-02 -9.59374309e-02
    -1.03909969e-02  1.38591886e-01 -9.04690474e-02 -1.76978916e-01
     6.39621466e-02  1.16951436e-01  1.33817613e-01 -4.85350490e-02]
   [-6.42985851e-02 -1.14503540e-01 -1.49273306e-01  6.70658201e-02
    -1.15240313e-01  1.05984628e-01 -1.68339431e-01  6.25888109e-02
     8.41828883e-02  1.18337244e-01 -6.16042241e-02 -5.10894656e-02]
   [-1.03813283e-01 -1.73969269e-01  1.42139852e-01 -7.57478178e-02
    -2.05801129e-02  4.91224378e-02 -6.06351346e-02 -5.70891649e-02
     3.74096781e-02 -7.16233999e-02 -8.07693377e-02  1.01306140e-02]
   [-1.70468539e-02  9.37549174e-02  2.21922547e-02  3.11460942e-02
     6.40661418e-02 -4.77975756e-02  4.64781225e-02 -5.60601354e-02
     1.77811980e-01 -1.71505868e-01 -1.51334792e-01 -7.61548206e-02]
   [ 1.52543306e-01 -1.58861890e-01 -7.21160620e-02  4.08331454e-02
    -3.71688753e-02 -1.30136758e-01  6.75946176e-02  1.19643956e-02
    -1.81868404e-01  1.05541915e-01  2.93406844e-02 -4.08212692e-02]]]


 [[[-1.26051843e-01 -1.70084387e-01 -9.52820629e-02  1.30769521e-01
    -1.04875259e-01 -3.49074900e-02  7.44546950e-02  1.76120907e-01
    -1.45677984e-01 -1.57409281e-01  7.59648979e-02  7.47658610e-02]
   [ 1.65956259e-01  4.41375226e-02  3.59243304e-02 -7.29618296e-02
    -1.42369032e-01  9.90335643e-02 -3.81329954e-02 -6.60448819e-02
    -5.02698570e-02  7.66457915e-02  3.91039103e-02  2.00575441e-02]
   [ 7.39718378e-02 -1.78248867e-01 -4.46717143e-02  1.50459915e-01
    -1.24331236e-01  1.54924780e-01  1.13002002e-01  1.11056924e-01
     3.68026644e-02  1.04091257e-01 -7.09437802e-02 -5.79119995e-02]
   [-1.10180579e-01  1.56654567e-01  3.64961773e-02 -4.38162386e-02
    -5.18400818e-02 -4.87378091e-02  1.57480896e-01  3.45415026e-02
    -6.92495853e-02  1.66018069e-01  5.02528399e-02 -1.57147631e-01]
   [-1.11175224e-01 -6.81748912e-02 -4.95221615e-02 -7.11339116e-02
    -1.62811160e-01  8.68570805e-02 -9.64322686e-02 -1.23721570e-01
     1.13224864e-01 -1.78154767e-01  2.28995532e-02  1.60965860e-01]
   [ 1.73273623e-01 -1.42604917e-01  9.60727334e-02  7.41100311e-02
    -1.10245645e-02  9.16182995e-02 -3.04630399e-02  4.74387705e-02
    -6.29801750e-02 -8.76510218e-02 -1.31499857e-01 -2.49503404e-02]
   [-9.36283022e-02  1.39113128e-01 -5.57173043e-02 -4.20599282e-02
    -1.49229646e-01  6.66291267e-02 -1.13109134e-01  1.00668132e-01
    -1.28383011e-01  1.62950575e-01 -1.02640823e-01 -1.04010336e-01]
   [ 5.51230013e-02  1.36328906e-01  8.22690129e-02 -8.52608830e-02
    -7.75496662e-02 -2.23609358e-02 -6.74213171e-02  1.71216428e-02
     1.47710085e-01  1.52977854e-01  4.76944447e-03  1.19491100e-01]]

  [[ 1.97386146e-02  1.41787380e-01  1.48842096e-01 -1.79836601e-01
     6.08225316e-02 -1.59452587e-01 -8.96047801e-02 -7.63107836e-02
    -1.11123033e-01  9.58444476e-02  1.51126266e-01 -1.11307204e-01]
   [-1.88637972e-02  1.46871716e-01  6.01410717e-02  2.86610723e-02
     1.23184323e-01 -1.35057673e-01 -1.49379343e-01 -5.34864366e-02
    -3.29534262e-02  3.02254111e-02 -1.36238098e-01 -8.39818642e-02]
   [-1.94984972e-02 -1.01037651e-01 -1.80198714e-01  6.18741959e-02
    -3.82479131e-02  1.00545645e-01  3.71569395e-02  1.80864781e-01
     8.67847800e-02  1.69556111e-01 -1.50802314e-01 -1.26330003e-01]
   [ 1.50527000e-01  5.19312769e-02  1.17203027e-01  7.27529228e-02
    -4.61325943e-02  1.22542679e-03 -1.64538175e-02 -1.26455456e-01
    -1.22738481e-02 -3.42369080e-03 -1.32781357e-01 -9.28237513e-02]
   [-1.29109412e-01  1.16934955e-01 -6.06799126e-03  3.48960012e-02
     1.12979501e-01  4.91897762e-02  5.11793196e-02  4.26351279e-02
     1.33226126e-01  1.48976833e-01 -9.27268192e-02 -6.90789521e-03]
   [-1.23111546e-01 -1.71052814e-01  8.02772939e-02 -1.01912886e-01
    -2.86003500e-02  1.14549160e-01  4.26118821e-02  8.39364231e-02
    -3.22494805e-02 -7.89153874e-02 -1.32538334e-01 -1.29463747e-01]
   [ 1.46687120e-01  1.52506828e-01  9.26443636e-02  6.21414185e-02
    -1.72423720e-01 -6.23126999e-02  2.05010623e-02 -1.00300699e-01
    -1.53363794e-02  1.37828499e-01 -8.18656608e-02  1.51547343e-01]
   [ 1.38815999e-01 -7.20064938e-02 -5.25365025e-02  2.56573856e-02
     6.23481721e-02  2.25929767e-02 -1.10020570e-01 -4.29743379e-02
     3.30728740e-02 -2.43608803e-02 -9.76782069e-02 -8.40325356e-02]]

  [[-1.63036332e-01  1.25057250e-02  7.12753832e-03 -1.06795110e-01
     6.51193708e-02  1.22607529e-01  1.57663882e-01 -4.83435243e-02
     1.39397770e-01 -2.29231119e-02  1.37293845e-01 -1.18514135e-01]
   [ 7.97202885e-02 -3.46474499e-02 -1.49823725e-01  6.80226386e-02
    -1.16630763e-01 -2.42122710e-02  4.53294814e-03 -3.08151096e-02
    -5.27321249e-02 -3.81362438e-03 -1.13759786e-02 -8.65967050e-02]
   [ 1.80331796e-01  6.82802200e-02 -8.55085179e-02  5.56591004e-02
    -3.77566814e-02 -8.91078115e-02 -1.47222176e-01  1.29493445e-01
     1.69769377e-01 -1.67796969e-01 -1.57929957e-02  7.98244476e-02]
   [ 1.39167458e-01 -1.52052820e-01 -4.07072157e-02  9.21656489e-02
     1.02456957e-02 -1.76625893e-01 -1.39610946e-01 -1.55866221e-01
     1.40045702e-01 -3.42336595e-02  5.93219548e-02 -1.42839015e-01]
   [-5.18756956e-02  1.35763884e-01  9.81894135e-02 -1.33831456e-01
    -1.48827434e-01  5.15295416e-02 -1.05127551e-01  8.44017863e-02
     1.17250323e-01  1.12633914e-01  1.10680908e-02 -1.19379058e-01]
   [-1.38842523e-01 -4.17533964e-02 -8.26727748e-02 -5.91531023e-02
     1.12382501e-01 -8.16313401e-02  7.49033093e-02  2.87096202e-03
     1.17437840e-01  1.01735413e-01  1.44566804e-01  1.13771379e-01]
   [-1.16637640e-01  5.05429655e-02  7.48217106e-03  7.32546151e-02
     9.94349122e-02 -7.83396289e-02 -1.66305840e-01 -1.37253538e-01
     1.25993550e-01 -1.71555489e-01  9.11465883e-02  7.38407373e-02]
   [ 1.10166609e-01 -3.80566865e-02 -9.39138532e-02 -1.52244821e-01
    -1.51174814e-02 -1.33969262e-01  1.64696008e-01  2.71832049e-02
     1.63365245e-01 -6.29455298e-02  1.39455616e-01  3.91784757e-02]]]]: "
2018-04-20 09:28:53,599 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv_1/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 09:28:53,606 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv_2/weights:0, var_value [[[[-0.02920526  0.03114332  0.07556178 ...  0.08078215  0.03317054
     0.08133997]
   [ 0.06541389 -0.0714056  -0.12045061 ... -0.01010297 -0.04065978
    -0.04366763]
   [-0.10315385  0.09700729 -0.03924992 ... -0.11348377  0.14366092
     0.14392848]
   ...
   [ 0.14039032  0.11492862 -0.13838169 ...  0.12618656 -0.14563419
     0.0656838 ]
   [-0.11907725  0.11028333 -0.08764619 ...  0.01702762  0.03354317
    -0.03116849]
   [ 0.00041163 -0.08662196 -0.10274317 ...  0.07911474  0.10078789
    -0.03744234]]

  [[ 0.12377752 -0.10194632  0.05374162 ... -0.01728672  0.07922804
    -0.12383551]
   [ 0.04989144 -0.03849512 -0.09851025 ...  0.01318242  0.01081064
     0.14884894]
   [ 0.05687344 -0.0954612   0.02583839 ... -0.00986621  0.01287015
    -0.12618616]
   ...
   [-0.09302413  0.06463918 -0.02820335 ...  0.13729946  0.04159676
     0.10923503]
   [-0.03035811 -0.07867058 -0.02609675 ... -0.0538284   0.11970116
     0.08582166]
   [-0.12506635 -0.1361765   0.03656243 ... -0.14304249 -0.02295403
    -0.14778678]]

  [[ 0.073322    0.00066382  0.01132812 ... -0.03657614  0.07289805
    -0.15138987]
   [-0.12140965  0.05063708  0.09882168 ... -0.01612529 -0.05614009
     0.05685283]
   [-0.14226279 -0.12296318  0.07010618 ... -0.09440058  0.11210941
    -0.03090063]
   ...
   [ 0.08294705 -0.03542627 -0.09705739 ... -0.06138823  0.02672639
     0.15292941]
   [ 0.06306201  0.00099602 -0.03438902 ...  0.14358433  0.01500393
    -0.10632665]
   [-0.00780861  0.06028855 -0.01955938 ...  0.06119812  0.13792737
     0.0712768 ]]]


 [[[ 0.00138822 -0.14444543  0.05700496 ... -0.1420688   0.05771205
    -0.06127967]
   [-0.142923   -0.15150027 -0.1405664  ...  0.07226712  0.14594705
     0.08877878]
   [ 0.01995686  0.08113527  0.1394745  ... -0.05097167 -0.05327528
     0.06352206]
   ...
   [-0.02183338 -0.02164148  0.14560981 ... -0.08714315  0.11033224
    -0.14970969]
   [ 0.11455075 -0.11459181  0.14244781 ...  0.14594416 -0.11412099
    -0.00499496]
   [-0.13352413 -0.13583553  0.15286417 ... -0.0552082   0.08746991
     0.15323408]]

  [[-0.1106329  -0.0358509   0.02746415 ... -0.06078894  0.04966255
     0.12742223]
   [ 0.09369339 -0.02016181  0.13986747 ... -0.07942931  0.03955626
    -0.08520231]
   [ 0.12014051 -0.1433076  -0.02773224 ... -0.04497212 -0.12718649
     0.07232293]
   ...
   [-0.11415031  0.04120016 -0.13765298 ... -0.03793531  0.09867357
     0.13389201]
   [-0.01294461 -0.13478827 -0.15234767 ... -0.08313898  0.0497714
     0.11732294]
   [-0.11552845 -0.03007513  0.1164618  ... -0.06640126 -0.14707418
     0.05282299]]

  [[-0.05480959  0.12044753 -0.01254866 ...  0.1409223  -0.10205963
    -0.08372974]
   [-0.14350599 -0.05941768 -0.11675452 ...  0.10383911 -0.00428914
    -0.09363412]
   [-0.02692752  0.10505442  0.12645723 ... -0.07301025  0.04839116
    -0.07205761]
   ...
   [ 0.06215242  0.01079732  0.00747621 ...  0.06894314  0.05767238
    -0.0177819 ]
   [-0.01610197 -0.07911693 -0.12925336 ...  0.06165558 -0.15149781
    -0.08739956]
   [ 0.00354733 -0.10406735  0.10553958 ...  0.05455711 -0.08983726
     0.11769201]]]


 [[[-0.1408274   0.05439532  0.07556535 ... -0.03507796  0.117148
    -0.11513217]
   [-0.03333833  0.05693002 -0.148012   ...  0.08571839 -0.11009482
    -0.03143985]
   [ 0.0369008   0.04954611  0.10708191 ... -0.09012675  0.00994809
    -0.14538626]
   ...
   [ 0.05741754  0.02945384  0.08636624 ...  0.14660443 -0.05157582
    -0.0426112 ]
   [ 0.125059    0.05557431 -0.04478034 ... -0.0117159   0.06688198
     0.04059625]
   [ 0.05203255  0.11688437 -0.11579502 ...  0.15246804 -0.15327331
    -0.02917311]]

  [[ 0.04812337  0.14541169 -0.02299583 ... -0.04381828  0.04496065
    -0.13958545]
   [ 0.0849608   0.02151982  0.13751878 ... -0.09880394 -0.05738863
    -0.11465292]
   [-0.04540027 -0.11332532 -0.14562838 ...  0.0929032   0.1173936
    -0.03032213]
   ...
   [-0.12221383  0.09325005  0.07185365 ...  0.09368923  0.03340632
     0.04187126]
   [-0.00506829 -0.10702516 -0.03905097 ...  0.10690762  0.14002176
     0.05246884]
   [ 0.07353538 -0.13594535 -0.03012741 ...  0.12792723 -0.04081091
    -0.1098295 ]]

  [[-0.06634346  0.02977486  0.08566067 ...  0.09430404  0.08419526
     0.08522362]
   [-0.08819869 -0.12208249  0.07034218 ...  0.0912735  -0.08815738
    -0.08286659]
   [-0.11275759 -0.05685685  0.10075052 ...  0.04972965 -0.05060253
    -0.09544295]
   ...
   [ 0.04746078  0.14117186 -0.00307433 ... -0.00714736  0.10469718
    -0.11343591]
   [-0.13416338 -0.12214646  0.0910908  ...  0.00146876 -0.04203351
     0.01481386]
   [-0.13841763  0.02974628  0.05971453 ...  0.08685987  0.01862156
    -0.02834779]]]]: "
2018-04-20 09:28:53,610 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv_2/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 09:28:53,614 (dqn_agent.py:161) DEBUG: "var_name: target_q/fully_connected/weights:0, var_value [[ 0.08157042  0.06623418  0.06776739 ...  0.05644212  0.07899103
   0.05643616]
 [ 0.02209343 -0.05179443 -0.02903633 ... -0.00462473  0.0866315
  -0.02627775]
 [-0.00445791  0.01925971  0.06567714 ... -0.03357385  0.07819278
   0.04664712]
 ...
 [ 0.03009177 -0.06488372  0.06634163 ... -0.03944565 -0.04472656
  -0.07609192]
 [-0.06219979  0.05804006 -0.01590803 ... -0.06922067 -0.0525541
   0.08135106]
 [-0.01098281 -0.08562314 -0.07261136 ... -0.08409451 -0.01397916
   0.02504937]]: "
2018-04-20 09:28:53,619 (dqn_agent.py:161) DEBUG: "var_name: target_q/fully_connected/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 09:28:53,626 (dqn_agent.py:161) DEBUG: "var_name: target_q/fully_connected_1/weights:0, var_value [[-1.33299828e-01  1.40574872e-02 -7.08519369e-02  6.46952689e-02
   9.59742069e-02]
 [-1.93864018e-01 -1.61325574e-01 -1.27446860e-01  2.11798012e-01
   1.96384192e-01]
 [-1.62822932e-01  1.54100925e-01 -2.03218877e-01  1.86855614e-01
   1.69897169e-01]
 [-1.34735703e-02  2.58669257e-04 -1.90357491e-01 -5.68246841e-03
   1.00014180e-01]
 [ 1.13576621e-01  3.52445692e-02  7.04729557e-02  9.39109623e-02
   1.04788691e-01]
 [ 4.65270877e-03 -4.56783473e-02  7.44275749e-02 -1.56244859e-01
   1.06541067e-01]
 [-3.39077413e-03 -5.53624034e-02  4.70186770e-02  2.04944879e-01
   3.21537405e-02]
 [-1.39143586e-01 -4.10440117e-02  1.65419012e-01  6.88962936e-02
   2.32711583e-02]
 [ 5.16156852e-02 -9.28531587e-03 -1.47460848e-02 -1.29877895e-01
  -2.08430141e-01]
 [-1.24819465e-01  1.29220456e-01 -1.76744461e-01 -1.65693939e-01
  -1.23002976e-01]
 [ 6.32750988e-02 -2.04019532e-01 -7.52302706e-02 -1.38983667e-01
   1.94035828e-01]
 [ 1.88507468e-01  1.17310137e-01 -9.67103615e-02 -1.20085582e-01
  -1.75580502e-01]
 [-1.36453196e-01  7.53062963e-02  1.86333507e-01  1.99722469e-01
   9.47043896e-02]
 [-8.57917666e-02  5.19664586e-02  1.13683581e-01  5.64240515e-02
  -8.79084468e-02]
 [ 4.06257510e-02  9.89227593e-02 -1.17120229e-01  1.42862946e-01
  -1.49873540e-01]
 [-2.06193388e-01  1.60203159e-01  2.06621438e-01 -5.88385612e-02
  -2.09971458e-01]
 [-1.63450658e-01 -5.57343662e-03  9.87532139e-02 -2.03066349e-01
   8.07760060e-02]
 [-1.60088852e-01 -1.01498790e-01  1.21336877e-02 -1.74619406e-02
   2.85941362e-03]
 [-9.28267837e-04  8.98760557e-02  1.31628960e-01 -2.18663663e-02
   5.96837699e-02]
 [ 1.03134096e-01 -1.22160636e-01 -8.58860016e-02  1.08571261e-01
  -1.11071490e-01]
 [-2.78026909e-02 -8.59253556e-02  1.14764988e-01  1.48713738e-01
   6.38012588e-03]
 [-1.55442983e-01 -1.29066616e-01 -1.29093245e-01 -5.37588000e-02
  -1.58720776e-01]
 [ 3.96580696e-02 -1.59128532e-01  1.77198738e-01 -1.03527457e-02
   1.32669419e-01]
 [ 2.05792040e-02 -1.53549463e-01  1.95737988e-01  1.42226875e-01
  -1.13157481e-01]
 [-1.14196606e-01  2.57390738e-03 -8.75675902e-02 -1.34542868e-01
  -1.19291604e-01]
 [ 7.68667459e-02  1.88262939e-01  9.44095552e-02 -8.99212211e-02
   9.73729193e-02]
 [ 2.07806557e-01  9.33260620e-02 -1.29229918e-01 -2.04818681e-01
   1.22991323e-01]
 [-1.07458860e-01  1.29220963e-01  7.39139616e-02 -1.23778522e-01
  -1.63169667e-01]
 [-2.27470398e-02  1.63773537e-01 -1.00449942e-01 -2.06083298e-01
  -1.72836930e-02]
 [ 5.94137609e-02 -8.15672129e-02 -1.27406180e-01 -1.91571876e-01
   1.71176940e-02]
 [-2.06798315e-02  1.38266891e-01  1.38171643e-01  1.91700399e-01
  -1.25953898e-01]
 [-5.31684905e-02 -3.75389010e-02  1.16632581e-02  3.84386182e-02
  -1.37449086e-01]
 [-4.07289416e-02 -5.69811463e-02  1.52470797e-01 -1.85510069e-01
   1.42048717e-01]
 [-4.06951606e-02  1.38778806e-01 -1.85947388e-01  1.43138587e-01
   1.28177285e-01]
 [ 8.99710357e-02 -1.61721781e-01 -3.68046761e-02 -4.57380563e-02
   4.95254993e-04]
 [-1.53600708e-01  4.52516675e-02  1.27036512e-01 -1.16491184e-01
   6.57955110e-02]
 [-6.16139024e-02 -5.18214703e-03 -1.30937845e-01 -1.14585012e-01
  -1.75196454e-01]
 [-1.94620371e-01 -2.03980654e-02 -1.58955842e-01  7.26519227e-02
  -1.73306316e-02]
 [-1.75178438e-01 -1.42431408e-02 -1.09862112e-01  2.25317180e-02
  -1.12451665e-01]
 [-1.53357133e-01 -1.09710343e-01 -1.37862548e-01  9.25220251e-02
  -1.44818902e-01]
 [ 5.81429601e-02 -1.29831821e-01 -1.75121158e-01 -4.49038148e-02
  -1.95001125e-01]
 [ 8.79958272e-03  1.03748083e-01  4.46168482e-02  1.19810611e-01
  -1.67408451e-01]
 [-1.94066912e-02 -4.55603004e-02 -1.62356049e-02 -1.00090802e-01
   6.25995994e-02]
 [ 2.04512358e-01 -5.51346838e-02  1.40624315e-01  1.60176247e-01
   1.87169224e-01]
 [ 2.11744457e-01 -3.81401479e-02  1.10687912e-02  7.24288821e-02
   8.87269974e-02]
 [ 9.30531323e-02 -9.58742499e-02  8.00922811e-02  8.39873254e-02
   8.94822776e-02]
 [ 1.53533459e-01  4.07693386e-02  1.16920471e-01  2.10090339e-01
  -4.98117507e-02]
 [ 9.24170315e-02 -8.13147277e-02  1.51871681e-01  1.61630422e-01
  -1.76149949e-01]
 [-9.98161361e-02 -1.97957620e-01  1.79989189e-02 -1.77015126e-01
   8.34802687e-02]
 [-1.34091109e-01 -2.21316665e-02 -1.89185783e-01  8.82847607e-02
   1.84389651e-01]
 [-1.12051971e-01 -1.52146801e-01  4.71714139e-02 -3.92214954e-02
  -1.32929534e-01]
 [ 1.91508263e-01  1.34995282e-01 -1.17333218e-01 -7.69265443e-02
  -3.91703099e-02]
 [-3.90403569e-02  7.71655142e-02  5.80673218e-02 -1.23770416e-01
   1.80938691e-02]
 [-1.99991658e-01 -1.30604208e-03  1.33748442e-01 -1.33045971e-01
   2.50199437e-03]
 [-1.20283075e-01 -4.17659432e-02  1.09589458e-01  6.80515766e-02
   1.12798393e-01]
 [ 9.99173522e-03  1.14754200e-01 -9.14048031e-02 -1.89841866e-01
   1.61151230e-01]
 [ 1.82970345e-01  2.11820155e-02  1.56734735e-01 -1.18818730e-01
  -4.47130501e-02]
 [-2.41348147e-02 -8.86413530e-02  1.89207852e-01 -1.25272632e-01
  -1.41281784e-01]
 [-1.16354607e-01  3.20801586e-02  1.47045374e-01 -3.08876932e-02
   2.02019781e-01]
 [ 6.14875555e-03  1.27297550e-01  7.21142292e-02 -2.00974122e-01
   2.68503129e-02]
 [ 1.92973077e-01 -7.58328438e-02  1.37268245e-01 -2.03969091e-01
  -5.90929687e-02]
 [-1.08924322e-01 -8.94440934e-02  1.97469890e-02 -1.35631725e-01
   1.10527873e-01]
 [-1.77012652e-01 -6.18345439e-02  1.03068411e-01 -1.19194679e-01
  -9.90418568e-02]
 [-4.15264666e-02  1.14324659e-01  4.54396307e-02 -2.01209292e-01
   1.91397458e-01]
 [ 2.10495889e-01  6.39667809e-02 -5.37462980e-02  1.83368206e-01
  -3.50108743e-02]
 [ 4.06920314e-02 -1.85996920e-01  4.13198769e-03 -3.35038453e-02
   1.44174308e-01]
 [ 1.62238747e-01  1.37864232e-01 -1.39489084e-01  1.02697134e-01
  -4.73292023e-02]
 [-6.67312741e-03 -1.80796742e-01  6.88863099e-02  1.51217908e-01
  -1.14925765e-01]
 [ 1.24556690e-01  1.96774036e-01  1.98205948e-01  9.99077559e-02
  -1.86149955e-01]
 [-6.42117113e-02  2.07862675e-01  8.95886123e-02 -1.92947894e-01
  -2.04674050e-01]
 [ 9.47193205e-02 -1.13070838e-01 -2.06116155e-01 -1.32610172e-01
   1.85954273e-01]
 [ 2.10419506e-01 -1.63228869e-01 -1.71216086e-01 -1.24598525e-01
  -1.54693916e-01]
 [ 1.45468861e-01 -3.27154249e-02  6.93160295e-02 -1.47741169e-01
  -1.58869356e-01]
 [-8.43391120e-02 -1.80306643e-01 -6.53254986e-03  1.79963320e-01
  -1.87741444e-01]
 [-1.16624981e-02 -2.42316425e-02 -1.79944515e-01  3.52976471e-02
  -4.84511703e-02]
 [ 1.06213987e-02  8.93397629e-03 -3.82776856e-02  1.05401129e-02
  -1.55844748e-01]
 [-1.01029508e-01  2.61832327e-02  1.35792792e-01 -1.03135407e-01
   3.71879637e-02]
 [ 9.54458416e-02 -1.16168968e-01  9.37369466e-02 -2.79847383e-02
  -1.37182206e-01]
 [-9.76120532e-02  2.05598891e-01 -1.06868811e-01  1.27204329e-01
   1.49802685e-01]
 [ 6.70772195e-02  3.02013308e-02 -7.55790323e-02 -1.99647725e-01
   7.73878396e-03]
 [ 1.14767253e-01  1.54064566e-01 -2.55355239e-03  1.31901413e-01
   1.53072029e-01]
 [-7.74801970e-02 -2.08543062e-01  6.48558140e-02  5.96918166e-03
   7.84949660e-02]
 [ 7.50566423e-02  1.12952858e-01 -1.34281576e-01  1.47529095e-01
   1.90393686e-01]
 [ 1.45587295e-01 -1.93827972e-01  2.03819215e-01  1.61185920e-01
  -1.70694143e-01]
 [ 1.84947193e-01 -9.87321138e-04  5.78837097e-02 -6.76939487e-02
   3.25574428e-02]
 [-1.23953968e-02  8.64458382e-02 -9.21477899e-02  8.11449289e-02
   2.07048833e-01]
 [ 1.52090222e-01  2.08526313e-01  9.52346325e-02  8.56096148e-02
   1.51132792e-01]
 [-1.38095587e-01  1.89284980e-01 -4.76497412e-02 -1.70217991e-01
  -6.45513535e-02]
 [ 1.62907451e-01  4.16189432e-05  5.21859229e-02 -4.28136736e-02
   2.83536464e-02]
 [ 2.49941200e-02  1.79801911e-01  2.23825872e-02  6.37984574e-02
   1.90637261e-01]
 [-1.11613177e-01  1.85310453e-01 -1.19038001e-01  1.50295615e-01
   1.55494332e-01]
 [ 2.11143196e-02 -8.70250165e-03  1.28290564e-01 -1.97300270e-01
   7.28970468e-02]
 [-2.51718163e-02  4.16837633e-02 -6.66119307e-02 -2.66940296e-02
   2.17834711e-02]
 [-5.59258163e-02  1.05253756e-01 -1.91947311e-01 -1.46291807e-01
   1.85605377e-01]
 [ 1.36108756e-01 -5.71402609e-02 -1.96304917e-03  1.74542964e-02
  -2.02672616e-01]
 [ 1.66650534e-01  9.12436843e-02  1.09799713e-01  1.00556284e-01
  -1.52703524e-01]
 [ 1.37518495e-01  1.06106132e-01 -1.89798936e-01 -1.85306042e-01
   2.87944674e-02]
 [ 2.33644396e-02 -3.53551209e-02 -1.29313275e-01  1.14356220e-01
   2.65521407e-02]
 [ 9.87855792e-02  2.04345733e-02  1.13541901e-01  1.27106309e-02
   1.28202289e-01]
 [-1.48128241e-01 -9.52904820e-02  1.90396339e-01 -2.11362988e-02
   2.09120154e-01]
 [ 1.60200477e-01 -2.08531618e-01 -4.95258421e-02 -1.57291830e-01
   1.95052624e-01]
 [ 1.00021899e-01 -3.89390886e-02 -2.34838873e-02 -3.31031829e-02
  -9.69290733e-04]
 [ 1.43746346e-01  1.96992368e-01 -5.24681509e-02 -3.16498727e-02
   1.64927810e-01]
 [-1.34221464e-01 -1.73774242e-01 -2.01056719e-01  1.65233731e-01
  -2.07562268e-01]
 [-1.62036598e-01 -1.27658367e-01  1.42982304e-01 -6.27174973e-04
  -8.96266475e-02]
 [-7.97394216e-02  5.48231006e-02 -1.03361160e-01 -4.32671010e-02
   1.03646606e-01]
 [-3.39051634e-02 -1.68837503e-01  1.50081098e-01 -9.88376290e-02
   1.41394466e-01]
 [-1.70523748e-01  7.36922920e-02 -4.59634960e-02 -1.47729874e-01
   1.26590282e-01]
 [ 3.94977927e-02 -4.23553735e-02 -1.07438959e-01  2.37901062e-02
  -1.30911961e-01]
 [ 5.04257977e-02  1.79057568e-01  2.02911735e-01  6.06529117e-02
   1.26227140e-02]
 [-9.79978219e-02  1.75997287e-01  4.79388535e-02  9.06721652e-02
  -1.76444769e-01]
 [-1.59125388e-01 -1.74650669e-01 -1.27384454e-01 -1.90612704e-01
  -4.08250093e-02]
 [ 1.83052123e-01 -5.32934219e-02  2.10260600e-01 -1.80872694e-01
  -7.23566860e-02]
 [ 7.72516429e-02  1.53194070e-01  1.58892840e-01 -2.86635011e-02
  -1.10854596e-01]
 [-1.37804210e-01 -1.53750509e-01  2.10951388e-01  3.84791195e-02
  -3.72670144e-02]
 [-2.05008924e-01  1.65603966e-01  1.37905627e-02 -1.31051019e-01
  -1.87281847e-01]
 [ 7.60070980e-02 -9.38904956e-02 -3.21145505e-02  2.05786556e-01
  -1.60290658e-01]
 [ 1.50911659e-01 -6.85408711e-04  7.17292130e-02 -1.12558112e-01
   8.05796683e-03]
 [ 1.79141074e-01  6.64601624e-02 -6.92120194e-02 -5.89349717e-02
   1.05314732e-01]
 [-5.36694676e-02  1.74739271e-01  1.08442426e-01 -6.52989000e-02
  -1.82026416e-01]
 [-1.94738805e-03 -3.06461006e-02 -1.07189305e-01  5.62258661e-02
   1.22701526e-01]
 [ 7.05108047e-04 -1.84519559e-01  8.60762596e-02 -6.98125511e-02
  -3.19413096e-02]
 [-2.30425596e-03 -1.85792834e-01 -2.10975885e-01  8.40231776e-03
  -1.17462605e-01]
 [ 7.62175024e-02  4.20083404e-02  1.55216455e-01 -9.79003385e-02
  -1.64052919e-01]
 [ 9.70424414e-02  1.73741877e-01 -3.36237103e-02  6.78210557e-02
   1.83016956e-02]
 [-1.61673069e-01 -8.19951296e-04 -1.96342975e-01  3.94056737e-03
  -2.08351642e-01]
 [-1.43294185e-01 -1.36637330e-01  1.64014935e-01 -6.10820353e-02
   1.85837388e-01]
 [ 1.45880431e-02  1.55484349e-01 -1.23854734e-01  9.29306746e-02
  -5.54155707e-02]]: "
2018-04-20 09:28:53,630 (dqn_agent.py:161) DEBUG: "var_name: target_q/fully_connected_1/biases:0, var_value [0. 0. 0. 0. 0.]: "
2018-04-20 09:28:54,502 (dqn_main.py:212) DEBUG: "Episode 1, mean reward over last 10000 episodes: 0"
2018-04-20 09:28:54,502 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:28:54,502 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -1.0, done: True"
2018-04-20 09:28:54,502 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:29,070 (dqn_main.py:61) DEBUG: ">>>> RUNNING data_file=7_17.npy,reuse_weights=None,test=True<<<<"
2018-04-20 09:30:29,491 (tf_logging.py:160) Level 1: "Registering Batch (<function _BatchGrad at 0x7fa912df4378>) in gradient."
2018-04-20 09:30:29,492 (tf_logging.py:160) Level 1: "Registering Unbatch (<function _UnbatchGrad at 0x7fa912df4e18>) in gradient."
2018-04-20 09:30:29,499 (tf_logging.py:160) Level 1: "Registering ZeroInitializer (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,524 (tf_logging.py:160) Level 1: "Registering SparseFeatureCross (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,527 (tf_logging.py:160) Level 1: "Registering SparseFeatureCrossV2 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,533 (tf_logging.py:160) Level 1: "Registering SparseFeatureCross (None) in gradient."
2018-04-20 09:30:29,534 (tf_logging.py:160) Level 1: "Registering SparseFeatureCrossV2 (None) in gradient."
2018-04-20 09:30:29,540 (tf_logging.py:160) Level 1: "Registering GDNLowerBound (<function GDN._lower_bound_grad at 0x7fa9104d76a8>) in gradient."
2018-04-20 09:30:29,568 (tf_logging.py:160) Level 1: "Registering ObtainNext (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,581 (tf_logging.py:160) Level 1: "Registering hparams ((<class 'tensorflow.contrib.training.python.training.hparam_pb2.HParamDef'>, <function HParams.to_proto at 0x7fa910093620>, <function HParams.from_proto at 0x7fa9100936a8>)) in proto functions."
2018-04-20 09:30:29,591 (tf_logging.py:160) Level 1: "Registering GRUBlockCell (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,593 (tf_logging.py:160) Level 1: "Registering GRUBlockCellGrad (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,595 (tf_logging.py:160) Level 1: "Registering GRUBlockCell (<function _GRUBlockCellGrad at 0x7fa91002cb70>) in gradient."
2018-04-20 09:30:29,597 (tf_logging.py:160) Level 1: "Registering BlockLSTM (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,599 (tf_logging.py:160) Level 1: "Registering BlockLSTMGrad (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,600 (tf_logging.py:160) Level 1: "Registering LSTMBlockCell (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,602 (tf_logging.py:160) Level 1: "Registering LSTMBlockCellGrad (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,605 (tf_logging.py:160) Level 1: "Registering LSTMBlockCell (<function _LSTMBlockCellGrad at 0x7fa9082e0d90>) in gradient."
2018-04-20 09:30:29,605 (tf_logging.py:160) Level 1: "Registering BlockLSTM (<function _BlockLSTMGrad at 0x7fa9082e0e18>) in gradient."
2018-04-20 09:30:29,610 (tf_logging.py:160) Level 1: "Registering KMC2ChainInitialization (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,611 (tf_logging.py:160) Level 1: "Registering KmeansPlusPlusInitialization (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,613 (tf_logging.py:160) Level 1: "Registering NearestNeighbors (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,616 (tf_logging.py:160) Level 1: "Registering MaskedMatmul (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,618 (tf_logging.py:160) Level 1: "Registering WALSComputePartialLhsAndRhs (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,633 (tf_logging.py:160) Level 1: "Registering ConfigureDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,634 (tf_logging.py:160) Level 1: "Registering CrossReplicaSum (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,635 (tf_logging.py:160) Level 1: "Registering InfeedDequeue (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,636 (tf_logging.py:160) Level 1: "Registering InfeedDequeueTuple (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,636 (tf_logging.py:160) Level 1: "Registering InfeedEnqueue (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,637 (tf_logging.py:160) Level 1: "Registering InfeedEnqueueTuple (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,638 (tf_logging.py:160) Level 1: "Registering OutfeedDequeue (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,638 (tf_logging.py:160) Level 1: "Registering OutfeedDequeueTuple (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,639 (tf_logging.py:160) Level 1: "Registering OutfeedEnqueue (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,639 (tf_logging.py:160) Level 1: "Registering OutfeedEnqueueTuple (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,640 (tf_logging.py:160) Level 1: "Registering ShutdownDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,641 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingActivations (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,641 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingEnqueueSparseBatch (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,642 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingLoadAdagradParameters (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,643 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingLoadGradientDescentParameters (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,643 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingReceiveActivations (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,653 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingRetrieveAdagradParameters (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,653 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingRetrieveGradientDescentParameters (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,654 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingSendGradients (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,655 (tf_logging.py:160) Level 1: "Registering TPUReplicate (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,655 (tf_logging.py:160) Level 1: "Registering TPUReplicateMetadata (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,656 (tf_logging.py:160) Level 1: "Registering TPUReplicatedInput (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,657 (tf_logging.py:160) Level 1: "Registering TPUReplicatedOutput (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,673 (tf_logging.py:160) Level 1: "Registering _ConfigureDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,674 (tf_logging.py:160) Level 1: "Registering _WaitForDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,675 (tf_logging.py:160) Level 1: "Registering _SetGlobalTPUArray (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,676 (tf_logging.py:160) Level 1: "Registering _ShutdownDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,676 (tf_logging.py:160) Level 1: "Registering _InitializeHostForDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,677 (tf_logging.py:160) Level 1: "Registering _DisconnectHostFromDistributedTPUSystem (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,679 (tf_logging.py:160) Level 1: "Registering CrossReplicaSum (<function _cross_replica_sum_grad at 0x7fa908198400>) in gradient."
2018-04-20 09:30:29,692 (tf_logging.py:160) Level 1: "Registering CloseSummaryWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,694 (tf_logging.py:160) Level 1: "Registering CreateSummaryDbWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,695 (tf_logging.py:160) Level 1: "Registering CreateSummaryFileWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,695 (tf_logging.py:160) Level 1: "Registering FlushSummaryWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,696 (tf_logging.py:160) Level 1: "Registering ImportEvent (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,697 (tf_logging.py:160) Level 1: "Registering SummaryWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,697 (tf_logging.py:160) Level 1: "Registering WriteAudioSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,723 (tf_logging.py:160) Level 1: "Registering WriteGraphSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,724 (tf_logging.py:160) Level 1: "Registering WriteHistogramSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,724 (tf_logging.py:160) Level 1: "Registering WriteImageSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,725 (tf_logging.py:160) Level 1: "Registering WriteScalarSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,725 (tf_logging.py:160) Level 1: "Registering WriteSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,763 (tf_logging.py:160) Level 1: "Registering BigQueryReader (None) in gradient."
2018-04-20 09:30:29,766 (tf_logging.py:160) Level 1: "Registering RangeDecode (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,767 (tf_logging.py:160) Level 1: "Registering RangeEncode (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,802 (tf_logging.py:160) Level 1: "Registering CudnnRNN (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,806 (tf_logging.py:160) Level 1: "Registering CudnnRNNBackprop (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,807 (tf_logging.py:160) Level 1: "Registering CudnnRNNCanonicalToParams (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,808 (tf_logging.py:160) Level 1: "Registering CudnnRNNParamsSize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,810 (tf_logging.py:160) Level 1: "Registering CudnnRNNParamsToCanonical (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,819 (tf_logging.py:160) Level 1: "Registering CudnnRNN (<function _cudnn_rnn_backward at 0x7fa8d5d546a8>) in gradient."
2018-04-20 09:30:29,821 (tf_logging.py:160) Level 1: "Registering CudnnRNNParamsSize (<function call_cpp_shape_fn at 0x7fa97e53d840>) in shape functions."
2018-04-20 09:30:29,822 (tf_logging.py:160) Level 1: "Registering CudnnRNNParamsToCanonical (<function call_cpp_shape_fn at 0x7fa97e53d840>) in shape functions."
2018-04-20 09:30:29,822 (tf_logging.py:160) Level 1: "Registering CudnnRNNCanonicalToParams (<function call_cpp_shape_fn at 0x7fa97e53d840>) in shape functions."
2018-04-20 09:30:29,823 (tf_logging.py:160) Level 1: "Registering CudnnRNN (<function call_cpp_shape_fn at 0x7fa97e53d840>) in shape functions."
2018-04-20 09:30:29,824 (tf_logging.py:160) Level 1: "Registering CudnnRNNBackprop (<function call_cpp_shape_fn at 0x7fa97e53d840>) in shape functions."
2018-04-20 09:30:29,856 (tf_logging.py:160) Level 1: "Registering AdjustHsvInYiq (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,860 (tf_logging.py:160) Level 1: "Registering BipartiteMatch (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,861 (tf_logging.py:160) Level 1: "Registering ImageConnectedComponents (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,862 (tf_logging.py:160) Level 1: "Registering ImageProjectiveTransform (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,865 (tf_logging.py:160) Level 1: "Registering ImageConnectedComponents (<function call_cpp_shape_fn at 0x7fa97e53d840>) in shape functions."
2018-04-20 09:30:29,866 (tf_logging.py:160) Level 1: "Registering ImageProjectiveTransform (<function call_cpp_shape_fn at 0x7fa97e53d840>) in shape functions."
2018-04-20 09:30:29,867 (tf_logging.py:160) Level 1: "Registering ImageProjectiveTransform (<function _image_projective_transform_grad at 0x7fa8d5674b70>) in gradient."
2018-04-20 09:30:29,867 (tf_logging.py:160) Level 1: "Registering BipartiteMatch (None) in gradient."
2018-04-20 09:30:29,868 (tf_logging.py:160) Level 1: "Registering ImageConnectedComponents (None) in gradient."
2018-04-20 09:30:29,869 (tf_logging.py:160) Level 1: "Registering SingleImageRandomDotStereograms (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,874 (tf_logging.py:160) Level 1: "Registering SingleImageRandomDotStereograms (None) in gradient."
2018-04-20 09:30:29,904 (tf_logging.py:160) Level 1: "Registering BytesInUse (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,904 (tf_logging.py:160) Level 1: "Registering BytesLimit (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,905 (tf_logging.py:160) Level 1: "Registering MaxBytesInUse (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,910 (tf_logging.py:160) Level 1: "Registering NcclAllReduce (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,910 (tf_logging.py:160) Level 1: "Registering NcclBroadcast (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,911 (tf_logging.py:160) Level 1: "Registering NcclReduce (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,913 (tf_logging.py:160) Level 1: "Registering _NcclReduceSend (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,914 (tf_logging.py:160) Level 1: "Registering _NcclReduceRecv (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,914 (tf_logging.py:160) Level 1: "Registering _NcclBroadcastSend (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,914 (tf_logging.py:160) Level 1: "Registering _NcclBroadcastRecv (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,915 (tf_logging.py:160) Level 1: "Registering NcclAllReduce (<function _all_sum_grad at 0x7fa8d4d26950>) in gradient."
2018-04-20 09:30:29,915 (tf_logging.py:160) Level 1: "Registering NcclReduce (<function _reduce_sum_grad at 0x7fa8d4d26bf8>) in gradient."
2018-04-20 09:30:29,915 (tf_logging.py:160) Level 1: "Registering NcclBroadcast (<function _broadcast_grad at 0x7fa8d4d26d90>) in gradient."
2018-04-20 09:30:29,916 (tf_logging.py:160) Level 1: "Registering PeriodicResample (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,921 (tf_logging.py:160) Level 1: "Registering FoldFusedBatchNormGrad (<function _FoldFusedBatchNormGrad at 0x7fa8d4a6c048>) in gradient."
2018-04-20 09:30:29,924 (tf_logging.py:160) Level 1: "Registering Resampler (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,925 (tf_logging.py:160) Level 1: "Registering ResamplerGrad (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,926 (tf_logging.py:160) Level 1: "Registering Resampler (<function _resampler_grad at 0x7fa8d479ac80>) in gradient."
2018-04-20 09:30:29,927 (tf_logging.py:160) Level 1: "Registering ResamplerGrad (None) in gradient."
2018-04-20 09:30:29,930 (tf_logging.py:160) Level 1: "Registering GatherTree (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,940 (tf_logging.py:160) Level 1: "Registering StatelessRandomNormal (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,941 (tf_logging.py:160) Level 1: "Registering StatelessRandomUniform (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,941 (tf_logging.py:160) Level 1: "Registering StatelessTruncatedNormal (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,942 (tf_logging.py:160) Level 1: "Registering StatelessRandomNormal (None) in gradient."
2018-04-20 09:30:29,942 (tf_logging.py:160) Level 1: "Registering StatelessRandomUniform (None) in gradient."
2018-04-20 09:30:29,942 (tf_logging.py:160) Level 1: "Registering StatelessTruncatedNormal (None) in gradient."
2018-04-20 09:30:29,949 (tf_logging.py:160) Level 1: "Registering ReinterpretStringToFloat (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,951 (tf_logging.py:160) Level 1: "Registering ScatterAddNdim (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,958 (tf_logging.py:160) Level 1: "Registering CreateTreeVariable (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,958 (tf_logging.py:160) Level 1: "Registering DecisionTreeResourceHandleOp (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,959 (tf_logging.py:160) Level 1: "Registering FeatureUsageCounts (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,959 (tf_logging.py:160) Level 1: "Registering TraverseTreeV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,959 (tf_logging.py:160) Level 1: "Registering TreeDeserialize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,959 (tf_logging.py:160) Level 1: "Registering TreeIsInitializedOp (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,960 (tf_logging.py:160) Level 1: "Registering TreePredictionsV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,961 (tf_logging.py:160) Level 1: "Registering TreeSerialize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,961 (tf_logging.py:160) Level 1: "Registering TreeSize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,961 (tf_logging.py:160) Level 1: "Registering UpdateModelV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,964 (tf_logging.py:160) Level 1: "Registering TreeVariable (None) in gradient."
2018-04-20 09:30:29,965 (tf_logging.py:160) Level 1: "Registering TreeSerialize (None) in gradient."
2018-04-20 09:30:29,965 (tf_logging.py:160) Level 1: "Registering TreeDeserialize (None) in gradient."
2018-04-20 09:30:29,965 (tf_logging.py:160) Level 1: "Registering TreeSize (None) in gradient."
2018-04-20 09:30:29,965 (tf_logging.py:160) Level 1: "Registering TreePredictionsV4 (None) in gradient."
2018-04-20 09:30:29,966 (tf_logging.py:160) Level 1: "Registering FeatureUsageCounts (None) in gradient."
2018-04-20 09:30:29,966 (tf_logging.py:160) Level 1: "Registering CreateFertileStatsVariable (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,967 (tf_logging.py:160) Level 1: "Registering FertileStatsDeserialize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,967 (tf_logging.py:160) Level 1: "Registering FertileStatsIsInitializedOp (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,967 (tf_logging.py:160) Level 1: "Registering FertileStatsResourceHandleOp (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,967 (tf_logging.py:160) Level 1: "Registering FertileStatsSerialize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,968 (tf_logging.py:160) Level 1: "Registering FinalizeTree (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,968 (tf_logging.py:160) Level 1: "Registering GrowTreeV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,968 (tf_logging.py:160) Level 1: "Registering ProcessInputV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,971 (tf_logging.py:160) Level 1: "Registering FertileStatsVariable (None) in gradient."
2018-04-20 09:30:29,971 (tf_logging.py:160) Level 1: "Registering FertileStatsSerialize (None) in gradient."
2018-04-20 09:30:29,971 (tf_logging.py:160) Level 1: "Registering FertileStatsDeserialize (None) in gradient."
2018-04-20 09:30:29,972 (tf_logging.py:160) Level 1: "Registering GrowTreeV4 (None) in gradient."
2018-04-20 09:30:29,972 (tf_logging.py:160) Level 1: "Registering ProcessInputV4 (None) in gradient."
2018-04-20 09:30:29,972 (tf_logging.py:160) Level 1: "Registering FinalizeTree (None) in gradient."
2018-04-20 09:30:29,986 (tf_logging.py:160) Level 1: "Registering FunctionBufferingResource (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,987 (tf_logging.py:160) Level 1: "Registering FunctionBufferingResourceGetNext (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,994 (tf_logging.py:160) Level 1: "Registering RemoteFusedGraphExecute (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,995 (tf_logging.py:160) Level 1: "Registering RemoteFusedGraphExecute (None) in gradient."
2018-04-20 09:30:30,019 (tf_logging.py:160) Level 1: "Created variable q/Conv/weights:0 with shape (1, 1, 2, 8) and init <function variance_scaling_initializer.<locals>._initializer at 0x7fa9104ce510>"
2018-04-20 09:30:30,023 (tf_logging.py:160) Level 1: "Created variable q/Conv/biases:0 with shape (8,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa9104d3208>"
2018-04-20 09:30:30,044 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/weights:0 with shape (3, 3, 8, 12) and init <function variance_scaling_initializer.<locals>._initializer at 0x7fa9104ce510>"
2018-04-20 09:30:30,048 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/biases:0 with shape (12,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa9104d3208>"
2018-04-20 09:30:30,070 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/weights:0 with shape (3, 3, 12, 16) and init <function variance_scaling_initializer.<locals>._initializer at 0x7fa9104ce510>"
2018-04-20 09:30:30,086 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/biases:0 with shape (16,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa9104d3208>"
2018-04-20 09:30:30,107 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/weights:0 with shape (576, 128) and init <function variance_scaling_initializer.<locals>._initializer at 0x7fa9104d72f0>"
2018-04-20 09:30:30,111 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/biases:0 with shape (128,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa9104d35f8>"
2018-04-20 09:30:30,117 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/weights:0 with shape (128, 5) and init <function variance_scaling_initializer.<locals>._initializer at 0x7fa9104d72f0>"
2018-04-20 09:30:30,121 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/biases:0 with shape (5,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa9104d35f8>"
2018-04-20 09:30:30,128 (tf_logging.py:160) Level 1: "Created variable target_q/Conv/weights:0 with shape (1, 1, 2, 8) and init <function variance_scaling_initializer.<locals>._initializer at 0x7fa9104ce510>"
2018-04-20 09:30:30,132 (tf_logging.py:160) Level 1: "Created variable target_q/Conv/biases:0 with shape (8,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa9104d3208>"
2018-04-20 09:30:30,139 (tf_logging.py:160) Level 1: "Created variable target_q/Conv_1/weights:0 with shape (3, 3, 8, 12) and init <function variance_scaling_initializer.<locals>._initializer at 0x7fa9104ce510>"
2018-04-20 09:30:30,142 (tf_logging.py:160) Level 1: "Created variable target_q/Conv_1/biases:0 with shape (12,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa9104d3208>"
2018-04-20 09:30:30,150 (tf_logging.py:160) Level 1: "Created variable target_q/Conv_2/weights:0 with shape (3, 3, 12, 16) and init <function variance_scaling_initializer.<locals>._initializer at 0x7fa9104ce510>"
2018-04-20 09:30:30,153 (tf_logging.py:160) Level 1: "Created variable target_q/Conv_2/biases:0 with shape (16,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa9104d3208>"
2018-04-20 09:30:30,165 (tf_logging.py:160) Level 1: "Created variable target_q/fully_connected/weights:0 with shape (576, 128) and init <function variance_scaling_initializer.<locals>._initializer at 0x7fa9104d72f0>"
2018-04-20 09:30:30,168 (tf_logging.py:160) Level 1: "Created variable target_q/fully_connected/biases:0 with shape (128,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa9104d35f8>"
2018-04-20 09:30:30,175 (tf_logging.py:160) Level 1: "Created variable target_q/fully_connected_1/weights:0 with shape (128, 5) and init <function variance_scaling_initializer.<locals>._initializer at 0x7fa9104d72f0>"
2018-04-20 09:30:30,193 (tf_logging.py:160) Level 1: "Created variable target_q/fully_connected_1/biases:0 with shape (5,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa9104d35f8>"
2018-04-20 09:30:30,267 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/value'"
2018-04-20 09:30:30,274 (tf_logging.py:160) Level 1: "  in  --> gradients/Fill:0"
2018-04-20 09:30:30,274 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/value_grad/tuple/control_dependency:0, gradients/mean_squared_error/value_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,284 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/div'"
2018-04-20 09:30:30,293 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/value_grad/tuple/control_dependency:0"
2018-04-20 09:30:30,294 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/div_grad/tuple/control_dependency:0, gradients/mean_squared_error/div_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,297 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/Sum_1'"
2018-04-20 09:30:30,297 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/div_grad/tuple/control_dependency:0"
2018-04-20 09:30:30,297 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/Sum_1_grad/Tile:0"
2018-04-20 09:30:30,301 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/Select'"
2018-04-20 09:30:30,302 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/div_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,302 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/Select_grad/tuple/control_dependency:0, gradients/mean_squared_error/Select_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,304 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/Sum'"
2018-04-20 09:30:30,304 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/Sum_1_grad/Tile:0"
2018-04-20 09:30:30,304 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/Sum_grad/Tile:0"
2018-04-20 09:30:30,310 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/Mul'"
2018-04-20 09:30:30,311 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/Sum_grad/Tile:0"
2018-04-20 09:30:30,311 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/Mul_grad/tuple/control_dependency:0, gradients/mean_squared_error/Mul_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,313 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/num_present'"
2018-04-20 09:30:30,313 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/Select_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,313 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/num_present_grad/Tile:0"
2018-04-20 09:30:30,319 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/num_present/broadcast_weights'"
2018-04-20 09:30:30,319 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/num_present_grad/Tile:0"
2018-04-20 09:30:30,319 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/num_present/broadcast_weights_grad/tuple/control_dependency:0, gradients/mean_squared_error/num_present/broadcast_weights_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,320 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/num_present/broadcast_weights/ones_like'"
2018-04-20 09:30:30,320 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/num_present/broadcast_weights_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,320 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/num_present/broadcast_weights/ones_like_grad/Sum:0"
2018-04-20 09:30:30,326 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/SquaredDifference'"
2018-04-20 09:30:30,327 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/Mul_grad/tuple/control_dependency:0"
2018-04-20 09:30:30,327 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/SquaredDifference_grad/tuple/control_dependency:0, gradients/mean_squared_error/SquaredDifference_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,334 (tf_logging.py:160) Level 1: "Gradient for 'Sum'"
2018-04-20 09:30:30,334 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/SquaredDifference_grad/tuple/control_dependency:0"
2018-04-20 09:30:30,334 (tf_logging.py:160) Level 1: "  out --> gradients/Sum_grad/Tile:0"
2018-04-20 09:30:30,339 (tf_logging.py:160) Level 1: "Gradient for 'mul'"
2018-04-20 09:30:30,339 (tf_logging.py:160) Level 1: "  in  --> gradients/Sum_grad/Tile:0"
2018-04-20 09:30:30,339 (tf_logging.py:160) Level 1: "  out --> gradients/mul_grad/tuple/control_dependency:0, gradients/mul_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,341 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected_1/BiasAdd'"
2018-04-20 09:30:30,341 (tf_logging.py:160) Level 1: "  in  --> gradients/mul_grad/tuple/control_dependency:0"
2018-04-20 09:30:30,341 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency:0, gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,344 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected_1/MatMul'"
2018-04-20 09:30:30,344 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 09:30:30,344 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency:0, gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,344 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected_1/biases/read'"
2018-04-20 09:30:30,344 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,344 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,345 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/Relu'"
2018-04-20 09:30:30,345 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency:0"
2018-04-20 09:30:30,345 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/Relu_grad/ReluGrad:0"
2018-04-20 09:30:30,345 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected_1/weights/read'"
2018-04-20 09:30:30,346 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,346 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,347 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/BiasAdd'"
2018-04-20 09:30:30,348 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/Relu_grad/ReluGrad:0"
2018-04-20 09:30:30,348 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency:0, gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,350 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/MatMul'"
2018-04-20 09:30:30,350 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 09:30:30,350 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/MatMul_grad/tuple/control_dependency:0, gradients/q/fully_connected/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,351 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/biases/read'"
2018-04-20 09:30:30,351 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,351 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,352 (tf_logging.py:160) Level 1: "Gradient for 'q/Flatten/flatten/Reshape'"
2018-04-20 09:30:30,352 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/MatMul_grad/tuple/control_dependency:0"
2018-04-20 09:30:30,352 (tf_logging.py:160) Level 1: "  out --> gradients/q/Flatten/flatten/Reshape_grad/Reshape:0"
2018-04-20 09:30:30,352 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/weights/read'"
2018-04-20 09:30:30,352 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,352 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,353 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/Relu'"
2018-04-20 09:30:30,353 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Flatten/flatten/Reshape_grad/Reshape:0"
2018-04-20 09:30:30,353 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/Relu_grad/ReluGrad:0"
2018-04-20 09:30:30,355 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/BiasAdd'"
2018-04-20 09:30:30,355 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/Relu_grad/ReluGrad:0"
2018-04-20 09:30:30,355 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency:0, gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,359 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/Conv2D'"
2018-04-20 09:30:30,360 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 09:30:30,360 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency:0, gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,360 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/biases/read'"
2018-04-20 09:30:30,360 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,360 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,361 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/Relu'"
2018-04-20 09:30:30,361 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency:0"
2018-04-20 09:30:30,361 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/Relu_grad/ReluGrad:0"
2018-04-20 09:30:30,361 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/weights/read'"
2018-04-20 09:30:30,361 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,361 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,363 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/BiasAdd'"
2018-04-20 09:30:30,363 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/Relu_grad/ReluGrad:0"
2018-04-20 09:30:30,363 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency:0, gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,367 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/Conv2D'"
2018-04-20 09:30:30,367 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 09:30:30,367 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency:0, gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,368 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/biases/read'"
2018-04-20 09:30:30,368 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,368 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,368 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/Relu'"
2018-04-20 09:30:30,369 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency:0"
2018-04-20 09:30:30,369 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/Relu_grad/ReluGrad:0"
2018-04-20 09:30:30,369 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/weights/read'"
2018-04-20 09:30:30,369 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,369 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,371 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/BiasAdd'"
2018-04-20 09:30:30,371 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv/Relu_grad/ReluGrad:0"
2018-04-20 09:30:30,371 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/BiasAdd_grad/tuple/control_dependency:0, gradients/q/Conv/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,375 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/Conv2D'"
2018-04-20 09:30:30,375 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 09:30:30,375 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/Conv2D_grad/tuple/control_dependency:0, gradients/q/Conv/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,376 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/biases/read'"
2018-04-20 09:30:30,376 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,376 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,376 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/weights/read'"
2018-04-20 09:30:30,376 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,376 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,477 (tf_logging.py:126) WARNING: "From /home/syedeqbal/.local/lib/python3.5/site-packages/tensorflow/python/ops/clip_ops.py:113: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead"
2018-04-20 09:30:30,584 (tf_logging.py:160) Level 1: "Created variable q/Conv/weights/Adam:0 with shape (1, 1, 2, 8) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa8b8ddf358>"
2018-04-20 09:30:30,597 (tf_logging.py:160) Level 1: "Created variable q/Conv/weights/Adam_1:0 with shape (1, 1, 2, 8) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa8b8ddf358>"
2018-04-20 09:30:30,607 (tf_logging.py:160) Level 1: "Created variable q/Conv/biases/Adam:0 with shape (8,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa8b8ddf358>"
2018-04-20 09:30:30,617 (tf_logging.py:160) Level 1: "Created variable q/Conv/biases/Adam_1:0 with shape (8,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa8b8ddf358>"
2018-04-20 09:30:30,627 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/weights/Adam:0 with shape (3, 3, 8, 12) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa8b8ddf358>"
2018-04-20 09:30:30,640 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/weights/Adam_1:0 with shape (3, 3, 8, 12) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa8b8ddf358>"
2018-04-20 09:30:30,649 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/biases/Adam:0 with shape (12,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa8b8ddf358>"
2018-04-20 09:30:30,658 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/biases/Adam_1:0 with shape (12,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa8b8ddf358>"
2018-04-20 09:30:30,661 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/weights/Adam:0 with shape (3, 3, 12, 16) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa8b8ddf358>"
2018-04-20 09:30:30,665 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/weights/Adam_1:0 with shape (3, 3, 12, 16) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa8b8e0cf28>"
2018-04-20 09:30:30,668 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/biases/Adam:0 with shape (16,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa8b8e0cf28>"
2018-04-20 09:30:30,670 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/biases/Adam_1:0 with shape (16,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa8b8e0cf28>"
2018-04-20 09:30:30,673 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/weights/Adam:0 with shape (576, 128) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa8b8e0cf28>"
2018-04-20 09:30:30,675 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/weights/Adam_1:0 with shape (576, 128) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa8b8e0cf28>"
2018-04-20 09:30:30,678 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/biases/Adam:0 with shape (128,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa8b8e0cf28>"
2018-04-20 09:30:30,680 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/biases/Adam_1:0 with shape (128,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa8b8e0cf28>"
2018-04-20 09:30:30,683 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/weights/Adam:0 with shape (128, 5) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa8b8e0cf28>"
2018-04-20 09:30:30,685 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/weights/Adam_1:0 with shape (128, 5) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa8b8e0cf28>"
2018-04-20 09:30:30,688 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/biases/Adam:0 with shape (5,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa8b8e0cf28>"
2018-04-20 09:30:30,691 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/biases/Adam_1:0 with shape (5,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa8b8e0cf28>"
2018-04-20 09:30:30,819 (dqn_agent.py:161) DEBUG: "var_name: q/Conv/weights:0, var_value [[[[ 0.16578859 -0.16878021  0.7039348  -0.5990083  -0.5231885
     0.12528002  0.3845706   0.58010113]
   [-0.1548481  -0.41433412 -0.21852148 -0.35893342  0.6082158
     0.3999889   0.58211505 -0.26015198]]]]: "
2018-04-20 09:30:30,825 (dqn_agent.py:161) DEBUG: "var_name: q/Conv/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 09:30:30,837 (dqn_agent.py:161) DEBUG: "var_name: q/Conv_1/weights:0, var_value [[[[ 1.50372803e-01 -4.65755910e-02  6.63120598e-02 -1.35417745e-01
    -8.24370235e-02 -1.52714670e-01 -1.77968279e-01 -1.38832420e-01
    -1.16875656e-01  1.51195586e-01  1.10575348e-01  9.78565514e-02]
   [ 9.89191234e-02  7.67598152e-02 -1.66469067e-02  7.34809935e-02
     8.29356015e-02  1.19481683e-02 -1.79388598e-01 -1.44438356e-01
     7.07273185e-03 -1.77472010e-01  8.87598395e-02  1.48418576e-01]
   [-1.66158974e-01 -1.18967593e-02 -4.12107557e-02 -1.54847249e-01
     1.17666066e-01 -1.38515577e-01  1.65102780e-02 -1.09486468e-01
    -1.41777694e-01  9.60279405e-02  2.53623426e-02 -1.03353307e-01]
   [ 5.52144647e-03  9.48200822e-02  3.09036374e-02  1.07741743e-01
    -1.58003852e-01  1.00059152e-01 -3.98937464e-02 -1.39132082e-01
     1.46161884e-01 -9.86199975e-02  5.65466583e-02 -1.79113835e-01]
   [-1.25564590e-01  1.41239941e-01 -5.20381778e-02 -6.02059364e-02
     3.34170163e-02  7.30284750e-02 -8.97882581e-02 -4.29988056e-02
    -1.51726469e-01  3.51880342e-02 -7.81367794e-02 -3.25431228e-02]
   [ 1.82122052e-01 -9.67563912e-02  1.00072682e-01 -1.05278946e-01
    -3.69303375e-02  4.92800772e-03 -2.31504589e-02 -5.03832102e-03
     1.81149483e-01  1.81027949e-01  1.24728292e-01 -1.31427914e-01]
   [-1.80586249e-01 -1.36025965e-01  4.48914468e-02 -5.97371310e-02
    -6.78593963e-02 -6.46777675e-02  1.34997427e-01  1.21811777e-02
     9.64576602e-02  1.58229679e-01  1.37813747e-01 -2.31378824e-02]
   [-9.52447131e-02  1.47893041e-01 -3.06760669e-02 -2.78017670e-02
    -2.98631638e-02 -1.24209307e-01  9.12289321e-02 -9.49710608e-04
     1.14439696e-01  1.43336982e-01 -1.32964581e-01 -9.92896929e-02]]

  [[-6.49723262e-02  1.58546180e-01  5.85785955e-02 -1.50315136e-01
    -6.15584701e-02 -1.41734332e-01  6.16731346e-02 -1.22978218e-01
     1.81306928e-01 -2.63602883e-02  1.26414150e-02 -1.50923759e-01]
   [-1.40209600e-01 -9.67322737e-02  1.24145299e-02  6.59394115e-02
     1.41328335e-01  8.43215585e-02  1.14990234e-01 -1.16814151e-01
     3.76809388e-02  2.42543519e-02  5.33993393e-02 -7.67892525e-02]
   [-9.87472758e-02  1.74100071e-01  4.51567620e-02  1.41774416e-01
     1.41309172e-01  2.58868784e-02 -1.43943951e-01 -1.37666881e-01
     1.47413224e-01  1.99114233e-02  1.03365660e-01 -9.21891481e-02]
   [-1.67833194e-01  1.96955949e-02 -1.77946121e-01 -1.34419441e-01
     1.75737649e-01  8.71360302e-03  3.25536728e-03 -1.43141359e-01
     1.20177001e-01 -1.45054042e-01  1.27553076e-01  1.53062642e-02]
   [-1.55145079e-02  1.71647877e-01  4.45766449e-02  8.31186771e-02
    -7.10270032e-02 -1.09896958e-02 -2.90575325e-02 -6.20858297e-02
    -4.92762625e-02  2.22920179e-02 -5.88739440e-02  1.71498477e-01]
   [-8.99066553e-02 -1.71779886e-01 -1.65016860e-01  1.04004711e-01
     9.67311859e-03 -1.54113770e-02 -1.70659572e-01 -8.31511989e-02
     3.37359458e-02  1.55402720e-03  9.14124548e-02  7.11061060e-03]
   [-1.43738240e-01 -1.68416440e-01 -1.72697783e-01 -1.13055982e-01
     1.71616912e-01  1.39764518e-01 -1.03619576e-01  1.14000082e-01
    -9.52616334e-03  1.18024051e-01 -4.03728336e-02  1.08210146e-01]
   [ 1.73561484e-01  9.88033414e-02 -1.72187835e-01  1.25137299e-01
    -1.23160735e-01  7.95265436e-02  8.18993449e-02  2.86989361e-02
     2.07359940e-02 -7.31796026e-05  1.80210263e-01  6.27235323e-02]]

  [[ 6.60870969e-03 -1.21559039e-01 -6.81037679e-02  4.53340560e-02
     7.55124092e-02  1.80749804e-01 -7.44268298e-03 -5.38325906e-02
    -1.13388635e-01 -3.08124125e-02 -1.79469511e-01  1.35015100e-01]
   [ 1.67978674e-01  1.71190590e-01 -1.61744744e-01  6.67512417e-04
     1.17815793e-01  2.60507613e-02  3.34459543e-02  1.59345895e-01
    -1.78536028e-01  1.41344666e-01  1.04296505e-02 -7.02945814e-02]
   [ 4.77891862e-02 -1.02742903e-01  1.56789571e-02 -1.36362284e-01
     1.65883392e-01 -1.68079048e-01  1.21308386e-01 -1.42047554e-02
     8.56704414e-02 -7.17130676e-02  1.17512047e-01 -8.82266909e-02]
   [-3.50956172e-02 -8.91575217e-02  3.36481035e-02 -1.23550743e-02
    -7.22268820e-02  1.74243808e-01 -1.39517486e-01  1.28090173e-01
    -1.26272231e-01  1.55808061e-01  2.08957046e-02 -1.18645594e-01]
   [ 7.13585317e-02 -3.16085517e-02 -1.65610015e-03 -8.18596482e-02
     7.13812411e-02  1.46497369e-01 -1.18483707e-01 -4.29078937e-03
     5.63763082e-03 -4.74429578e-02 -9.13266167e-02  6.01610541e-02]
   [-3.59444022e-02  2.49007642e-02  8.52181911e-02  1.11225158e-01
    -1.68843284e-01  1.38022453e-02 -1.29408032e-01 -1.27537102e-01
    -1.64736927e-01 -1.63101792e-01 -5.62077910e-02  4.17557508e-02]
   [-4.67253774e-02 -1.25943989e-01  1.78297579e-01  7.24245906e-02
     1.71259105e-01 -1.48414478e-01  8.97851586e-02  1.71935797e-01
    -1.20076180e-01  6.27714545e-02 -1.31946474e-01  5.90580702e-03]
   [-1.11516714e-02 -4.76029217e-02 -8.17512199e-02 -6.77612349e-02
    -6.90109134e-02 -1.18763387e-01  1.14549041e-01  1.24193341e-01
    -4.94612157e-02  1.08101368e-01 -4.13815677e-02  1.03034586e-01]]]


 [[[ 1.03024930e-01 -7.02546537e-03 -2.97795087e-02  9.59316492e-02
    -1.21294126e-01 -8.22076201e-02 -8.04460421e-02  1.67265356e-01
    -7.78349936e-02  1.49735332e-01  4.41252887e-02  1.56957269e-01]
   [ 5.70124686e-02  2.57944614e-02 -1.11137785e-01 -7.57582635e-02
     1.59029961e-02 -1.73812002e-01  4.12420630e-02  1.76606685e-01
    -1.10035628e-01 -1.08016923e-01 -7.28153959e-02 -4.51277643e-02]
   [ 1.05051905e-01 -3.10264379e-02  8.81486833e-02  1.43133968e-01
     3.28181833e-02  1.27911597e-01 -3.45832855e-02  1.39498591e-01
     1.14050001e-01 -4.24026698e-02 -8.59723687e-02 -1.65779963e-01]
   [-6.03268147e-02 -1.46665573e-02 -1.37881398e-01  3.95148993e-03
    -5.62563688e-02  8.25574100e-02 -6.08313605e-02 -1.90340877e-02
    -7.64632225e-03 -1.05154760e-01  1.13561392e-01 -5.71756214e-02]
   [ 1.35875374e-01 -1.67817473e-01  1.01750970e-01 -8.54162350e-02
    -1.76406413e-01  1.36459082e-01 -4.39292789e-02 -2.14182138e-02
     1.56653315e-01 -1.64324746e-01 -1.60880029e-01 -8.23006034e-04]
   [ 9.53239202e-02 -1.11630887e-01  7.12765157e-02  6.14777207e-02
    -1.69305697e-01  2.91113704e-02 -3.56722027e-02  4.45723385e-02
    -4.42971438e-02  9.62186754e-02  1.60977006e-01  6.78107142e-02]
   [-1.72911420e-01 -1.43857628e-01  8.68752599e-04  9.54736769e-03
    -9.24694315e-02 -1.78487062e-01 -5.61368465e-03  6.78707063e-02
    -2.06757486e-02 -3.45145464e-02 -1.74988851e-01 -7.25035146e-02]
   [ 7.36595690e-02  1.87935531e-02 -1.59472674e-02 -5.99457622e-02
    -7.34177977e-02  5.31561375e-02 -6.85833693e-02  8.55869055e-03
     1.18327230e-01  8.56759846e-02 -1.35336205e-01  1.29384041e-01]]

  [[-9.49209407e-02 -1.43931061e-01  1.39986843e-01  1.04966283e-01
    -1.22518159e-01  1.38866931e-01  1.80403054e-01 -1.03378445e-02
     1.81240708e-01 -9.13791135e-02 -1.13647759e-01 -1.33086234e-01]
   [ 1.48116529e-01 -1.08002000e-01 -5.76655343e-02  1.56000018e-01
     1.43986583e-01  9.11345780e-02 -2.25448012e-02 -5.31424284e-02
    -2.57670432e-02 -1.24103621e-01 -1.23525642e-01  7.62276053e-02]
   [-7.34393895e-02 -1.79097041e-01  1.46193624e-01  4.55062091e-02
    -7.12102205e-02 -9.33868438e-02  1.12774521e-01  1.34814084e-01
     1.39555365e-01 -1.31254926e-01  1.81404173e-01  1.51048422e-01]
   [ 7.08374381e-02 -1.38815701e-01 -4.12131548e-02  1.45837814e-01
     4.25314754e-02 -1.42138585e-01 -4.18532938e-02 -1.43844575e-01
    -1.28269911e-01 -1.44390166e-01  5.82012087e-02  6.23516589e-02]
   [ 1.66853756e-01  1.08520240e-01 -5.43589443e-02 -1.01308919e-01
    -7.73917362e-02 -1.01675436e-01 -2.85132229e-03 -7.55310878e-02
     9.21154916e-02 -1.01184249e-02  1.36583239e-01  1.27481431e-01]
   [ 1.51185572e-01 -7.94477016e-02  6.14285767e-02 -1.09383434e-01
    -1.11160576e-02  6.78442419e-02 -1.52483404e-01 -1.91215426e-02
    -1.80681631e-01  6.66188151e-02  5.03838211e-02  6.95326626e-02]
   [ 3.85258496e-02 -5.02071828e-02  3.06560546e-02 -1.79994345e-01
     9.67103839e-02  1.20052457e-01  1.13115132e-01 -1.55062199e-01
     1.63078249e-01 -6.48751706e-02  1.65045142e-01 -1.62858605e-01]
   [ 6.52627647e-03 -3.22298855e-02  1.31609440e-01  1.30915135e-01
    -1.60923213e-01  5.48911244e-02  1.80156499e-01 -1.70418173e-01
    -1.52948812e-01 -8.17985386e-02  9.87262428e-02  1.77291811e-01]]

  [[-1.21646821e-02  1.11088246e-01  4.17499542e-02  1.78560048e-01
     1.13445967e-01  3.90263498e-02  1.50789201e-01 -1.12456851e-01
    -3.18788737e-02  1.05727613e-01 -1.43852800e-01  3.73693258e-02]
   [ 1.51212364e-01 -8.62382874e-02  1.55266970e-02  9.51764584e-02
    -1.38199165e-01  1.18672848e-02 -1.41300172e-01 -1.69071898e-01
     1.52420819e-01 -1.76010519e-01  8.78888667e-02  7.76669681e-02]
   [-5.28266728e-02 -7.85517693e-03 -9.20811519e-02  1.63302064e-01
     1.41457707e-01 -8.70479271e-02 -1.75527871e-01 -1.49765193e-01
     1.02608055e-02 -1.22574881e-01 -7.00742826e-02 -1.72640368e-01]
   [-6.49261028e-02  3.76553088e-02  1.51447207e-02 -1.18315905e-01
    -8.06945935e-02  1.49511456e-01  4.14071679e-02 -1.27147347e-01
     1.80286735e-01  7.19477832e-02  1.55820101e-02 -1.03261203e-01]
   [ 1.41694337e-01 -6.24322295e-02  1.15811795e-01 -9.51586142e-02
     1.49993539e-01  1.17649287e-01  3.02957594e-02  2.66269594e-02
    -1.63218677e-01  1.16232336e-01 -6.88857660e-02 -3.34617198e-02]
   [ 1.85265839e-02 -1.72780707e-01  1.06177509e-01 -8.92564133e-02
     1.17356837e-01  1.70722187e-01  8.87984335e-02 -1.47996560e-01
     1.34868056e-01  1.92952156e-02 -1.66095763e-01  2.49674916e-02]
   [ 2.87357569e-02  1.41703129e-01  7.52265155e-02 -8.48462209e-02
     2.94032395e-02  1.42702430e-01  1.53979063e-01 -1.11719072e-02
     1.29699051e-01 -5.90743572e-02  1.40473545e-02  1.56315535e-01]
   [ 6.19040430e-02 -2.06189901e-02 -5.67361414e-02  1.76428229e-01
    -1.10530704e-02  8.85301828e-02 -8.84541869e-03 -1.52084410e-01
    -3.88459563e-02  1.40014976e-01  1.55961126e-01 -1.64046645e-01]]]


 [[[ 4.25648689e-03  8.98439586e-02 -4.35977727e-02  1.06983155e-01
     2.51899362e-02  8.77319276e-03 -1.19932838e-01 -1.42490342e-01
    -6.24369755e-02  1.74831808e-01 -1.11000672e-01 -1.73406303e-03]
   [-4.36147004e-02 -7.79993609e-02  1.46764934e-01  1.20519042e-01
     3.80317420e-02  1.32458508e-01 -2.51937658e-02  9.32906568e-02
     9.58300531e-02  6.76800609e-02  6.37915134e-02 -2.08935142e-03]
   [ 9.21428204e-02 -1.26626223e-01 -1.05295703e-01  1.64834261e-01
     1.80658787e-01 -9.24042687e-02 -1.29927993e-01 -6.22721314e-02
    -1.05359912e-01  5.23713529e-02  2.36761123e-02 -1.63138628e-01]
   [-9.54960063e-02 -2.14881748e-02  1.12646163e-01  1.74191535e-01
     3.44628096e-03  1.61926299e-01  1.58273250e-01  1.56867951e-02
     2.06706077e-02  1.25562221e-01 -1.65372059e-01  4.79232520e-02]
   [ 1.19962305e-01 -4.58623618e-02 -1.49416864e-01  1.55377656e-01
    -3.89145166e-02 -5.39887697e-02  1.60350204e-01 -9.65190232e-02
     3.29748392e-02 -1.64857507e-01  1.05096161e-01  7.07103014e-02]
   [-1.20915376e-01  1.08093202e-01 -1.31271765e-01 -1.79597750e-01
    -2.57807970e-02 -9.47172716e-02  1.47617459e-01 -1.55910969e-01
     1.50786340e-01  1.54214382e-01  5.77574670e-02  1.12168819e-01]
   [-1.90540254e-02  1.39549166e-01 -9.14754868e-02 -9.72161889e-02
     1.55543745e-01 -1.36237085e-01 -1.10009469e-01  1.20209605e-01
     6.74618781e-02  8.37951601e-02  1.76556736e-01 -7.34775141e-02]
   [-1.59330264e-01  1.18923366e-01  6.27512187e-02 -3.31075639e-02
    -1.00204982e-01  1.22297585e-01 -5.15450388e-02 -8.07907060e-02
    -1.34177387e-01 -1.10616878e-01  1.72897637e-01 -1.29213497e-01]]

  [[ 1.11783534e-01 -5.45459390e-02 -1.35401487e-02  1.18027538e-01
     6.95149004e-02 -6.89958036e-03 -5.83146513e-03  1.51529521e-01
     8.57773423e-02 -8.92933309e-02  1.61266744e-01  1.33006960e-01]
   [ 1.64932668e-01 -9.97894555e-02  3.20096761e-02  1.32233053e-01
    -1.15717351e-01  9.46811736e-02 -8.10090527e-02  1.63969189e-01
     1.59583390e-01 -1.23477802e-01  1.80558830e-01 -1.50979385e-01]
   [-1.52807906e-01 -6.37370348e-03  1.46654993e-01 -1.25455454e-01
    -1.45555139e-02  6.47767484e-02 -1.07124448e-01 -9.12621915e-02
    -1.72373012e-01  1.76593721e-01  1.15190953e-01  1.16567612e-01]
   [ 1.20363206e-01  1.19858354e-01 -3.20471972e-02  1.29741937e-01
    -4.45766896e-02  1.33567452e-01  1.54925525e-01 -1.41365811e-01
     6.83134794e-02 -1.05220228e-01 -1.36043519e-01  1.47954345e-01]
   [-9.96115506e-02 -1.23997279e-01  1.29717439e-01  1.12763107e-01
    -6.63868934e-02 -1.78603247e-01  1.59075797e-01 -5.31462580e-02
    -1.72569335e-01 -8.85271728e-02  6.40488118e-02  5.85163087e-02]
   [-1.77035809e-01 -5.47862202e-02 -9.55599472e-02 -1.43166661e-01
     8.62739384e-02  2.65710652e-02  5.07326573e-02 -1.33114621e-01
    -1.68177992e-01 -1.21893562e-01  8.01801682e-04 -1.74880162e-01]
   [ 1.62263334e-01  1.25606716e-01 -1.22779377e-01  4.77101356e-02
     1.39659226e-01 -6.95866719e-02  1.48140907e-01 -5.99611700e-02
     8.73327255e-02  1.65933937e-01 -7.29069784e-02 -2.85871178e-02]
   [ 8.90282691e-02 -7.42706582e-02 -1.20910458e-01  1.25831723e-01
     1.14927262e-01 -1.81317806e-01 -1.38245776e-01 -1.76458612e-01
     9.16392505e-02 -6.08193949e-02  1.08285099e-02 -1.50721297e-01]]

  [[ 6.03461862e-02  1.24547660e-01 -8.12763646e-02 -1.74457580e-01
     9.16769803e-02 -6.66351616e-03  1.56731755e-01  3.42933834e-02
    -3.50841731e-02  1.58686489e-02 -6.58075660e-02  1.26392215e-01]
   [ 1.39954239e-02  5.04558980e-02  5.04422784e-02 -1.74083263e-02
    -1.06142305e-01  6.49550408e-02  8.85375440e-02  3.10065448e-02
    -1.31664664e-01  1.75815821e-01  2.67497450e-02  2.62670070e-02]
   [ 6.33399040e-02 -1.31615520e-01 -1.40392184e-02 -3.05083990e-02
     7.33584166e-02 -1.15155280e-02 -4.37519848e-02  9.74804163e-02
    -5.79845607e-02 -1.43975466e-02 -1.52669489e-01  1.07540905e-01]
   [ 1.42249972e-01 -1.79174826e-01  1.14173412e-01 -1.15154043e-01
     1.23451293e-01  8.14085901e-02  3.12688947e-02 -5.90064973e-02
    -9.61571261e-02 -2.31606066e-02 -1.56199604e-01  1.80257291e-01]
   [-1.03674076e-01 -4.80517745e-04 -1.49942353e-01 -1.45888090e-01
     3.76347601e-02 -6.96528330e-02  8.85638595e-02 -7.45727122e-03
     1.21188790e-01  3.01212966e-02 -1.78860933e-01 -4.83771712e-02]
   [-1.33370608e-01  7.48704374e-02 -6.24780655e-02  4.20927107e-02
     6.18667901e-02  1.31099313e-01 -3.75017822e-02 -7.03971386e-02
     1.62500918e-01 -1.47199631e-02 -8.18408430e-02 -2.02136785e-02]
   [ 4.42216694e-02 -8.60013142e-02  1.57468051e-01  1.37674659e-02
     6.86165392e-02  2.51895785e-02  5.50284088e-02 -1.44589245e-02
     9.32712853e-02 -1.61228791e-01  1.78502589e-01  1.29311472e-01]
   [-5.49125373e-02 -1.51102275e-01  1.31593674e-01  9.53472257e-02
     1.79685354e-02 -8.44948590e-02  4.86635119e-02  2.34054476e-02
    -1.06498890e-01  7.17085004e-02 -1.80102378e-01  1.50361359e-01]]]]: "
2018-04-20 09:30:30,843 (dqn_agent.py:161) DEBUG: "var_name: q/Conv_1/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 09:30:30,851 (dqn_agent.py:161) DEBUG: "var_name: q/Conv_2/weights:0, var_value [[[[-0.12522422 -0.1354345   0.09417535 ... -0.11621692  0.029524
    -0.07588997]
   [-0.08668954 -0.00297628 -0.0280368  ...  0.13890739  0.04549155
     0.02974808]
   [ 0.00260571  0.00451906  0.09286064 ... -0.13508692  0.05490991
     0.00800513]
   ...
   [ 0.04271789 -0.11691079 -0.14807814 ...  0.05746791 -0.02532297
    -0.06981846]
   [-0.04235376  0.00743799  0.12039594 ...  0.13588114 -0.03065713
     0.03426272]
   [-0.08544461  0.06057513 -0.14685057 ...  0.12645708 -0.10506473
    -0.05202372]]

  [[-0.0017053  -0.06590755 -0.12074768 ... -0.03506527  0.0471594
    -0.12902296]
   [ 0.06385727  0.02352367 -0.10391571 ... -0.06317076  0.10501872
     0.13921537]
   [-0.08738466  0.07329221 -0.1053246  ...  0.08514492  0.09068289
     0.05181745]
   ...
   [-0.11489826 -0.08441728 -0.05160032 ... -0.11444561 -0.02635787
     0.09266385]
   [-0.08226252 -0.05534509  0.03708895 ...  0.09940009  0.09619759
    -0.08005884]
   [ 0.14432804 -0.1319058  -0.0333412  ... -0.07117078 -0.03679721
    -0.08127585]]

  [[-0.14999907  0.00182149 -0.1291438  ...  0.1006272  -0.08041786
     0.10595734]
   [-0.15308557  0.04255168 -0.07102057 ... -0.0605379   0.09419173
    -0.11082023]
   [ 0.00714652  0.07216077 -0.07786005 ... -0.00067776  0.03274879
     0.05973859]
   ...
   [ 0.05690575 -0.13456014  0.09023222 ...  0.06514753  0.00051269
     0.15151139]
   [ 0.10813822 -0.05123677 -0.06322377 ... -0.07094847  0.03822237
     0.10246955]
   [ 0.1189784  -0.08899488  0.05898589 ... -0.11835147 -0.11053056
     0.1398172 ]]]


 [[[-0.13088883 -0.09102157 -0.01774706 ... -0.1386186  -0.03951944
     0.04540797]
   [ 0.0129533   0.01806973  0.11763816 ... -0.11220305 -0.11066774
    -0.09547827]
   [-0.10805482 -0.00213471 -0.04634861 ... -0.0838397   0.04927443
    -0.139608  ]
   ...
   [-0.08670194  0.12110518 -0.04537459 ...  0.03149109 -0.14170036
    -0.0120991 ]
   [-0.07291777  0.0526129  -0.06326388 ...  0.10662468 -0.08225171
     0.07743359]
   [-0.0266626   0.02086495  0.0366534  ...  0.11856143  0.11629193
     0.03119802]]

  [[-0.12298562  0.11590634 -0.00844648 ... -0.08813802 -0.04071294
    -0.05604029]
   [-0.1068588   0.03327785 -0.09436019 ...  0.04751584  0.01258445
     0.05925806]
   [ 0.07963617  0.03043199  0.01705211 ... -0.00663181 -0.1299533
     0.01570322]
   ...
   [-0.03363621  0.06438722  0.05083276 ... -0.03031117  0.12927397
     0.06691447]
   [-0.13986729  0.07173596  0.04670653 ... -0.115233    0.06701972
     0.14322536]
   [ 0.08088674 -0.08694081 -0.11239843 ... -0.1351938   0.11261041
     0.02717426]]

  [[ 0.13991122 -0.13064092  0.09233956 ...  0.0161047  -0.14876941
    -0.02430941]
   [ 0.01682532  0.13362668 -0.01136413 ... -0.05301271 -0.13972676
    -0.10186359]
   [ 0.02111846 -0.07457238  0.03911866 ... -0.06220826  0.10248439
     0.06369692]
   ...
   [ 0.15007146 -0.09400775 -0.05343858 ... -0.14926487 -0.09633681
     0.09016615]
   [-0.08707546 -0.03527912 -0.08245905 ...  0.09516852 -0.0007882
     0.05023497]
   [ 0.09024264 -0.09672493  0.02637583 ... -0.07301643 -0.01900829
    -0.12638085]]]


 [[[ 0.03938733  0.03906973  0.11211483 ... -0.04197498  0.0372963
     0.04559989]
   [-0.04688451 -0.01231976  0.06546494 ... -0.02586299 -0.04173272
    -0.10286638]
   [-0.09964574  0.1187769  -0.11503078 ...  0.02263713 -0.06730957
    -0.00470072]
   ...
   [ 0.1311542   0.11009382  0.11269118 ... -0.04250956  0.03042756
    -0.09522898]
   [-0.02665584  0.01291297  0.12490769 ... -0.0878212   0.14664848
     0.04764427]
   [ 0.07134758  0.08039707 -0.06811168 ...  0.02068302  0.03081958
     0.01278549]]

  [[ 0.14920895  0.07616501  0.02586679 ...  0.14995386  0.12782706
    -0.04017604]
   [ 0.03853169 -0.15360948  0.05542544 ... -0.07664546 -0.0714123
    -0.03333351]
   [-0.01313841  0.05898832  0.12622394 ... -0.020441    0.15000705
     0.0939586 ]
   ...
   [-0.04966236 -0.09621243  0.0729572  ... -0.05230574  0.08345963
    -0.11977363]
   [ 0.0275363  -0.02793138  0.10183831 ...  0.12256519 -0.10003938
     0.01554742]
   [ 0.08111656  0.0452089   0.13995512 ... -0.10029098  0.03191343
    -0.11672935]]

  [[ 0.1199619  -0.08640862  0.06365936 ... -0.12824656  0.09125014
     0.10840641]
   [ 0.02333318  0.10390221  0.09637664 ... -0.1134121  -0.12880318
    -0.11095425]
   [ 0.02464764  0.04679088 -0.1422983  ... -0.07373875 -0.05465475
     0.13453986]
   ...
   [ 0.02748016 -0.13626346  0.08940756 ...  0.02961722  0.07047635
     0.09916653]
   [ 0.0960225  -0.02609561  0.09388299 ... -0.01542278  0.02156408
     0.08577876]
   [ 0.06079799  0.12907632 -0.08451672 ... -0.05292048  0.0811267
     0.13957442]]]]: "
2018-04-20 09:30:30,855 (dqn_agent.py:161) DEBUG: "var_name: q/Conv_2/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 09:30:30,861 (dqn_agent.py:161) DEBUG: "var_name: q/fully_connected/weights:0, var_value [[-0.01165338  0.06772149 -0.07559088 ... -0.04275567 -0.07500613
  -0.07135338]
 [-0.06975953 -0.01027971  0.02858579 ... -0.04060309 -0.02329833
   0.02616174]
 [ 0.02934137  0.06960989 -0.01913106 ...  0.09125461  0.02750253
   0.07366175]
 ...
 [ 0.05613547  0.06916746 -0.07303284 ...  0.03601373 -0.00402633
   0.07013955]
 [-0.08416068 -0.07750266 -0.03354026 ... -0.02956528 -0.07028671
  -0.04191624]
 [-0.06461404 -0.01216286 -0.03355556 ... -0.05218419 -0.08294372
   0.08601653]]: "
2018-04-20 09:30:30,867 (dqn_agent.py:161) DEBUG: "var_name: q/fully_connected/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 09:30:30,876 (dqn_agent.py:161) DEBUG: "var_name: q/fully_connected_1/weights:0, var_value [[ 0.11870596 -0.15481125 -0.08325458 -0.08356291  0.08852899]
 [-0.01849052  0.06371495  0.0184916  -0.05823043  0.0574483 ]
 [ 0.19474357  0.0282993   0.14010581  0.16359675  0.00182505]
 [-0.08241451  0.00947648  0.10794613  0.05049366 -0.01001088]
 [-0.14022098  0.1514669   0.0678007   0.01713617  0.15390167]
 [-0.05876082 -0.07358465 -0.13201798 -0.12570804  0.01221827]
 [-0.07425344  0.12143624  0.07878765  0.02007711  0.09286267]
 [-0.13791743  0.07838187 -0.05613495  0.09285158  0.19956061]
 [ 0.10805166 -0.05447119  0.13778886 -0.07942197  0.20851532]
 [-0.19574533 -0.06973067 -0.04073122  0.05821517 -0.1321418 ]
 [ 0.16401622  0.15225562 -0.03095718 -0.04711439  0.0270002 ]
 [ 0.11706933  0.0592455   0.09083107  0.11641932  0.03405657]
 [ 0.03040607  0.04500788  0.05787361 -0.14870766 -0.1327883 ]
 [ 0.03028473  0.03329678  0.12971964 -0.17246987 -0.07720664]
 [ 0.07415843  0.04051423  0.18194291 -0.06031424  0.06225461]
 [-0.06854317  0.13581443  0.2008906   0.01990129  0.11714604]
 [-0.05915804  0.01314983 -0.07446997  0.07476658  0.15690085]
 [-0.05559535 -0.18741989  0.2027219   0.2009961   0.05214098]
 [-0.05809887  0.11117184  0.15488884  0.16936141  0.19524512]
 [-0.14364335 -0.02939688  0.08226016 -0.19049396 -0.08981791]
 [-0.07796057  0.09598601 -0.1731134   0.08341271 -0.04922266]
 [-0.01838033  0.16872826  0.10187683  0.15695244  0.00467034]
 [ 0.12725466  0.09740776 -0.11939754  0.17046866  0.16501188]
 [-0.058165   -0.09144739 -0.1762802   0.00307301 -0.07133847]
 [ 0.12365672 -0.18159056 -0.12886395 -0.04562421 -0.14570783]
 [-0.14515418 -0.1258271   0.12732568 -0.06867458 -0.1598238 ]
 [ 0.12676376 -0.20967916 -0.01580501  0.12767547 -0.14316487]
 [ 0.07466397  0.19889629 -0.06243522 -0.08853775 -0.00535955]
 [-0.13031472 -0.02444483 -0.08873296  0.00349337  0.10584959]
 [ 0.11085191 -0.08651499  0.05576751  0.10258698  0.06979695]
 [ 0.0460459   0.1971511   0.01044288  0.14720884 -0.20767003]
 [-0.03380635 -0.03087747  0.20766097  0.15110832  0.17644873]
 [ 0.17145759 -0.06252871  0.03008197  0.01492693 -0.00988074]
 [-0.03732611  0.18120414 -0.12720662  0.01327081  0.06358033]
 [ 0.06066501 -0.05360521 -0.18311344 -0.00502719  0.07951105]
 [-0.04452883 -0.19004758 -0.08509952 -0.03402294  0.01059683]
 [ 0.02818963  0.20387697  0.15909317  0.19612503 -0.18932626]
 [ 0.16145715  0.07530695 -0.0775439  -0.01408909  0.10275957]
 [-0.13024464  0.03376448  0.13551894  0.11391729 -0.11753183]
 [-0.09155996 -0.09994835 -0.14183679  0.12092179  0.2008149 ]
 [ 0.08213508  0.03913659 -0.19157365 -0.14531796  0.10953736]
 [ 0.01025492  0.15585119 -0.0205951   0.1926255   0.03500374]
 [-0.17024046 -0.02630918  0.02272911  0.00827192  0.21206793]
 [ 0.04478785 -0.06176957 -0.16253135 -0.08820727 -0.19107611]
 [ 0.03661002  0.02499609 -0.13273752 -0.14817317 -0.20688543]
 [-0.136457   -0.16357595  0.06342134 -0.08944865  0.088478  ]
 [ 0.13113368 -0.05381112 -0.21110208  0.08085087 -0.07331403]
 [-0.02425291 -0.12829804 -0.096749   -0.12726212  0.10596576]
 [ 0.18752867  0.05446807 -0.11938838  0.18519834  0.02568363]
 [ 0.05107617 -0.13383083  0.12638038  0.06299251 -0.19418857]
 [ 0.21073759 -0.08026709  0.02570985  0.06507269 -0.17872274]
 [-0.08997803 -0.09236554  0.2098794   0.1007517  -0.18008167]
 [-0.05088186  0.01850961 -0.1553129  -0.11694446 -0.02926728]
 [ 0.12238765 -0.1467902   0.17086092  0.03407668 -0.1571192 ]
 [ 0.2001664   0.06628212 -0.18702677 -0.08881039 -0.05014227]
 [-0.16131322 -0.01338322 -0.11745212  0.10844958  0.03619209]
 [ 0.16515875  0.20122135 -0.00852163 -0.15165995  0.05736285]
 [-0.0056102   0.01120335 -0.039601   -0.0784713   0.1706138 ]
 [-0.18446264 -0.13866833  0.12121865 -0.13670716 -0.06040463]
 [-0.06053007  0.06257394 -0.19829705  0.0083417   0.11260951]
 [-0.09664686 -0.01276755  0.09975061  0.11941856  0.16222301]
 [ 0.19435817 -0.20760411  0.14799121  0.0387938   0.15001747]
 [ 0.18698838  0.1820336   0.08803049  0.06564122  0.19509685]
 [-0.00950119  0.05600187 -0.01585135  0.0136506   0.07987544]
 [ 0.01071411  0.13388419  0.20310634 -0.12489062  0.18849719]
 [ 0.17595473 -0.03391731  0.00028606  0.01688054  0.11814392]
 [ 0.14996955  0.16897684  0.08489561 -0.16387957 -0.09658629]
 [-0.00572459 -0.03371689 -0.00589196 -0.12346446  0.17268154]
 [ 0.14934197 -0.13974467 -0.20037621  0.0794566  -0.20891617]
 [ 0.08974302 -0.0734383  -0.03546232 -0.05977382  0.13392445]
 [-0.06005476 -0.17769825  0.05928564 -0.06719276  0.0247198 ]
 [-0.15733245  0.16773114  0.05051798  0.10795903 -0.19855264]
 [-0.19375646 -0.14612946  0.02872367 -0.01842095 -0.18731324]
 [ 0.04998356 -0.06341602 -0.12803528 -0.18418524 -0.09847698]
 [-0.10515785 -0.13462126 -0.08387348 -0.01258479  0.04680407]
 [-0.16451901  0.10233438  0.07279852 -0.0383343   0.04631194]
 [-0.05804706  0.06967178  0.0796783  -0.11187002  0.04453248]
 [-0.16981372 -0.03683335 -0.05120616  0.05916715 -0.12504143]
 [-0.1842099  -0.12976742  0.06102619  0.053002    0.11583146]
 [ 0.06445989  0.00352162 -0.02236424  0.05631351 -0.18259268]
 [-0.186566   -0.1534721  -0.00459099  0.06794512  0.15025187]
 [ 0.16575283 -0.08664975 -0.11617312  0.05678836 -0.12248691]
 [-0.19396895  0.03695837 -0.00519243 -0.05851391 -0.18112351]
 [-0.1592849  -0.1529779   0.1379495  -0.16804002  0.10364354]
 [-0.08048671 -0.10631137  0.14507023  0.10860464 -0.15571897]
 [ 0.05767405  0.15034914  0.03106216  0.03045295 -0.06186159]
 [-0.129422   -0.21169983 -0.1626545   0.14628795 -0.0628999 ]
 [ 0.01872949 -0.07295378  0.06444728  0.04372817 -0.18703948]
 [ 0.16834888 -0.12346137 -0.20794638 -0.11178424  0.1723615 ]
 [-0.05670936  0.06118587 -0.03188844 -0.14303224  0.20373943]
 [ 0.11243004  0.11467034  0.15567076 -0.08211325 -0.11773717]
 [-0.10844365  0.12770891 -0.20028517 -0.07567084 -0.04560679]
 [ 0.124928   -0.21079926  0.08473417 -0.15557262  0.02163063]
 [ 0.02932152  0.12775981  0.13599658 -0.17701118 -0.16031364]
 [-0.01065761 -0.11042659 -0.09209082 -0.18266428 -0.0700178 ]
 [-0.04550071 -0.11339108  0.19916847  0.06390637 -0.08612877]
 [ 0.14215967  0.00669667  0.16665241  0.00307089  0.09122986]
 [ 0.1852211   0.05512637 -0.12161277  0.2123535   0.01983683]
 [-0.07329944 -0.14195108 -0.15203196 -0.08365381  0.09283501]
 [ 0.10755169 -0.02434866  0.11233383  0.05180568 -0.01607811]
 [-0.13685755  0.19209418 -0.13852623  0.13343418  0.16740105]
 [ 0.09855086 -0.16175449 -0.15750082 -0.11597005  0.19820035]
 [-0.02913056 -0.04245529  0.08314037 -0.01706158  0.19339389]
 [-0.21121754  0.06868714  0.13475317 -0.05326384 -0.00214358]
 [ 0.05587006  0.11235818  0.02798373 -0.15585741 -0.12964344]
 [ 0.16723248  0.16166076 -0.13607234 -0.11485618 -0.13980564]
 [ 0.15420306  0.04603398  0.20680773 -0.18654817 -0.01594858]
 [-0.04814774  0.13367876  0.16997239 -0.01469879 -0.03121002]
 [ 0.03704789 -0.12046593 -0.17657067  0.03373668 -0.05611451]
 [ 0.13235953 -0.01615311  0.00642343 -0.05527449  0.06542054]
 [ 0.01838723 -0.11417508 -0.14777616  0.1668779   0.13927963]
 [ 0.14299482 -0.16021495 -0.00349504 -0.00945121 -0.03680909]
 [ 0.15246865  0.16281214  0.16994256  0.09518212  0.12469292]
 [-0.00890876  0.14164087  0.09123138  0.21208566 -0.11661971]
 [ 0.17379218  0.1704965  -0.02545093 -0.2097229   0.1095877 ]
 [ 0.15858415  0.03697285 -0.14251359 -0.08646128 -0.09676763]
 [ 0.08376098 -0.19605236 -0.03285114  0.16838276 -0.09117926]
 [-0.08535226 -0.14517277  0.1861194  -0.16224594  0.08802232]
 [ 0.06046149  0.02778006  0.20381129 -0.00219168 -0.19863513]
 [ 0.03249429  0.11393541  0.03708826 -0.13691509 -0.12910494]
 [ 0.13910034  0.16108185  0.02288209 -0.05193147 -0.05181526]
 [-0.02375491 -0.01449531 -0.06506823  0.15824932  0.05737817]
 [-0.15993921 -0.15391265 -0.00290221 -0.16329236 -0.11534227]
 [-0.152004    0.02057642  0.04729456 -0.15693027 -0.00726774]
 [ 0.03124861 -0.19861938  0.17666292  0.08555436  0.04093698]
 [-0.14260468 -0.2113337   0.1300441   0.04472855  0.20611334]
 [ 0.09716618 -0.20655754  0.16672412 -0.18893832 -0.00610258]
 [-0.01092255 -0.14002511 -0.00033168 -0.17544875 -0.08068506]]: "
2018-04-20 09:30:30,881 (dqn_agent.py:161) DEBUG: "var_name: q/fully_connected_1/biases:0, var_value [0. 0. 0. 0. 0.]: "
2018-04-20 09:30:30,886 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv/weights:0, var_value [[[[ 0.16578859 -0.16878021  0.7039348  -0.5990083  -0.5231885
     0.12528002  0.3845706   0.58010113]
   [-0.1548481  -0.41433412 -0.21852148 -0.35893342  0.6082158
     0.3999889   0.58211505 -0.26015198]]]]: "
2018-04-20 09:30:30,891 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 09:30:30,902 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv_1/weights:0, var_value [[[[ 1.50372803e-01 -4.65755910e-02  6.63120598e-02 -1.35417745e-01
    -8.24370235e-02 -1.52714670e-01 -1.77968279e-01 -1.38832420e-01
    -1.16875656e-01  1.51195586e-01  1.10575348e-01  9.78565514e-02]
   [ 9.89191234e-02  7.67598152e-02 -1.66469067e-02  7.34809935e-02
     8.29356015e-02  1.19481683e-02 -1.79388598e-01 -1.44438356e-01
     7.07273185e-03 -1.77472010e-01  8.87598395e-02  1.48418576e-01]
   [-1.66158974e-01 -1.18967593e-02 -4.12107557e-02 -1.54847249e-01
     1.17666066e-01 -1.38515577e-01  1.65102780e-02 -1.09486468e-01
    -1.41777694e-01  9.60279405e-02  2.53623426e-02 -1.03353307e-01]
   [ 5.52144647e-03  9.48200822e-02  3.09036374e-02  1.07741743e-01
    -1.58003852e-01  1.00059152e-01 -3.98937464e-02 -1.39132082e-01
     1.46161884e-01 -9.86199975e-02  5.65466583e-02 -1.79113835e-01]
   [-1.25564590e-01  1.41239941e-01 -5.20381778e-02 -6.02059364e-02
     3.34170163e-02  7.30284750e-02 -8.97882581e-02 -4.29988056e-02
    -1.51726469e-01  3.51880342e-02 -7.81367794e-02 -3.25431228e-02]
   [ 1.82122052e-01 -9.67563912e-02  1.00072682e-01 -1.05278946e-01
    -3.69303375e-02  4.92800772e-03 -2.31504589e-02 -5.03832102e-03
     1.81149483e-01  1.81027949e-01  1.24728292e-01 -1.31427914e-01]
   [-1.80586249e-01 -1.36025965e-01  4.48914468e-02 -5.97371310e-02
    -6.78593963e-02 -6.46777675e-02  1.34997427e-01  1.21811777e-02
     9.64576602e-02  1.58229679e-01  1.37813747e-01 -2.31378824e-02]
   [-9.52447131e-02  1.47893041e-01 -3.06760669e-02 -2.78017670e-02
    -2.98631638e-02 -1.24209307e-01  9.12289321e-02 -9.49710608e-04
     1.14439696e-01  1.43336982e-01 -1.32964581e-01 -9.92896929e-02]]

  [[-6.49723262e-02  1.58546180e-01  5.85785955e-02 -1.50315136e-01
    -6.15584701e-02 -1.41734332e-01  6.16731346e-02 -1.22978218e-01
     1.81306928e-01 -2.63602883e-02  1.26414150e-02 -1.50923759e-01]
   [-1.40209600e-01 -9.67322737e-02  1.24145299e-02  6.59394115e-02
     1.41328335e-01  8.43215585e-02  1.14990234e-01 -1.16814151e-01
     3.76809388e-02  2.42543519e-02  5.33993393e-02 -7.67892525e-02]
   [-9.87472758e-02  1.74100071e-01  4.51567620e-02  1.41774416e-01
     1.41309172e-01  2.58868784e-02 -1.43943951e-01 -1.37666881e-01
     1.47413224e-01  1.99114233e-02  1.03365660e-01 -9.21891481e-02]
   [-1.67833194e-01  1.96955949e-02 -1.77946121e-01 -1.34419441e-01
     1.75737649e-01  8.71360302e-03  3.25536728e-03 -1.43141359e-01
     1.20177001e-01 -1.45054042e-01  1.27553076e-01  1.53062642e-02]
   [-1.55145079e-02  1.71647877e-01  4.45766449e-02  8.31186771e-02
    -7.10270032e-02 -1.09896958e-02 -2.90575325e-02 -6.20858297e-02
    -4.92762625e-02  2.22920179e-02 -5.88739440e-02  1.71498477e-01]
   [-8.99066553e-02 -1.71779886e-01 -1.65016860e-01  1.04004711e-01
     9.67311859e-03 -1.54113770e-02 -1.70659572e-01 -8.31511989e-02
     3.37359458e-02  1.55402720e-03  9.14124548e-02  7.11061060e-03]
   [-1.43738240e-01 -1.68416440e-01 -1.72697783e-01 -1.13055982e-01
     1.71616912e-01  1.39764518e-01 -1.03619576e-01  1.14000082e-01
    -9.52616334e-03  1.18024051e-01 -4.03728336e-02  1.08210146e-01]
   [ 1.73561484e-01  9.88033414e-02 -1.72187835e-01  1.25137299e-01
    -1.23160735e-01  7.95265436e-02  8.18993449e-02  2.86989361e-02
     2.07359940e-02 -7.31796026e-05  1.80210263e-01  6.27235323e-02]]

  [[ 6.60870969e-03 -1.21559039e-01 -6.81037679e-02  4.53340560e-02
     7.55124092e-02  1.80749804e-01 -7.44268298e-03 -5.38325906e-02
    -1.13388635e-01 -3.08124125e-02 -1.79469511e-01  1.35015100e-01]
   [ 1.67978674e-01  1.71190590e-01 -1.61744744e-01  6.67512417e-04
     1.17815793e-01  2.60507613e-02  3.34459543e-02  1.59345895e-01
    -1.78536028e-01  1.41344666e-01  1.04296505e-02 -7.02945814e-02]
   [ 4.77891862e-02 -1.02742903e-01  1.56789571e-02 -1.36362284e-01
     1.65883392e-01 -1.68079048e-01  1.21308386e-01 -1.42047554e-02
     8.56704414e-02 -7.17130676e-02  1.17512047e-01 -8.82266909e-02]
   [-3.50956172e-02 -8.91575217e-02  3.36481035e-02 -1.23550743e-02
    -7.22268820e-02  1.74243808e-01 -1.39517486e-01  1.28090173e-01
    -1.26272231e-01  1.55808061e-01  2.08957046e-02 -1.18645594e-01]
   [ 7.13585317e-02 -3.16085517e-02 -1.65610015e-03 -8.18596482e-02
     7.13812411e-02  1.46497369e-01 -1.18483707e-01 -4.29078937e-03
     5.63763082e-03 -4.74429578e-02 -9.13266167e-02  6.01610541e-02]
   [-3.59444022e-02  2.49007642e-02  8.52181911e-02  1.11225158e-01
    -1.68843284e-01  1.38022453e-02 -1.29408032e-01 -1.27537102e-01
    -1.64736927e-01 -1.63101792e-01 -5.62077910e-02  4.17557508e-02]
   [-4.67253774e-02 -1.25943989e-01  1.78297579e-01  7.24245906e-02
     1.71259105e-01 -1.48414478e-01  8.97851586e-02  1.71935797e-01
    -1.20076180e-01  6.27714545e-02 -1.31946474e-01  5.90580702e-03]
   [-1.11516714e-02 -4.76029217e-02 -8.17512199e-02 -6.77612349e-02
    -6.90109134e-02 -1.18763387e-01  1.14549041e-01  1.24193341e-01
    -4.94612157e-02  1.08101368e-01 -4.13815677e-02  1.03034586e-01]]]


 [[[ 1.03024930e-01 -7.02546537e-03 -2.97795087e-02  9.59316492e-02
    -1.21294126e-01 -8.22076201e-02 -8.04460421e-02  1.67265356e-01
    -7.78349936e-02  1.49735332e-01  4.41252887e-02  1.56957269e-01]
   [ 5.70124686e-02  2.57944614e-02 -1.11137785e-01 -7.57582635e-02
     1.59029961e-02 -1.73812002e-01  4.12420630e-02  1.76606685e-01
    -1.10035628e-01 -1.08016923e-01 -7.28153959e-02 -4.51277643e-02]
   [ 1.05051905e-01 -3.10264379e-02  8.81486833e-02  1.43133968e-01
     3.28181833e-02  1.27911597e-01 -3.45832855e-02  1.39498591e-01
     1.14050001e-01 -4.24026698e-02 -8.59723687e-02 -1.65779963e-01]
   [-6.03268147e-02 -1.46665573e-02 -1.37881398e-01  3.95148993e-03
    -5.62563688e-02  8.25574100e-02 -6.08313605e-02 -1.90340877e-02
    -7.64632225e-03 -1.05154760e-01  1.13561392e-01 -5.71756214e-02]
   [ 1.35875374e-01 -1.67817473e-01  1.01750970e-01 -8.54162350e-02
    -1.76406413e-01  1.36459082e-01 -4.39292789e-02 -2.14182138e-02
     1.56653315e-01 -1.64324746e-01 -1.60880029e-01 -8.23006034e-04]
   [ 9.53239202e-02 -1.11630887e-01  7.12765157e-02  6.14777207e-02
    -1.69305697e-01  2.91113704e-02 -3.56722027e-02  4.45723385e-02
    -4.42971438e-02  9.62186754e-02  1.60977006e-01  6.78107142e-02]
   [-1.72911420e-01 -1.43857628e-01  8.68752599e-04  9.54736769e-03
    -9.24694315e-02 -1.78487062e-01 -5.61368465e-03  6.78707063e-02
    -2.06757486e-02 -3.45145464e-02 -1.74988851e-01 -7.25035146e-02]
   [ 7.36595690e-02  1.87935531e-02 -1.59472674e-02 -5.99457622e-02
    -7.34177977e-02  5.31561375e-02 -6.85833693e-02  8.55869055e-03
     1.18327230e-01  8.56759846e-02 -1.35336205e-01  1.29384041e-01]]

  [[-9.49209407e-02 -1.43931061e-01  1.39986843e-01  1.04966283e-01
    -1.22518159e-01  1.38866931e-01  1.80403054e-01 -1.03378445e-02
     1.81240708e-01 -9.13791135e-02 -1.13647759e-01 -1.33086234e-01]
   [ 1.48116529e-01 -1.08002000e-01 -5.76655343e-02  1.56000018e-01
     1.43986583e-01  9.11345780e-02 -2.25448012e-02 -5.31424284e-02
    -2.57670432e-02 -1.24103621e-01 -1.23525642e-01  7.62276053e-02]
   [-7.34393895e-02 -1.79097041e-01  1.46193624e-01  4.55062091e-02
    -7.12102205e-02 -9.33868438e-02  1.12774521e-01  1.34814084e-01
     1.39555365e-01 -1.31254926e-01  1.81404173e-01  1.51048422e-01]
   [ 7.08374381e-02 -1.38815701e-01 -4.12131548e-02  1.45837814e-01
     4.25314754e-02 -1.42138585e-01 -4.18532938e-02 -1.43844575e-01
    -1.28269911e-01 -1.44390166e-01  5.82012087e-02  6.23516589e-02]
   [ 1.66853756e-01  1.08520240e-01 -5.43589443e-02 -1.01308919e-01
    -7.73917362e-02 -1.01675436e-01 -2.85132229e-03 -7.55310878e-02
     9.21154916e-02 -1.01184249e-02  1.36583239e-01  1.27481431e-01]
   [ 1.51185572e-01 -7.94477016e-02  6.14285767e-02 -1.09383434e-01
    -1.11160576e-02  6.78442419e-02 -1.52483404e-01 -1.91215426e-02
    -1.80681631e-01  6.66188151e-02  5.03838211e-02  6.95326626e-02]
   [ 3.85258496e-02 -5.02071828e-02  3.06560546e-02 -1.79994345e-01
     9.67103839e-02  1.20052457e-01  1.13115132e-01 -1.55062199e-01
     1.63078249e-01 -6.48751706e-02  1.65045142e-01 -1.62858605e-01]
   [ 6.52627647e-03 -3.22298855e-02  1.31609440e-01  1.30915135e-01
    -1.60923213e-01  5.48911244e-02  1.80156499e-01 -1.70418173e-01
    -1.52948812e-01 -8.17985386e-02  9.87262428e-02  1.77291811e-01]]

  [[-1.21646821e-02  1.11088246e-01  4.17499542e-02  1.78560048e-01
     1.13445967e-01  3.90263498e-02  1.50789201e-01 -1.12456851e-01
    -3.18788737e-02  1.05727613e-01 -1.43852800e-01  3.73693258e-02]
   [ 1.51212364e-01 -8.62382874e-02  1.55266970e-02  9.51764584e-02
    -1.38199165e-01  1.18672848e-02 -1.41300172e-01 -1.69071898e-01
     1.52420819e-01 -1.76010519e-01  8.78888667e-02  7.76669681e-02]
   [-5.28266728e-02 -7.85517693e-03 -9.20811519e-02  1.63302064e-01
     1.41457707e-01 -8.70479271e-02 -1.75527871e-01 -1.49765193e-01
     1.02608055e-02 -1.22574881e-01 -7.00742826e-02 -1.72640368e-01]
   [-6.49261028e-02  3.76553088e-02  1.51447207e-02 -1.18315905e-01
    -8.06945935e-02  1.49511456e-01  4.14071679e-02 -1.27147347e-01
     1.80286735e-01  7.19477832e-02  1.55820101e-02 -1.03261203e-01]
   [ 1.41694337e-01 -6.24322295e-02  1.15811795e-01 -9.51586142e-02
     1.49993539e-01  1.17649287e-01  3.02957594e-02  2.66269594e-02
    -1.63218677e-01  1.16232336e-01 -6.88857660e-02 -3.34617198e-02]
   [ 1.85265839e-02 -1.72780707e-01  1.06177509e-01 -8.92564133e-02
     1.17356837e-01  1.70722187e-01  8.87984335e-02 -1.47996560e-01
     1.34868056e-01  1.92952156e-02 -1.66095763e-01  2.49674916e-02]
   [ 2.87357569e-02  1.41703129e-01  7.52265155e-02 -8.48462209e-02
     2.94032395e-02  1.42702430e-01  1.53979063e-01 -1.11719072e-02
     1.29699051e-01 -5.90743572e-02  1.40473545e-02  1.56315535e-01]
   [ 6.19040430e-02 -2.06189901e-02 -5.67361414e-02  1.76428229e-01
    -1.10530704e-02  8.85301828e-02 -8.84541869e-03 -1.52084410e-01
    -3.88459563e-02  1.40014976e-01  1.55961126e-01 -1.64046645e-01]]]


 [[[ 4.25648689e-03  8.98439586e-02 -4.35977727e-02  1.06983155e-01
     2.51899362e-02  8.77319276e-03 -1.19932838e-01 -1.42490342e-01
    -6.24369755e-02  1.74831808e-01 -1.11000672e-01 -1.73406303e-03]
   [-4.36147004e-02 -7.79993609e-02  1.46764934e-01  1.20519042e-01
     3.80317420e-02  1.32458508e-01 -2.51937658e-02  9.32906568e-02
     9.58300531e-02  6.76800609e-02  6.37915134e-02 -2.08935142e-03]
   [ 9.21428204e-02 -1.26626223e-01 -1.05295703e-01  1.64834261e-01
     1.80658787e-01 -9.24042687e-02 -1.29927993e-01 -6.22721314e-02
    -1.05359912e-01  5.23713529e-02  2.36761123e-02 -1.63138628e-01]
   [-9.54960063e-02 -2.14881748e-02  1.12646163e-01  1.74191535e-01
     3.44628096e-03  1.61926299e-01  1.58273250e-01  1.56867951e-02
     2.06706077e-02  1.25562221e-01 -1.65372059e-01  4.79232520e-02]
   [ 1.19962305e-01 -4.58623618e-02 -1.49416864e-01  1.55377656e-01
    -3.89145166e-02 -5.39887697e-02  1.60350204e-01 -9.65190232e-02
     3.29748392e-02 -1.64857507e-01  1.05096161e-01  7.07103014e-02]
   [-1.20915376e-01  1.08093202e-01 -1.31271765e-01 -1.79597750e-01
    -2.57807970e-02 -9.47172716e-02  1.47617459e-01 -1.55910969e-01
     1.50786340e-01  1.54214382e-01  5.77574670e-02  1.12168819e-01]
   [-1.90540254e-02  1.39549166e-01 -9.14754868e-02 -9.72161889e-02
     1.55543745e-01 -1.36237085e-01 -1.10009469e-01  1.20209605e-01
     6.74618781e-02  8.37951601e-02  1.76556736e-01 -7.34775141e-02]
   [-1.59330264e-01  1.18923366e-01  6.27512187e-02 -3.31075639e-02
    -1.00204982e-01  1.22297585e-01 -5.15450388e-02 -8.07907060e-02
    -1.34177387e-01 -1.10616878e-01  1.72897637e-01 -1.29213497e-01]]

  [[ 1.11783534e-01 -5.45459390e-02 -1.35401487e-02  1.18027538e-01
     6.95149004e-02 -6.89958036e-03 -5.83146513e-03  1.51529521e-01
     8.57773423e-02 -8.92933309e-02  1.61266744e-01  1.33006960e-01]
   [ 1.64932668e-01 -9.97894555e-02  3.20096761e-02  1.32233053e-01
    -1.15717351e-01  9.46811736e-02 -8.10090527e-02  1.63969189e-01
     1.59583390e-01 -1.23477802e-01  1.80558830e-01 -1.50979385e-01]
   [-1.52807906e-01 -6.37370348e-03  1.46654993e-01 -1.25455454e-01
    -1.45555139e-02  6.47767484e-02 -1.07124448e-01 -9.12621915e-02
    -1.72373012e-01  1.76593721e-01  1.15190953e-01  1.16567612e-01]
   [ 1.20363206e-01  1.19858354e-01 -3.20471972e-02  1.29741937e-01
    -4.45766896e-02  1.33567452e-01  1.54925525e-01 -1.41365811e-01
     6.83134794e-02 -1.05220228e-01 -1.36043519e-01  1.47954345e-01]
   [-9.96115506e-02 -1.23997279e-01  1.29717439e-01  1.12763107e-01
    -6.63868934e-02 -1.78603247e-01  1.59075797e-01 -5.31462580e-02
    -1.72569335e-01 -8.85271728e-02  6.40488118e-02  5.85163087e-02]
   [-1.77035809e-01 -5.47862202e-02 -9.55599472e-02 -1.43166661e-01
     8.62739384e-02  2.65710652e-02  5.07326573e-02 -1.33114621e-01
    -1.68177992e-01 -1.21893562e-01  8.01801682e-04 -1.74880162e-01]
   [ 1.62263334e-01  1.25606716e-01 -1.22779377e-01  4.77101356e-02
     1.39659226e-01 -6.95866719e-02  1.48140907e-01 -5.99611700e-02
     8.73327255e-02  1.65933937e-01 -7.29069784e-02 -2.85871178e-02]
   [ 8.90282691e-02 -7.42706582e-02 -1.20910458e-01  1.25831723e-01
     1.14927262e-01 -1.81317806e-01 -1.38245776e-01 -1.76458612e-01
     9.16392505e-02 -6.08193949e-02  1.08285099e-02 -1.50721297e-01]]

  [[ 6.03461862e-02  1.24547660e-01 -8.12763646e-02 -1.74457580e-01
     9.16769803e-02 -6.66351616e-03  1.56731755e-01  3.42933834e-02
    -3.50841731e-02  1.58686489e-02 -6.58075660e-02  1.26392215e-01]
   [ 1.39954239e-02  5.04558980e-02  5.04422784e-02 -1.74083263e-02
    -1.06142305e-01  6.49550408e-02  8.85375440e-02  3.10065448e-02
    -1.31664664e-01  1.75815821e-01  2.67497450e-02  2.62670070e-02]
   [ 6.33399040e-02 -1.31615520e-01 -1.40392184e-02 -3.05083990e-02
     7.33584166e-02 -1.15155280e-02 -4.37519848e-02  9.74804163e-02
    -5.79845607e-02 -1.43975466e-02 -1.52669489e-01  1.07540905e-01]
   [ 1.42249972e-01 -1.79174826e-01  1.14173412e-01 -1.15154043e-01
     1.23451293e-01  8.14085901e-02  3.12688947e-02 -5.90064973e-02
    -9.61571261e-02 -2.31606066e-02 -1.56199604e-01  1.80257291e-01]
   [-1.03674076e-01 -4.80517745e-04 -1.49942353e-01 -1.45888090e-01
     3.76347601e-02 -6.96528330e-02  8.85638595e-02 -7.45727122e-03
     1.21188790e-01  3.01212966e-02 -1.78860933e-01 -4.83771712e-02]
   [-1.33370608e-01  7.48704374e-02 -6.24780655e-02  4.20927107e-02
     6.18667901e-02  1.31099313e-01 -3.75017822e-02 -7.03971386e-02
     1.62500918e-01 -1.47199631e-02 -8.18408430e-02 -2.02136785e-02]
   [ 4.42216694e-02 -8.60013142e-02  1.57468051e-01  1.37674659e-02
     6.86165392e-02  2.51895785e-02  5.50284088e-02 -1.44589245e-02
     9.32712853e-02 -1.61228791e-01  1.78502589e-01  1.29311472e-01]
   [-5.49125373e-02 -1.51102275e-01  1.31593674e-01  9.53472257e-02
     1.79685354e-02 -8.44948590e-02  4.86635119e-02  2.34054476e-02
    -1.06498890e-01  7.17085004e-02 -1.80102378e-01  1.50361359e-01]]]]: "
2018-04-20 09:30:30,908 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv_1/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 09:30:30,918 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv_2/weights:0, var_value [[[[-0.12522422 -0.1354345   0.09417535 ... -0.11621692  0.029524
    -0.07588997]
   [-0.08668954 -0.00297628 -0.0280368  ...  0.13890739  0.04549155
     0.02974808]
   [ 0.00260571  0.00451906  0.09286064 ... -0.13508692  0.05490991
     0.00800513]
   ...
   [ 0.04271789 -0.11691079 -0.14807814 ...  0.05746791 -0.02532297
    -0.06981846]
   [-0.04235376  0.00743799  0.12039594 ...  0.13588114 -0.03065713
     0.03426272]
   [-0.08544461  0.06057513 -0.14685057 ...  0.12645708 -0.10506473
    -0.05202372]]

  [[-0.0017053  -0.06590755 -0.12074768 ... -0.03506527  0.0471594
    -0.12902296]
   [ 0.06385727  0.02352367 -0.10391571 ... -0.06317076  0.10501872
     0.13921537]
   [-0.08738466  0.07329221 -0.1053246  ...  0.08514492  0.09068289
     0.05181745]
   ...
   [-0.11489826 -0.08441728 -0.05160032 ... -0.11444561 -0.02635787
     0.09266385]
   [-0.08226252 -0.05534509  0.03708895 ...  0.09940009  0.09619759
    -0.08005884]
   [ 0.14432804 -0.1319058  -0.0333412  ... -0.07117078 -0.03679721
    -0.08127585]]

  [[-0.14999907  0.00182149 -0.1291438  ...  0.1006272  -0.08041786
     0.10595734]
   [-0.15308557  0.04255168 -0.07102057 ... -0.0605379   0.09419173
    -0.11082023]
   [ 0.00714652  0.07216077 -0.07786005 ... -0.00067776  0.03274879
     0.05973859]
   ...
   [ 0.05690575 -0.13456014  0.09023222 ...  0.06514753  0.00051269
     0.15151139]
   [ 0.10813822 -0.05123677 -0.06322377 ... -0.07094847  0.03822237
     0.10246955]
   [ 0.1189784  -0.08899488  0.05898589 ... -0.11835147 -0.11053056
     0.1398172 ]]]


 [[[-0.13088883 -0.09102157 -0.01774706 ... -0.1386186  -0.03951944
     0.04540797]
   [ 0.0129533   0.01806973  0.11763816 ... -0.11220305 -0.11066774
    -0.09547827]
   [-0.10805482 -0.00213471 -0.04634861 ... -0.0838397   0.04927443
    -0.139608  ]
   ...
   [-0.08670194  0.12110518 -0.04537459 ...  0.03149109 -0.14170036
    -0.0120991 ]
   [-0.07291777  0.0526129  -0.06326388 ...  0.10662468 -0.08225171
     0.07743359]
   [-0.0266626   0.02086495  0.0366534  ...  0.11856143  0.11629193
     0.03119802]]

  [[-0.12298562  0.11590634 -0.00844648 ... -0.08813802 -0.04071294
    -0.05604029]
   [-0.1068588   0.03327785 -0.09436019 ...  0.04751584  0.01258445
     0.05925806]
   [ 0.07963617  0.03043199  0.01705211 ... -0.00663181 -0.1299533
     0.01570322]
   ...
   [-0.03363621  0.06438722  0.05083276 ... -0.03031117  0.12927397
     0.06691447]
   [-0.13986729  0.07173596  0.04670653 ... -0.115233    0.06701972
     0.14322536]
   [ 0.08088674 -0.08694081 -0.11239843 ... -0.1351938   0.11261041
     0.02717426]]

  [[ 0.13991122 -0.13064092  0.09233956 ...  0.0161047  -0.14876941
    -0.02430941]
   [ 0.01682532  0.13362668 -0.01136413 ... -0.05301271 -0.13972676
    -0.10186359]
   [ 0.02111846 -0.07457238  0.03911866 ... -0.06220826  0.10248439
     0.06369692]
   ...
   [ 0.15007146 -0.09400775 -0.05343858 ... -0.14926487 -0.09633681
     0.09016615]
   [-0.08707546 -0.03527912 -0.08245905 ...  0.09516852 -0.0007882
     0.05023497]
   [ 0.09024264 -0.09672493  0.02637583 ... -0.07301643 -0.01900829
    -0.12638085]]]


 [[[ 0.03938733  0.03906973  0.11211483 ... -0.04197498  0.0372963
     0.04559989]
   [-0.04688451 -0.01231976  0.06546494 ... -0.02586299 -0.04173272
    -0.10286638]
   [-0.09964574  0.1187769  -0.11503078 ...  0.02263713 -0.06730957
    -0.00470072]
   ...
   [ 0.1311542   0.11009382  0.11269118 ... -0.04250956  0.03042756
    -0.09522898]
   [-0.02665584  0.01291297  0.12490769 ... -0.0878212   0.14664848
     0.04764427]
   [ 0.07134758  0.08039707 -0.06811168 ...  0.02068302  0.03081958
     0.01278549]]

  [[ 0.14920895  0.07616501  0.02586679 ...  0.14995386  0.12782706
    -0.04017604]
   [ 0.03853169 -0.15360948  0.05542544 ... -0.07664546 -0.0714123
    -0.03333351]
   [-0.01313841  0.05898832  0.12622394 ... -0.020441    0.15000705
     0.0939586 ]
   ...
   [-0.04966236 -0.09621243  0.0729572  ... -0.05230574  0.08345963
    -0.11977363]
   [ 0.0275363  -0.02793138  0.10183831 ...  0.12256519 -0.10003938
     0.01554742]
   [ 0.08111656  0.0452089   0.13995512 ... -0.10029098  0.03191343
    -0.11672935]]

  [[ 0.1199619  -0.08640862  0.06365936 ... -0.12824656  0.09125014
     0.10840641]
   [ 0.02333318  0.10390221  0.09637664 ... -0.1134121  -0.12880318
    -0.11095425]
   [ 0.02464764  0.04679088 -0.1422983  ... -0.07373875 -0.05465475
     0.13453986]
   ...
   [ 0.02748016 -0.13626346  0.08940756 ...  0.02961722  0.07047635
     0.09916653]
   [ 0.0960225  -0.02609561  0.09388299 ... -0.01542278  0.02156408
     0.08577876]
   [ 0.06079799  0.12907632 -0.08451672 ... -0.05292048  0.0811267
     0.13957442]]]]: "
2018-04-20 09:30:30,923 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv_2/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 09:30:30,929 (dqn_agent.py:161) DEBUG: "var_name: target_q/fully_connected/weights:0, var_value [[-0.01165338  0.06772149 -0.07559088 ... -0.04275567 -0.07500613
  -0.07135338]
 [-0.06975953 -0.01027971  0.02858579 ... -0.04060309 -0.02329833
   0.02616174]
 [ 0.02934137  0.06960989 -0.01913106 ...  0.09125461  0.02750253
   0.07366175]
 ...
 [ 0.05613547  0.06916746 -0.07303284 ...  0.03601373 -0.00402633
   0.07013955]
 [-0.08416068 -0.07750266 -0.03354026 ... -0.02956528 -0.07028671
  -0.04191624]
 [-0.06461404 -0.01216286 -0.03355556 ... -0.05218419 -0.08294372
   0.08601653]]: "
2018-04-20 09:30:30,935 (dqn_agent.py:161) DEBUG: "var_name: target_q/fully_connected/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 09:30:30,945 (dqn_agent.py:161) DEBUG: "var_name: target_q/fully_connected_1/weights:0, var_value [[ 0.11870596 -0.15481125 -0.08325458 -0.08356291  0.08852899]
 [-0.01849052  0.06371495  0.0184916  -0.05823043  0.0574483 ]
 [ 0.19474357  0.0282993   0.14010581  0.16359675  0.00182505]
 [-0.08241451  0.00947648  0.10794613  0.05049366 -0.01001088]
 [-0.14022098  0.1514669   0.0678007   0.01713617  0.15390167]
 [-0.05876082 -0.07358465 -0.13201798 -0.12570804  0.01221827]
 [-0.07425344  0.12143624  0.07878765  0.02007711  0.09286267]
 [-0.13791743  0.07838187 -0.05613495  0.09285158  0.19956061]
 [ 0.10805166 -0.05447119  0.13778886 -0.07942197  0.20851532]
 [-0.19574533 -0.06973067 -0.04073122  0.05821517 -0.1321418 ]
 [ 0.16401622  0.15225562 -0.03095718 -0.04711439  0.0270002 ]
 [ 0.11706933  0.0592455   0.09083107  0.11641932  0.03405657]
 [ 0.03040607  0.04500788  0.05787361 -0.14870766 -0.1327883 ]
 [ 0.03028473  0.03329678  0.12971964 -0.17246987 -0.07720664]
 [ 0.07415843  0.04051423  0.18194291 -0.06031424  0.06225461]
 [-0.06854317  0.13581443  0.2008906   0.01990129  0.11714604]
 [-0.05915804  0.01314983 -0.07446997  0.07476658  0.15690085]
 [-0.05559535 -0.18741989  0.2027219   0.2009961   0.05214098]
 [-0.05809887  0.11117184  0.15488884  0.16936141  0.19524512]
 [-0.14364335 -0.02939688  0.08226016 -0.19049396 -0.08981791]
 [-0.07796057  0.09598601 -0.1731134   0.08341271 -0.04922266]
 [-0.01838033  0.16872826  0.10187683  0.15695244  0.00467034]
 [ 0.12725466  0.09740776 -0.11939754  0.17046866  0.16501188]
 [-0.058165   -0.09144739 -0.1762802   0.00307301 -0.07133847]
 [ 0.12365672 -0.18159056 -0.12886395 -0.04562421 -0.14570783]
 [-0.14515418 -0.1258271   0.12732568 -0.06867458 -0.1598238 ]
 [ 0.12676376 -0.20967916 -0.01580501  0.12767547 -0.14316487]
 [ 0.07466397  0.19889629 -0.06243522 -0.08853775 -0.00535955]
 [-0.13031472 -0.02444483 -0.08873296  0.00349337  0.10584959]
 [ 0.11085191 -0.08651499  0.05576751  0.10258698  0.06979695]
 [ 0.0460459   0.1971511   0.01044288  0.14720884 -0.20767003]
 [-0.03380635 -0.03087747  0.20766097  0.15110832  0.17644873]
 [ 0.17145759 -0.06252871  0.03008197  0.01492693 -0.00988074]
 [-0.03732611  0.18120414 -0.12720662  0.01327081  0.06358033]
 [ 0.06066501 -0.05360521 -0.18311344 -0.00502719  0.07951105]
 [-0.04452883 -0.19004758 -0.08509952 -0.03402294  0.01059683]
 [ 0.02818963  0.20387697  0.15909317  0.19612503 -0.18932626]
 [ 0.16145715  0.07530695 -0.0775439  -0.01408909  0.10275957]
 [-0.13024464  0.03376448  0.13551894  0.11391729 -0.11753183]
 [-0.09155996 -0.09994835 -0.14183679  0.12092179  0.2008149 ]
 [ 0.08213508  0.03913659 -0.19157365 -0.14531796  0.10953736]
 [ 0.01025492  0.15585119 -0.0205951   0.1926255   0.03500374]
 [-0.17024046 -0.02630918  0.02272911  0.00827192  0.21206793]
 [ 0.04478785 -0.06176957 -0.16253135 -0.08820727 -0.19107611]
 [ 0.03661002  0.02499609 -0.13273752 -0.14817317 -0.20688543]
 [-0.136457   -0.16357595  0.06342134 -0.08944865  0.088478  ]
 [ 0.13113368 -0.05381112 -0.21110208  0.08085087 -0.07331403]
 [-0.02425291 -0.12829804 -0.096749   -0.12726212  0.10596576]
 [ 0.18752867  0.05446807 -0.11938838  0.18519834  0.02568363]
 [ 0.05107617 -0.13383083  0.12638038  0.06299251 -0.19418857]
 [ 0.21073759 -0.08026709  0.02570985  0.06507269 -0.17872274]
 [-0.08997803 -0.09236554  0.2098794   0.1007517  -0.18008167]
 [-0.05088186  0.01850961 -0.1553129  -0.11694446 -0.02926728]
 [ 0.12238765 -0.1467902   0.17086092  0.03407668 -0.1571192 ]
 [ 0.2001664   0.06628212 -0.18702677 -0.08881039 -0.05014227]
 [-0.16131322 -0.01338322 -0.11745212  0.10844958  0.03619209]
 [ 0.16515875  0.20122135 -0.00852163 -0.15165995  0.05736285]
 [-0.0056102   0.01120335 -0.039601   -0.0784713   0.1706138 ]
 [-0.18446264 -0.13866833  0.12121865 -0.13670716 -0.06040463]
 [-0.06053007  0.06257394 -0.19829705  0.0083417   0.11260951]
 [-0.09664686 -0.01276755  0.09975061  0.11941856  0.16222301]
 [ 0.19435817 -0.20760411  0.14799121  0.0387938   0.15001747]
 [ 0.18698838  0.1820336   0.08803049  0.06564122  0.19509685]
 [-0.00950119  0.05600187 -0.01585135  0.0136506   0.07987544]
 [ 0.01071411  0.13388419  0.20310634 -0.12489062  0.18849719]
 [ 0.17595473 -0.03391731  0.00028606  0.01688054  0.11814392]
 [ 0.14996955  0.16897684  0.08489561 -0.16387957 -0.09658629]
 [-0.00572459 -0.03371689 -0.00589196 -0.12346446  0.17268154]
 [ 0.14934197 -0.13974467 -0.20037621  0.0794566  -0.20891617]
 [ 0.08974302 -0.0734383  -0.03546232 -0.05977382  0.13392445]
 [-0.06005476 -0.17769825  0.05928564 -0.06719276  0.0247198 ]
 [-0.15733245  0.16773114  0.05051798  0.10795903 -0.19855264]
 [-0.19375646 -0.14612946  0.02872367 -0.01842095 -0.18731324]
 [ 0.04998356 -0.06341602 -0.12803528 -0.18418524 -0.09847698]
 [-0.10515785 -0.13462126 -0.08387348 -0.01258479  0.04680407]
 [-0.16451901  0.10233438  0.07279852 -0.0383343   0.04631194]
 [-0.05804706  0.06967178  0.0796783  -0.11187002  0.04453248]
 [-0.16981372 -0.03683335 -0.05120616  0.05916715 -0.12504143]
 [-0.1842099  -0.12976742  0.06102619  0.053002    0.11583146]
 [ 0.06445989  0.00352162 -0.02236424  0.05631351 -0.18259268]
 [-0.186566   -0.1534721  -0.00459099  0.06794512  0.15025187]
 [ 0.16575283 -0.08664975 -0.11617312  0.05678836 -0.12248691]
 [-0.19396895  0.03695837 -0.00519243 -0.05851391 -0.18112351]
 [-0.1592849  -0.1529779   0.1379495  -0.16804002  0.10364354]
 [-0.08048671 -0.10631137  0.14507023  0.10860464 -0.15571897]
 [ 0.05767405  0.15034914  0.03106216  0.03045295 -0.06186159]
 [-0.129422   -0.21169983 -0.1626545   0.14628795 -0.0628999 ]
 [ 0.01872949 -0.07295378  0.06444728  0.04372817 -0.18703948]
 [ 0.16834888 -0.12346137 -0.20794638 -0.11178424  0.1723615 ]
 [-0.05670936  0.06118587 -0.03188844 -0.14303224  0.20373943]
 [ 0.11243004  0.11467034  0.15567076 -0.08211325 -0.11773717]
 [-0.10844365  0.12770891 -0.20028517 -0.07567084 -0.04560679]
 [ 0.124928   -0.21079926  0.08473417 -0.15557262  0.02163063]
 [ 0.02932152  0.12775981  0.13599658 -0.17701118 -0.16031364]
 [-0.01065761 -0.11042659 -0.09209082 -0.18266428 -0.0700178 ]
 [-0.04550071 -0.11339108  0.19916847  0.06390637 -0.08612877]
 [ 0.14215967  0.00669667  0.16665241  0.00307089  0.09122986]
 [ 0.1852211   0.05512637 -0.12161277  0.2123535   0.01983683]
 [-0.07329944 -0.14195108 -0.15203196 -0.08365381  0.09283501]
 [ 0.10755169 -0.02434866  0.11233383  0.05180568 -0.01607811]
 [-0.13685755  0.19209418 -0.13852623  0.13343418  0.16740105]
 [ 0.09855086 -0.16175449 -0.15750082 -0.11597005  0.19820035]
 [-0.02913056 -0.04245529  0.08314037 -0.01706158  0.19339389]
 [-0.21121754  0.06868714  0.13475317 -0.05326384 -0.00214358]
 [ 0.05587006  0.11235818  0.02798373 -0.15585741 -0.12964344]
 [ 0.16723248  0.16166076 -0.13607234 -0.11485618 -0.13980564]
 [ 0.15420306  0.04603398  0.20680773 -0.18654817 -0.01594858]
 [-0.04814774  0.13367876  0.16997239 -0.01469879 -0.03121002]
 [ 0.03704789 -0.12046593 -0.17657067  0.03373668 -0.05611451]
 [ 0.13235953 -0.01615311  0.00642343 -0.05527449  0.06542054]
 [ 0.01838723 -0.11417508 -0.14777616  0.1668779   0.13927963]
 [ 0.14299482 -0.16021495 -0.00349504 -0.00945121 -0.03680909]
 [ 0.15246865  0.16281214  0.16994256  0.09518212  0.12469292]
 [-0.00890876  0.14164087  0.09123138  0.21208566 -0.11661971]
 [ 0.17379218  0.1704965  -0.02545093 -0.2097229   0.1095877 ]
 [ 0.15858415  0.03697285 -0.14251359 -0.08646128 -0.09676763]
 [ 0.08376098 -0.19605236 -0.03285114  0.16838276 -0.09117926]
 [-0.08535226 -0.14517277  0.1861194  -0.16224594  0.08802232]
 [ 0.06046149  0.02778006  0.20381129 -0.00219168 -0.19863513]
 [ 0.03249429  0.11393541  0.03708826 -0.13691509 -0.12910494]
 [ 0.13910034  0.16108185  0.02288209 -0.05193147 -0.05181526]
 [-0.02375491 -0.01449531 -0.06506823  0.15824932  0.05737817]
 [-0.15993921 -0.15391265 -0.00290221 -0.16329236 -0.11534227]
 [-0.152004    0.02057642  0.04729456 -0.15693027 -0.00726774]
 [ 0.03124861 -0.19861938  0.17666292  0.08555436  0.04093698]
 [-0.14260468 -0.2113337   0.1300441   0.04472855  0.20611334]
 [ 0.09716618 -0.20655754  0.16672412 -0.18893832 -0.00610258]
 [-0.01092255 -0.14002511 -0.00033168 -0.17544875 -0.08068506]]: "
2018-04-20 09:30:30,951 (dqn_agent.py:161) DEBUG: "var_name: target_q/fully_connected_1/biases:0, var_value [0. 0. 0. 0. 0.]: "
2018-04-20 09:30:32,395 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:32,395 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:32,395 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:32,395 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:33,005 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:33,006 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:33,006 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:33,006 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:33,474 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:33,474 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:33,474 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:33,474 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:34,153 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:34,154 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:34,154 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:34,154 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:34,874 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:34,874 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:34,874 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:34,874 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:35,585 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:35,585 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:35,585 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:35,585 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:36,437 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:36,437 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:36,437 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:36,437 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:37,128 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:37,129 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:37,129 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:37,129 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:37,705 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:37,706 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:37,706 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:37,706 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:38,575 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:38,575 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:38,576 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:38,576 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:39,387 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:39,388 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:39,388 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:39,388 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:40,112 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:40,112 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:40,112 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:40,112 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:40,838 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:40,838 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:40,838 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:40,838 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:41,566 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:41,567 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:41,567 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:41,567 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:42,182 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:42,182 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:42,183 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:42,183 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:42,810 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:42,810 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:42,810 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:42,810 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:43,573 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:43,573 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:43,573 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:43,573 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:44,113 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:44,113 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:44,113 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:44,113 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:44,923 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:44,923 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:44,923 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:44,923 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:45,612 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:45,612 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:45,612 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:45,612 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:46,313 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:46,313 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:46,313 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:46,313 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:47,058 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:47,059 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:47,059 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:47,059 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:47,977 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:47,977 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:47,977 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:47,977 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:48,768 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:48,769 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:48,769 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:48,769 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:56,144 (dqn_main.py:61) DEBUG: ">>>> RUNNING data_file=7_17.npy,reuse_weights=None,test=True<<<<"
2018-04-20 09:30:56,616 (tf_logging.py:160) Level 1: "Registering Batch (<function _BatchGrad at 0x7f3038cb4378>) in gradient."
2018-04-20 09:30:56,618 (tf_logging.py:160) Level 1: "Registering Unbatch (<function _UnbatchGrad at 0x7f3038cb4e18>) in gradient."
2018-04-20 09:30:56,624 (tf_logging.py:160) Level 1: "Registering ZeroInitializer (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,643 (tf_logging.py:160) Level 1: "Registering SparseFeatureCross (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,646 (tf_logging.py:160) Level 1: "Registering SparseFeatureCrossV2 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,649 (tf_logging.py:160) Level 1: "Registering SparseFeatureCross (None) in gradient."
2018-04-20 09:30:56,650 (tf_logging.py:160) Level 1: "Registering SparseFeatureCrossV2 (None) in gradient."
2018-04-20 09:30:56,654 (tf_logging.py:160) Level 1: "Registering GDNLowerBound (<function GDN._lower_bound_grad at 0x7f30381586a8>) in gradient."
2018-04-20 09:30:56,673 (tf_logging.py:160) Level 1: "Registering ObtainNext (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,684 (tf_logging.py:160) Level 1: "Registering hparams ((<class 'tensorflow.contrib.training.python.training.hparam_pb2.HParamDef'>, <function HParams.to_proto at 0x7f3030240620>, <function HParams.from_proto at 0x7f30302406a8>)) in proto functions."
2018-04-20 09:30:56,691 (tf_logging.py:160) Level 1: "Registering GRUBlockCell (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,693 (tf_logging.py:160) Level 1: "Registering GRUBlockCellGrad (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,695 (tf_logging.py:160) Level 1: "Registering GRUBlockCell (<function _GRUBlockCellGrad at 0x7f30301d9b70>) in gradient."
2018-04-20 09:30:56,697 (tf_logging.py:160) Level 1: "Registering BlockLSTM (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,698 (tf_logging.py:160) Level 1: "Registering BlockLSTMGrad (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,700 (tf_logging.py:160) Level 1: "Registering LSTMBlockCell (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,701 (tf_logging.py:160) Level 1: "Registering LSTMBlockCellGrad (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,704 (tf_logging.py:160) Level 1: "Registering LSTMBlockCell (<function _LSTMBlockCellGrad at 0x7f30301a0d90>) in gradient."
2018-04-20 09:30:56,704 (tf_logging.py:160) Level 1: "Registering BlockLSTM (<function _BlockLSTMGrad at 0x7f30301a0e18>) in gradient."
2018-04-20 09:30:56,709 (tf_logging.py:160) Level 1: "Registering KMC2ChainInitialization (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,710 (tf_logging.py:160) Level 1: "Registering KmeansPlusPlusInitialization (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,711 (tf_logging.py:160) Level 1: "Registering NearestNeighbors (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,714 (tf_logging.py:160) Level 1: "Registering MaskedMatmul (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,716 (tf_logging.py:160) Level 1: "Registering WALSComputePartialLhsAndRhs (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,730 (tf_logging.py:160) Level 1: "Registering ConfigureDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,731 (tf_logging.py:160) Level 1: "Registering CrossReplicaSum (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,732 (tf_logging.py:160) Level 1: "Registering InfeedDequeue (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,733 (tf_logging.py:160) Level 1: "Registering InfeedDequeueTuple (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,733 (tf_logging.py:160) Level 1: "Registering InfeedEnqueue (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,734 (tf_logging.py:160) Level 1: "Registering InfeedEnqueueTuple (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,735 (tf_logging.py:160) Level 1: "Registering OutfeedDequeue (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,735 (tf_logging.py:160) Level 1: "Registering OutfeedDequeueTuple (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,736 (tf_logging.py:160) Level 1: "Registering OutfeedEnqueue (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,736 (tf_logging.py:160) Level 1: "Registering OutfeedEnqueueTuple (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,737 (tf_logging.py:160) Level 1: "Registering ShutdownDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,738 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingActivations (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,738 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingEnqueueSparseBatch (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,739 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingLoadAdagradParameters (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,740 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingLoadGradientDescentParameters (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,740 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingReceiveActivations (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,741 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingRetrieveAdagradParameters (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,742 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingRetrieveGradientDescentParameters (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,743 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingSendGradients (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,743 (tf_logging.py:160) Level 1: "Registering TPUReplicate (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,744 (tf_logging.py:160) Level 1: "Registering TPUReplicateMetadata (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,745 (tf_logging.py:160) Level 1: "Registering TPUReplicatedInput (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,745 (tf_logging.py:160) Level 1: "Registering TPUReplicatedOutput (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,751 (tf_logging.py:160) Level 1: "Registering _ConfigureDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,752 (tf_logging.py:160) Level 1: "Registering _WaitForDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,752 (tf_logging.py:160) Level 1: "Registering _SetGlobalTPUArray (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,753 (tf_logging.py:160) Level 1: "Registering _ShutdownDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,754 (tf_logging.py:160) Level 1: "Registering _InitializeHostForDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,754 (tf_logging.py:160) Level 1: "Registering _DisconnectHostFromDistributedTPUSystem (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,756 (tf_logging.py:160) Level 1: "Registering CrossReplicaSum (<function _cross_replica_sum_grad at 0x7f3030058400>) in gradient."
2018-04-20 09:30:56,760 (tf_logging.py:160) Level 1: "Registering CloseSummaryWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,762 (tf_logging.py:160) Level 1: "Registering CreateSummaryDbWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,762 (tf_logging.py:160) Level 1: "Registering CreateSummaryFileWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,763 (tf_logging.py:160) Level 1: "Registering FlushSummaryWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,764 (tf_logging.py:160) Level 1: "Registering ImportEvent (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,764 (tf_logging.py:160) Level 1: "Registering SummaryWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,765 (tf_logging.py:160) Level 1: "Registering WriteAudioSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,765 (tf_logging.py:160) Level 1: "Registering WriteGraphSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,766 (tf_logging.py:160) Level 1: "Registering WriteHistogramSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,766 (tf_logging.py:160) Level 1: "Registering WriteImageSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,767 (tf_logging.py:160) Level 1: "Registering WriteScalarSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,767 (tf_logging.py:160) Level 1: "Registering WriteSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,785 (tf_logging.py:160) Level 1: "Registering BigQueryReader (None) in gradient."
2018-04-20 09:30:56,787 (tf_logging.py:160) Level 1: "Registering RangeDecode (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,788 (tf_logging.py:160) Level 1: "Registering RangeEncode (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,829 (tf_logging.py:160) Level 1: "Registering CudnnRNN (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,830 (tf_logging.py:160) Level 1: "Registering CudnnRNNBackprop (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,831 (tf_logging.py:160) Level 1: "Registering CudnnRNNCanonicalToParams (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,831 (tf_logging.py:160) Level 1: "Registering CudnnRNNParamsSize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,832 (tf_logging.py:160) Level 1: "Registering CudnnRNNParamsToCanonical (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,839 (tf_logging.py:160) Level 1: "Registering CudnnRNN (<function _cudnn_rnn_backward at 0x7f2fe316f6a8>) in gradient."
2018-04-20 09:30:56,839 (tf_logging.py:160) Level 1: "Registering CudnnRNNParamsSize (<function call_cpp_shape_fn at 0x7f30a4421840>) in shape functions."
2018-04-20 09:30:56,839 (tf_logging.py:160) Level 1: "Registering CudnnRNNParamsToCanonical (<function call_cpp_shape_fn at 0x7f30a4421840>) in shape functions."
2018-04-20 09:30:56,840 (tf_logging.py:160) Level 1: "Registering CudnnRNNCanonicalToParams (<function call_cpp_shape_fn at 0x7f30a4421840>) in shape functions."
2018-04-20 09:30:56,840 (tf_logging.py:160) Level 1: "Registering CudnnRNN (<function call_cpp_shape_fn at 0x7f30a4421840>) in shape functions."
2018-04-20 09:30:56,840 (tf_logging.py:160) Level 1: "Registering CudnnRNNBackprop (<function call_cpp_shape_fn at 0x7f30a4421840>) in shape functions."
2018-04-20 09:30:56,888 (tf_logging.py:160) Level 1: "Registering AdjustHsvInYiq (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,897 (tf_logging.py:160) Level 1: "Registering BipartiteMatch (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,901 (tf_logging.py:160) Level 1: "Registering ImageConnectedComponents (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,902 (tf_logging.py:160) Level 1: "Registering ImageProjectiveTransform (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,906 (tf_logging.py:160) Level 1: "Registering ImageConnectedComponents (<function call_cpp_shape_fn at 0x7f30a4421840>) in shape functions."
2018-04-20 09:30:56,909 (tf_logging.py:160) Level 1: "Registering ImageProjectiveTransform (<function call_cpp_shape_fn at 0x7f30a4421840>) in shape functions."
2018-04-20 09:30:56,910 (tf_logging.py:160) Level 1: "Registering ImageProjectiveTransform (<function _image_projective_transform_grad at 0x7f2fe2a8fb70>) in gradient."
2018-04-20 09:30:56,911 (tf_logging.py:160) Level 1: "Registering BipartiteMatch (None) in gradient."
2018-04-20 09:30:56,912 (tf_logging.py:160) Level 1: "Registering ImageConnectedComponents (None) in gradient."
2018-04-20 09:30:56,913 (tf_logging.py:160) Level 1: "Registering SingleImageRandomDotStereograms (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,920 (tf_logging.py:160) Level 1: "Registering SingleImageRandomDotStereograms (None) in gradient."
2018-04-20 09:30:56,974 (tf_logging.py:160) Level 1: "Registering BytesInUse (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,974 (tf_logging.py:160) Level 1: "Registering BytesLimit (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,975 (tf_logging.py:160) Level 1: "Registering MaxBytesInUse (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,979 (tf_logging.py:160) Level 1: "Registering NcclAllReduce (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,980 (tf_logging.py:160) Level 1: "Registering NcclBroadcast (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,981 (tf_logging.py:160) Level 1: "Registering NcclReduce (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,983 (tf_logging.py:160) Level 1: "Registering _NcclReduceSend (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,983 (tf_logging.py:160) Level 1: "Registering _NcclReduceRecv (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,984 (tf_logging.py:160) Level 1: "Registering _NcclBroadcastSend (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,984 (tf_logging.py:160) Level 1: "Registering _NcclBroadcastRecv (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,985 (tf_logging.py:160) Level 1: "Registering NcclAllReduce (<function _all_sum_grad at 0x7f2fe2141950>) in gradient."
2018-04-20 09:30:56,985 (tf_logging.py:160) Level 1: "Registering NcclReduce (<function _reduce_sum_grad at 0x7f2fe2141bf8>) in gradient."
2018-04-20 09:30:56,985 (tf_logging.py:160) Level 1: "Registering NcclBroadcast (<function _broadcast_grad at 0x7f2fe2141d90>) in gradient."
2018-04-20 09:30:56,986 (tf_logging.py:160) Level 1: "Registering PeriodicResample (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,992 (tf_logging.py:160) Level 1: "Registering FoldFusedBatchNormGrad (<function _FoldFusedBatchNormGrad at 0x7f2fe0b6a048>) in gradient."
2018-04-20 09:30:56,994 (tf_logging.py:160) Level 1: "Registering Resampler (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,995 (tf_logging.py:160) Level 1: "Registering ResamplerGrad (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,997 (tf_logging.py:160) Level 1: "Registering Resampler (<function _resampler_grad at 0x7f2fe0898c80>) in gradient."
2018-04-20 09:30:56,998 (tf_logging.py:160) Level 1: "Registering ResamplerGrad (None) in gradient."
2018-04-20 09:30:57,001 (tf_logging.py:160) Level 1: "Registering GatherTree (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,009 (tf_logging.py:160) Level 1: "Registering StatelessRandomNormal (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,009 (tf_logging.py:160) Level 1: "Registering StatelessRandomUniform (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,010 (tf_logging.py:160) Level 1: "Registering StatelessTruncatedNormal (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,010 (tf_logging.py:160) Level 1: "Registering StatelessRandomNormal (None) in gradient."
2018-04-20 09:30:57,010 (tf_logging.py:160) Level 1: "Registering StatelessRandomUniform (None) in gradient."
2018-04-20 09:30:57,011 (tf_logging.py:160) Level 1: "Registering StatelessTruncatedNormal (None) in gradient."
2018-04-20 09:30:57,015 (tf_logging.py:160) Level 1: "Registering ReinterpretStringToFloat (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,016 (tf_logging.py:160) Level 1: "Registering ScatterAddNdim (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,022 (tf_logging.py:160) Level 1: "Registering CreateTreeVariable (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,022 (tf_logging.py:160) Level 1: "Registering DecisionTreeResourceHandleOp (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,023 (tf_logging.py:160) Level 1: "Registering FeatureUsageCounts (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,023 (tf_logging.py:160) Level 1: "Registering TraverseTreeV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,024 (tf_logging.py:160) Level 1: "Registering TreeDeserialize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,024 (tf_logging.py:160) Level 1: "Registering TreeIsInitializedOp (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,025 (tf_logging.py:160) Level 1: "Registering TreePredictionsV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,026 (tf_logging.py:160) Level 1: "Registering TreeSerialize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,026 (tf_logging.py:160) Level 1: "Registering TreeSize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,027 (tf_logging.py:160) Level 1: "Registering UpdateModelV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,030 (tf_logging.py:160) Level 1: "Registering TreeVariable (None) in gradient."
2018-04-20 09:30:57,030 (tf_logging.py:160) Level 1: "Registering TreeSerialize (None) in gradient."
2018-04-20 09:30:57,030 (tf_logging.py:160) Level 1: "Registering TreeDeserialize (None) in gradient."
2018-04-20 09:30:57,031 (tf_logging.py:160) Level 1: "Registering TreeSize (None) in gradient."
2018-04-20 09:30:57,031 (tf_logging.py:160) Level 1: "Registering TreePredictionsV4 (None) in gradient."
2018-04-20 09:30:57,031 (tf_logging.py:160) Level 1: "Registering FeatureUsageCounts (None) in gradient."
2018-04-20 09:30:57,032 (tf_logging.py:160) Level 1: "Registering CreateFertileStatsVariable (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,033 (tf_logging.py:160) Level 1: "Registering FertileStatsDeserialize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,033 (tf_logging.py:160) Level 1: "Registering FertileStatsIsInitializedOp (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,034 (tf_logging.py:160) Level 1: "Registering FertileStatsResourceHandleOp (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,034 (tf_logging.py:160) Level 1: "Registering FertileStatsSerialize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,034 (tf_logging.py:160) Level 1: "Registering FinalizeTree (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,035 (tf_logging.py:160) Level 1: "Registering GrowTreeV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,035 (tf_logging.py:160) Level 1: "Registering ProcessInputV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,038 (tf_logging.py:160) Level 1: "Registering FertileStatsVariable (None) in gradient."
2018-04-20 09:30:57,038 (tf_logging.py:160) Level 1: "Registering FertileStatsSerialize (None) in gradient."
2018-04-20 09:30:57,039 (tf_logging.py:160) Level 1: "Registering FertileStatsDeserialize (None) in gradient."
2018-04-20 09:30:57,039 (tf_logging.py:160) Level 1: "Registering GrowTreeV4 (None) in gradient."
2018-04-20 09:30:57,039 (tf_logging.py:160) Level 1: "Registering ProcessInputV4 (None) in gradient."
2018-04-20 09:30:57,054 (tf_logging.py:160) Level 1: "Registering FinalizeTree (None) in gradient."
2018-04-20 09:30:57,102 (tf_logging.py:160) Level 1: "Registering FunctionBufferingResource (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,108 (tf_logging.py:160) Level 1: "Registering FunctionBufferingResourceGetNext (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,121 (tf_logging.py:160) Level 1: "Registering RemoteFusedGraphExecute (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,145 (tf_logging.py:160) Level 1: "Registering RemoteFusedGraphExecute (None) in gradient."
2018-04-20 09:30:57,170 (tf_logging.py:160) Level 1: "Created variable q/Conv/weights:0 with shape (1, 1, 2, 8) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f3038155510>"
2018-04-20 09:30:57,185 (tf_logging.py:160) Level 1: "Created variable q/Conv/biases:0 with shape (8,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f303815a208>"
2018-04-20 09:30:57,193 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/weights:0 with shape (3, 3, 8, 12) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f3038155510>"
2018-04-20 09:30:57,197 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/biases:0 with shape (12,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f303815a208>"
2018-04-20 09:30:57,204 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/weights:0 with shape (3, 3, 12, 16) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f3038155510>"
2018-04-20 09:30:57,207 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/biases:0 with shape (16,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f303815a208>"
2018-04-20 09:30:57,224 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/weights:0 with shape (576, 128) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f30381582f0>"
2018-04-20 09:30:57,228 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/biases:0 with shape (128,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f303815a5f8>"
2018-04-20 09:30:57,235 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/weights:0 with shape (128, 5) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f30381582f0>"
2018-04-20 09:30:57,239 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/biases:0 with shape (5,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f303815a5f8>"
2018-04-20 09:30:57,249 (tf_logging.py:160) Level 1: "Created variable target_q/Conv/weights:0 with shape (1, 1, 2, 8) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f3038155510>"
2018-04-20 09:30:57,253 (tf_logging.py:160) Level 1: "Created variable target_q/Conv/biases:0 with shape (8,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f303815a208>"
2018-04-20 09:30:57,261 (tf_logging.py:160) Level 1: "Created variable target_q/Conv_1/weights:0 with shape (3, 3, 8, 12) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f3038155510>"
2018-04-20 09:30:57,265 (tf_logging.py:160) Level 1: "Created variable target_q/Conv_1/biases:0 with shape (12,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f303815a208>"
2018-04-20 09:30:57,273 (tf_logging.py:160) Level 1: "Created variable target_q/Conv_2/weights:0 with shape (3, 3, 12, 16) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f3038155510>"
2018-04-20 09:30:57,276 (tf_logging.py:160) Level 1: "Created variable target_q/Conv_2/biases:0 with shape (16,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f303815a208>"
2018-04-20 09:30:57,288 (tf_logging.py:160) Level 1: "Created variable target_q/fully_connected/weights:0 with shape (576, 128) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f30381582f0>"
2018-04-20 09:30:57,292 (tf_logging.py:160) Level 1: "Created variable target_q/fully_connected/biases:0 with shape (128,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f303815a5f8>"
2018-04-20 09:30:57,299 (tf_logging.py:160) Level 1: "Created variable target_q/fully_connected_1/weights:0 with shape (128, 5) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f30381582f0>"
2018-04-20 09:30:57,302 (tf_logging.py:160) Level 1: "Created variable target_q/fully_connected_1/biases:0 with shape (5,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f303815a5f8>"
2018-04-20 09:30:57,329 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/value'"
2018-04-20 09:30:57,330 (tf_logging.py:160) Level 1: "  in  --> gradients/Fill:0"
2018-04-20 09:30:57,330 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/value_grad/tuple/control_dependency:0, gradients/mean_squared_error/value_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,336 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/div'"
2018-04-20 09:30:57,336 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/value_grad/tuple/control_dependency:0"
2018-04-20 09:30:57,336 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/div_grad/tuple/control_dependency:0, gradients/mean_squared_error/div_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,338 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/Sum_1'"
2018-04-20 09:30:57,338 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/div_grad/tuple/control_dependency:0"
2018-04-20 09:30:57,338 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/Sum_1_grad/Tile:0"
2018-04-20 09:30:57,341 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/Select'"
2018-04-20 09:30:57,342 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/div_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,342 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/Select_grad/tuple/control_dependency:0, gradients/mean_squared_error/Select_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,344 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/Sum'"
2018-04-20 09:30:57,344 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/Sum_1_grad/Tile:0"
2018-04-20 09:30:57,344 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/Sum_grad/Tile:0"
2018-04-20 09:30:57,351 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/Mul'"
2018-04-20 09:30:57,351 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/Sum_grad/Tile:0"
2018-04-20 09:30:57,351 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/Mul_grad/tuple/control_dependency:0, gradients/mean_squared_error/Mul_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,353 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/num_present'"
2018-04-20 09:30:57,354 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/Select_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,354 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/num_present_grad/Tile:0"
2018-04-20 09:30:57,359 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/num_present/broadcast_weights'"
2018-04-20 09:30:57,359 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/num_present_grad/Tile:0"
2018-04-20 09:30:57,359 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/num_present/broadcast_weights_grad/tuple/control_dependency:0, gradients/mean_squared_error/num_present/broadcast_weights_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,361 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/num_present/broadcast_weights/ones_like'"
2018-04-20 09:30:57,361 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/num_present/broadcast_weights_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,361 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/num_present/broadcast_weights/ones_like_grad/Sum:0"
2018-04-20 09:30:57,367 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/SquaredDifference'"
2018-04-20 09:30:57,367 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/Mul_grad/tuple/control_dependency:0"
2018-04-20 09:30:57,367 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/SquaredDifference_grad/tuple/control_dependency:0, gradients/mean_squared_error/SquaredDifference_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,374 (tf_logging.py:160) Level 1: "Gradient for 'Sum'"
2018-04-20 09:30:57,374 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/SquaredDifference_grad/tuple/control_dependency:0"
2018-04-20 09:30:57,374 (tf_logging.py:160) Level 1: "  out --> gradients/Sum_grad/Tile:0"
2018-04-20 09:30:57,379 (tf_logging.py:160) Level 1: "Gradient for 'mul'"
2018-04-20 09:30:57,380 (tf_logging.py:160) Level 1: "  in  --> gradients/Sum_grad/Tile:0"
2018-04-20 09:30:57,380 (tf_logging.py:160) Level 1: "  out --> gradients/mul_grad/tuple/control_dependency:0, gradients/mul_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,381 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected_1/BiasAdd'"
2018-04-20 09:30:57,382 (tf_logging.py:160) Level 1: "  in  --> gradients/mul_grad/tuple/control_dependency:0"
2018-04-20 09:30:57,382 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency:0, gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,384 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected_1/MatMul'"
2018-04-20 09:30:57,384 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 09:30:57,384 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency:0, gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,384 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected_1/biases/read'"
2018-04-20 09:30:57,385 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,385 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,385 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/Relu'"
2018-04-20 09:30:57,385 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency:0"
2018-04-20 09:30:57,385 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/Relu_grad/ReluGrad:0"
2018-04-20 09:30:57,386 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected_1/weights/read'"
2018-04-20 09:30:57,386 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,386 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,388 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/BiasAdd'"
2018-04-20 09:30:57,388 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/Relu_grad/ReluGrad:0"
2018-04-20 09:30:57,388 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency:0, gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,390 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/MatMul'"
2018-04-20 09:30:57,390 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 09:30:57,390 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/MatMul_grad/tuple/control_dependency:0, gradients/q/fully_connected/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,391 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/biases/read'"
2018-04-20 09:30:57,391 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,391 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,392 (tf_logging.py:160) Level 1: "Gradient for 'q/Flatten/flatten/Reshape'"
2018-04-20 09:30:57,392 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/MatMul_grad/tuple/control_dependency:0"
2018-04-20 09:30:57,392 (tf_logging.py:160) Level 1: "  out --> gradients/q/Flatten/flatten/Reshape_grad/Reshape:0"
2018-04-20 09:30:57,392 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/weights/read'"
2018-04-20 09:30:57,393 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,393 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,393 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/Relu'"
2018-04-20 09:30:57,393 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Flatten/flatten/Reshape_grad/Reshape:0"
2018-04-20 09:30:57,394 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/Relu_grad/ReluGrad:0"
2018-04-20 09:30:57,395 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/BiasAdd'"
2018-04-20 09:30:57,395 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/Relu_grad/ReluGrad:0"
2018-04-20 09:30:57,395 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency:0, gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,399 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/Conv2D'"
2018-04-20 09:30:57,400 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 09:30:57,400 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency:0, gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,400 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/biases/read'"
2018-04-20 09:30:57,400 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,400 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,401 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/Relu'"
2018-04-20 09:30:57,401 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency:0"
2018-04-20 09:30:57,401 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/Relu_grad/ReluGrad:0"
2018-04-20 09:30:57,401 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/weights/read'"
2018-04-20 09:30:57,401 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,401 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,403 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/BiasAdd'"
2018-04-20 09:30:57,403 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/Relu_grad/ReluGrad:0"
2018-04-20 09:30:57,403 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency:0, gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,407 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/Conv2D'"
2018-04-20 09:30:57,407 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 09:30:57,408 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency:0, gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,408 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/biases/read'"
2018-04-20 09:30:57,408 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,408 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,409 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/Relu'"
2018-04-20 09:30:57,409 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency:0"
2018-04-20 09:30:57,409 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/Relu_grad/ReluGrad:0"
2018-04-20 09:30:57,409 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/weights/read'"
2018-04-20 09:30:57,409 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,409 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,411 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/BiasAdd'"
2018-04-20 09:30:57,411 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv/Relu_grad/ReluGrad:0"
2018-04-20 09:30:57,411 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/BiasAdd_grad/tuple/control_dependency:0, gradients/q/Conv/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,415 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/Conv2D'"
2018-04-20 09:30:57,416 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 09:30:57,416 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/Conv2D_grad/tuple/control_dependency:0, gradients/q/Conv/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,416 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/biases/read'"
2018-04-20 09:30:57,416 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,416 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,416 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/weights/read'"
2018-04-20 09:30:57,416 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,417 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,502 (tf_logging.py:126) WARNING: "From /home/syedeqbal/.local/lib/python3.5/site-packages/tensorflow/python/ops/clip_ops.py:113: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead"
2018-04-20 09:34:44,397 (dqn_main.py:61) DEBUG: ">>>> RUNNING data_file=7_17.npy,reuse_weights=None,test=False<<<<"
2018-04-20 09:34:44,847 (tf_logging.py:160) Level 1: "Registering Batch (<function _BatchGrad at 0x7efe9fc75378>) in gradient."
2018-04-20 09:34:44,848 (tf_logging.py:160) Level 1: "Registering Unbatch (<function _UnbatchGrad at 0x7efe9fc75e18>) in gradient."
2018-04-20 09:34:44,853 (tf_logging.py:160) Level 1: "Registering ZeroInitializer (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:44,870 (tf_logging.py:160) Level 1: "Registering SparseFeatureCross (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:44,872 (tf_logging.py:160) Level 1: "Registering SparseFeatureCrossV2 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:44,875 (tf_logging.py:160) Level 1: "Registering SparseFeatureCross (None) in gradient."
2018-04-20 09:34:44,876 (tf_logging.py:160) Level 1: "Registering SparseFeatureCrossV2 (None) in gradient."
2018-04-20 09:34:44,880 (tf_logging.py:160) Level 1: "Registering GDNLowerBound (<function GDN._lower_bound_grad at 0x7efe9c0c16a8>) in gradient."
2018-04-20 09:34:44,918 (tf_logging.py:160) Level 1: "Registering ObtainNext (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:44,935 (tf_logging.py:160) Level 1: "Registering hparams ((<class 'tensorflow.contrib.training.python.training.hparam_pb2.HParamDef'>, <function HParams.to_proto at 0x7efe97694620>, <function HParams.from_proto at 0x7efe976946a8>)) in proto functions."
2018-04-20 09:34:44,944 (tf_logging.py:160) Level 1: "Registering GRUBlockCell (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:44,947 (tf_logging.py:160) Level 1: "Registering GRUBlockCellGrad (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:44,950 (tf_logging.py:160) Level 1: "Registering GRUBlockCell (<function _GRUBlockCellGrad at 0x7efe9416fb70>) in gradient."
2018-04-20 09:34:44,952 (tf_logging.py:160) Level 1: "Registering BlockLSTM (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:44,954 (tf_logging.py:160) Level 1: "Registering BlockLSTMGrad (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:44,956 (tf_logging.py:160) Level 1: "Registering LSTMBlockCell (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:44,958 (tf_logging.py:160) Level 1: "Registering LSTMBlockCellGrad (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:44,961 (tf_logging.py:160) Level 1: "Registering LSTMBlockCell (<function _LSTMBlockCellGrad at 0x7efe94138d90>) in gradient."
2018-04-20 09:34:44,962 (tf_logging.py:160) Level 1: "Registering BlockLSTM (<function _BlockLSTMGrad at 0x7efe94138e18>) in gradient."
2018-04-20 09:34:44,968 (tf_logging.py:160) Level 1: "Registering KMC2ChainInitialization (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:44,970 (tf_logging.py:160) Level 1: "Registering KmeansPlusPlusInitialization (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:44,972 (tf_logging.py:160) Level 1: "Registering NearestNeighbors (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:44,976 (tf_logging.py:160) Level 1: "Registering MaskedMatmul (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:44,978 (tf_logging.py:160) Level 1: "Registering WALSComputePartialLhsAndRhs (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:44,995 (tf_logging.py:160) Level 1: "Registering ConfigureDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:44,997 (tf_logging.py:160) Level 1: "Registering CrossReplicaSum (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,002 (tf_logging.py:160) Level 1: "Registering InfeedDequeue (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,003 (tf_logging.py:160) Level 1: "Registering InfeedDequeueTuple (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,004 (tf_logging.py:160) Level 1: "Registering InfeedEnqueue (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,005 (tf_logging.py:160) Level 1: "Registering InfeedEnqueueTuple (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,005 (tf_logging.py:160) Level 1: "Registering OutfeedDequeue (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,006 (tf_logging.py:160) Level 1: "Registering OutfeedDequeueTuple (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,007 (tf_logging.py:160) Level 1: "Registering OutfeedEnqueue (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,007 (tf_logging.py:160) Level 1: "Registering OutfeedEnqueueTuple (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,008 (tf_logging.py:160) Level 1: "Registering ShutdownDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,009 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingActivations (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,010 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingEnqueueSparseBatch (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,010 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingLoadAdagradParameters (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,011 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingLoadGradientDescentParameters (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,012 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingReceiveActivations (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,013 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingRetrieveAdagradParameters (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,014 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingRetrieveGradientDescentParameters (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,015 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingSendGradients (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,016 (tf_logging.py:160) Level 1: "Registering TPUReplicate (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,017 (tf_logging.py:160) Level 1: "Registering TPUReplicateMetadata (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,018 (tf_logging.py:160) Level 1: "Registering TPUReplicatedInput (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,019 (tf_logging.py:160) Level 1: "Registering TPUReplicatedOutput (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,026 (tf_logging.py:160) Level 1: "Registering _ConfigureDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,027 (tf_logging.py:160) Level 1: "Registering _WaitForDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,027 (tf_logging.py:160) Level 1: "Registering _SetGlobalTPUArray (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,028 (tf_logging.py:160) Level 1: "Registering _ShutdownDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,029 (tf_logging.py:160) Level 1: "Registering _InitializeHostForDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,029 (tf_logging.py:160) Level 1: "Registering _DisconnectHostFromDistributedTPUSystem (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,031 (tf_logging.py:160) Level 1: "Registering CrossReplicaSum (<function _cross_replica_sum_grad at 0x7efe56846400>) in gradient."
2018-04-20 09:34:45,035 (tf_logging.py:160) Level 1: "Registering CloseSummaryWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,036 (tf_logging.py:160) Level 1: "Registering CreateSummaryDbWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,037 (tf_logging.py:160) Level 1: "Registering CreateSummaryFileWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,037 (tf_logging.py:160) Level 1: "Registering FlushSummaryWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,038 (tf_logging.py:160) Level 1: "Registering ImportEvent (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,038 (tf_logging.py:160) Level 1: "Registering SummaryWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,039 (tf_logging.py:160) Level 1: "Registering WriteAudioSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,039 (tf_logging.py:160) Level 1: "Registering WriteGraphSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,040 (tf_logging.py:160) Level 1: "Registering WriteHistogramSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,041 (tf_logging.py:160) Level 1: "Registering WriteImageSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,041 (tf_logging.py:160) Level 1: "Registering WriteScalarSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,042 (tf_logging.py:160) Level 1: "Registering WriteSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,060 (tf_logging.py:160) Level 1: "Registering BigQueryReader (None) in gradient."
2018-04-20 09:34:45,062 (tf_logging.py:160) Level 1: "Registering RangeDecode (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,063 (tf_logging.py:160) Level 1: "Registering RangeEncode (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,097 (tf_logging.py:160) Level 1: "Registering CudnnRNN (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,098 (tf_logging.py:160) Level 1: "Registering CudnnRNNBackprop (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,098 (tf_logging.py:160) Level 1: "Registering CudnnRNNCanonicalToParams (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,099 (tf_logging.py:160) Level 1: "Registering CudnnRNNParamsSize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,099 (tf_logging.py:160) Level 1: "Registering CudnnRNNParamsToCanonical (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,105 (tf_logging.py:160) Level 1: "Registering CudnnRNN (<function _cudnn_rnn_backward at 0x7efe561486a8>) in gradient."
2018-04-20 09:34:45,105 (tf_logging.py:160) Level 1: "Registering CudnnRNNParamsSize (<function call_cpp_shape_fn at 0x7eff0b3d3840>) in shape functions."
2018-04-20 09:34:45,105 (tf_logging.py:160) Level 1: "Registering CudnnRNNParamsToCanonical (<function call_cpp_shape_fn at 0x7eff0b3d3840>) in shape functions."
2018-04-20 09:34:45,106 (tf_logging.py:160) Level 1: "Registering CudnnRNNCanonicalToParams (<function call_cpp_shape_fn at 0x7eff0b3d3840>) in shape functions."
2018-04-20 09:34:45,106 (tf_logging.py:160) Level 1: "Registering CudnnRNN (<function call_cpp_shape_fn at 0x7eff0b3d3840>) in shape functions."
2018-04-20 09:34:45,106 (tf_logging.py:160) Level 1: "Registering CudnnRNNBackprop (<function call_cpp_shape_fn at 0x7eff0b3d3840>) in shape functions."
2018-04-20 09:34:45,132 (tf_logging.py:160) Level 1: "Registering AdjustHsvInYiq (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,134 (tf_logging.py:160) Level 1: "Registering BipartiteMatch (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,135 (tf_logging.py:160) Level 1: "Registering ImageConnectedComponents (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,135 (tf_logging.py:160) Level 1: "Registering ImageProjectiveTransform (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,137 (tf_logging.py:160) Level 1: "Registering ImageConnectedComponents (<function call_cpp_shape_fn at 0x7eff0b3d3840>) in shape functions."
2018-04-20 09:34:45,138 (tf_logging.py:160) Level 1: "Registering ImageProjectiveTransform (<function call_cpp_shape_fn at 0x7eff0b3d3840>) in shape functions."
2018-04-20 09:34:45,138 (tf_logging.py:160) Level 1: "Registering ImageProjectiveTransform (<function _image_projective_transform_grad at 0x7efe55a68b70>) in gradient."
2018-04-20 09:34:45,138 (tf_logging.py:160) Level 1: "Registering BipartiteMatch (None) in gradient."
2018-04-20 09:34:45,138 (tf_logging.py:160) Level 1: "Registering ImageConnectedComponents (None) in gradient."
2018-04-20 09:34:45,139 (tf_logging.py:160) Level 1: "Registering SingleImageRandomDotStereograms (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,144 (tf_logging.py:160) Level 1: "Registering SingleImageRandomDotStereograms (None) in gradient."
2018-04-20 09:34:45,171 (tf_logging.py:160) Level 1: "Registering BytesInUse (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,172 (tf_logging.py:160) Level 1: "Registering BytesLimit (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,172 (tf_logging.py:160) Level 1: "Registering MaxBytesInUse (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,178 (tf_logging.py:160) Level 1: "Registering NcclAllReduce (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,178 (tf_logging.py:160) Level 1: "Registering NcclBroadcast (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,179 (tf_logging.py:160) Level 1: "Registering NcclReduce (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,181 (tf_logging.py:160) Level 1: "Registering _NcclReduceSend (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,182 (tf_logging.py:160) Level 1: "Registering _NcclReduceRecv (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,182 (tf_logging.py:160) Level 1: "Registering _NcclBroadcastSend (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,182 (tf_logging.py:160) Level 1: "Registering _NcclBroadcastRecv (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,183 (tf_logging.py:160) Level 1: "Registering NcclAllReduce (<function _all_sum_grad at 0x7efe5511b950>) in gradient."
2018-04-20 09:34:45,183 (tf_logging.py:160) Level 1: "Registering NcclReduce (<function _reduce_sum_grad at 0x7efe5511bbf8>) in gradient."
2018-04-20 09:34:45,183 (tf_logging.py:160) Level 1: "Registering NcclBroadcast (<function _broadcast_grad at 0x7efe5511bd90>) in gradient."
2018-04-20 09:34:45,184 (tf_logging.py:160) Level 1: "Registering PeriodicResample (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,190 (tf_logging.py:160) Level 1: "Registering FoldFusedBatchNormGrad (<function _FoldFusedBatchNormGrad at 0x7efe54e60048>) in gradient."
2018-04-20 09:34:45,193 (tf_logging.py:160) Level 1: "Registering Resampler (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,194 (tf_logging.py:160) Level 1: "Registering ResamplerGrad (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,196 (tf_logging.py:160) Level 1: "Registering Resampler (<function _resampler_grad at 0x7efe54b8dc80>) in gradient."
2018-04-20 09:34:45,197 (tf_logging.py:160) Level 1: "Registering ResamplerGrad (None) in gradient."
2018-04-20 09:34:45,201 (tf_logging.py:160) Level 1: "Registering GatherTree (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,209 (tf_logging.py:160) Level 1: "Registering StatelessRandomNormal (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,209 (tf_logging.py:160) Level 1: "Registering StatelessRandomUniform (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,210 (tf_logging.py:160) Level 1: "Registering StatelessTruncatedNormal (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,210 (tf_logging.py:160) Level 1: "Registering StatelessRandomNormal (None) in gradient."
2018-04-20 09:34:45,210 (tf_logging.py:160) Level 1: "Registering StatelessRandomUniform (None) in gradient."
2018-04-20 09:34:45,210 (tf_logging.py:160) Level 1: "Registering StatelessTruncatedNormal (None) in gradient."
2018-04-20 09:34:45,215 (tf_logging.py:160) Level 1: "Registering ReinterpretStringToFloat (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,217 (tf_logging.py:160) Level 1: "Registering ScatterAddNdim (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,224 (tf_logging.py:160) Level 1: "Registering CreateTreeVariable (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,224 (tf_logging.py:160) Level 1: "Registering DecisionTreeResourceHandleOp (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,225 (tf_logging.py:160) Level 1: "Registering FeatureUsageCounts (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,225 (tf_logging.py:160) Level 1: "Registering TraverseTreeV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,225 (tf_logging.py:160) Level 1: "Registering TreeDeserialize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,226 (tf_logging.py:160) Level 1: "Registering TreeIsInitializedOp (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,226 (tf_logging.py:160) Level 1: "Registering TreePredictionsV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,227 (tf_logging.py:160) Level 1: "Registering TreeSerialize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,227 (tf_logging.py:160) Level 1: "Registering TreeSize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,228 (tf_logging.py:160) Level 1: "Registering UpdateModelV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,231 (tf_logging.py:160) Level 1: "Registering TreeVariable (None) in gradient."
2018-04-20 09:34:45,231 (tf_logging.py:160) Level 1: "Registering TreeSerialize (None) in gradient."
2018-04-20 09:34:45,232 (tf_logging.py:160) Level 1: "Registering TreeDeserialize (None) in gradient."
2018-04-20 09:34:45,232 (tf_logging.py:160) Level 1: "Registering TreeSize (None) in gradient."
2018-04-20 09:34:45,232 (tf_logging.py:160) Level 1: "Registering TreePredictionsV4 (None) in gradient."
2018-04-20 09:34:45,232 (tf_logging.py:160) Level 1: "Registering FeatureUsageCounts (None) in gradient."
2018-04-20 09:34:45,233 (tf_logging.py:160) Level 1: "Registering CreateFertileStatsVariable (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,234 (tf_logging.py:160) Level 1: "Registering FertileStatsDeserialize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,234 (tf_logging.py:160) Level 1: "Registering FertileStatsIsInitializedOp (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,234 (tf_logging.py:160) Level 1: "Registering FertileStatsResourceHandleOp (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,235 (tf_logging.py:160) Level 1: "Registering FertileStatsSerialize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,235 (tf_logging.py:160) Level 1: "Registering FinalizeTree (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,235 (tf_logging.py:160) Level 1: "Registering GrowTreeV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,235 (tf_logging.py:160) Level 1: "Registering ProcessInputV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,238 (tf_logging.py:160) Level 1: "Registering FertileStatsVariable (None) in gradient."
2018-04-20 09:34:45,239 (tf_logging.py:160) Level 1: "Registering FertileStatsSerialize (None) in gradient."
2018-04-20 09:34:45,239 (tf_logging.py:160) Level 1: "Registering FertileStatsDeserialize (None) in gradient."
2018-04-20 09:34:45,239 (tf_logging.py:160) Level 1: "Registering GrowTreeV4 (None) in gradient."
2018-04-20 09:34:45,240 (tf_logging.py:160) Level 1: "Registering ProcessInputV4 (None) in gradient."
2018-04-20 09:34:45,240 (tf_logging.py:160) Level 1: "Registering FinalizeTree (None) in gradient."
2018-04-20 09:34:45,255 (tf_logging.py:160) Level 1: "Registering FunctionBufferingResource (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,255 (tf_logging.py:160) Level 1: "Registering FunctionBufferingResourceGetNext (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,263 (tf_logging.py:160) Level 1: "Registering RemoteFusedGraphExecute (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7eff0b3d3950>) in default shape functions."
2018-04-20 09:34:45,264 (tf_logging.py:160) Level 1: "Registering RemoteFusedGraphExecute (None) in gradient."
2018-04-20 09:34:45,272 (tf_logging.py:160) Level 1: "Created variable q/Conv/weights:0 with shape (1, 1, 2, 8) and init <function variance_scaling_initializer.<locals>._initializer at 0x7efe9c0b7510>"
2018-04-20 09:34:45,276 (tf_logging.py:160) Level 1: "Created variable q/Conv/biases:0 with shape (8,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7efe9c0bb208>"
2018-04-20 09:34:45,283 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/weights:0 with shape (3, 3, 8, 12) and init <function variance_scaling_initializer.<locals>._initializer at 0x7efe9c0b7510>"
2018-04-20 09:34:45,286 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/biases:0 with shape (12,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7efe9c0bb208>"
2018-04-20 09:34:45,292 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/weights:0 with shape (3, 3, 12, 16) and init <function variance_scaling_initializer.<locals>._initializer at 0x7efe9c0b7510>"
2018-04-20 09:34:45,294 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/biases:0 with shape (16,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7efe9c0bb208>"
2018-04-20 09:34:45,304 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/weights:0 with shape (576, 128) and init <function variance_scaling_initializer.<locals>._initializer at 0x7efe9c0c12f0>"
2018-04-20 09:34:45,306 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/biases:0 with shape (128,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7efe9c0bb5f8>"
2018-04-20 09:34:45,312 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/weights:0 with shape (128, 5) and init <function variance_scaling_initializer.<locals>._initializer at 0x7efe9c0c12f0>"
2018-04-20 09:34:45,315 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/biases:0 with shape (5,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7efe9c0bb5f8>"
2018-04-20 09:34:45,321 (tf_logging.py:160) Level 1: "Created variable target_q/Conv/weights:0 with shape (1, 1, 2, 8) and init <function variance_scaling_initializer.<locals>._initializer at 0x7efe9c0b7510>"
2018-04-20 09:34:45,324 (tf_logging.py:160) Level 1: "Created variable target_q/Conv/biases:0 with shape (8,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7efe9c0bb208>"
2018-04-20 09:34:45,331 (tf_logging.py:160) Level 1: "Created variable target_q/Conv_1/weights:0 with shape (3, 3, 8, 12) and init <function variance_scaling_initializer.<locals>._initializer at 0x7efe9c0b7510>"
2018-04-20 09:34:45,334 (tf_logging.py:160) Level 1: "Created variable target_q/Conv_1/biases:0 with shape (12,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7efe9c0bb208>"
2018-04-20 09:34:45,341 (tf_logging.py:160) Level 1: "Created variable target_q/Conv_2/weights:0 with shape (3, 3, 12, 16) and init <function variance_scaling_initializer.<locals>._initializer at 0x7efe9c0b7510>"
2018-04-20 09:34:45,345 (tf_logging.py:160) Level 1: "Created variable target_q/Conv_2/biases:0 with shape (16,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7efe9c0bb208>"
2018-04-20 09:34:45,355 (tf_logging.py:160) Level 1: "Created variable target_q/fully_connected/weights:0 with shape (576, 128) and init <function variance_scaling_initializer.<locals>._initializer at 0x7efe9c0c12f0>"
2018-04-20 09:34:45,359 (tf_logging.py:160) Level 1: "Created variable target_q/fully_connected/biases:0 with shape (128,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7efe9c0bb5f8>"
2018-04-20 09:34:45,365 (tf_logging.py:160) Level 1: "Created variable target_q/fully_connected_1/weights:0 with shape (128, 5) and init <function variance_scaling_initializer.<locals>._initializer at 0x7efe9c0c12f0>"
2018-04-20 09:34:45,368 (tf_logging.py:160) Level 1: "Created variable target_q/fully_connected_1/biases:0 with shape (5,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7efe9c0bb5f8>"
2018-04-20 09:34:45,393 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/value'"
2018-04-20 09:34:45,393 (tf_logging.py:160) Level 1: "  in  --> gradients/Fill:0"
2018-04-20 09:34:45,394 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/value_grad/tuple/control_dependency:0, gradients/mean_squared_error/value_grad/tuple/control_dependency_1:0"
2018-04-20 09:34:45,399 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/div'"
2018-04-20 09:34:45,400 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/value_grad/tuple/control_dependency:0"
2018-04-20 09:34:45,400 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/div_grad/tuple/control_dependency:0, gradients/mean_squared_error/div_grad/tuple/control_dependency_1:0"
2018-04-20 09:34:45,402 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/Sum_1'"
2018-04-20 09:34:45,402 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/div_grad/tuple/control_dependency:0"
2018-04-20 09:34:45,402 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/Sum_1_grad/Tile:0"
2018-04-20 09:34:45,405 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/Select'"
2018-04-20 09:34:45,405 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/div_grad/tuple/control_dependency_1:0"
2018-04-20 09:34:45,405 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/Select_grad/tuple/control_dependency:0, gradients/mean_squared_error/Select_grad/tuple/control_dependency_1:0"
2018-04-20 09:34:45,407 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/Sum'"
2018-04-20 09:34:45,407 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/Sum_1_grad/Tile:0"
2018-04-20 09:34:45,408 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/Sum_grad/Tile:0"
2018-04-20 09:34:45,413 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/Mul'"
2018-04-20 09:34:45,413 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/Sum_grad/Tile:0"
2018-04-20 09:34:45,414 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/Mul_grad/tuple/control_dependency:0, gradients/mean_squared_error/Mul_grad/tuple/control_dependency_1:0"
2018-04-20 09:34:45,416 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/num_present'"
2018-04-20 09:34:45,416 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/Select_grad/tuple/control_dependency_1:0"
2018-04-20 09:34:45,416 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/num_present_grad/Tile:0"
2018-04-20 09:34:45,421 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/num_present/broadcast_weights'"
2018-04-20 09:34:45,421 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/num_present_grad/Tile:0"
2018-04-20 09:34:45,421 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/num_present/broadcast_weights_grad/tuple/control_dependency:0, gradients/mean_squared_error/num_present/broadcast_weights_grad/tuple/control_dependency_1:0"
2018-04-20 09:34:45,422 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/num_present/broadcast_weights/ones_like'"
2018-04-20 09:34:45,422 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/num_present/broadcast_weights_grad/tuple/control_dependency_1:0"
2018-04-20 09:34:45,422 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/num_present/broadcast_weights/ones_like_grad/Sum:0"
2018-04-20 09:34:45,427 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/SquaredDifference'"
2018-04-20 09:34:45,428 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/Mul_grad/tuple/control_dependency:0"
2018-04-20 09:34:45,428 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/SquaredDifference_grad/tuple/control_dependency:0, gradients/mean_squared_error/SquaredDifference_grad/tuple/control_dependency_1:0"
2018-04-20 09:34:45,434 (tf_logging.py:160) Level 1: "Gradient for 'Sum'"
2018-04-20 09:34:45,434 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/SquaredDifference_grad/tuple/control_dependency:0"
2018-04-20 09:34:45,434 (tf_logging.py:160) Level 1: "  out --> gradients/Sum_grad/Tile:0"
2018-04-20 09:34:45,439 (tf_logging.py:160) Level 1: "Gradient for 'mul'"
2018-04-20 09:34:45,439 (tf_logging.py:160) Level 1: "  in  --> gradients/Sum_grad/Tile:0"
2018-04-20 09:34:45,439 (tf_logging.py:160) Level 1: "  out --> gradients/mul_grad/tuple/control_dependency:0, gradients/mul_grad/tuple/control_dependency_1:0"
2018-04-20 09:34:45,441 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected_1/BiasAdd'"
2018-04-20 09:34:45,441 (tf_logging.py:160) Level 1: "  in  --> gradients/mul_grad/tuple/control_dependency:0"
2018-04-20 09:34:45,441 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency:0, gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:34:45,443 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected_1/MatMul'"
2018-04-20 09:34:45,443 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 09:34:45,443 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency:0, gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 09:34:45,444 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected_1/biases/read'"
2018-04-20 09:34:45,444 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:34:45,444 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:34:45,445 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/Relu'"
2018-04-20 09:34:45,445 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency:0"
2018-04-20 09:34:45,445 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/Relu_grad/ReluGrad:0"
2018-04-20 09:34:45,445 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected_1/weights/read'"
2018-04-20 09:34:45,445 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 09:34:45,445 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 09:34:45,447 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/BiasAdd'"
2018-04-20 09:34:45,447 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/Relu_grad/ReluGrad:0"
2018-04-20 09:34:45,447 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency:0, gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:34:45,449 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/MatMul'"
2018-04-20 09:34:45,449 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 09:34:45,450 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/MatMul_grad/tuple/control_dependency:0, gradients/q/fully_connected/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 09:34:45,450 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/biases/read'"
2018-04-20 09:34:45,450 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:34:45,450 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:34:45,451 (tf_logging.py:160) Level 1: "Gradient for 'q/Flatten/flatten/Reshape'"
2018-04-20 09:34:45,451 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/MatMul_grad/tuple/control_dependency:0"
2018-04-20 09:34:45,452 (tf_logging.py:160) Level 1: "  out --> gradients/q/Flatten/flatten/Reshape_grad/Reshape:0"
2018-04-20 09:34:45,452 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/weights/read'"
2018-04-20 09:34:45,452 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 09:34:45,452 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 09:34:45,453 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/Relu'"
2018-04-20 09:34:45,453 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Flatten/flatten/Reshape_grad/Reshape:0"
2018-04-20 09:34:45,453 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/Relu_grad/ReluGrad:0"
2018-04-20 09:34:45,455 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/BiasAdd'"
2018-04-20 09:34:45,455 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/Relu_grad/ReluGrad:0"
2018-04-20 09:34:45,455 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency:0, gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:34:45,458 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/Conv2D'"
2018-04-20 09:34:45,458 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 09:34:45,459 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency:0, gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:34:45,459 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/biases/read'"
2018-04-20 09:34:45,459 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:34:45,459 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:34:45,460 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/Relu'"
2018-04-20 09:34:45,460 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency:0"
2018-04-20 09:34:45,460 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/Relu_grad/ReluGrad:0"
2018-04-20 09:34:45,460 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/weights/read'"
2018-04-20 09:34:45,460 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:34:45,460 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:34:45,462 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/BiasAdd'"
2018-04-20 09:34:45,462 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/Relu_grad/ReluGrad:0"
2018-04-20 09:34:45,462 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency:0, gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:34:45,470 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/Conv2D'"
2018-04-20 09:34:45,471 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 09:34:45,471 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency:0, gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:34:45,471 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/biases/read'"
2018-04-20 09:34:45,472 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:34:45,472 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:34:45,473 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/Relu'"
2018-04-20 09:34:45,473 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency:0"
2018-04-20 09:34:45,473 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/Relu_grad/ReluGrad:0"
2018-04-20 09:34:45,474 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/weights/read'"
2018-04-20 09:34:45,474 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:34:45,474 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:34:45,477 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/BiasAdd'"
2018-04-20 09:34:45,477 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv/Relu_grad/ReluGrad:0"
2018-04-20 09:34:45,477 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/BiasAdd_grad/tuple/control_dependency:0, gradients/q/Conv/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:34:45,482 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/Conv2D'"
2018-04-20 09:34:45,482 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 09:34:45,483 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/Conv2D_grad/tuple/control_dependency:0, gradients/q/Conv/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:34:45,483 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/biases/read'"
2018-04-20 09:34:45,484 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:34:45,484 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:34:45,484 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/weights/read'"
2018-04-20 09:34:45,485 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:34:45,485 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:34:45,601 (tf_logging.py:126) WARNING: "From /home/syedeqbal/.local/lib/python3.5/site-packages/tensorflow/python/ops/clip_ops.py:113: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead"
2018-04-20 09:34:45,638 (tf_logging.py:160) Level 1: "Created variable q/Conv/weights/Adam:0 with shape (1, 1, 2, 8) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7efe4dc52358>"
2018-04-20 09:34:45,641 (tf_logging.py:160) Level 1: "Created variable q/Conv/weights/Adam_1:0 with shape (1, 1, 2, 8) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7efe4dc52358>"
2018-04-20 09:34:45,644 (tf_logging.py:160) Level 1: "Created variable q/Conv/biases/Adam:0 with shape (8,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7efe4dc52358>"
2018-04-20 09:34:45,647 (tf_logging.py:160) Level 1: "Created variable q/Conv/biases/Adam_1:0 with shape (8,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7efe4dc52358>"
2018-04-20 09:34:45,650 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/weights/Adam:0 with shape (3, 3, 8, 12) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7efe4dc52358>"
2018-04-20 09:34:45,654 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/weights/Adam_1:0 with shape (3, 3, 8, 12) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7efe4dc52358>"
2018-04-20 09:34:45,657 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/biases/Adam:0 with shape (12,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7efe4dc52358>"
2018-04-20 09:34:45,660 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/biases/Adam_1:0 with shape (12,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7efe4dc52358>"
2018-04-20 09:34:45,663 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/weights/Adam:0 with shape (3, 3, 12, 16) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7efe4dc52358>"
2018-04-20 09:34:45,666 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/weights/Adam_1:0 with shape (3, 3, 12, 16) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7efe4dc7feb8>"
2018-04-20 09:34:45,670 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/biases/Adam:0 with shape (16,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7efe4dc7feb8>"
2018-04-20 09:34:45,673 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/biases/Adam_1:0 with shape (16,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7efe4dc7feb8>"
2018-04-20 09:34:45,676 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/weights/Adam:0 with shape (576, 128) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7efe4dc7feb8>"
2018-04-20 09:34:45,679 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/weights/Adam_1:0 with shape (576, 128) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7efe4dc7feb8>"
2018-04-20 09:34:45,682 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/biases/Adam:0 with shape (128,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7efe4dc7feb8>"
2018-04-20 09:34:45,692 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/biases/Adam_1:0 with shape (128,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7efe4dc7feb8>"
2018-04-20 09:34:45,697 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/weights/Adam:0 with shape (128, 5) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7efe4dc7feb8>"
2018-04-20 09:34:45,702 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/weights/Adam_1:0 with shape (128, 5) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7efe4dc7feb8>"
2018-04-20 09:34:45,708 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/biases/Adam:0 with shape (5,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7efe4dc7feb8>"
2018-04-20 09:34:45,713 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/biases/Adam_1:0 with shape (5,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7efe4dc7feb8>"
2018-04-20 09:34:45,891 (dqn_agent.py:161) DEBUG: "var_name: q/Conv/weights:0, var_value [[[[-0.5065052   0.51942587 -0.59897566 -0.28246     0.4392544
    -0.16779715 -0.21814543 -0.69820213]
   [ 0.68456256 -0.51737595 -0.13999772 -0.3475432  -0.3713318
    -0.36173075 -0.5888333  -0.13174593]]]]: "
2018-04-20 09:34:45,898 (dqn_agent.py:161) DEBUG: "var_name: q/Conv/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 09:34:45,910 (dqn_agent.py:161) DEBUG: "var_name: q/Conv_1/weights:0, var_value [[[[ 1.15084738e-01  9.05344784e-02  8.58393013e-02  1.77509964e-01
     6.06891513e-02 -1.78514704e-01 -8.70768726e-02  1.88047737e-02
    -7.61388838e-02 -1.53597310e-01 -4.81006354e-02  5.06064296e-02]
   [ 1.82275891e-01  1.67471945e-01  4.54558432e-02  3.75341177e-02
     1.59016371e-01  1.15182996e-01 -1.42512321e-01  5.06981015e-02
    -1.66003138e-01  1.49708062e-01  6.11787736e-02  1.36551142e-01]
   [ 3.91823500e-02  6.60028309e-02 -4.01660204e-02 -1.29066542e-01
     3.21386009e-02  1.16352707e-01  9.87316072e-02  1.40943766e-01
     8.69557261e-02 -1.37657657e-01  1.45227969e-01  9.38086808e-02]
   [ 6.99088275e-02  1.12624735e-01 -1.63305387e-01  3.46968919e-02
    -1.99363679e-02  1.80165499e-01  3.20716947e-02 -1.46666870e-01
    -5.01990318e-03 -1.69233680e-02  4.25749272e-02  1.47550642e-01]
   [-7.33372644e-02 -9.85057354e-02  6.73456639e-02  1.45397663e-01
     4.83483076e-02  1.56063437e-02  1.55619621e-01  7.26403594e-02
    -6.30283654e-02 -5.29495478e-02  7.30874538e-02 -2.14876235e-03]
   [ 1.27607197e-01 -1.35979623e-01  1.25893146e-01 -7.67754540e-02
     1.39980555e-01  2.83474028e-02 -8.31421018e-02  2.22646445e-02
    -6.45795614e-02  5.94750345e-02  1.79903358e-01  7.45081007e-02]
   [-8.36186185e-02 -3.46408337e-02  1.27734601e-01  1.42840356e-01
    -1.25892758e-01  4.61139232e-02  7.08087385e-02 -3.14902812e-02
    -8.33935738e-02 -1.76132172e-02 -9.40179750e-02  1.70375973e-01]
   [-2.26318091e-02  1.54261947e-01 -1.74328506e-01  1.41071588e-01
     1.70604557e-01  1.30161732e-01 -6.23068660e-02 -1.71945989e-02
    -4.04705107e-02 -1.50747940e-01  3.66477817e-02 -1.41648099e-01]]

  [[-1.09314747e-01 -1.61456764e-02  7.17388690e-02  1.18717760e-01
    -6.91071525e-02  9.04278755e-02 -1.07291773e-01 -8.06433186e-02
    -1.11393780e-01 -1.75349787e-01 -6.60184026e-03 -1.29856333e-01]
   [-1.41096458e-01 -7.28023350e-02 -2.08425522e-02  1.80151969e-01
    -1.15540057e-01  1.48467749e-01 -3.26013267e-02 -1.79077059e-01
     2.02122331e-03  5.54967076e-02 -1.24399513e-02 -2.71303654e-02]
   [ 4.72054929e-02 -1.39215693e-01  1.43141627e-01 -5.72198033e-02
    -1.40783578e-01 -7.40583688e-02 -2.07286775e-02 -9.00124311e-02
     6.75009191e-03 -1.17478058e-01 -6.50844574e-02  1.03811026e-01]
   [ 1.43658131e-01  1.27082497e-01 -1.42062664e-01  1.98172629e-02
     9.70597565e-02  1.02215379e-01 -1.58396959e-01  1.06195658e-01
    -5.26904613e-02  6.38068318e-02  6.08922094e-02  1.15099758e-01]
   [-8.01548362e-03 -1.68817639e-01 -1.06588125e-01 -3.84726524e-02
     2.19917297e-03 -1.55455053e-01 -7.28779063e-02 -1.28170416e-01
    -7.37497061e-02 -4.54047918e-02 -1.17131695e-01 -8.17541778e-03]
   [ 1.20770484e-02 -5.63667566e-02 -8.67433101e-02 -1.05056554e-01
     5.79686761e-02 -1.25893325e-01  1.30007297e-01 -3.34772170e-02
     2.43204385e-02 -2.69568115e-02 -1.76688045e-01 -5.15948385e-02]
   [-1.10039242e-01 -1.09094664e-01  3.49410474e-02  2.58871764e-02
     1.08914614e-01  6.89161122e-02  1.29074812e-01 -9.24974158e-02
     5.28159589e-02 -1.69843435e-04  8.11699033e-03 -7.69324228e-02]
   [ 1.17504865e-01 -1.70158729e-01  9.15698111e-02 -5.34759015e-02
    -1.15439244e-01  1.57874256e-01  1.67788804e-01 -1.44610256e-01
    -8.17432553e-02 -7.27074891e-02  1.42443299e-01 -7.91600645e-02]]

  [[-1.77420303e-01 -2.37468481e-02  1.58302754e-01  1.22182757e-01
    -1.01729371e-01  5.47116548e-02 -1.13397732e-01  1.44437402e-01
     1.62951976e-01 -2.09491998e-02 -1.49722874e-01  1.16285354e-01]
   [-1.37282610e-01 -1.58556849e-02  1.65785491e-01 -5.81752658e-02
    -1.23960063e-01  3.50769460e-02  1.24914944e-02 -1.28913194e-01
     5.09981811e-03  2.89600641e-02 -1.27022713e-01  1.28617406e-01]
   [ 1.68857127e-02 -1.51626706e-01  1.43795699e-01 -5.30299991e-02
     2.64239758e-02  8.02513063e-02  7.66032934e-03 -1.47117570e-01
     1.21232182e-01  1.38019949e-01  1.36439204e-01  1.72299445e-01]
   [-1.55842885e-01  1.90472305e-02  1.49322331e-01 -6.75605685e-02
     1.43982947e-01 -1.55381218e-01  1.27005607e-01 -4.67005372e-03
    -1.18270807e-01  5.93548119e-02  1.80076063e-01  1.39639527e-02]
   [ 9.06531513e-03  3.25953513e-02  1.64583027e-02 -1.04353301e-01
     1.58710241e-01  1.14731640e-01 -9.74407122e-02 -1.02213807e-01
     1.42844617e-02  9.04915631e-02  4.70439196e-02 -1.39237151e-01]
   [-1.70262635e-01 -4.96194512e-02  9.04366672e-02  1.79456294e-01
     3.83335352e-02 -1.71772361e-01  1.50101453e-01  7.78810978e-02
    -1.44695491e-01  1.77884489e-01 -8.49089473e-02 -1.18051685e-01]
   [-1.00906365e-01  8.24175775e-02  1.15483046e-01  1.40128762e-01
    -1.02541894e-02  4.21380997e-02  5.45582175e-02  1.60037696e-01
     3.40330750e-02  8.24938118e-02 -9.60426405e-02 -1.77605376e-01]
   [-1.46964610e-01 -8.76923725e-02 -5.96019700e-02  1.75252736e-01
     4.58887517e-02  1.06242746e-02  3.05578113e-03 -2.96599716e-02
     1.52468294e-01 -4.86564487e-02  1.24228865e-01  3.37116122e-02]]]


 [[[-1.79211795e-02  1.76192611e-01  1.77153945e-03 -3.93828750e-03
    -1.70213670e-01  1.71548605e-01  2.47462094e-03  5.32713681e-02
     1.29406750e-02  5.99020571e-02  1.47002667e-01  4.75997925e-02]
   [-8.93595368e-02  8.94483030e-02  1.64599359e-01 -1.07296780e-01
     1.79576576e-02  1.11405104e-01 -1.35766894e-01  1.18909001e-01
     1.51132882e-01 -8.34674835e-02  1.57548547e-01 -1.63488731e-01]
   [ 6.90662861e-03 -9.24164504e-02 -3.35253179e-02 -1.09867431e-01
     7.81056583e-02  1.13724947e-01 -1.42705202e-01  9.30275619e-02
     8.35433900e-02 -5.16433269e-02  4.60255593e-02  1.24624968e-01]
   [ 1.36229604e-01 -1.24531336e-01  1.55326068e-01  1.26503587e-01
    -1.00224741e-01  4.33207899e-02  1.36378706e-02 -2.45499611e-03
    -4.89519686e-02 -3.89294326e-03 -1.41197890e-02  1.35164917e-01]
   [-1.37865424e-01  1.52610689e-01 -2.02232152e-02  1.38165206e-01
     1.36722863e-01  5.41018993e-02  8.07501078e-02 -2.20896602e-02
     1.60670012e-01 -7.57635757e-02 -7.51208737e-02  1.39496773e-02]
   [ 1.03326678e-01  4.00359631e-02 -8.06783587e-02  1.73397869e-01
    -6.20167032e-02 -9.05527547e-02 -6.76215515e-02  6.65970445e-02
    -9.72208381e-03  1.72025651e-01 -8.22490454e-03 -1.66009232e-01]
   [ 2.81233937e-02 -7.14335665e-02  4.30795550e-02  1.81236804e-01
    -1.26882121e-01 -6.05326667e-02  1.10382676e-01  7.94595480e-02
    -1.70224071e-01  1.75908059e-01  1.74227566e-01  3.29306573e-02]
   [ 7.43140280e-02 -1.56319007e-01  1.25954390e-01 -5.68811595e-03
    -1.44271210e-01  5.62345684e-02  2.27895677e-02 -1.19531021e-01
     1.74515784e-01  1.64852619e-01  6.63862377e-02  4.30923551e-02]]

  [[-1.61484569e-01  1.83692575e-03 -3.62255871e-02  5.88123947e-02
    -9.22487825e-02 -1.43215671e-01 -1.60967171e-01  4.27317172e-02
     6.23140484e-02 -2.39082128e-02  1.78368479e-01  1.19227469e-02]
   [-4.45342064e-03 -9.35201347e-02 -6.90475181e-02 -9.37319919e-02
    -8.96788687e-02 -5.90591207e-02  9.71559286e-02 -1.12797335e-01
    -6.37715310e-02 -6.32413104e-02 -1.07720539e-01  7.94748962e-02]
   [ 3.79066914e-02 -1.71022743e-01  6.31742328e-02  1.31374896e-01
     6.65467680e-02  1.33865833e-01 -1.71934456e-01 -1.57838300e-01
    -9.22940075e-02  3.68826240e-02 -9.24402624e-02  5.59771061e-03]
   [ 2.79645175e-02  1.34376526e-01  1.27403826e-01  9.77413654e-02
    -1.78682640e-01  1.38084739e-02 -6.35732561e-02  1.39192700e-01
    -1.10247485e-01  1.14033043e-01  3.08721662e-02  7.22031295e-02]
   [ 1.51804179e-01  1.29943252e-01  1.58611864e-01 -7.30182230e-03
    -1.75404251e-01  1.10463649e-01 -1.80683449e-01  7.38049448e-02
    -9.02057886e-02 -1.31015256e-01  1.55743003e-01  1.63429528e-02]
   [-1.74949974e-01  1.81346625e-01 -8.28931630e-02  7.16936588e-02
     4.21220809e-02  7.53470361e-02 -2.76030898e-02  1.08418018e-01
     1.44511849e-01 -8.55066031e-02 -1.68486565e-01 -5.77657819e-02]
   [-1.16706155e-01  1.60558879e-01 -1.06583990e-01  1.34898216e-01
     8.00959468e-02  9.88377631e-02 -1.40862793e-01  4.67927158e-02
    -1.09771408e-01 -5.48179895e-02 -4.49934751e-02  1.23688996e-01]
   [-6.12505451e-02  1.34886593e-01 -1.35522172e-01  9.95688140e-02
    -1.60152406e-01 -7.84794912e-02  4.86523658e-02 -6.63246438e-02
    -1.54782087e-01  1.23399884e-01  9.84022021e-03  2.81123817e-03]]

  [[ 1.63985521e-01  1.05007887e-01 -1.14388101e-01  6.33540452e-02
     1.02521062e-01 -1.52022511e-01  1.43916309e-02 -6.23708144e-02
     4.67478335e-02 -1.35008663e-01  1.03650093e-02 -6.63535297e-03]
   [ 1.16324931e-01 -1.09860122e-01  8.51898491e-02 -3.20411921e-02
     1.48238152e-01 -1.33084923e-01 -8.04418623e-02  8.74477923e-02
     3.19176912e-02 -2.23328173e-02 -1.41216904e-01  3.47148329e-02]
   [ 8.26008320e-02  8.61492157e-02 -1.81418180e-01 -4.05653566e-02
    -1.27392069e-01  1.69542938e-01 -5.93472421e-02  1.31722778e-01
    -3.16179097e-02 -7.46746138e-02 -3.67768109e-03 -1.36957020e-01]
   [ 1.61119491e-01  7.15574920e-02 -8.97622108e-03  3.95019352e-02
    -8.21593031e-02  1.13881081e-01 -1.10784851e-01  3.42567265e-02
    -1.58135042e-01 -1.74070343e-01  5.92126399e-02  1.43492997e-01]
   [-1.22186556e-01  1.25486583e-01  1.79121405e-01  1.42309517e-01
    -1.76526040e-01  1.52319044e-01  1.21126920e-01 -6.33774623e-02
     5.09698987e-02  7.10683167e-02 -1.33839503e-01 -1.55689180e-01]
   [ 9.73039269e-02 -1.42143339e-01 -1.80508554e-01 -5.35972267e-02
    -3.67146730e-03  4.35398668e-02 -1.07161999e-02  7.42670596e-02
     1.11117274e-01  1.38685733e-01 -1.56088918e-01  1.64478064e-01]
   [ 1.50687039e-01  4.67911363e-03 -8.81368518e-02  1.82513624e-01
     1.45062387e-01  7.77812302e-02 -1.33082792e-01 -1.42140239e-01
     5.53249717e-02  7.68020749e-04  4.21478599e-02  9.31636393e-02]
   [-1.47334740e-01 -1.53980151e-01  1.02467835e-01  1.00924700e-01
    -1.43698752e-01  9.37018692e-02  1.60395980e-01  8.21182132e-02
    -1.64435804e-02 -3.11196297e-02  1.66809350e-01 -1.15737766e-01]]]


 [[[ 1.35665864e-01 -1.55690923e-01  8.90878737e-02 -6.12835437e-02
    -1.80697560e-01  4.93211895e-02  9.06006694e-02  4.34838980e-02
     5.32819480e-02  1.68871701e-01 -1.36037290e-01 -4.61269766e-02]
   [ 1.08789921e-01 -7.97250271e-02  6.73242509e-02 -1.56381607e-01
     8.43695700e-02  1.19805217e-01  1.72469258e-01  1.65697187e-01
    -9.40489247e-02  7.48263896e-02 -1.10584274e-01  1.71732873e-01]
   [ 6.83417022e-02 -1.77200437e-01  7.34985769e-02 -3.10563445e-02
    -2.33198702e-03 -1.56644255e-01  7.92194903e-03 -7.83959031e-03
    -6.82720095e-02  7.34769106e-02 -1.11427516e-01  1.33485317e-01]
   [-3.13179493e-02  1.01474553e-01 -6.14661053e-02 -6.01295903e-02
     1.23669326e-01 -3.50395590e-02  1.05152458e-01 -6.24648780e-02
    -1.60078883e-01  1.26718879e-01  1.58957660e-01  3.59189808e-02]
   [ 4.42900062e-02 -3.50268930e-02  1.04497164e-01  1.56381220e-01
     2.87044048e-03 -1.42665729e-01 -1.34494901e-02 -2.89812237e-02
    -8.46730694e-02  1.53694302e-01 -4.19539809e-02 -1.13815911e-01]
   [-1.22476026e-01 -9.71738324e-02  1.41873002e-01 -9.17227715e-02
     1.63012177e-01 -1.14006311e-01  1.67486519e-01  1.00238621e-03
     1.74196213e-01  1.55352741e-01  9.41871703e-02  1.24721587e-01]
   [ 1.05432242e-01  1.58030540e-02 -1.49985492e-01  6.94580376e-03
     3.57705802e-02 -2.35713869e-02  8.01324248e-02  7.97395706e-02
     8.32912028e-02  3.47560942e-02 -4.81787175e-02 -1.18199810e-01]
   [ 3.79540473e-02 -1.55723885e-01 -1.39826685e-02  1.23033851e-01
     7.35325515e-02 -2.72727907e-02 -1.54073253e-01  1.22538745e-01
     8.05682838e-02  1.37644738e-01 -2.35742629e-02  1.76844805e-01]]

  [[ 1.55002594e-01 -1.64121121e-01 -1.05905458e-01 -2.62693167e-02
    -1.63618743e-01  1.52733922e-02  7.23264217e-02  1.31728202e-01
    -1.60836801e-01  2.33124197e-03 -1.26495153e-01 -5.89447245e-02]
   [-4.30664867e-02  5.07556945e-02 -1.45076364e-02  6.64809197e-02
     1.14549935e-01 -1.64946258e-01 -1.09771848e-01  1.69305921e-01
     2.09187716e-02  7.87111521e-02  1.09207362e-01  5.50405085e-02]
   [ 1.69653744e-01  1.38472617e-01 -1.61807939e-01 -6.23544008e-02
     1.46560043e-01 -1.21372819e-01 -1.49739116e-01 -9.75037813e-02
    -9.59846601e-02  1.40398741e-02  1.48057550e-01 -1.40369132e-01]
   [-1.53138816e-01  5.49907237e-02  1.41894251e-01 -1.82538792e-01
    -6.11386374e-02  1.58585250e-01  9.95388627e-03 -1.37266994e-01
    -6.22256398e-02 -1.79013640e-01 -1.49451554e-01 -3.71727496e-02]
   [-1.00083053e-01 -1.58406362e-01 -1.52994782e-01 -1.40586257e-01
    -1.11182533e-01 -1.27629936e-02  1.46238685e-01 -2.68721581e-02
    -7.90815055e-03  1.40256345e-01  3.50961834e-02  8.82386267e-02]
   [-1.36190385e-01 -1.71206519e-01  5.31310290e-02  1.01643711e-01
    -3.83612514e-03 -1.44006252e-01  9.77560282e-02 -1.66743055e-01
     1.41511738e-01  1.13334060e-02  2.74433047e-02 -4.35131937e-02]
   [ 2.15985179e-02 -5.84372208e-02  5.78191876e-03  1.17053181e-01
    -1.06947899e-01 -1.54872537e-01  1.01087183e-01  2.15525925e-02
     1.10697269e-01  4.39689755e-02 -5.77781871e-02  9.08153653e-02]
   [ 8.28956962e-02 -7.59829208e-02  9.36451852e-02  6.05572611e-02
    -7.56003410e-02  3.66328061e-02 -1.18398003e-01 -1.26961961e-01
    -9.11097527e-02  1.61877751e-01 -6.16949350e-02  1.12000704e-01]]

  [[ 6.54442757e-02 -3.52126658e-02  6.75645769e-02 -9.63331982e-02
     7.36210644e-02 -4.42836583e-02 -8.74806046e-02 -1.69271260e-01
     7.37665892e-02 -1.43920019e-01 -3.44733745e-02 -1.19997829e-01]
   [-1.66580468e-01  1.09033406e-01  5.50605357e-02 -2.88511962e-02
    -5.58578223e-02  1.72737777e-01 -1.69504106e-01 -1.02619797e-01
     1.15295500e-01  3.99060696e-02 -7.63702840e-02 -1.69902295e-01]
   [-1.27149045e-01  6.66344464e-02  1.60403311e-01  1.36793733e-01
    -5.84559813e-02 -1.29001945e-01 -1.40514970e-02  1.18141145e-01
     5.09639084e-03  1.17779374e-01  1.42025769e-01  1.05675399e-01]
   [-1.01990633e-01  6.93272948e-02 -3.27154547e-02  1.05818242e-01
     1.13284439e-02 -3.16650569e-02  6.02966994e-02 -3.55527252e-02
    -1.74503282e-01  5.04914224e-02 -1.15612052e-01 -1.56989276e-01]
   [ 6.63249493e-02  1.49286836e-01 -1.57417953e-01  5.17912507e-02
    -1.19623043e-01  2.16366351e-03 -7.20754266e-03 -1.41096711e-01
     4.25551981e-02  1.03924185e-01 -7.53309429e-02 -9.96881574e-02]
   [ 1.79113984e-01  1.67744517e-01 -1.57430261e-01  1.57400668e-02
    -1.64505050e-01 -8.17086920e-02 -1.59377232e-01  1.20524883e-01
     8.73407125e-02  2.86670774e-02  7.85922706e-02  1.69887125e-01]
   [-1.55991927e-01  3.42931598e-02  1.38600111e-01  6.44472390e-02
    -1.75565571e-01 -8.70519280e-02  4.44203764e-02  1.44709855e-01
     2.20600069e-02  1.99121535e-02  1.93680078e-02  8.41656029e-02]
   [ 1.35410517e-01 -7.62692541e-02 -1.64822236e-01 -4.54047471e-02
     1.29582316e-01 -7.38021582e-02  1.55390888e-01 -1.50056869e-01
    -1.20546207e-01  1.45383984e-01 -1.32250965e-01 -9.44358110e-02]]]]: "
2018-04-20 09:34:45,917 (dqn_agent.py:161) DEBUG: "var_name: q/Conv_1/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 09:34:45,927 (dqn_agent.py:161) DEBUG: "var_name: q/Conv_2/weights:0, var_value [[[[-0.13658337  0.02345863 -0.01830676 ... -0.04524105 -0.11525144
    -0.03715149]
   [ 0.0889782  -0.03085545 -0.12125823 ...  0.13330369 -0.1434836
    -0.11708458]
   [ 0.12874593  0.09376745  0.05907653 ...  0.13500266 -0.11625536
     0.14452691]
   ...
   [-0.04354049  0.10859127 -0.01560654 ... -0.02955681 -0.01991378
    -0.13117045]
   [ 0.03087591 -0.07006921  0.08027281 ... -0.0604371   0.133969
    -0.0068614 ]
   [ 0.14753856 -0.08917915 -0.06580888 ... -0.07753086  0.06499165
    -0.13931726]]

  [[-0.01739204 -0.10683854  0.0155206  ...  0.01821987 -0.05029524
     0.05588213]
   [ 0.1351041  -0.09253447 -0.07088776 ... -0.13195609  0.11025898
    -0.09946294]
   [-0.05343358  0.0229767   0.03093621 ...  0.14424075 -0.08035532
     0.11235903]
   ...
   [-0.0071587   0.05752158  0.00378318 ... -0.04271274 -0.01135354
     0.03515853]
   [-0.02107203 -0.05149772 -0.06752063 ... -0.05628905 -0.09955311
     0.02246466]
   [ 0.03342713  0.08655994 -0.02862263 ... -0.08843572  0.10192661
    -0.02719784]]

  [[ 0.14001228  0.09850834  0.08471803 ... -0.03706732  0.15297912
     0.08322708]
   [-0.03173371  0.01813845 -0.02318749 ...  0.11214031 -0.12261018
     0.02727896]
   [-0.0757469  -0.10042548 -0.11866209 ...  0.07366402 -0.07696273
    -0.1489859 ]
   ...
   [-0.0552827  -0.11778681 -0.06502569 ... -0.09664646  0.0856799
     0.11255793]
   [ 0.02466261 -0.0866174  -0.0657033  ...  0.09767379  0.0582855
     0.13662781]
   [-0.09057973 -0.07789599  0.05241938 ... -0.0173429  -0.15089491
     0.11109792]]]


 [[[ 0.04933469  0.11412902  0.01025042 ...  0.08422914  0.04769298
     0.0541833 ]
   [-0.11827418 -0.05818827  0.0225707  ... -0.06406403 -0.03529318
    -0.1456304 ]
   [-0.07517546  0.03933138  0.05762655 ... -0.15274803 -0.00364611
    -0.07105508]
   ...
   [ 0.06871031  0.07240133  0.01433022 ... -0.07978281  0.08828029
     0.01449235]
   [-0.14904322  0.04006074  0.12503593 ... -0.11974246 -0.08787987
    -0.0163893 ]
   [-0.09480909  0.01481576 -0.07247578 ... -0.04688562 -0.01850836
    -0.10022792]]

  [[-0.00774054 -0.13048261  0.04178327 ... -0.07440102 -0.04600228
     0.12662719]
   [-0.07830894  0.09401268  0.03233665 ...  0.1202039  -0.04668184
    -0.11466138]
   [ 0.12830059 -0.0008226   0.11480735 ... -0.11881259  0.11211769
     0.09688245]
   ...
   [ 0.0092463  -0.10293536 -0.01972732 ...  0.1141413  -0.10621908
     0.12104   ]
   [ 0.01454659 -0.07529186  0.09023844 ... -0.05571213 -0.02690372
    -0.08842575]
   [-0.09757111 -0.14088258  0.06369637 ...  0.05775678 -0.01753369
    -0.0350596 ]]

  [[ 0.10763149  0.02846827 -0.12212148 ...  0.09517466  0.0047888
     0.12113954]
   [ 0.11413683 -0.10183033  0.02909739 ...  0.0942156   0.10403846
    -0.05486179]
   [-0.09300721  0.0510451  -0.10885659 ... -0.11536787  0.13671581
    -0.15375234]
   ...
   [-0.01437077  0.14259227  0.1299461  ... -0.15085533  0.0882844
    -0.02026227]
   [ 0.10322149  0.00609016 -0.12542206 ... -0.11973801 -0.04638863
     0.14051254]
   [-0.07490925  0.11549206 -0.03258876 ...  0.0632323  -0.12730356
     0.00784215]]]


 [[[ 0.12350793  0.09787606 -0.10983819 ... -0.03831589 -0.0729185
    -0.10601082]
   [-0.00706866 -0.1344955   0.15228759 ... -0.05387916  0.06213892
     0.08567928]
   [-0.08645122  0.07055998  0.12822144 ...  0.06876545 -0.13459182
    -0.08251224]
   ...
   [-0.11190575 -0.0426413  -0.04780309 ... -0.02502005  0.1435671
     0.0543817 ]
   [-0.00522272  0.07916896 -0.02328999 ...  0.11105813 -0.00227933
    -0.11914755]
   [ 0.13784619  0.04214983 -0.04287244 ...  0.0456735  -0.11980033
    -0.06378892]]

  [[-0.03600467 -0.02478825 -0.05549096 ... -0.05852044  0.12099458
     0.13805   ]
   [-0.10591764 -0.02084552  0.05921328 ...  0.04578155 -0.05478873
    -0.11016957]
   [ 0.1206633   0.09304498  0.15282916 ... -0.03670027 -0.09350507
    -0.10330468]
   ...
   [ 0.01450089  0.14091836  0.14790325 ... -0.04419179  0.02274047
     0.09923966]
   [ 0.120928    0.02751036 -0.02248938 ... -0.03764688  0.04703142
    -0.13381061]
   [-0.15271339 -0.11594203  0.09164602 ... -0.03630877  0.01527195
     0.03243932]]

  [[-0.01452631 -0.07487839  0.02821806 ... -0.12052684  0.02126344
    -0.1418884 ]
   [ 0.15374185 -0.14218259  0.07162137 ... -0.12048736  0.14849518
     0.00047447]
   [ 0.06171136 -0.06212379  0.03019936 ... -0.04607049 -0.13498081
    -0.1069116 ]
   ...
   [ 0.08243175 -0.00920478 -0.1461436  ...  0.10883869  0.14469291
    -0.10252358]
   [ 0.12306641 -0.10147613  0.13862224 ...  0.00904758 -0.01622815
    -0.07968646]
   [ 0.01073004  0.15412898  0.06240107 ... -0.13240874 -0.12116615
    -0.14728464]]]]: "
2018-04-20 09:34:45,933 (dqn_agent.py:161) DEBUG: "var_name: q/Conv_2/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 09:34:45,940 (dqn_agent.py:161) DEBUG: "var_name: q/fully_connected/weights:0, var_value [[-0.05176491  0.07394349 -0.0456101  ... -0.0062022  -0.08874341
   0.07867972]
 [ 0.06033123  0.0795683   0.00124795 ...  0.03402465 -0.07069045
   0.00781717]
 [ 0.07757252 -0.0031314  -0.06964948 ...  0.07017333  0.03872178
  -0.01151057]
 ...
 [-0.05913787  0.06658725 -0.03977464 ... -0.08682036  0.06463618
  -0.07943281]
 [-0.05705196 -0.01294874  0.06737942 ...  0.08033413  0.03417852
   0.02346264]
 [ 0.05311853 -0.02772107 -0.01369294 ... -0.0550375   0.02844208
   0.00294447]]: "
2018-04-20 09:34:45,948 (dqn_agent.py:161) DEBUG: "var_name: q/fully_connected/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 09:34:45,959 (dqn_agent.py:161) DEBUG: "var_name: q/fully_connected_1/weights:0, var_value [[-0.13446358  0.14717728 -0.06535095 -0.11754611  0.08771956]
 [-0.01528504 -0.00875862  0.07805064  0.16065803 -0.19920927]
 [ 0.08784777  0.16690731 -0.16769396  0.13755146 -0.02381827]
 [-0.12056661  0.17241335 -0.11286969  0.15230545 -0.06481807]
 [-0.0642494  -0.10228872  0.00286934 -0.1974849  -0.06795003]
 [ 0.19522434  0.06654575 -0.09818134  0.08368039 -0.17807233]
 [ 0.02830057  0.2086218   0.12405688 -0.14420743  0.1358324 ]
 [-0.0570845  -0.16688478 -0.08956107  0.18122572  0.04451707]
 [ 0.06157723 -0.17282546  0.06213433  0.00986089 -0.16132715]
 [ 0.12329209 -0.1690386   0.11771408  0.02626619  0.12050691]
 [ 0.04477766 -0.18580529  0.14148226  0.02658926 -0.17811638]
 [ 0.14998785 -0.02261208 -0.16618364 -0.08223246  0.14990991]
 [ 0.08077151  0.09338537  0.09721518  0.15927967 -0.07242282]
 [-0.11966345  0.0667547   0.08729172 -0.05328836 -0.18742688]
 [-0.10841788 -0.09671842  0.13925269 -0.11819131  0.00805326]
 [-0.10455524  0.1175727   0.02221861 -0.20497692  0.12558386]
 [-0.02876443 -0.0722868   0.06302544 -0.00128163  0.05702555]
 [-0.00213072  0.20670232 -0.18729982  0.17787236  0.16493294]
 [ 0.12329328 -0.20297757  0.17020422  0.00610602 -0.12291811]
 [ 0.13031489 -0.05102396 -0.20403144 -0.00583626  0.19686842]
 [ 0.13589945 -0.19167882 -0.00417817 -0.12023006 -0.02697797]
 [-0.21114512 -0.08483736  0.1508604  -0.0749751  -0.00463843]
 [ 0.03588492  0.19086605  0.1869579  -0.02370153  0.07388139]
 [-0.10315976 -0.14732824 -0.17353265  0.05111623 -0.0720254 ]
 [-0.12997063 -0.08518997  0.13765329  0.1891528   0.02442397]
 [ 0.03625169 -0.20258978  0.19684756  0.14148986  0.04896811]
 [ 0.0971888  -0.08970043 -0.13968724  0.10208455 -0.06945549]
 [-0.04022133 -0.05863099  0.00228146  0.19000867  0.20389718]
 [-0.11479507 -0.08984125  0.04054552 -0.01287855  0.1397717 ]
 [ 0.03954059  0.03959548  0.16266885  0.12233195 -0.1746016 ]
 [ 0.09819525  0.0705238  -0.13390127 -0.03606103 -0.17941266]
 [ 0.15311018  0.06143853  0.10865     0.05728763  0.16048977]
 [ 0.1847403   0.03539376 -0.03023891  0.09693256 -0.04703331]
 [ 0.12934583 -0.20826606  0.04314542 -0.2054263   0.10019335]
 [ 0.19269148  0.08624727  0.03661336  0.12123677 -0.04591088]
 [-0.06105226 -0.2067678  -0.12758592  0.16294205  0.16709495]
 [-0.05513477  0.19105718 -0.18828876  0.08177635  0.00141062]
 [-0.06816828  0.15618956  0.13669172 -0.06319924 -0.18835606]
 [ 0.12843335 -0.14137217  0.19211853 -0.13592654  0.18828344]
 [ 0.08537859 -0.20513172 -0.12398351 -0.16814885 -0.09137447]
 [-0.15936816  0.0059941  -0.092323   -0.16406968  0.16121969]
 [ 0.16567707  0.13096493 -0.00054088 -0.18560785  0.20741537]
 [-0.01787515 -0.01749612  0.075932   -0.00923008  0.1937091 ]
 [-0.13127601  0.1039376   0.14378065  0.14998555  0.01111782]
 [ 0.01282872 -0.08811086 -0.02096878 -0.06432216 -0.09563802]
 [ 0.16808414  0.00824134 -0.0093511   0.17357153  0.06671917]
 [ 0.15221581  0.06599322  0.09444055 -0.19823928  0.10493183]
 [-0.02532642 -0.11340486  0.14749795  0.17250389 -0.03421761]
 [ 0.16623873 -0.19940981 -0.00803711  0.05028537 -0.18014349]
 [ 0.20462656  0.15061268 -0.15127175  0.12055305  0.12082294]
 [-0.02044749 -0.1955798   0.18716371  0.1435996  -0.04042313]
 [ 0.08643508 -0.13081788  0.0056376  -0.20112766  0.19727656]
 [ 0.19291958  0.01759025 -0.01285125  0.04556918  0.09280783]
 [-0.03603597 -0.06203741 -0.04332057 -0.15482067  0.03802085]
 [-0.20692518 -0.03692454 -0.07618463 -0.18498002  0.06554875]
 [-0.06965263  0.02749354  0.18326998  0.18931639  0.07900095]
 [ 0.02895844 -0.14340782  0.00791293  0.1346272   0.07633644]
 [-0.11339919 -0.18922018 -0.16030084 -0.04779144 -0.078942  ]
 [ 0.12018681 -0.0095454  -0.15086553 -0.05323403 -0.12096706]
 [ 0.17811632 -0.04214174 -0.04126911 -0.1390774   0.1945985 ]
 [-0.14187908  0.08771637  0.0606474   0.09562972  0.20613   ]
 [-0.11097841 -0.19621679 -0.13793233  0.17031085  0.02280061]
 [-0.11554322  0.11538962  0.02422424  0.02665459  0.11729988]
 [ 0.08157566 -0.19494452 -0.00293188 -0.10547577 -0.07991028]
 [ 0.07708636  0.07844412  0.14771539 -0.17016345  0.11220172]
 [ 0.00482884  0.0099214   0.19770342 -0.19969401 -0.07281421]
 [ 0.19110209  0.04319483 -0.07661897  0.20225286  0.20385268]
 [-0.1901401   0.1572423   0.19435051  0.01795684  0.20493728]
 [-0.02472633 -0.1766016  -0.15508977 -0.13827176 -0.02873106]
 [ 0.20946854 -0.03953612  0.20214567 -0.1200356   0.148024  ]
 [ 0.1570243   0.09810179 -0.14409259  0.13931677  0.11752924]
 [ 0.14339063 -0.09190609  0.15003443  0.17827499  0.15659776]
 [-0.19195831 -0.05016841 -0.14777052  0.16534403  0.05229822]
 [-0.11705886 -0.2104812  -0.1113696   0.06449899  0.04722697]
 [ 0.18216136  0.14589784  0.18173367  0.16715357 -0.12231058]
 [-0.12616137  0.19391856  0.03774464  0.18158731 -0.15628856]
 [-0.05105734  0.10110599 -0.04243752 -0.1288915  -0.07320835]
 [ 0.03611031  0.15455055 -0.17676476 -0.19416082  0.18190074]
 [-0.17306757 -0.01025274 -0.20883602  0.10454845 -0.18633923]
 [-0.01037544  0.09630013 -0.20794384 -0.16690251 -0.15348333]
 [-0.06067611  0.00537828  0.18328774 -0.15258965  0.08430681]
 [ 0.17956674  0.14627752  0.11088857 -0.04550608  0.14091474]
 [ 0.00516129  0.18900257 -0.11871927 -0.09590063  0.16513652]
 [ 0.18128896  0.19262311  0.13905707 -0.06069805  0.06233051]
 [ 0.19704843  0.08967695 -0.01543149 -0.08493789 -0.08106786]
 [ 0.1651392  -0.02378474 -0.09242225  0.07630759  0.14633322]
 [ 0.04226321  0.17378938 -0.01494196  0.17095986  0.01324721]
 [ 0.01446605 -0.20659314  0.20522699  0.04060963 -0.11757411]
 [ 0.02316481 -0.03690423 -0.18119405  0.01397155  0.00912413]
 [ 0.16147918 -0.03191279  0.08530289  0.03516182  0.09506533]
 [-0.1443633   0.02326696 -0.21053031  0.05429119 -0.08553042]
 [-0.1920017  -0.16221951  0.1877934   0.14260104  0.00435778]
 [-0.0778293  -0.07687688  0.0332149  -0.05663604  0.14386365]
 [-0.1048212   0.13202909  0.13704762  0.02542445  0.14820617]
 [-0.18758927 -0.12638383 -0.164499    0.06236723 -0.14122492]
 [-0.13806024  0.09983149  0.0474807  -0.12150116 -0.11947861]
 [ 0.08376557 -0.1348099   0.07039186  0.17725441  0.14971751]
 [-0.17293459 -0.17529753 -0.07023737 -0.04136781 -0.186266  ]
 [ 0.13078445  0.04815534 -0.01195033 -0.20249629  0.10353142]
 [ 0.16496018  0.18428513 -0.16142462  0.03560083  0.15392566]
 [-0.03165418  0.06789064  0.08991134 -0.10124093 -0.01006076]
 [ 0.1286656   0.06900474  0.1884391  -0.09244494 -0.18195254]
 [ 0.13844496  0.01049995 -0.12106065 -0.00341943  0.15692747]
 [-0.03782065  0.16825747 -0.00380693 -0.05254345 -0.18005142]
 [ 0.01992874  0.1563592  -0.1105139   0.18401054  0.07652706]
 [-0.05782369 -0.12739971  0.20137852 -0.00663732 -0.14410406]
 [-0.14864203  0.12634447  0.09152269  0.12486008 -0.20049188]
 [-0.02176063 -0.17487267 -0.20050845 -0.03146043 -0.16757697]
 [ 0.17097545  0.0952954   0.0750863   0.1264244   0.07353634]
 [-0.09625734  0.15204936 -0.16125736 -0.17843789 -0.15530534]
 [-0.08287969 -0.16840762  0.14791405  0.0167429   0.13199863]
 [-0.01463422 -0.21229424  0.08524972  0.18693966 -0.1784978 ]
 [ 0.095561    0.12785596  0.11775094 -0.08970352  0.1806716 ]
 [ 0.16996717  0.1666593   0.00960431  0.12974507 -0.2090286 ]
 [-0.15838681 -0.05195421 -0.19832714  0.1411165   0.10550955]
 [ 0.08508062 -0.18627548  0.03752279  0.01515596 -0.08315825]
 [-0.09481224 -0.17169225  0.14941865  0.08412871  0.07986733]
 [-0.15730646  0.07507679  0.15138203  0.0707899   0.19851172]
 [ 0.04343826 -0.03125989 -0.08985443 -0.08199349 -0.00492622]
 [ 0.00995812  0.10973537 -0.05657168 -0.03194743  0.19988936]
 [-0.07395431 -0.02883841 -0.0546101  -0.13578668  0.05086252]
 [ 0.2112974   0.12578931  0.20297915  0.16098598  0.07809779]
 [ 0.04575142 -0.05614838 -0.16816054  0.15892729 -0.12842697]
 [-0.1236062  -0.06226604  0.02850379  0.07179028 -0.02205773]
 [-0.12456171 -0.15822987  0.16889605 -0.0109742  -0.09680131]
 [ 0.19469875  0.01244584  0.00752033 -0.12521102  0.21067363]
 [ 0.06036484  0.16449988 -0.07530801  0.14880753 -0.01264484]
 [ 0.17718807 -0.06731197 -0.1620127   0.03783819  0.07202253]]: "
2018-04-20 09:34:45,966 (dqn_agent.py:161) DEBUG: "var_name: q/fully_connected_1/biases:0, var_value [0. 0. 0. 0. 0.]: "
2018-04-20 09:34:45,973 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv/weights:0, var_value [[[[-0.5065052   0.51942587 -0.59897566 -0.28246     0.4392544
    -0.16779715 -0.21814543 -0.69820213]
   [ 0.68456256 -0.51737595 -0.13999772 -0.3475432  -0.3713318
    -0.36173075 -0.5888333  -0.13174593]]]]: "
2018-04-20 09:34:45,979 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 09:34:45,990 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv_1/weights:0, var_value [[[[ 1.15084738e-01  9.05344784e-02  8.58393013e-02  1.77509964e-01
     6.06891513e-02 -1.78514704e-01 -8.70768726e-02  1.88047737e-02
    -7.61388838e-02 -1.53597310e-01 -4.81006354e-02  5.06064296e-02]
   [ 1.82275891e-01  1.67471945e-01  4.54558432e-02  3.75341177e-02
     1.59016371e-01  1.15182996e-01 -1.42512321e-01  5.06981015e-02
    -1.66003138e-01  1.49708062e-01  6.11787736e-02  1.36551142e-01]
   [ 3.91823500e-02  6.60028309e-02 -4.01660204e-02 -1.29066542e-01
     3.21386009e-02  1.16352707e-01  9.87316072e-02  1.40943766e-01
     8.69557261e-02 -1.37657657e-01  1.45227969e-01  9.38086808e-02]
   [ 6.99088275e-02  1.12624735e-01 -1.63305387e-01  3.46968919e-02
    -1.99363679e-02  1.80165499e-01  3.20716947e-02 -1.46666870e-01
    -5.01990318e-03 -1.69233680e-02  4.25749272e-02  1.47550642e-01]
   [-7.33372644e-02 -9.85057354e-02  6.73456639e-02  1.45397663e-01
     4.83483076e-02  1.56063437e-02  1.55619621e-01  7.26403594e-02
    -6.30283654e-02 -5.29495478e-02  7.30874538e-02 -2.14876235e-03]
   [ 1.27607197e-01 -1.35979623e-01  1.25893146e-01 -7.67754540e-02
     1.39980555e-01  2.83474028e-02 -8.31421018e-02  2.22646445e-02
    -6.45795614e-02  5.94750345e-02  1.79903358e-01  7.45081007e-02]
   [-8.36186185e-02 -3.46408337e-02  1.27734601e-01  1.42840356e-01
    -1.25892758e-01  4.61139232e-02  7.08087385e-02 -3.14902812e-02
    -8.33935738e-02 -1.76132172e-02 -9.40179750e-02  1.70375973e-01]
   [-2.26318091e-02  1.54261947e-01 -1.74328506e-01  1.41071588e-01
     1.70604557e-01  1.30161732e-01 -6.23068660e-02 -1.71945989e-02
    -4.04705107e-02 -1.50747940e-01  3.66477817e-02 -1.41648099e-01]]

  [[-1.09314747e-01 -1.61456764e-02  7.17388690e-02  1.18717760e-01
    -6.91071525e-02  9.04278755e-02 -1.07291773e-01 -8.06433186e-02
    -1.11393780e-01 -1.75349787e-01 -6.60184026e-03 -1.29856333e-01]
   [-1.41096458e-01 -7.28023350e-02 -2.08425522e-02  1.80151969e-01
    -1.15540057e-01  1.48467749e-01 -3.26013267e-02 -1.79077059e-01
     2.02122331e-03  5.54967076e-02 -1.24399513e-02 -2.71303654e-02]
   [ 4.72054929e-02 -1.39215693e-01  1.43141627e-01 -5.72198033e-02
    -1.40783578e-01 -7.40583688e-02 -2.07286775e-02 -9.00124311e-02
     6.75009191e-03 -1.17478058e-01 -6.50844574e-02  1.03811026e-01]
   [ 1.43658131e-01  1.27082497e-01 -1.42062664e-01  1.98172629e-02
     9.70597565e-02  1.02215379e-01 -1.58396959e-01  1.06195658e-01
    -5.26904613e-02  6.38068318e-02  6.08922094e-02  1.15099758e-01]
   [-8.01548362e-03 -1.68817639e-01 -1.06588125e-01 -3.84726524e-02
     2.19917297e-03 -1.55455053e-01 -7.28779063e-02 -1.28170416e-01
    -7.37497061e-02 -4.54047918e-02 -1.17131695e-01 -8.17541778e-03]
   [ 1.20770484e-02 -5.63667566e-02 -8.67433101e-02 -1.05056554e-01
     5.79686761e-02 -1.25893325e-01  1.30007297e-01 -3.34772170e-02
     2.43204385e-02 -2.69568115e-02 -1.76688045e-01 -5.15948385e-02]
   [-1.10039242e-01 -1.09094664e-01  3.49410474e-02  2.58871764e-02
     1.08914614e-01  6.89161122e-02  1.29074812e-01 -9.24974158e-02
     5.28159589e-02 -1.69843435e-04  8.11699033e-03 -7.69324228e-02]
   [ 1.17504865e-01 -1.70158729e-01  9.15698111e-02 -5.34759015e-02
    -1.15439244e-01  1.57874256e-01  1.67788804e-01 -1.44610256e-01
    -8.17432553e-02 -7.27074891e-02  1.42443299e-01 -7.91600645e-02]]

  [[-1.77420303e-01 -2.37468481e-02  1.58302754e-01  1.22182757e-01
    -1.01729371e-01  5.47116548e-02 -1.13397732e-01  1.44437402e-01
     1.62951976e-01 -2.09491998e-02 -1.49722874e-01  1.16285354e-01]
   [-1.37282610e-01 -1.58556849e-02  1.65785491e-01 -5.81752658e-02
    -1.23960063e-01  3.50769460e-02  1.24914944e-02 -1.28913194e-01
     5.09981811e-03  2.89600641e-02 -1.27022713e-01  1.28617406e-01]
   [ 1.68857127e-02 -1.51626706e-01  1.43795699e-01 -5.30299991e-02
     2.64239758e-02  8.02513063e-02  7.66032934e-03 -1.47117570e-01
     1.21232182e-01  1.38019949e-01  1.36439204e-01  1.72299445e-01]
   [-1.55842885e-01  1.90472305e-02  1.49322331e-01 -6.75605685e-02
     1.43982947e-01 -1.55381218e-01  1.27005607e-01 -4.67005372e-03
    -1.18270807e-01  5.93548119e-02  1.80076063e-01  1.39639527e-02]
   [ 9.06531513e-03  3.25953513e-02  1.64583027e-02 -1.04353301e-01
     1.58710241e-01  1.14731640e-01 -9.74407122e-02 -1.02213807e-01
     1.42844617e-02  9.04915631e-02  4.70439196e-02 -1.39237151e-01]
   [-1.70262635e-01 -4.96194512e-02  9.04366672e-02  1.79456294e-01
     3.83335352e-02 -1.71772361e-01  1.50101453e-01  7.78810978e-02
    -1.44695491e-01  1.77884489e-01 -8.49089473e-02 -1.18051685e-01]
   [-1.00906365e-01  8.24175775e-02  1.15483046e-01  1.40128762e-01
    -1.02541894e-02  4.21380997e-02  5.45582175e-02  1.60037696e-01
     3.40330750e-02  8.24938118e-02 -9.60426405e-02 -1.77605376e-01]
   [-1.46964610e-01 -8.76923725e-02 -5.96019700e-02  1.75252736e-01
     4.58887517e-02  1.06242746e-02  3.05578113e-03 -2.96599716e-02
     1.52468294e-01 -4.86564487e-02  1.24228865e-01  3.37116122e-02]]]


 [[[-1.79211795e-02  1.76192611e-01  1.77153945e-03 -3.93828750e-03
    -1.70213670e-01  1.71548605e-01  2.47462094e-03  5.32713681e-02
     1.29406750e-02  5.99020571e-02  1.47002667e-01  4.75997925e-02]
   [-8.93595368e-02  8.94483030e-02  1.64599359e-01 -1.07296780e-01
     1.79576576e-02  1.11405104e-01 -1.35766894e-01  1.18909001e-01
     1.51132882e-01 -8.34674835e-02  1.57548547e-01 -1.63488731e-01]
   [ 6.90662861e-03 -9.24164504e-02 -3.35253179e-02 -1.09867431e-01
     7.81056583e-02  1.13724947e-01 -1.42705202e-01  9.30275619e-02
     8.35433900e-02 -5.16433269e-02  4.60255593e-02  1.24624968e-01]
   [ 1.36229604e-01 -1.24531336e-01  1.55326068e-01  1.26503587e-01
    -1.00224741e-01  4.33207899e-02  1.36378706e-02 -2.45499611e-03
    -4.89519686e-02 -3.89294326e-03 -1.41197890e-02  1.35164917e-01]
   [-1.37865424e-01  1.52610689e-01 -2.02232152e-02  1.38165206e-01
     1.36722863e-01  5.41018993e-02  8.07501078e-02 -2.20896602e-02
     1.60670012e-01 -7.57635757e-02 -7.51208737e-02  1.39496773e-02]
   [ 1.03326678e-01  4.00359631e-02 -8.06783587e-02  1.73397869e-01
    -6.20167032e-02 -9.05527547e-02 -6.76215515e-02  6.65970445e-02
    -9.72208381e-03  1.72025651e-01 -8.22490454e-03 -1.66009232e-01]
   [ 2.81233937e-02 -7.14335665e-02  4.30795550e-02  1.81236804e-01
    -1.26882121e-01 -6.05326667e-02  1.10382676e-01  7.94595480e-02
    -1.70224071e-01  1.75908059e-01  1.74227566e-01  3.29306573e-02]
   [ 7.43140280e-02 -1.56319007e-01  1.25954390e-01 -5.68811595e-03
    -1.44271210e-01  5.62345684e-02  2.27895677e-02 -1.19531021e-01
     1.74515784e-01  1.64852619e-01  6.63862377e-02  4.30923551e-02]]

  [[-1.61484569e-01  1.83692575e-03 -3.62255871e-02  5.88123947e-02
    -9.22487825e-02 -1.43215671e-01 -1.60967171e-01  4.27317172e-02
     6.23140484e-02 -2.39082128e-02  1.78368479e-01  1.19227469e-02]
   [-4.45342064e-03 -9.35201347e-02 -6.90475181e-02 -9.37319919e-02
    -8.96788687e-02 -5.90591207e-02  9.71559286e-02 -1.12797335e-01
    -6.37715310e-02 -6.32413104e-02 -1.07720539e-01  7.94748962e-02]
   [ 3.79066914e-02 -1.71022743e-01  6.31742328e-02  1.31374896e-01
     6.65467680e-02  1.33865833e-01 -1.71934456e-01 -1.57838300e-01
    -9.22940075e-02  3.68826240e-02 -9.24402624e-02  5.59771061e-03]
   [ 2.79645175e-02  1.34376526e-01  1.27403826e-01  9.77413654e-02
    -1.78682640e-01  1.38084739e-02 -6.35732561e-02  1.39192700e-01
    -1.10247485e-01  1.14033043e-01  3.08721662e-02  7.22031295e-02]
   [ 1.51804179e-01  1.29943252e-01  1.58611864e-01 -7.30182230e-03
    -1.75404251e-01  1.10463649e-01 -1.80683449e-01  7.38049448e-02
    -9.02057886e-02 -1.31015256e-01  1.55743003e-01  1.63429528e-02]
   [-1.74949974e-01  1.81346625e-01 -8.28931630e-02  7.16936588e-02
     4.21220809e-02  7.53470361e-02 -2.76030898e-02  1.08418018e-01
     1.44511849e-01 -8.55066031e-02 -1.68486565e-01 -5.77657819e-02]
   [-1.16706155e-01  1.60558879e-01 -1.06583990e-01  1.34898216e-01
     8.00959468e-02  9.88377631e-02 -1.40862793e-01  4.67927158e-02
    -1.09771408e-01 -5.48179895e-02 -4.49934751e-02  1.23688996e-01]
   [-6.12505451e-02  1.34886593e-01 -1.35522172e-01  9.95688140e-02
    -1.60152406e-01 -7.84794912e-02  4.86523658e-02 -6.63246438e-02
    -1.54782087e-01  1.23399884e-01  9.84022021e-03  2.81123817e-03]]

  [[ 1.63985521e-01  1.05007887e-01 -1.14388101e-01  6.33540452e-02
     1.02521062e-01 -1.52022511e-01  1.43916309e-02 -6.23708144e-02
     4.67478335e-02 -1.35008663e-01  1.03650093e-02 -6.63535297e-03]
   [ 1.16324931e-01 -1.09860122e-01  8.51898491e-02 -3.20411921e-02
     1.48238152e-01 -1.33084923e-01 -8.04418623e-02  8.74477923e-02
     3.19176912e-02 -2.23328173e-02 -1.41216904e-01  3.47148329e-02]
   [ 8.26008320e-02  8.61492157e-02 -1.81418180e-01 -4.05653566e-02
    -1.27392069e-01  1.69542938e-01 -5.93472421e-02  1.31722778e-01
    -3.16179097e-02 -7.46746138e-02 -3.67768109e-03 -1.36957020e-01]
   [ 1.61119491e-01  7.15574920e-02 -8.97622108e-03  3.95019352e-02
    -8.21593031e-02  1.13881081e-01 -1.10784851e-01  3.42567265e-02
    -1.58135042e-01 -1.74070343e-01  5.92126399e-02  1.43492997e-01]
   [-1.22186556e-01  1.25486583e-01  1.79121405e-01  1.42309517e-01
    -1.76526040e-01  1.52319044e-01  1.21126920e-01 -6.33774623e-02
     5.09698987e-02  7.10683167e-02 -1.33839503e-01 -1.55689180e-01]
   [ 9.73039269e-02 -1.42143339e-01 -1.80508554e-01 -5.35972267e-02
    -3.67146730e-03  4.35398668e-02 -1.07161999e-02  7.42670596e-02
     1.11117274e-01  1.38685733e-01 -1.56088918e-01  1.64478064e-01]
   [ 1.50687039e-01  4.67911363e-03 -8.81368518e-02  1.82513624e-01
     1.45062387e-01  7.77812302e-02 -1.33082792e-01 -1.42140239e-01
     5.53249717e-02  7.68020749e-04  4.21478599e-02  9.31636393e-02]
   [-1.47334740e-01 -1.53980151e-01  1.02467835e-01  1.00924700e-01
    -1.43698752e-01  9.37018692e-02  1.60395980e-01  8.21182132e-02
    -1.64435804e-02 -3.11196297e-02  1.66809350e-01 -1.15737766e-01]]]


 [[[ 1.35665864e-01 -1.55690923e-01  8.90878737e-02 -6.12835437e-02
    -1.80697560e-01  4.93211895e-02  9.06006694e-02  4.34838980e-02
     5.32819480e-02  1.68871701e-01 -1.36037290e-01 -4.61269766e-02]
   [ 1.08789921e-01 -7.97250271e-02  6.73242509e-02 -1.56381607e-01
     8.43695700e-02  1.19805217e-01  1.72469258e-01  1.65697187e-01
    -9.40489247e-02  7.48263896e-02 -1.10584274e-01  1.71732873e-01]
   [ 6.83417022e-02 -1.77200437e-01  7.34985769e-02 -3.10563445e-02
    -2.33198702e-03 -1.56644255e-01  7.92194903e-03 -7.83959031e-03
    -6.82720095e-02  7.34769106e-02 -1.11427516e-01  1.33485317e-01]
   [-3.13179493e-02  1.01474553e-01 -6.14661053e-02 -6.01295903e-02
     1.23669326e-01 -3.50395590e-02  1.05152458e-01 -6.24648780e-02
    -1.60078883e-01  1.26718879e-01  1.58957660e-01  3.59189808e-02]
   [ 4.42900062e-02 -3.50268930e-02  1.04497164e-01  1.56381220e-01
     2.87044048e-03 -1.42665729e-01 -1.34494901e-02 -2.89812237e-02
    -8.46730694e-02  1.53694302e-01 -4.19539809e-02 -1.13815911e-01]
   [-1.22476026e-01 -9.71738324e-02  1.41873002e-01 -9.17227715e-02
     1.63012177e-01 -1.14006311e-01  1.67486519e-01  1.00238621e-03
     1.74196213e-01  1.55352741e-01  9.41871703e-02  1.24721587e-01]
   [ 1.05432242e-01  1.58030540e-02 -1.49985492e-01  6.94580376e-03
     3.57705802e-02 -2.35713869e-02  8.01324248e-02  7.97395706e-02
     8.32912028e-02  3.47560942e-02 -4.81787175e-02 -1.18199810e-01]
   [ 3.79540473e-02 -1.55723885e-01 -1.39826685e-02  1.23033851e-01
     7.35325515e-02 -2.72727907e-02 -1.54073253e-01  1.22538745e-01
     8.05682838e-02  1.37644738e-01 -2.35742629e-02  1.76844805e-01]]

  [[ 1.55002594e-01 -1.64121121e-01 -1.05905458e-01 -2.62693167e-02
    -1.63618743e-01  1.52733922e-02  7.23264217e-02  1.31728202e-01
    -1.60836801e-01  2.33124197e-03 -1.26495153e-01 -5.89447245e-02]
   [-4.30664867e-02  5.07556945e-02 -1.45076364e-02  6.64809197e-02
     1.14549935e-01 -1.64946258e-01 -1.09771848e-01  1.69305921e-01
     2.09187716e-02  7.87111521e-02  1.09207362e-01  5.50405085e-02]
   [ 1.69653744e-01  1.38472617e-01 -1.61807939e-01 -6.23544008e-02
     1.46560043e-01 -1.21372819e-01 -1.49739116e-01 -9.75037813e-02
    -9.59846601e-02  1.40398741e-02  1.48057550e-01 -1.40369132e-01]
   [-1.53138816e-01  5.49907237e-02  1.41894251e-01 -1.82538792e-01
    -6.11386374e-02  1.58585250e-01  9.95388627e-03 -1.37266994e-01
    -6.22256398e-02 -1.79013640e-01 -1.49451554e-01 -3.71727496e-02]
   [-1.00083053e-01 -1.58406362e-01 -1.52994782e-01 -1.40586257e-01
    -1.11182533e-01 -1.27629936e-02  1.46238685e-01 -2.68721581e-02
    -7.90815055e-03  1.40256345e-01  3.50961834e-02  8.82386267e-02]
   [-1.36190385e-01 -1.71206519e-01  5.31310290e-02  1.01643711e-01
    -3.83612514e-03 -1.44006252e-01  9.77560282e-02 -1.66743055e-01
     1.41511738e-01  1.13334060e-02  2.74433047e-02 -4.35131937e-02]
   [ 2.15985179e-02 -5.84372208e-02  5.78191876e-03  1.17053181e-01
    -1.06947899e-01 -1.54872537e-01  1.01087183e-01  2.15525925e-02
     1.10697269e-01  4.39689755e-02 -5.77781871e-02  9.08153653e-02]
   [ 8.28956962e-02 -7.59829208e-02  9.36451852e-02  6.05572611e-02
    -7.56003410e-02  3.66328061e-02 -1.18398003e-01 -1.26961961e-01
    -9.11097527e-02  1.61877751e-01 -6.16949350e-02  1.12000704e-01]]

  [[ 6.54442757e-02 -3.52126658e-02  6.75645769e-02 -9.63331982e-02
     7.36210644e-02 -4.42836583e-02 -8.74806046e-02 -1.69271260e-01
     7.37665892e-02 -1.43920019e-01 -3.44733745e-02 -1.19997829e-01]
   [-1.66580468e-01  1.09033406e-01  5.50605357e-02 -2.88511962e-02
    -5.58578223e-02  1.72737777e-01 -1.69504106e-01 -1.02619797e-01
     1.15295500e-01  3.99060696e-02 -7.63702840e-02 -1.69902295e-01]
   [-1.27149045e-01  6.66344464e-02  1.60403311e-01  1.36793733e-01
    -5.84559813e-02 -1.29001945e-01 -1.40514970e-02  1.18141145e-01
     5.09639084e-03  1.17779374e-01  1.42025769e-01  1.05675399e-01]
   [-1.01990633e-01  6.93272948e-02 -3.27154547e-02  1.05818242e-01
     1.13284439e-02 -3.16650569e-02  6.02966994e-02 -3.55527252e-02
    -1.74503282e-01  5.04914224e-02 -1.15612052e-01 -1.56989276e-01]
   [ 6.63249493e-02  1.49286836e-01 -1.57417953e-01  5.17912507e-02
    -1.19623043e-01  2.16366351e-03 -7.20754266e-03 -1.41096711e-01
     4.25551981e-02  1.03924185e-01 -7.53309429e-02 -9.96881574e-02]
   [ 1.79113984e-01  1.67744517e-01 -1.57430261e-01  1.57400668e-02
    -1.64505050e-01 -8.17086920e-02 -1.59377232e-01  1.20524883e-01
     8.73407125e-02  2.86670774e-02  7.85922706e-02  1.69887125e-01]
   [-1.55991927e-01  3.42931598e-02  1.38600111e-01  6.44472390e-02
    -1.75565571e-01 -8.70519280e-02  4.44203764e-02  1.44709855e-01
     2.20600069e-02  1.99121535e-02  1.93680078e-02  8.41656029e-02]
   [ 1.35410517e-01 -7.62692541e-02 -1.64822236e-01 -4.54047471e-02
     1.29582316e-01 -7.38021582e-02  1.55390888e-01 -1.50056869e-01
    -1.20546207e-01  1.45383984e-01 -1.32250965e-01 -9.44358110e-02]]]]: "
2018-04-20 09:34:45,997 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv_1/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 09:34:46,006 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv_2/weights:0, var_value [[[[-0.13658337  0.02345863 -0.01830676 ... -0.04524105 -0.11525144
    -0.03715149]
   [ 0.0889782  -0.03085545 -0.12125823 ...  0.13330369 -0.1434836
    -0.11708458]
   [ 0.12874593  0.09376745  0.05907653 ...  0.13500266 -0.11625536
     0.14452691]
   ...
   [-0.04354049  0.10859127 -0.01560654 ... -0.02955681 -0.01991378
    -0.13117045]
   [ 0.03087591 -0.07006921  0.08027281 ... -0.0604371   0.133969
    -0.0068614 ]
   [ 0.14753856 -0.08917915 -0.06580888 ... -0.07753086  0.06499165
    -0.13931726]]

  [[-0.01739204 -0.10683854  0.0155206  ...  0.01821987 -0.05029524
     0.05588213]
   [ 0.1351041  -0.09253447 -0.07088776 ... -0.13195609  0.11025898
    -0.09946294]
   [-0.05343358  0.0229767   0.03093621 ...  0.14424075 -0.08035532
     0.11235903]
   ...
   [-0.0071587   0.05752158  0.00378318 ... -0.04271274 -0.01135354
     0.03515853]
   [-0.02107203 -0.05149772 -0.06752063 ... -0.05628905 -0.09955311
     0.02246466]
   [ 0.03342713  0.08655994 -0.02862263 ... -0.08843572  0.10192661
    -0.02719784]]

  [[ 0.14001228  0.09850834  0.08471803 ... -0.03706732  0.15297912
     0.08322708]
   [-0.03173371  0.01813845 -0.02318749 ...  0.11214031 -0.12261018
     0.02727896]
   [-0.0757469  -0.10042548 -0.11866209 ...  0.07366402 -0.07696273
    -0.1489859 ]
   ...
   [-0.0552827  -0.11778681 -0.06502569 ... -0.09664646  0.0856799
     0.11255793]
   [ 0.02466261 -0.0866174  -0.0657033  ...  0.09767379  0.0582855
     0.13662781]
   [-0.09057973 -0.07789599  0.05241938 ... -0.0173429  -0.15089491
     0.11109792]]]


 [[[ 0.04933469  0.11412902  0.01025042 ...  0.08422914  0.04769298
     0.0541833 ]
   [-0.11827418 -0.05818827  0.0225707  ... -0.06406403 -0.03529318
    -0.1456304 ]
   [-0.07517546  0.03933138  0.05762655 ... -0.15274803 -0.00364611
    -0.07105508]
   ...
   [ 0.06871031  0.07240133  0.01433022 ... -0.07978281  0.08828029
     0.01449235]
   [-0.14904322  0.04006074  0.12503593 ... -0.11974246 -0.08787987
    -0.0163893 ]
   [-0.09480909  0.01481576 -0.07247578 ... -0.04688562 -0.01850836
    -0.10022792]]

  [[-0.00774054 -0.13048261  0.04178327 ... -0.07440102 -0.04600228
     0.12662719]
   [-0.07830894  0.09401268  0.03233665 ...  0.1202039  -0.04668184
    -0.11466138]
   [ 0.12830059 -0.0008226   0.11480735 ... -0.11881259  0.11211769
     0.09688245]
   ...
   [ 0.0092463  -0.10293536 -0.01972732 ...  0.1141413  -0.10621908
     0.12104   ]
   [ 0.01454659 -0.07529186  0.09023844 ... -0.05571213 -0.02690372
    -0.08842575]
   [-0.09757111 -0.14088258  0.06369637 ...  0.05775678 -0.01753369
    -0.0350596 ]]

  [[ 0.10763149  0.02846827 -0.12212148 ...  0.09517466  0.0047888
     0.12113954]
   [ 0.11413683 -0.10183033  0.02909739 ...  0.0942156   0.10403846
    -0.05486179]
   [-0.09300721  0.0510451  -0.10885659 ... -0.11536787  0.13671581
    -0.15375234]
   ...
   [-0.01437077  0.14259227  0.1299461  ... -0.15085533  0.0882844
    -0.02026227]
   [ 0.10322149  0.00609016 -0.12542206 ... -0.11973801 -0.04638863
     0.14051254]
   [-0.07490925  0.11549206 -0.03258876 ...  0.0632323  -0.12730356
     0.00784215]]]


 [[[ 0.12350793  0.09787606 -0.10983819 ... -0.03831589 -0.0729185
    -0.10601082]
   [-0.00706866 -0.1344955   0.15228759 ... -0.05387916  0.06213892
     0.08567928]
   [-0.08645122  0.07055998  0.12822144 ...  0.06876545 -0.13459182
    -0.08251224]
   ...
   [-0.11190575 -0.0426413  -0.04780309 ... -0.02502005  0.1435671
     0.0543817 ]
   [-0.00522272  0.07916896 -0.02328999 ...  0.11105813 -0.00227933
    -0.11914755]
   [ 0.13784619  0.04214983 -0.04287244 ...  0.0456735  -0.11980033
    -0.06378892]]

  [[-0.03600467 -0.02478825 -0.05549096 ... -0.05852044  0.12099458
     0.13805   ]
   [-0.10591764 -0.02084552  0.05921328 ...  0.04578155 -0.05478873
    -0.11016957]
   [ 0.1206633   0.09304498  0.15282916 ... -0.03670027 -0.09350507
    -0.10330468]
   ...
   [ 0.01450089  0.14091836  0.14790325 ... -0.04419179  0.02274047
     0.09923966]
   [ 0.120928    0.02751036 -0.02248938 ... -0.03764688  0.04703142
    -0.13381061]
   [-0.15271339 -0.11594203  0.09164602 ... -0.03630877  0.01527195
     0.03243932]]

  [[-0.01452631 -0.07487839  0.02821806 ... -0.12052684  0.02126344
    -0.1418884 ]
   [ 0.15374185 -0.14218259  0.07162137 ... -0.12048736  0.14849518
     0.00047447]
   [ 0.06171136 -0.06212379  0.03019936 ... -0.04607049 -0.13498081
    -0.1069116 ]
   ...
   [ 0.08243175 -0.00920478 -0.1461436  ...  0.10883869  0.14469291
    -0.10252358]
   [ 0.12306641 -0.10147613  0.13862224 ...  0.00904758 -0.01622815
    -0.07968646]
   [ 0.01073004  0.15412898  0.06240107 ... -0.13240874 -0.12116615
    -0.14728464]]]]: "
2018-04-20 09:34:46,012 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv_2/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 09:34:46,017 (dqn_agent.py:161) DEBUG: "var_name: target_q/fully_connected/weights:0, var_value [[-0.05176491  0.07394349 -0.0456101  ... -0.0062022  -0.08874341
   0.07867972]
 [ 0.06033123  0.0795683   0.00124795 ...  0.03402465 -0.07069045
   0.00781717]
 [ 0.07757252 -0.0031314  -0.06964948 ...  0.07017333  0.03872178
  -0.01151057]
 ...
 [-0.05913787  0.06658725 -0.03977464 ... -0.08682036  0.06463618
  -0.07943281]
 [-0.05705196 -0.01294874  0.06737942 ...  0.08033413  0.03417852
   0.02346264]
 [ 0.05311853 -0.02772107 -0.01369294 ... -0.0550375   0.02844208
   0.00294447]]: "
2018-04-20 09:34:46,024 (dqn_agent.py:161) DEBUG: "var_name: target_q/fully_connected/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 09:34:46,033 (dqn_agent.py:161) DEBUG: "var_name: target_q/fully_connected_1/weights:0, var_value [[-0.13446358  0.14717728 -0.06535095 -0.11754611  0.08771956]
 [-0.01528504 -0.00875862  0.07805064  0.16065803 -0.19920927]
 [ 0.08784777  0.16690731 -0.16769396  0.13755146 -0.02381827]
 [-0.12056661  0.17241335 -0.11286969  0.15230545 -0.06481807]
 [-0.0642494  -0.10228872  0.00286934 -0.1974849  -0.06795003]
 [ 0.19522434  0.06654575 -0.09818134  0.08368039 -0.17807233]
 [ 0.02830057  0.2086218   0.12405688 -0.14420743  0.1358324 ]
 [-0.0570845  -0.16688478 -0.08956107  0.18122572  0.04451707]
 [ 0.06157723 -0.17282546  0.06213433  0.00986089 -0.16132715]
 [ 0.12329209 -0.1690386   0.11771408  0.02626619  0.12050691]
 [ 0.04477766 -0.18580529  0.14148226  0.02658926 -0.17811638]
 [ 0.14998785 -0.02261208 -0.16618364 -0.08223246  0.14990991]
 [ 0.08077151  0.09338537  0.09721518  0.15927967 -0.07242282]
 [-0.11966345  0.0667547   0.08729172 -0.05328836 -0.18742688]
 [-0.10841788 -0.09671842  0.13925269 -0.11819131  0.00805326]
 [-0.10455524  0.1175727   0.02221861 -0.20497692  0.12558386]
 [-0.02876443 -0.0722868   0.06302544 -0.00128163  0.05702555]
 [-0.00213072  0.20670232 -0.18729982  0.17787236  0.16493294]
 [ 0.12329328 -0.20297757  0.17020422  0.00610602 -0.12291811]
 [ 0.13031489 -0.05102396 -0.20403144 -0.00583626  0.19686842]
 [ 0.13589945 -0.19167882 -0.00417817 -0.12023006 -0.02697797]
 [-0.21114512 -0.08483736  0.1508604  -0.0749751  -0.00463843]
 [ 0.03588492  0.19086605  0.1869579  -0.02370153  0.07388139]
 [-0.10315976 -0.14732824 -0.17353265  0.05111623 -0.0720254 ]
 [-0.12997063 -0.08518997  0.13765329  0.1891528   0.02442397]
 [ 0.03625169 -0.20258978  0.19684756  0.14148986  0.04896811]
 [ 0.0971888  -0.08970043 -0.13968724  0.10208455 -0.06945549]
 [-0.04022133 -0.05863099  0.00228146  0.19000867  0.20389718]
 [-0.11479507 -0.08984125  0.04054552 -0.01287855  0.1397717 ]
 [ 0.03954059  0.03959548  0.16266885  0.12233195 -0.1746016 ]
 [ 0.09819525  0.0705238  -0.13390127 -0.03606103 -0.17941266]
 [ 0.15311018  0.06143853  0.10865     0.05728763  0.16048977]
 [ 0.1847403   0.03539376 -0.03023891  0.09693256 -0.04703331]
 [ 0.12934583 -0.20826606  0.04314542 -0.2054263   0.10019335]
 [ 0.19269148  0.08624727  0.03661336  0.12123677 -0.04591088]
 [-0.06105226 -0.2067678  -0.12758592  0.16294205  0.16709495]
 [-0.05513477  0.19105718 -0.18828876  0.08177635  0.00141062]
 [-0.06816828  0.15618956  0.13669172 -0.06319924 -0.18835606]
 [ 0.12843335 -0.14137217  0.19211853 -0.13592654  0.18828344]
 [ 0.08537859 -0.20513172 -0.12398351 -0.16814885 -0.09137447]
 [-0.15936816  0.0059941  -0.092323   -0.16406968  0.16121969]
 [ 0.16567707  0.13096493 -0.00054088 -0.18560785  0.20741537]
 [-0.01787515 -0.01749612  0.075932   -0.00923008  0.1937091 ]
 [-0.13127601  0.1039376   0.14378065  0.14998555  0.01111782]
 [ 0.01282872 -0.08811086 -0.02096878 -0.06432216 -0.09563802]
 [ 0.16808414  0.00824134 -0.0093511   0.17357153  0.06671917]
 [ 0.15221581  0.06599322  0.09444055 -0.19823928  0.10493183]
 [-0.02532642 -0.11340486  0.14749795  0.17250389 -0.03421761]
 [ 0.16623873 -0.19940981 -0.00803711  0.05028537 -0.18014349]
 [ 0.20462656  0.15061268 -0.15127175  0.12055305  0.12082294]
 [-0.02044749 -0.1955798   0.18716371  0.1435996  -0.04042313]
 [ 0.08643508 -0.13081788  0.0056376  -0.20112766  0.19727656]
 [ 0.19291958  0.01759025 -0.01285125  0.04556918  0.09280783]
 [-0.03603597 -0.06203741 -0.04332057 -0.15482067  0.03802085]
 [-0.20692518 -0.03692454 -0.07618463 -0.18498002  0.06554875]
 [-0.06965263  0.02749354  0.18326998  0.18931639  0.07900095]
 [ 0.02895844 -0.14340782  0.00791293  0.1346272   0.07633644]
 [-0.11339919 -0.18922018 -0.16030084 -0.04779144 -0.078942  ]
 [ 0.12018681 -0.0095454  -0.15086553 -0.05323403 -0.12096706]
 [ 0.17811632 -0.04214174 -0.04126911 -0.1390774   0.1945985 ]
 [-0.14187908  0.08771637  0.0606474   0.09562972  0.20613   ]
 [-0.11097841 -0.19621679 -0.13793233  0.17031085  0.02280061]
 [-0.11554322  0.11538962  0.02422424  0.02665459  0.11729988]
 [ 0.08157566 -0.19494452 -0.00293188 -0.10547577 -0.07991028]
 [ 0.07708636  0.07844412  0.14771539 -0.17016345  0.11220172]
 [ 0.00482884  0.0099214   0.19770342 -0.19969401 -0.07281421]
 [ 0.19110209  0.04319483 -0.07661897  0.20225286  0.20385268]
 [-0.1901401   0.1572423   0.19435051  0.01795684  0.20493728]
 [-0.02472633 -0.1766016  -0.15508977 -0.13827176 -0.02873106]
 [ 0.20946854 -0.03953612  0.20214567 -0.1200356   0.148024  ]
 [ 0.1570243   0.09810179 -0.14409259  0.13931677  0.11752924]
 [ 0.14339063 -0.09190609  0.15003443  0.17827499  0.15659776]
 [-0.19195831 -0.05016841 -0.14777052  0.16534403  0.05229822]
 [-0.11705886 -0.2104812  -0.1113696   0.06449899  0.04722697]
 [ 0.18216136  0.14589784  0.18173367  0.16715357 -0.12231058]
 [-0.12616137  0.19391856  0.03774464  0.18158731 -0.15628856]
 [-0.05105734  0.10110599 -0.04243752 -0.1288915  -0.07320835]
 [ 0.03611031  0.15455055 -0.17676476 -0.19416082  0.18190074]
 [-0.17306757 -0.01025274 -0.20883602  0.10454845 -0.18633923]
 [-0.01037544  0.09630013 -0.20794384 -0.16690251 -0.15348333]
 [-0.06067611  0.00537828  0.18328774 -0.15258965  0.08430681]
 [ 0.17956674  0.14627752  0.11088857 -0.04550608  0.14091474]
 [ 0.00516129  0.18900257 -0.11871927 -0.09590063  0.16513652]
 [ 0.18128896  0.19262311  0.13905707 -0.06069805  0.06233051]
 [ 0.19704843  0.08967695 -0.01543149 -0.08493789 -0.08106786]
 [ 0.1651392  -0.02378474 -0.09242225  0.07630759  0.14633322]
 [ 0.04226321  0.17378938 -0.01494196  0.17095986  0.01324721]
 [ 0.01446605 -0.20659314  0.20522699  0.04060963 -0.11757411]
 [ 0.02316481 -0.03690423 -0.18119405  0.01397155  0.00912413]
 [ 0.16147918 -0.03191279  0.08530289  0.03516182  0.09506533]
 [-0.1443633   0.02326696 -0.21053031  0.05429119 -0.08553042]
 [-0.1920017  -0.16221951  0.1877934   0.14260104  0.00435778]
 [-0.0778293  -0.07687688  0.0332149  -0.05663604  0.14386365]
 [-0.1048212   0.13202909  0.13704762  0.02542445  0.14820617]
 [-0.18758927 -0.12638383 -0.164499    0.06236723 -0.14122492]
 [-0.13806024  0.09983149  0.0474807  -0.12150116 -0.11947861]
 [ 0.08376557 -0.1348099   0.07039186  0.17725441  0.14971751]
 [-0.17293459 -0.17529753 -0.07023737 -0.04136781 -0.186266  ]
 [ 0.13078445  0.04815534 -0.01195033 -0.20249629  0.10353142]
 [ 0.16496018  0.18428513 -0.16142462  0.03560083  0.15392566]
 [-0.03165418  0.06789064  0.08991134 -0.10124093 -0.01006076]
 [ 0.1286656   0.06900474  0.1884391  -0.09244494 -0.18195254]
 [ 0.13844496  0.01049995 -0.12106065 -0.00341943  0.15692747]
 [-0.03782065  0.16825747 -0.00380693 -0.05254345 -0.18005142]
 [ 0.01992874  0.1563592  -0.1105139   0.18401054  0.07652706]
 [-0.05782369 -0.12739971  0.20137852 -0.00663732 -0.14410406]
 [-0.14864203  0.12634447  0.09152269  0.12486008 -0.20049188]
 [-0.02176063 -0.17487267 -0.20050845 -0.03146043 -0.16757697]
 [ 0.17097545  0.0952954   0.0750863   0.1264244   0.07353634]
 [-0.09625734  0.15204936 -0.16125736 -0.17843789 -0.15530534]
 [-0.08287969 -0.16840762  0.14791405  0.0167429   0.13199863]
 [-0.01463422 -0.21229424  0.08524972  0.18693966 -0.1784978 ]
 [ 0.095561    0.12785596  0.11775094 -0.08970352  0.1806716 ]
 [ 0.16996717  0.1666593   0.00960431  0.12974507 -0.2090286 ]
 [-0.15838681 -0.05195421 -0.19832714  0.1411165   0.10550955]
 [ 0.08508062 -0.18627548  0.03752279  0.01515596 -0.08315825]
 [-0.09481224 -0.17169225  0.14941865  0.08412871  0.07986733]
 [-0.15730646  0.07507679  0.15138203  0.0707899   0.19851172]
 [ 0.04343826 -0.03125989 -0.08985443 -0.08199349 -0.00492622]
 [ 0.00995812  0.10973537 -0.05657168 -0.03194743  0.19988936]
 [-0.07395431 -0.02883841 -0.0546101  -0.13578668  0.05086252]
 [ 0.2112974   0.12578931  0.20297915  0.16098598  0.07809779]
 [ 0.04575142 -0.05614838 -0.16816054  0.15892729 -0.12842697]
 [-0.1236062  -0.06226604  0.02850379  0.07179028 -0.02205773]
 [-0.12456171 -0.15822987  0.16889605 -0.0109742  -0.09680131]
 [ 0.19469875  0.01244584  0.00752033 -0.12521102  0.21067363]
 [ 0.06036484  0.16449988 -0.07530801  0.14880753 -0.01264484]
 [ 0.17718807 -0.06731197 -0.1620127   0.03783819  0.07202253]]: "
2018-04-20 09:34:46,040 (dqn_agent.py:161) DEBUG: "var_name: target_q/fully_connected_1/biases:0, var_value [0. 0. 0. 0. 0.]: "
2018-04-20 09:37:03,291 (dqn_main.py:212) DEBUG: "Episode 10000, mean reward over last 10000 episodes: -3.08805"
2018-04-20 09:37:03,291 (dqn_main.py:213) DEBUG: "Epsilon: 0.9957988000001383"
2018-04-20 09:37:03,291 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -1.5, done: True"
2018-04-20 09:37:03,291 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:40:19,977 (dqn_main.py:212) DEBUG: "Episode 20000, mean reward over last 10000 episodes: -3.12665"
2018-04-20 09:40:19,978 (dqn_main.py:213) DEBUG: "Epsilon: 0.9450010000018108"
2018-04-20 09:40:19,978 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -3.5, done: True"
2018-04-20 09:40:19,978 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:43:34,717 (dqn_main.py:212) DEBUG: "Episode 30000, mean reward over last 10000 episodes: -3.4039"
2018-04-20 09:43:34,717 (dqn_main.py:213) DEBUG: "Epsilon: 0.8869987000037204"
2018-04-20 09:43:34,717 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -1.5, done: True"
2018-04-20 09:43:34,717 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:47:05,353 (dqn_main.py:212) DEBUG: "Episode 40000, mean reward over last 10000 episodes: -3.5332"
2018-04-20 09:47:05,354 (dqn_main.py:213) DEBUG: "Epsilon: 0.8240365000057933"
2018-04-20 09:47:05,354 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -1.0, done: True"
2018-04-20 09:47:05,354 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:48:45,956 (dqn_main.py:212) DEBUG: "Episode 50000, mean reward over last 10000 episodes: -3.6699"
2018-04-20 09:48:45,956 (dqn_main.py:213) DEBUG: "Epsilon: 0.7525549000081467"
2018-04-20 09:48:45,956 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -1.0, done: True"
2018-04-20 09:48:45,956 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:50:21,265 (dqn_main.py:212) DEBUG: "Episode 60000, mean reward over last 10000 episodes: -3.90365"
2018-04-20 09:50:21,265 (dqn_main.py:213) DEBUG: "Epsilon: 0.6724297000107847"
2018-04-20 09:50:21,265 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -1.0, done: True"
2018-04-20 09:50:21,265 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:52:21,598 (dqn_main.py:212) DEBUG: "Episode 70000, mean reward over last 10000 episodes: -3.7785"
2018-04-20 09:52:21,598 (dqn_main.py:213) DEBUG: "Epsilon: 0.5773609000139147"
2018-04-20 09:52:21,598 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -7.0, done: True"
2018-04-20 09:52:21,598 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:55:00,234 (dqn_main.py:212) DEBUG: "Episode 80000, mean reward over last 10000 episodes: -3.6057"
2018-04-20 09:55:00,234 (dqn_main.py:213) DEBUG: "Epsilon: 0.4599820000153109"
2018-04-20 09:55:00,234 (dqn_main.py:214) DEBUG: "RL steps: [(2, 2), (4, 4)], reward: -6.5, done: True"
2018-04-20 09:55:00,234 (dqn_main.py:215) DEBUG: "Steps: 2, coords: 40"
2018-04-20 09:58:49,367 (dqn_main.py:212) DEBUG: "Episode 90000, mean reward over last 10000 episodes: -2.6885"
2018-04-20 09:58:49,368 (dqn_main.py:213) DEBUG: "Epsilon: 0.3071026000109148"
2018-04-20 09:58:49,368 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (2, 2), (2, 3), (2, 4), (3, 4), (4, 4), (3, 5), (4, 5), (4, 6), (5, 6), (6, 6)], reward: -2.5, done: True"
2018-04-20 09:58:49,368 (dqn_main.py:215) DEBUG: "Steps: 11, coords: 40"
2018-04-20 10:05:13,185 (dqn_main.py:212) DEBUG: "Episode 100000, mean reward over last 10000 episodes: -0.10565"
2018-04-20 10:05:13,185 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 10:05:13,185 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (3, 3), (2, 3), (2, 4), (3, 4), (4, 4), (4, 5), (4, 6), (5, 6), (6, 6), (7, 6), (8, 6)], reward: 4.0, done: True"
2018-04-20 10:05:13,185 (dqn_main.py:215) DEBUG: "Steps: 14, coords: 40"
2018-04-20 10:14:42,367 (dqn_main.py:212) DEBUG: "Episode 110000, mean reward over last 10000 episodes: 2.6384"
2018-04-20 10:14:42,367 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 10:14:42,367 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (2, 4), (2, 3), (3, 3), (3, 4), (4, 4), (4, 5), (4, 6), (5, 6), (6, 6), (6, 5), (6, 4), (7, 4), (8, 4), (9, 4)], reward: 6.5, done: True"
2018-04-20 10:14:42,367 (dqn_main.py:215) DEBUG: "Steps: 18, coords: 40"
2018-04-20 10:25:36,978 (dqn_main.py:212) DEBUG: "Episode 120000, mean reward over last 10000 episodes: 3.4174"
2018-04-20 10:25:36,978 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 10:25:36,978 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (2, 3)], reward: 0.5, done: True"
2018-04-20 10:25:36,979 (dqn_main.py:215) DEBUG: "Steps: 5, coords: 40"
2018-04-20 10:37:27,633 (dqn_main.py:212) DEBUG: "Episode 130000, mean reward over last 10000 episodes: 3.79635"
2018-04-20 10:37:27,633 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 10:37:27,633 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (2, 3), (3, 3), (3, 4), (2, 4), (2, 5), (2, 6), (3, 6), (3, 5), (4, 6), (4, 5), (5, 5), (5, 6), (6, 6), (6, 5), (7, 4), (8, 4), (9, 4), (9, 5)], reward: 8.0, done: True"
2018-04-20 10:37:27,634 (dqn_main.py:215) DEBUG: "Steps: 22, coords: 40"
2018-04-20 10:50:09,756 (dqn_main.py:212) DEBUG: "Episode 140000, mean reward over last 10000 episodes: 4.44635"
2018-04-20 10:50:09,757 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 10:50:09,757 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 3), (2, 2), (3, 3), (3, 4), (2, 4), (2, 5), (2, 6), (3, 6), (4, 6), (4, 5), (5, 5), (5, 6), (6, 6), (7, 6), (7, 5), (6, 5), (6, 4)], reward: 2.5, done: True"
2018-04-20 10:50:09,757 (dqn_main.py:215) DEBUG: "Steps: 20, coords: 40"
2018-04-20 11:03:35,687 (dqn_main.py:212) DEBUG: "Episode 150000, mean reward over last 10000 episodes: 4.72335"
2018-04-20 11:03:35,687 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 11:03:35,687 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (3, 3), (2, 3), (2, 4), (3, 4), (4, 4), (4, 5), (3, 5), (3, 6), (2, 5), (2, 7), (2, 6), (4, 6), (5, 6), (6, 6), (7, 6)], reward: 2.5, done: True"
2018-04-20 11:03:35,688 (dqn_main.py:215) DEBUG: "Steps: 18, coords: 40"
2018-04-20 11:17:15,334 (dqn_main.py:212) DEBUG: "Episode 160000, mean reward over last 10000 episodes: 4.9316"
2018-04-20 11:17:15,334 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 11:17:15,335 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (2, 3), (3, 3), (3, 4), (4, 4), (4, 5), (3, 5), (2, 5), (2, 6), (3, 6), (3, 7), (4, 6), (4, 7), (5, 6), (5, 5), (6, 5), (6, 6)], reward: 6.0, done: True"
2018-04-20 11:17:15,335 (dqn_main.py:215) DEBUG: "Steps: 20, coords: 40"
2018-04-20 11:30:47,592 (dqn_main.py:212) DEBUG: "Episode 170000, mean reward over last 10000 episodes: 5.2408"
2018-04-20 11:30:47,593 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 11:30:47,593 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (2, 2), (3, 1), (3, 2), (3, 3), (2, 3), (2, 4), (3, 4), (4, 4), (4, 5), (3, 5), (2, 5), (2, 6), (3, 6), (3, 7), (4, 7)], reward: 2.5, done: True"
2018-04-20 11:30:47,593 (dqn_main.py:215) DEBUG: "Steps: 16, coords: 40"
2018-04-20 11:45:34,179 (dqn_main.py:212) DEBUG: "Episode 180000, mean reward over last 10000 episodes: 5.43535"
2018-04-20 11:45:34,179 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 11:45:34,179 (dqn_main.py:214) DEBUG: "RL steps: [(2, 2), (2, 1), (3, 1), (3, 2), (3, 3), (2, 3), (2, 4), (3, 4), (3, 5), (2, 5), (2, 6), (3, 6), (3, 7), (4, 7), (4, 6), (4, 5), (5, 5), (5, 6), (6, 6), (6, 7), (7, 7), (7, 6), (7, 5), (6, 5), (6, 4), (7, 4), (7, 3), (8, 3), (8, 4), (9, 4), (9, 5), (8, 5), (8, 6)], reward: 7.5, done: True"
2018-04-20 11:45:34,179 (dqn_main.py:215) DEBUG: "Steps: 33, coords: 40"
2018-04-20 12:00:35,302 (dqn_main.py:212) DEBUG: "Episode 190000, mean reward over last 10000 episodes: 5.7005"
2018-04-20 12:00:35,302 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 12:00:35,302 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (2, 3), (3, 3), (3, 4), (2, 4), (2, 5), (3, 5), (3, 6), (2, 6), (2, 7), (3, 7), (4, 7)], reward: 1.5, done: True"
2018-04-20 12:00:35,302 (dqn_main.py:215) DEBUG: "Steps: 15, coords: 40"
2018-04-20 12:15:37,517 (dqn_main.py:212) DEBUG: "Episode 200000, mean reward over last 10000 episodes: 5.76895"
2018-04-20 12:15:37,517 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 12:15:37,517 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2)], reward: -0.5, done: True"
2018-04-20 12:15:37,517 (dqn_main.py:215) DEBUG: "Steps: 3, coords: 40"
2018-04-20 12:30:57,466 (dqn_main.py:212) DEBUG: "Episode 210000, mean reward over last 10000 episodes: 5.97795"
2018-04-20 12:30:57,466 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 12:30:57,466 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (2, 3), (3, 3), (3, 4), (2, 4), (2, 5), (3, 5), (3, 6), (2, 6), (2, 7), (3, 7), (4, 8), (4, 7), (4, 6), (4, 5), (5, 5), (5, 6)], reward: 3.5, done: True"
2018-04-20 12:30:57,466 (dqn_main.py:215) DEBUG: "Steps: 20, coords: 40"
2018-04-20 12:46:35,485 (dqn_main.py:212) DEBUG: "Episode 220000, mean reward over last 10000 episodes: 6.05335"
2018-04-20 12:46:35,485 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 12:46:35,485 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (2, 3), (3, 3), (3, 4), (2, 4), (2, 5), (3, 5), (3, 6), (2, 6), (2, 7), (3, 7), (3, 8), (4, 8), (4, 7), (4, 4), (4, 5), (4, 6), (5, 6), (6, 6), (6, 7), (7, 7), (7, 6), (7, 5), (6, 5), (6, 4), (7, 4), (7, 3), (8, 3), (8, 4), (9, 4), (9, 5), (8, 5), (8, 6)], reward: 10.0, done: True"
2018-04-20 12:46:35,485 (dqn_main.py:215) DEBUG: "Steps: 36, coords: 40"
2018-04-20 13:01:51,417 (dqn_main.py:212) DEBUG: "Episode 230000, mean reward over last 10000 episodes: 6.15015"
2018-04-20 13:01:51,417 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 13:01:51,418 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (2, 3), (3, 3), (2, 4), (3, 4), (3, 5), (2, 5), (2, 6), (2, 7), (3, 7), (3, 8), (4, 8), (4, 7), (4, 6), (4, 4), (4, 5), (5, 5), (5, 6), (6, 6), (6, 7), (7, 7), (7, 6), (7, 5), (6, 5), (6, 4), (7, 4), (7, 3), (8, 3), (9, 3), (9, 4), (9, 5), (8, 5), (8, 4), (8, 6)], reward: 8.0, done: True"
2018-04-20 13:01:51,418 (dqn_main.py:215) DEBUG: "Steps: 37, coords: 40"
2018-04-20 13:16:59,509 (dqn_main.py:212) DEBUG: "Episode 240000, mean reward over last 10000 episodes: 6.29485"
2018-04-20 13:16:59,509 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 13:16:59,509 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -1.0, done: True"
2018-04-20 13:16:59,509 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 13:31:40,713 (dqn_main.py:212) DEBUG: "Episode 250000, mean reward over last 10000 episodes: 6.1504"
2018-04-20 13:31:40,713 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 13:31:40,714 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (2, 3), (3, 3), (3, 4), (2, 4), (2, 5), (3, 5), (3, 6), (2, 6), (2, 7), (3, 7)], reward: 5.0, done: True"
2018-04-20 13:31:40,714 (dqn_main.py:215) DEBUG: "Steps: 14, coords: 40"
2018-04-20 13:46:53,801 (dqn_main.py:212) DEBUG: "Episode 260000, mean reward over last 10000 episodes: 6.2819"
2018-04-20 13:46:53,802 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 13:46:53,802 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (3, 3), (2, 3), (2, 4), (3, 4), (4, 4), (4, 5), (3, 5), (2, 5), (2, 6), (2, 7), (3, 7), (3, 8), (4, 8), (5, 8), (5, 7), (4, 7), (4, 6), (5, 6), (6, 6), (6, 7), (7, 7), (7, 6), (7, 5), (6, 4), (6, 5), (5, 5), (7, 4), (7, 3), (8, 3), (9, 3), (8, 4), (9, 4), (9, 5), (8, 5), (8, 6)], reward: 12.0, done: True"
2018-04-20 13:46:53,802 (dqn_main.py:215) DEBUG: "Steps: 38, coords: 40"
2018-04-20 14:01:26,111 (dqn_main.py:212) DEBUG: "Episode 270000, mean reward over last 10000 episodes: 6.3569"
2018-04-20 14:01:26,111 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 14:01:26,112 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 3), (3, 3), (3, 4), (2, 4), (2, 5), (3, 5), (2, 6), (2, 7), (3, 7), (3, 8), (4, 8), (5, 8), (5, 7), (4, 7), (4, 6), (4, 5), (5, 5), (5, 6), (6, 6), (6, 7), (7, 7), (7, 6), (7, 5), (6, 5), (6, 4), (7, 4), (7, 3), (8, 3), (9, 3), (9, 4), (9, 5), (8, 4), (8, 5), (8, 6)], reward: 8.0, done: True"
2018-04-20 14:01:26,112 (dqn_main.py:215) DEBUG: "Steps: 37, coords: 40"
2018-04-20 14:16:35,265 (dqn_main.py:212) DEBUG: "Episode 280000, mean reward over last 10000 episodes: 6.4843"
2018-04-20 14:16:35,265 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 14:16:35,265 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (2, 3), (3, 3), (4, 4), (3, 4)], reward: 0.5, done: True"
2018-04-20 14:16:35,265 (dqn_main.py:215) DEBUG: "Steps: 8, coords: 40"
2018-04-20 14:32:14,026 (dqn_main.py:212) DEBUG: "Episode 290000, mean reward over last 10000 episodes: 6.3553"
2018-04-20 14:32:14,026 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 14:32:14,026 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -1.0, done: True"
2018-04-20 14:32:14,026 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 14:47:53,518 (dqn_main.py:212) DEBUG: "Episode 300000, mean reward over last 10000 episodes: 6.41425"
2018-04-20 14:47:53,518 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 14:47:53,518 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (3, 3), (2, 3), (2, 4)], reward: 0.5, done: True"
2018-04-20 14:47:53,518 (dqn_main.py:215) DEBUG: "Steps: 7, coords: 40"
2018-04-20 15:03:53,088 (dqn_main.py:212) DEBUG: "Episode 310000, mean reward over last 10000 episodes: 6.5334"
2018-04-20 15:03:53,089 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 15:03:53,089 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 3), (3, 3), (3, 4), (2, 4), (2, 5), (3, 5), (3, 6), (2, 6), (2, 7), (3, 8), (4, 8)], reward: 3.0, done: True"
2018-04-20 15:03:53,089 (dqn_main.py:215) DEBUG: "Steps: 14, coords: 40"
2018-04-20 15:20:00,436 (dqn_main.py:212) DEBUG: "Episode 320000, mean reward over last 10000 episodes: 6.49055"
2018-04-20 15:20:00,436 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 15:20:00,436 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 2), (2, 2), (2, 3), (3, 3), (3, 4), (2, 4), (2, 5), (3, 5), (3, 6), (2, 6), (2, 7), (3, 7), (3, 8), (4, 8), (5, 8), (5, 7), (5, 6), (4, 6), (4, 7), (4, 5), (4, 4), (5, 5), (6, 5), (6, 6), (6, 7)], reward: 8.5, done: True"
2018-04-20 15:20:00,436 (dqn_main.py:215) DEBUG: "Steps: 26, coords: 40"
2018-04-20 15:35:56,114 (dqn_main.py:212) DEBUG: "Episode 330000, mean reward over last 10000 episodes: 6.4836"
2018-04-20 15:35:56,114 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 15:35:56,115 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (2, 3), (3, 3), (2, 4), (3, 4), (3, 5), (2, 5), (2, 6), (2, 7), (3, 7), (4, 8), (5, 8), (5, 7), (4, 7), (4, 6), (4, 5), (4, 4), (5, 5), (6, 6), (5, 6), (6, 7), (7, 7), (7, 6), (7, 5), (6, 5)], reward: 6.5, done: True"
2018-04-20 15:35:56,115 (dqn_main.py:215) DEBUG: "Steps: 28, coords: 40"
2018-04-20 15:51:59,379 (dqn_main.py:212) DEBUG: "Episode 340000, mean reward over last 10000 episodes: 6.4713"
2018-04-20 15:51:59,379 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 15:51:59,379 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (2, 3)], reward: 0.5, done: True"
2018-04-20 15:51:59,379 (dqn_main.py:215) DEBUG: "Steps: 5, coords: 40"
2018-04-20 16:08:03,724 (dqn_main.py:212) DEBUG: "Episode 350000, mean reward over last 10000 episodes: 6.4789"
2018-04-20 16:08:03,724 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 16:08:03,724 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (2, 2), (3, 2)], reward: -0.5, done: True"
2018-04-20 16:08:03,724 (dqn_main.py:215) DEBUG: "Steps: 3, coords: 40"
2018-04-20 16:24:01,588 (dqn_main.py:212) DEBUG: "Episode 360000, mean reward over last 10000 episodes: 6.53665"
2018-04-20 16:24:01,588 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 16:24:01,588 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (3, 3), (4, 4), (3, 4), (2, 4), (2, 5), (3, 5), (3, 6), (2, 6), (2, 7), (3, 7), (3, 8), (4, 8), (5, 8), (5, 7), (4, 7), (4, 6), (4, 5), (5, 5), (5, 6), (6, 6), (6, 7), (7, 7), (7, 6), (7, 5), (6, 5), (6, 4), (7, 4), (7, 3), (8, 3), (9, 3), (9, 4), (9, 5), (8, 4), (8, 5), (8, 6)], reward: 16.0, done: True"
2018-04-20 16:24:01,589 (dqn_main.py:215) DEBUG: "Steps: 39, coords: 40"
2018-04-20 16:39:55,825 (dqn_main.py:212) DEBUG: "Episode 370000, mean reward over last 10000 episodes: 6.4475"
2018-04-20 16:39:55,825 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 16:39:55,825 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -1.0, done: True"
2018-04-20 16:39:55,825 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 16:56:08,172 (dqn_main.py:212) DEBUG: "Episode 380000, mean reward over last 10000 episodes: 6.61415"
2018-04-20 16:56:08,172 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 16:56:08,172 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (2, 3), (3, 3), (3, 4), (2, 4), (2, 5), (3, 5)], reward: 1.0, done: True"
2018-04-20 16:56:08,172 (dqn_main.py:215) DEBUG: "Steps: 10, coords: 40"
2018-04-20 17:12:18,861 (dqn_main.py:212) DEBUG: "Episode 390000, mean reward over last 10000 episodes: 6.54555"
2018-04-20 17:12:18,861 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 17:12:18,861 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (2, 3), (3, 3), (3, 4), (2, 4), (2, 5), (3, 5), (3, 6), (2, 6), (2, 7), (3, 8), (3, 7), (4, 7), (4, 8), (5, 7), (5, 6), (4, 6), (4, 5), (4, 4), (5, 5), (6, 5), (6, 6), (7, 6), (8, 6), (7, 5), (7, 4), (6, 4)], reward: 6.5, done: True"
2018-04-20 17:12:18,862 (dqn_main.py:215) DEBUG: "Steps: 30, coords: 40"
2018-04-20 17:28:29,007 (dqn_main.py:212) DEBUG: "Episode 400000, mean reward over last 10000 episodes: 6.59295"
2018-04-20 17:28:29,007 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 17:28:29,007 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1)], reward: -2.0, done: True"
2018-04-20 17:28:29,007 (dqn_main.py:215) DEBUG: "Steps: 2, coords: 40"
2018-04-20 17:45:56,826 (dqn_main.py:212) DEBUG: "Episode 410000, mean reward over last 10000 episodes: 6.50785"
2018-04-20 17:45:56,826 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 17:45:56,826 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (2, 3), (3, 3), (3, 4), (2, 4), (2, 5), (4, 4), (4, 5), (3, 5), (3, 6), (2, 6), (2, 7), (3, 7), (4, 7), (3, 8), (4, 8), (5, 8), (5, 7), (4, 6), (5, 6), (5, 5), (6, 5), (6, 6), (6, 7), (7, 7), (7, 6), (7, 5), (7, 3), (7, 4), (8, 3), (9, 3), (9, 4), (9, 5), (8, 5), (8, 4), (8, 6)], reward: 10.5, done: True"
2018-04-20 17:45:56,827 (dqn_main.py:215) DEBUG: "Steps: 39, coords: 40"
2018-04-20 18:03:07,386 (dqn_main.py:212) DEBUG: "Episode 420000, mean reward over last 10000 episodes: 6.57815"
2018-04-20 18:03:07,386 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 18:03:07,386 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (2, 3), (3, 3), (3, 4), (2, 4), (2, 5), (3, 5), (3, 6), (2, 6), (2, 7), (3, 7), (3, 8), (4, 8), (5, 8), (5, 7), (4, 7), (4, 6), (4, 5), (4, 4), (5, 5), (5, 6), (6, 6), (6, 7), (7, 7), (7, 6), (7, 5), (7, 4), (6, 4), (6, 5), (7, 3), (9, 3), (8, 3), (8, 4)], reward: 9.0, done: True"
2018-04-20 18:03:07,386 (dqn_main.py:215) DEBUG: "Steps: 36, coords: 40"
2018-04-20 18:19:28,973 (dqn_main.py:212) DEBUG: "Episode 430000, mean reward over last 10000 episodes: 6.4471"
2018-04-20 18:19:28,973 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 18:19:28,973 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -1.5, done: True"
2018-04-20 18:19:28,973 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 18:36:40,479 (dqn_main.py:212) DEBUG: "Episode 440000, mean reward over last 10000 episodes: 6.607"
2018-04-20 18:36:40,479 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 18:36:40,479 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (2, 3), (3, 3), (3, 4), (2, 4), (2, 5), (3, 5), (3, 6), (2, 6), (2, 7)], reward: 1.0, done: True"
2018-04-20 18:36:40,479 (dqn_main.py:215) DEBUG: "Steps: 13, coords: 40"
2018-04-20 18:54:06,225 (dqn_main.py:212) DEBUG: "Episode 450000, mean reward over last 10000 episodes: 6.64775"
2018-04-20 18:54:06,225 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 18:54:06,225 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (2, 3), (3, 3), (3, 4), (2, 4), (2, 5), (3, 5), (3, 6), (2, 6), (2, 7), (3, 7), (3, 8), (4, 8), (5, 8), (5, 7), (4, 7), (4, 6), (4, 5), (4, 4), (5, 5), (5, 6), (6, 6), (6, 7), (7, 7), (7, 6), (7, 5), (6, 5), (6, 4), (7, 4), (7, 3), (8, 3), (9, 3), (9, 4), (9, 5), (8, 5), (8, 4), (8, 6)], reward: 14.0, done: True"
2018-04-20 18:54:06,225 (dqn_main.py:215) DEBUG: "Steps: 40, coords: 40"
2018-04-20 18:54:06,396 (tsp_computer.py:36) DEBUG: "tour"
2018-04-20 18:54:06,396 (dqn_main.py:217) DEBUG: "tsp_cost 42"
2018-04-20 19:10:34,224 (dqn_main.py:212) DEBUG: "Episode 460000, mean reward over last 10000 episodes: 6.56415"
2018-04-20 19:10:34,224 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 19:10:34,225 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 3), (3, 2), (2, 3), (2, 4), (3, 4), (4, 4), (4, 5), (3, 5), (2, 5), (2, 6), (2, 7), (3, 7), (3, 8), (4, 8), (5, 8), (5, 7), (4, 7), (4, 6), (5, 6), (5, 5), (6, 5), (6, 6), (6, 7), (7, 7), (7, 6), (7, 5), (7, 4), (6, 4), (7, 3), (8, 3), (8, 4), (9, 3), (9, 4), (9, 5), (8, 5), (8, 6)], reward: 9.5, done: True"
2018-04-20 19:10:34,225 (dqn_main.py:215) DEBUG: "Steps: 38, coords: 40"
2018-04-20 19:27:57,475 (dqn_main.py:212) DEBUG: "Episode 470000, mean reward over last 10000 episodes: 6.62885"
2018-04-20 19:27:57,476 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 19:27:57,476 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (2, 3), (3, 3), (3, 4), (4, 4), (2, 4), (2, 5), (3, 5), (3, 6), (2, 6), (2, 7), (3, 7), (3, 8), (4, 8), (5, 8), (5, 7)], reward: 7.0, done: True"
2018-04-20 19:27:57,476 (dqn_main.py:215) DEBUG: "Steps: 19, coords: 40"
2018-04-20 19:44:05,687 (dqn_main.py:212) DEBUG: "Episode 480000, mean reward over last 10000 episodes: 6.532"
2018-04-20 19:44:05,687 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 19:44:05,687 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1)], reward: -1.5, done: True"
2018-04-20 19:44:05,687 (dqn_main.py:215) DEBUG: "Steps: 1, coords: 40"
2018-04-20 20:00:37,645 (dqn_main.py:212) DEBUG: "Episode 490000, mean reward over last 10000 episodes: 6.4936"
2018-04-20 20:00:37,645 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 20:00:37,645 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (2, 3), (3, 3), (3, 4), (4, 4), (2, 4), (2, 5), (3, 5), (3, 6), (2, 6), (2, 7), (3, 7), (3, 8), (4, 8), (5, 8), (5, 7), (4, 7), (4, 6), (4, 5), (5, 6), (5, 5), (6, 5), (6, 6), (6, 7), (7, 7), (7, 6), (7, 5), (7, 4), (6, 4), (7, 3), (8, 3), (9, 3), (9, 4), (9, 5), (8, 4), (8, 5), (8, 6)], reward: 14.0, done: True"
2018-04-20 20:00:37,646 (dqn_main.py:215) DEBUG: "Steps: 40, coords: 40"
2018-04-20 20:00:37,929 (tsp_computer.py:36) DEBUG: "tour"
2018-04-20 20:00:37,929 (dqn_main.py:217) DEBUG: "tsp_cost 42"
2018-04-20 20:17:00,235 (dqn_main.py:212) DEBUG: "Episode 500000, mean reward over last 10000 episodes: 6.5385"
2018-04-20 20:17:00,236 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 20:17:00,236 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (2, 2), (3, 2), (3, 1), (3, 3), (2, 3), (2, 4), (2, 5), (3, 5), (3, 4), (4, 4), (4, 5), (3, 6), (3, 7), (2, 7), (2, 6), (3, 8), (4, 8), (5, 8), (5, 7), (4, 7), (4, 6), (5, 6), (5, 5), (6, 5), (6, 6), (6, 7), (7, 7), (7, 6), (7, 5), (6, 4), (7, 4), (7, 3), (8, 3), (9, 3), (9, 4), (8, 4), (9, 5), (8, 5), (8, 6)], reward: 11.0, done: True"
2018-04-20 20:17:00,236 (dqn_main.py:215) DEBUG: "Steps: 40, coords: 40"
2018-04-20 20:17:00,369 (tsp_computer.py:36) DEBUG: "tour"
2018-04-20 20:17:00,370 (dqn_main.py:217) DEBUG: "tsp_cost 42"
2018-04-20 20:33:06,107 (dqn_main.py:212) DEBUG: "Episode 510000, mean reward over last 10000 episodes: 6.451"
2018-04-20 20:33:06,107 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 20:33:06,107 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (2, 3), (3, 3), (4, 4), (3, 4), (2, 4), (2, 5), (3, 5), (3, 6), (2, 6), (2, 7), (3, 7), (3, 8), (4, 8), (5, 8), (5, 7), (4, 7), (4, 6), (4, 5), (5, 5), (5, 6), (6, 6), (6, 7), (7, 7), (7, 6), (7, 5), (6, 5), (6, 4), (7, 3), (7, 4), (8, 4), (8, 3), (9, 3), (9, 4), (9, 5), (8, 5), (8, 6)], reward: 17.0, done: True"
2018-04-20 20:33:06,107 (dqn_main.py:215) DEBUG: "Steps: 40, coords: 40"
2018-04-20 20:33:06,259 (tsp_computer.py:36) DEBUG: "tour"
2018-04-20 20:33:06,260 (dqn_main.py:217) DEBUG: "tsp_cost 42"
2018-04-20 20:49:45,203 (dqn_main.py:212) DEBUG: "Episode 520000, mean reward over last 10000 episodes: 6.57605"
2018-04-20 20:49:45,203 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 20:49:45,203 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (2, 3), (3, 3), (3, 4), (2, 4), (2, 5), (3, 5), (3, 6), (2, 6), (2, 7), (3, 7), (3, 8), (4, 8), (5, 8), (5, 7), (4, 7), (4, 6), (4, 4), (4, 5), (5, 5), (5, 6), (6, 6), (6, 7), (7, 7)], reward: 8.5, done: True"
2018-04-20 20:49:45,203 (dqn_main.py:215) DEBUG: "Steps: 27, coords: 40"
2018-04-20 21:06:55,961 (dqn_main.py:212) DEBUG: "Episode 530000, mean reward over last 10000 episodes: 6.69705"
2018-04-20 21:06:55,961 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 21:06:55,962 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (2, 3), (3, 3), (3, 4), (2, 4), (2, 5), (3, 5), (3, 6)], reward: 3.5, done: True"
2018-04-20 21:06:55,962 (dqn_main.py:215) DEBUG: "Steps: 11, coords: 40"
2018-04-20 21:23:53,406 (dqn_main.py:212) DEBUG: "Episode 540000, mean reward over last 10000 episodes: 6.565"
2018-04-20 21:23:53,407 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 21:23:53,407 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (2, 3), (3, 3), (3, 4), (2, 4), (2, 5), (4, 4), (4, 5), (3, 5), (3, 6), (2, 6), (2, 7), (3, 7), (3, 8), (4, 8), (5, 8), (5, 7), (4, 7), (4, 6), (5, 6), (5, 5), (6, 5), (6, 6), (6, 7), (7, 7), (7, 6), (7, 5), (6, 4), (7, 4), (7, 3), (8, 3), (9, 3), (9, 4), (9, 5), (8, 5), (8, 4), (8, 6)], reward: 12.0, done: True"
2018-04-20 21:23:53,407 (dqn_main.py:215) DEBUG: "Steps: 40, coords: 40"
2018-04-20 21:23:53,652 (tsp_computer.py:36) DEBUG: "tour"
2018-04-20 21:23:53,652 (dqn_main.py:217) DEBUG: "tsp_cost 42"
2018-04-20 21:41:00,070 (dqn_main.py:212) DEBUG: "Episode 550000, mean reward over last 10000 episodes: 6.5836"
2018-04-20 21:41:00,071 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 21:41:00,071 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (2, 3), (3, 3), (3, 4), (2, 4), (2, 5), (3, 5), (3, 6), (2, 6), (2, 7), (3, 7), (3, 8), (4, 8), (5, 8), (5, 7), (4, 7), (4, 6), (4, 5), (4, 4), (6, 4), (5, 6), (5, 5), (6, 6), (6, 7), (7, 7), (7, 6), (7, 5), (6, 5), (7, 4), (7, 3), (8, 3), (9, 3), (9, 4), (9, 5), (8, 4), (8, 5), (8, 6)], reward: 11.0, done: True"
2018-04-20 21:41:00,071 (dqn_main.py:215) DEBUG: "Steps: 40, coords: 40"
2018-04-20 21:41:00,382 (tsp_computer.py:36) DEBUG: "tour"
2018-04-20 21:41:00,382 (dqn_main.py:217) DEBUG: "tsp_cost 42"
2018-04-20 21:57:31,886 (dqn_main.py:212) DEBUG: "Episode 560000, mean reward over last 10000 episodes: 6.567"
2018-04-20 21:57:31,886 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 21:57:31,886 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (2, 3), (3, 3), (3, 4), (2, 4), (2, 5), (3, 5), (3, 6), (2, 6), (2, 7), (3, 7), (3, 8), (4, 8), (5, 8), (5, 7), (4, 7), (4, 6), (4, 5), (4, 4), (5, 5), (6, 4), (6, 5), (5, 6), (6, 6), (6, 7), (7, 7), (7, 6), (7, 5)], reward: 5.5, done: True"
2018-04-20 21:57:31,886 (dqn_main.py:215) DEBUG: "Steps: 31, coords: 40"
2018-04-20 22:14:36,162 (dqn_main.py:212) DEBUG: "Episode 570000, mean reward over last 10000 episodes: 6.63735"
2018-04-20 22:14:36,162 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 22:14:36,162 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1)], reward: -1.0, done: True"
2018-04-20 22:14:36,162 (dqn_main.py:215) DEBUG: "Steps: 2, coords: 40"
2018-04-20 22:31:16,037 (dqn_main.py:212) DEBUG: "Episode 580000, mean reward over last 10000 episodes: 6.56075"
2018-04-20 22:31:16,038 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 22:31:16,038 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1)], reward: -1.0, done: True"
2018-04-20 22:31:16,038 (dqn_main.py:215) DEBUG: "Steps: 2, coords: 40"
2018-04-20 22:47:32,729 (dqn_main.py:212) DEBUG: "Episode 590000, mean reward over last 10000 episodes: 6.56585"
2018-04-20 22:47:32,729 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 22:47:32,729 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (2, 3), (3, 3), (2, 4), (3, 4), (4, 4), (4, 5), (3, 5), (2, 5), (2, 6), (3, 6), (3, 7), (2, 7), (3, 8), (4, 8), (5, 8), (5, 7), (4, 6), (4, 7), (5, 6), (5, 5), (6, 5), (6, 6), (6, 7), (7, 7), (7, 6), (8, 6), (8, 5), (7, 5), (8, 4), (6, 4), (7, 4), (7, 3), (8, 3), (9, 3), (9, 4), (9, 5)], reward: 7.0, done: True"
2018-04-20 22:47:32,730 (dqn_main.py:215) DEBUG: "Steps: 40, coords: 40"
2018-04-20 22:47:32,997 (tsp_computer.py:36) DEBUG: "tour"
2018-04-20 22:47:32,997 (dqn_main.py:217) DEBUG: "tsp_cost 42"
2018-04-20 23:04:34,267 (dqn_main.py:212) DEBUG: "Episode 600000, mean reward over last 10000 episodes: 6.58005"
2018-04-20 23:04:34,267 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 23:04:34,267 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (2, 3), (3, 3), (3, 4), (2, 4), (2, 5), (3, 5), (3, 6), (2, 6), (2, 7), (3, 7), (3, 8), (4, 8), (5, 8), (5, 7), (4, 7), (4, 6), (4, 5), (4, 4), (6, 4), (6, 5), (5, 5), (5, 6), (6, 6), (6, 7)], reward: 8.0, done: True"
2018-04-20 23:04:34,267 (dqn_main.py:215) DEBUG: "Steps: 28, coords: 40"
2018-04-20 23:21:37,575 (dqn_main.py:212) DEBUG: "Episode 610000, mean reward over last 10000 episodes: 6.64055"
2018-04-20 23:21:37,575 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 23:21:37,576 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 3), (3, 2), (2, 2), (2, 3), (2, 4), (3, 4), (4, 4), (4, 5), (3, 5)], reward: 1.0, done: True"
2018-04-20 23:21:37,576 (dqn_main.py:215) DEBUG: "Steps: 11, coords: 40"
2018-04-20 23:35:50,717 (dqn_main.py:61) DEBUG: ">>>> RUNNING data_file=0_13.npy,reuse_weights=None,test=False<<<<"
2018-04-20 23:35:51,151 (tf_logging.py:160) Level 1: "Registering Batch (<function _BatchGrad at 0x7fcec2c35378>) in gradient."
2018-04-20 23:35:51,164 (tf_logging.py:160) Level 1: "Registering Unbatch (<function _UnbatchGrad at 0x7fcec2c35e18>) in gradient."
2018-04-20 23:35:51,189 (tf_logging.py:160) Level 1: "Registering ZeroInitializer (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,220 (tf_logging.py:160) Level 1: "Registering SparseFeatureCross (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,226 (tf_logging.py:160) Level 1: "Registering SparseFeatureCrossV2 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,229 (tf_logging.py:160) Level 1: "Registering SparseFeatureCross (None) in gradient."
2018-04-20 23:35:51,229 (tf_logging.py:160) Level 1: "Registering SparseFeatureCrossV2 (None) in gradient."
2018-04-20 23:35:51,235 (tf_logging.py:160) Level 1: "Registering GDNLowerBound (<function GDN._lower_bound_grad at 0x7fcec008a6a8>) in gradient."
2018-04-20 23:35:51,260 (tf_logging.py:160) Level 1: "Registering ObtainNext (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,277 (tf_logging.py:160) Level 1: "Registering hparams ((<class 'tensorflow.contrib.training.python.training.hparam_pb2.HParamDef'>, <function HParams.to_proto at 0x7fceba651620>, <function HParams.from_proto at 0x7fceba6516a8>)) in proto functions."
2018-04-20 23:35:51,286 (tf_logging.py:160) Level 1: "Registering GRUBlockCell (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,289 (tf_logging.py:160) Level 1: "Registering GRUBlockCellGrad (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,290 (tf_logging.py:160) Level 1: "Registering GRUBlockCell (<function _GRUBlockCellGrad at 0x7fceb8132b70>) in gradient."
2018-04-20 23:35:51,292 (tf_logging.py:160) Level 1: "Registering BlockLSTM (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,294 (tf_logging.py:160) Level 1: "Registering BlockLSTMGrad (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,295 (tf_logging.py:160) Level 1: "Registering LSTMBlockCell (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,296 (tf_logging.py:160) Level 1: "Registering LSTMBlockCellGrad (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,298 (tf_logging.py:160) Level 1: "Registering LSTMBlockCell (<function _LSTMBlockCellGrad at 0x7fceb80fbd90>) in gradient."
2018-04-20 23:35:51,298 (tf_logging.py:160) Level 1: "Registering BlockLSTM (<function _BlockLSTMGrad at 0x7fceb80fbe18>) in gradient."
2018-04-20 23:35:51,303 (tf_logging.py:160) Level 1: "Registering KMC2ChainInitialization (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,305 (tf_logging.py:160) Level 1: "Registering KmeansPlusPlusInitialization (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,306 (tf_logging.py:160) Level 1: "Registering NearestNeighbors (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,309 (tf_logging.py:160) Level 1: "Registering MaskedMatmul (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,311 (tf_logging.py:160) Level 1: "Registering WALSComputePartialLhsAndRhs (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,330 (tf_logging.py:160) Level 1: "Registering ConfigureDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,332 (tf_logging.py:160) Level 1: "Registering CrossReplicaSum (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,332 (tf_logging.py:160) Level 1: "Registering InfeedDequeue (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,333 (tf_logging.py:160) Level 1: "Registering InfeedDequeueTuple (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,333 (tf_logging.py:160) Level 1: "Registering InfeedEnqueue (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,334 (tf_logging.py:160) Level 1: "Registering InfeedEnqueueTuple (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,334 (tf_logging.py:160) Level 1: "Registering OutfeedDequeue (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,334 (tf_logging.py:160) Level 1: "Registering OutfeedDequeueTuple (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,335 (tf_logging.py:160) Level 1: "Registering OutfeedEnqueue (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,335 (tf_logging.py:160) Level 1: "Registering OutfeedEnqueueTuple (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,335 (tf_logging.py:160) Level 1: "Registering ShutdownDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,336 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingActivations (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,336 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingEnqueueSparseBatch (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,337 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingLoadAdagradParameters (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,337 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingLoadGradientDescentParameters (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,337 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingReceiveActivations (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,338 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingRetrieveAdagradParameters (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,338 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingRetrieveGradientDescentParameters (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,339 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingSendGradients (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,339 (tf_logging.py:160) Level 1: "Registering TPUReplicate (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,340 (tf_logging.py:160) Level 1: "Registering TPUReplicateMetadata (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,340 (tf_logging.py:160) Level 1: "Registering TPUReplicatedInput (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,340 (tf_logging.py:160) Level 1: "Registering TPUReplicatedOutput (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,345 (tf_logging.py:160) Level 1: "Registering _ConfigureDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,346 (tf_logging.py:160) Level 1: "Registering _WaitForDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,346 (tf_logging.py:160) Level 1: "Registering _SetGlobalTPUArray (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,347 (tf_logging.py:160) Level 1: "Registering _ShutdownDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,347 (tf_logging.py:160) Level 1: "Registering _InitializeHostForDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,348 (tf_logging.py:160) Level 1: "Registering _DisconnectHostFromDistributedTPUSystem (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,350 (tf_logging.py:160) Level 1: "Registering CrossReplicaSum (<function _cross_replica_sum_grad at 0x7fce797fe400>) in gradient."
2018-04-20 23:35:51,357 (tf_logging.py:160) Level 1: "Registering CloseSummaryWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,359 (tf_logging.py:160) Level 1: "Registering CreateSummaryDbWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,360 (tf_logging.py:160) Level 1: "Registering CreateSummaryFileWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,360 (tf_logging.py:160) Level 1: "Registering FlushSummaryWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,361 (tf_logging.py:160) Level 1: "Registering ImportEvent (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,362 (tf_logging.py:160) Level 1: "Registering SummaryWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,362 (tf_logging.py:160) Level 1: "Registering WriteAudioSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,363 (tf_logging.py:160) Level 1: "Registering WriteGraphSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,364 (tf_logging.py:160) Level 1: "Registering WriteHistogramSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,365 (tf_logging.py:160) Level 1: "Registering WriteImageSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,365 (tf_logging.py:160) Level 1: "Registering WriteScalarSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,366 (tf_logging.py:160) Level 1: "Registering WriteSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,395 (tf_logging.py:160) Level 1: "Registering BigQueryReader (None) in gradient."
2018-04-20 23:35:51,399 (tf_logging.py:160) Level 1: "Registering RangeDecode (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,401 (tf_logging.py:160) Level 1: "Registering RangeEncode (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,459 (tf_logging.py:160) Level 1: "Registering CudnnRNN (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,464 (tf_logging.py:160) Level 1: "Registering CudnnRNNBackprop (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,464 (tf_logging.py:160) Level 1: "Registering CudnnRNNCanonicalToParams (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,465 (tf_logging.py:160) Level 1: "Registering CudnnRNNParamsSize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,467 (tf_logging.py:160) Level 1: "Registering CudnnRNNParamsToCanonical (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,482 (tf_logging.py:160) Level 1: "Registering CudnnRNN (<function _cudnn_rnn_backward at 0x7fce791016a8>) in gradient."
2018-04-20 23:35:51,482 (tf_logging.py:160) Level 1: "Registering CudnnRNNParamsSize (<function call_cpp_shape_fn at 0x7fcf2e3b0840>) in shape functions."
2018-04-20 23:35:51,483 (tf_logging.py:160) Level 1: "Registering CudnnRNNParamsToCanonical (<function call_cpp_shape_fn at 0x7fcf2e3b0840>) in shape functions."
2018-04-20 23:35:51,483 (tf_logging.py:160) Level 1: "Registering CudnnRNNCanonicalToParams (<function call_cpp_shape_fn at 0x7fcf2e3b0840>) in shape functions."
2018-04-20 23:35:51,483 (tf_logging.py:160) Level 1: "Registering CudnnRNN (<function call_cpp_shape_fn at 0x7fcf2e3b0840>) in shape functions."
2018-04-20 23:35:51,484 (tf_logging.py:160) Level 1: "Registering CudnnRNNBackprop (<function call_cpp_shape_fn at 0x7fcf2e3b0840>) in shape functions."
2018-04-20 23:35:51,535 (tf_logging.py:160) Level 1: "Registering AdjustHsvInYiq (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,539 (tf_logging.py:160) Level 1: "Registering BipartiteMatch (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,540 (tf_logging.py:160) Level 1: "Registering ImageConnectedComponents (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,541 (tf_logging.py:160) Level 1: "Registering ImageProjectiveTransform (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,544 (tf_logging.py:160) Level 1: "Registering ImageConnectedComponents (<function call_cpp_shape_fn at 0x7fcf2e3b0840>) in shape functions."
2018-04-20 23:35:51,545 (tf_logging.py:160) Level 1: "Registering ImageProjectiveTransform (<function call_cpp_shape_fn at 0x7fcf2e3b0840>) in shape functions."
2018-04-20 23:35:51,546 (tf_logging.py:160) Level 1: "Registering ImageProjectiveTransform (<function _image_projective_transform_grad at 0x7fce78a22b70>) in gradient."
2018-04-20 23:35:51,547 (tf_logging.py:160) Level 1: "Registering BipartiteMatch (None) in gradient."
2018-04-20 23:35:51,547 (tf_logging.py:160) Level 1: "Registering ImageConnectedComponents (None) in gradient."
2018-04-20 23:35:51,549 (tf_logging.py:160) Level 1: "Registering SingleImageRandomDotStereograms (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,555 (tf_logging.py:160) Level 1: "Registering SingleImageRandomDotStereograms (None) in gradient."
2018-04-20 23:35:51,602 (tf_logging.py:160) Level 1: "Registering BytesInUse (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,603 (tf_logging.py:160) Level 1: "Registering BytesLimit (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,604 (tf_logging.py:160) Level 1: "Registering MaxBytesInUse (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,612 (tf_logging.py:160) Level 1: "Registering NcclAllReduce (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,613 (tf_logging.py:160) Level 1: "Registering NcclBroadcast (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,613 (tf_logging.py:160) Level 1: "Registering NcclReduce (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,616 (tf_logging.py:160) Level 1: "Registering _NcclReduceSend (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,617 (tf_logging.py:160) Level 1: "Registering _NcclReduceRecv (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,617 (tf_logging.py:160) Level 1: "Registering _NcclBroadcastSend (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,617 (tf_logging.py:160) Level 1: "Registering _NcclBroadcastRecv (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,618 (tf_logging.py:160) Level 1: "Registering NcclAllReduce (<function _all_sum_grad at 0x7fce780d3950>) in gradient."
2018-04-20 23:35:51,618 (tf_logging.py:160) Level 1: "Registering NcclReduce (<function _reduce_sum_grad at 0x7fce780d3bf8>) in gradient."
2018-04-20 23:35:51,618 (tf_logging.py:160) Level 1: "Registering NcclBroadcast (<function _broadcast_grad at 0x7fce780d3d90>) in gradient."
2018-04-20 23:35:51,620 (tf_logging.py:160) Level 1: "Registering PeriodicResample (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,631 (tf_logging.py:160) Level 1: "Registering FoldFusedBatchNormGrad (<function _FoldFusedBatchNormGrad at 0x7fce7808f048>) in gradient."
2018-04-20 23:35:51,636 (tf_logging.py:160) Level 1: "Registering Resampler (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,638 (tf_logging.py:160) Level 1: "Registering ResamplerGrad (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,640 (tf_logging.py:160) Level 1: "Registering Resampler (<function _resampler_grad at 0x7fce78036c80>) in gradient."
2018-04-20 23:35:51,641 (tf_logging.py:160) Level 1: "Registering ResamplerGrad (None) in gradient."
2018-04-20 23:35:51,648 (tf_logging.py:160) Level 1: "Registering GatherTree (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,662 (tf_logging.py:160) Level 1: "Registering StatelessRandomNormal (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,663 (tf_logging.py:160) Level 1: "Registering StatelessRandomUniform (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,664 (tf_logging.py:160) Level 1: "Registering StatelessTruncatedNormal (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,664 (tf_logging.py:160) Level 1: "Registering StatelessRandomNormal (None) in gradient."
2018-04-20 23:35:51,664 (tf_logging.py:160) Level 1: "Registering StatelessRandomUniform (None) in gradient."
2018-04-20 23:35:51,665 (tf_logging.py:160) Level 1: "Registering StatelessTruncatedNormal (None) in gradient."
2018-04-20 23:35:51,673 (tf_logging.py:160) Level 1: "Registering ReinterpretStringToFloat (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,676 (tf_logging.py:160) Level 1: "Registering ScatterAddNdim (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,683 (tf_logging.py:160) Level 1: "Registering CreateTreeVariable (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,684 (tf_logging.py:160) Level 1: "Registering DecisionTreeResourceHandleOp (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,685 (tf_logging.py:160) Level 1: "Registering FeatureUsageCounts (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,685 (tf_logging.py:160) Level 1: "Registering TraverseTreeV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,686 (tf_logging.py:160) Level 1: "Registering TreeDeserialize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,686 (tf_logging.py:160) Level 1: "Registering TreeIsInitializedOp (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,687 (tf_logging.py:160) Level 1: "Registering TreePredictionsV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,687 (tf_logging.py:160) Level 1: "Registering TreeSerialize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,688 (tf_logging.py:160) Level 1: "Registering TreeSize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,688 (tf_logging.py:160) Level 1: "Registering UpdateModelV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,692 (tf_logging.py:160) Level 1: "Registering TreeVariable (None) in gradient."
2018-04-20 23:35:51,693 (tf_logging.py:160) Level 1: "Registering TreeSerialize (None) in gradient."
2018-04-20 23:35:51,693 (tf_logging.py:160) Level 1: "Registering TreeDeserialize (None) in gradient."
2018-04-20 23:35:51,693 (tf_logging.py:160) Level 1: "Registering TreeSize (None) in gradient."
2018-04-20 23:35:51,694 (tf_logging.py:160) Level 1: "Registering TreePredictionsV4 (None) in gradient."
2018-04-20 23:35:51,694 (tf_logging.py:160) Level 1: "Registering FeatureUsageCounts (None) in gradient."
2018-04-20 23:35:51,696 (tf_logging.py:160) Level 1: "Registering CreateFertileStatsVariable (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,697 (tf_logging.py:160) Level 1: "Registering FertileStatsDeserialize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,698 (tf_logging.py:160) Level 1: "Registering FertileStatsIsInitializedOp (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,699 (tf_logging.py:160) Level 1: "Registering FertileStatsResourceHandleOp (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,699 (tf_logging.py:160) Level 1: "Registering FertileStatsSerialize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,700 (tf_logging.py:160) Level 1: "Registering FinalizeTree (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,700 (tf_logging.py:160) Level 1: "Registering GrowTreeV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,701 (tf_logging.py:160) Level 1: "Registering ProcessInputV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,704 (tf_logging.py:160) Level 1: "Registering FertileStatsVariable (None) in gradient."
2018-04-20 23:35:51,705 (tf_logging.py:160) Level 1: "Registering FertileStatsSerialize (None) in gradient."
2018-04-20 23:35:51,705 (tf_logging.py:160) Level 1: "Registering FertileStatsDeserialize (None) in gradient."
2018-04-20 23:35:51,705 (tf_logging.py:160) Level 1: "Registering GrowTreeV4 (None) in gradient."
2018-04-20 23:35:51,706 (tf_logging.py:160) Level 1: "Registering ProcessInputV4 (None) in gradient."
2018-04-20 23:35:51,706 (tf_logging.py:160) Level 1: "Registering FinalizeTree (None) in gradient."
2018-04-20 23:35:51,731 (tf_logging.py:160) Level 1: "Registering FunctionBufferingResource (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,732 (tf_logging.py:160) Level 1: "Registering FunctionBufferingResourceGetNext (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,748 (tf_logging.py:160) Level 1: "Registering RemoteFusedGraphExecute (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fcf2e3b0950>) in default shape functions."
2018-04-20 23:35:51,750 (tf_logging.py:160) Level 1: "Registering RemoteFusedGraphExecute (None) in gradient."
2018-04-20 23:35:51,759 (tf_logging.py:160) Level 1: "Created variable q/Conv/weights:0 with shape (1, 1, 2, 8) and init <function variance_scaling_initializer.<locals>._initializer at 0x7fcec0079510>"
2018-04-20 23:35:51,763 (tf_logging.py:160) Level 1: "Created variable q/Conv/biases:0 with shape (8,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fcec007c278>"
2018-04-20 23:35:51,770 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/weights:0 with shape (3, 3, 8, 12) and init <function variance_scaling_initializer.<locals>._initializer at 0x7fcec0079510>"
2018-04-20 23:35:51,773 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/biases:0 with shape (12,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fcec007c278>"
2018-04-20 23:35:51,781 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/weights:0 with shape (3, 3, 12, 16) and init <function variance_scaling_initializer.<locals>._initializer at 0x7fcec0079510>"
2018-04-20 23:35:51,785 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/biases:0 with shape (16,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fcec007c278>"
2018-04-20 23:35:51,796 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/weights:0 with shape (576, 128) and init <function variance_scaling_initializer.<locals>._initializer at 0x7fcec008a2f0>"
2018-04-20 23:35:51,799 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/biases:0 with shape (128,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fcec007c668>"
2018-04-20 23:35:51,806 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/weights:0 with shape (128, 5) and init <function variance_scaling_initializer.<locals>._initializer at 0x7fcec008a2f0>"
2018-04-20 23:35:51,809 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/biases:0 with shape (5,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fcec007c668>"
2018-04-20 23:35:51,816 (tf_logging.py:160) Level 1: "Created variable target_q/Conv/weights:0 with shape (1, 1, 2, 8) and init <function variance_scaling_initializer.<locals>._initializer at 0x7fcec0079510>"
2018-04-20 23:35:51,819 (tf_logging.py:160) Level 1: "Created variable target_q/Conv/biases:0 with shape (8,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fcec007c278>"
2018-04-20 23:35:51,826 (tf_logging.py:160) Level 1: "Created variable target_q/Conv_1/weights:0 with shape (3, 3, 8, 12) and init <function variance_scaling_initializer.<locals>._initializer at 0x7fcec0079510>"
2018-04-20 23:35:51,831 (tf_logging.py:160) Level 1: "Created variable target_q/Conv_1/biases:0 with shape (12,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fcec007c278>"
2018-04-20 23:35:51,840 (tf_logging.py:160) Level 1: "Created variable target_q/Conv_2/weights:0 with shape (3, 3, 12, 16) and init <function variance_scaling_initializer.<locals>._initializer at 0x7fcec0079510>"
2018-04-20 23:35:51,844 (tf_logging.py:160) Level 1: "Created variable target_q/Conv_2/biases:0 with shape (16,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fcec007c278>"
2018-04-20 23:35:51,857 (tf_logging.py:160) Level 1: "Created variable target_q/fully_connected/weights:0 with shape (576, 128) and init <function variance_scaling_initializer.<locals>._initializer at 0x7fcec008a2f0>"
2018-04-20 23:35:51,861 (tf_logging.py:160) Level 1: "Created variable target_q/fully_connected/biases:0 with shape (128,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fcec007c668>"
2018-04-20 23:35:51,868 (tf_logging.py:160) Level 1: "Created variable target_q/fully_connected_1/weights:0 with shape (128, 5) and init <function variance_scaling_initializer.<locals>._initializer at 0x7fcec008a2f0>"
2018-04-20 23:35:51,872 (tf_logging.py:160) Level 1: "Created variable target_q/fully_connected_1/biases:0 with shape (5,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fcec007c668>"
2018-04-20 23:35:51,900 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/value'"
2018-04-20 23:35:51,900 (tf_logging.py:160) Level 1: "  in  --> gradients/Fill:0"
2018-04-20 23:35:51,901 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/value_grad/tuple/control_dependency:0, gradients/mean_squared_error/value_grad/tuple/control_dependency_1:0"
2018-04-20 23:35:51,907 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/div'"
2018-04-20 23:35:51,907 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/value_grad/tuple/control_dependency:0"
2018-04-20 23:35:51,908 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/div_grad/tuple/control_dependency:0, gradients/mean_squared_error/div_grad/tuple/control_dependency_1:0"
2018-04-20 23:35:51,909 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/Sum_1'"
2018-04-20 23:35:51,910 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/div_grad/tuple/control_dependency:0"
2018-04-20 23:35:51,910 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/Sum_1_grad/Tile:0"
2018-04-20 23:35:51,913 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/Select'"
2018-04-20 23:35:51,913 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/div_grad/tuple/control_dependency_1:0"
2018-04-20 23:35:51,913 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/Select_grad/tuple/control_dependency:0, gradients/mean_squared_error/Select_grad/tuple/control_dependency_1:0"
2018-04-20 23:35:51,915 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/Sum'"
2018-04-20 23:35:51,916 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/Sum_1_grad/Tile:0"
2018-04-20 23:35:51,916 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/Sum_grad/Tile:0"
2018-04-20 23:35:51,922 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/Mul'"
2018-04-20 23:35:51,922 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/Sum_grad/Tile:0"
2018-04-20 23:35:51,922 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/Mul_grad/tuple/control_dependency:0, gradients/mean_squared_error/Mul_grad/tuple/control_dependency_1:0"
2018-04-20 23:35:51,924 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/num_present'"
2018-04-20 23:35:51,924 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/Select_grad/tuple/control_dependency_1:0"
2018-04-20 23:35:51,924 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/num_present_grad/Tile:0"
2018-04-20 23:35:51,930 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/num_present/broadcast_weights'"
2018-04-20 23:35:51,930 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/num_present_grad/Tile:0"
2018-04-20 23:35:51,930 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/num_present/broadcast_weights_grad/tuple/control_dependency:0, gradients/mean_squared_error/num_present/broadcast_weights_grad/tuple/control_dependency_1:0"
2018-04-20 23:35:51,932 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/num_present/broadcast_weights/ones_like'"
2018-04-20 23:35:51,932 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/num_present/broadcast_weights_grad/tuple/control_dependency_1:0"
2018-04-20 23:35:51,932 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/num_present/broadcast_weights/ones_like_grad/Sum:0"
2018-04-20 23:35:51,938 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/SquaredDifference'"
2018-04-20 23:35:51,938 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/Mul_grad/tuple/control_dependency:0"
2018-04-20 23:35:51,939 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/SquaredDifference_grad/tuple/control_dependency:0, gradients/mean_squared_error/SquaredDifference_grad/tuple/control_dependency_1:0"
2018-04-20 23:35:51,946 (tf_logging.py:160) Level 1: "Gradient for 'Sum'"
2018-04-20 23:35:51,946 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/SquaredDifference_grad/tuple/control_dependency:0"
2018-04-20 23:35:51,946 (tf_logging.py:160) Level 1: "  out --> gradients/Sum_grad/Tile:0"
2018-04-20 23:35:51,952 (tf_logging.py:160) Level 1: "Gradient for 'mul'"
2018-04-20 23:35:51,952 (tf_logging.py:160) Level 1: "  in  --> gradients/Sum_grad/Tile:0"
2018-04-20 23:35:51,952 (tf_logging.py:160) Level 1: "  out --> gradients/mul_grad/tuple/control_dependency:0, gradients/mul_grad/tuple/control_dependency_1:0"
2018-04-20 23:35:51,954 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected_1/BiasAdd'"
2018-04-20 23:35:51,954 (tf_logging.py:160) Level 1: "  in  --> gradients/mul_grad/tuple/control_dependency:0"
2018-04-20 23:35:51,954 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency:0, gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 23:35:51,957 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected_1/MatMul'"
2018-04-20 23:35:51,957 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 23:35:51,957 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency:0, gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 23:35:51,957 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected_1/biases/read'"
2018-04-20 23:35:51,957 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 23:35:51,957 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 23:35:51,958 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/Relu'"
2018-04-20 23:35:51,958 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency:0"
2018-04-20 23:35:51,958 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/Relu_grad/ReluGrad:0"
2018-04-20 23:35:51,959 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected_1/weights/read'"
2018-04-20 23:35:51,959 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 23:35:51,959 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 23:35:51,960 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/BiasAdd'"
2018-04-20 23:35:51,960 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/Relu_grad/ReluGrad:0"
2018-04-20 23:35:51,961 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency:0, gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 23:35:51,963 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/MatMul'"
2018-04-20 23:35:51,963 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 23:35:51,963 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/MatMul_grad/tuple/control_dependency:0, gradients/q/fully_connected/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 23:35:51,963 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/biases/read'"
2018-04-20 23:35:51,963 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 23:35:51,963 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 23:35:51,964 (tf_logging.py:160) Level 1: "Gradient for 'q/Flatten/flatten/Reshape'"
2018-04-20 23:35:51,964 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/MatMul_grad/tuple/control_dependency:0"
2018-04-20 23:35:51,964 (tf_logging.py:160) Level 1: "  out --> gradients/q/Flatten/flatten/Reshape_grad/Reshape:0"
2018-04-20 23:35:51,964 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/weights/read'"
2018-04-20 23:35:51,965 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 23:35:51,965 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 23:35:51,965 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/Relu'"
2018-04-20 23:35:51,965 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Flatten/flatten/Reshape_grad/Reshape:0"
2018-04-20 23:35:51,965 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/Relu_grad/ReluGrad:0"
2018-04-20 23:35:51,967 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/BiasAdd'"
2018-04-20 23:35:51,967 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/Relu_grad/ReluGrad:0"
2018-04-20 23:35:51,967 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency:0, gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 23:35:51,970 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/Conv2D'"
2018-04-20 23:35:51,970 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 23:35:51,970 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency:0, gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 23:35:51,971 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/biases/read'"
2018-04-20 23:35:51,971 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 23:35:51,971 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 23:35:51,971 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/Relu'"
2018-04-20 23:35:51,971 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency:0"
2018-04-20 23:35:51,972 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/Relu_grad/ReluGrad:0"
2018-04-20 23:35:51,972 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/weights/read'"
2018-04-20 23:35:51,972 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 23:35:51,972 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 23:35:51,973 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/BiasAdd'"
2018-04-20 23:35:51,974 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/Relu_grad/ReluGrad:0"
2018-04-20 23:35:51,974 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency:0, gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 23:35:51,977 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/Conv2D'"
2018-04-20 23:35:51,977 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 23:35:51,977 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency:0, gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 23:35:51,977 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/biases/read'"
2018-04-20 23:35:51,978 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 23:35:51,978 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 23:35:51,978 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/Relu'"
2018-04-20 23:35:51,978 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency:0"
2018-04-20 23:35:51,978 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/Relu_grad/ReluGrad:0"
2018-04-20 23:35:51,979 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/weights/read'"
2018-04-20 23:35:51,979 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 23:35:51,979 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 23:35:51,980 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/BiasAdd'"
2018-04-20 23:35:51,980 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv/Relu_grad/ReluGrad:0"
2018-04-20 23:35:51,980 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/BiasAdd_grad/tuple/control_dependency:0, gradients/q/Conv/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 23:35:51,984 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/Conv2D'"
2018-04-20 23:35:51,984 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 23:35:51,984 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/Conv2D_grad/tuple/control_dependency:0, gradients/q/Conv/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 23:35:51,984 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/biases/read'"
2018-04-20 23:35:51,984 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 23:35:51,984 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 23:35:51,985 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/weights/read'"
2018-04-20 23:35:51,985 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 23:35:51,985 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 23:35:52,065 (tf_logging.py:126) WARNING: "From /home/syedeqbal/.local/lib/python3.5/site-packages/tensorflow/python/ops/clip_ops.py:113: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead"
2018-04-20 23:35:52,162 (tf_logging.py:160) Level 1: "Created variable q/Conv/weights/Adam:0 with shape (1, 1, 2, 8) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fce70c033c8>"
2018-04-20 23:35:52,166 (tf_logging.py:160) Level 1: "Created variable q/Conv/weights/Adam_1:0 with shape (1, 1, 2, 8) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fce70c033c8>"
2018-04-20 23:35:52,183 (tf_logging.py:160) Level 1: "Created variable q/Conv/biases/Adam:0 with shape (8,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fce70c033c8>"
2018-04-20 23:35:52,187 (tf_logging.py:160) Level 1: "Created variable q/Conv/biases/Adam_1:0 with shape (8,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fce70c033c8>"
2018-04-20 23:35:52,191 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/weights/Adam:0 with shape (3, 3, 8, 12) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fce70c033c8>"
2018-04-20 23:35:52,195 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/weights/Adam_1:0 with shape (3, 3, 8, 12) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fce70c033c8>"
2018-04-20 23:35:52,198 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/biases/Adam:0 with shape (12,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fce70c1fa90>"
2018-04-20 23:35:52,202 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/biases/Adam_1:0 with shape (12,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fce70c1fa90>"
2018-04-20 23:35:52,206 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/weights/Adam:0 with shape (3, 3, 12, 16) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fce70c1fa90>"
2018-04-20 23:35:52,210 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/weights/Adam_1:0 with shape (3, 3, 12, 16) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fce70c1fa90>"
2018-04-20 23:35:52,213 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/biases/Adam:0 with shape (16,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fce70c1fa90>"
2018-04-20 23:35:52,217 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/biases/Adam_1:0 with shape (16,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fce70c1fa90>"
2018-04-20 23:35:52,221 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/weights/Adam:0 with shape (576, 128) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fce70c1fa90>"
2018-04-20 23:35:52,225 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/weights/Adam_1:0 with shape (576, 128) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fce70c1fa90>"
2018-04-20 23:35:52,228 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/biases/Adam:0 with shape (128,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fce70c1fa90>"
2018-04-20 23:35:52,232 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/biases/Adam_1:0 with shape (128,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fce70c1fa90>"
2018-04-20 23:35:52,236 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/weights/Adam:0 with shape (128, 5) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fce70c1fa90>"
2018-04-20 23:35:52,239 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/weights/Adam_1:0 with shape (128, 5) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fce70c1fa90>"
2018-04-20 23:35:52,243 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/biases/Adam:0 with shape (5,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fce70c1fa90>"
2018-04-20 23:35:52,247 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/biases/Adam_1:0 with shape (5,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fce70c1fa90>"
2018-04-20 23:35:52,351 (dqn_agent.py:161) DEBUG: "var_name: q/Conv/weights:0, var_value [[[[ 0.10241663  0.29239368  0.5257293   0.58401763 -0.34008738
    -0.31810182  0.04391998  0.24438548]
   [-0.491535    0.57338285  0.48198736 -0.08004802 -0.27636507
    -0.15062743 -0.03651714 -0.0926128 ]]]]: "
2018-04-20 23:35:52,355 (dqn_agent.py:161) DEBUG: "var_name: q/Conv/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 23:35:52,364 (dqn_agent.py:161) DEBUG: "var_name: q/Conv_1/weights:0, var_value [[[[ 0.04930386  0.12817636 -0.11733994 -0.11633207  0.08124065
    -0.05393888  0.12567046  0.09253716  0.07434395 -0.06923138
    -0.12568355 -0.09801546]
   [ 0.03628519  0.13854635  0.0221318   0.03164782 -0.04159643
    -0.13146052 -0.08889138 -0.14103474 -0.0840869  -0.0276639
    -0.03240192 -0.12190853]
   [ 0.03637007  0.18111295 -0.09941057  0.16764653  0.12172431
     0.02495553  0.13351104  0.06918329  0.14316666  0.06112684
    -0.00468208 -0.05249912]
   [-0.15472028 -0.13117039 -0.04071204 -0.11561336  0.11802879
    -0.16008702 -0.06079171  0.14545229  0.05294655 -0.1557248
    -0.02105275 -0.0954735 ]
   [-0.00761166  0.15885246  0.18038297 -0.12466267 -0.07105447
     0.17095837  0.0339199   0.08222952  0.12004289  0.11260402
    -0.09738356  0.02347144]
   [-0.00072576  0.17090365 -0.01647083 -0.01948735  0.13146487
     0.10526097  0.11121091  0.06537576  0.01257455 -0.03569977
     0.10423768 -0.15204567]
   [-0.02817036 -0.17417672 -0.00271861 -0.07032075  0.03263432
    -0.12569818  0.09931311 -0.02668889  0.17801747 -0.13491593
     0.02288054 -0.15480594]
   [ 0.0971145   0.07676029  0.16635007 -0.15773004  0.11000153
     0.15267178  0.15063205  0.02473505  0.16039792 -0.05975929
     0.01746325  0.05617659]]

  [[ 0.17118192  0.03445004 -0.1120424   0.01886515  0.10690111
    -0.0842981   0.0659533   0.01078963  0.00022839  0.07171023
    -0.18238257  0.14260131]
   [-0.17997828  0.07640624  0.09656751 -0.16016777 -0.05659795
     0.14622548 -0.09387237  0.15776375 -0.13030604  0.15649849
    -0.1255682   0.13553748]
   [-0.12823749  0.17772081 -0.13765387  0.13081616 -0.01589085
     0.08820465  0.01142725 -0.08194658 -0.08645985 -0.16708793
     0.13487098 -0.03955121]
   [-0.1144127  -0.16522297  0.11244217 -0.08786218  0.1654993
     0.1444276   0.10303083  0.15279597  0.01858792 -0.0032538
     0.13266277 -0.00460333]
   [-0.11746065 -0.12050555 -0.02894889  0.02036403  0.03973714
     0.0679605   0.06814089 -0.12096609  0.10359436 -0.05359387
     0.02096626  0.03899792]
   [ 0.06977895 -0.01037851  0.0242558  -0.00625865  0.02624768
     0.14819959  0.0507213   0.06339152  0.01664317 -0.14396366
     0.06176873 -0.0506587 ]
   [-0.08511114  0.09721816 -0.00501646  0.07871625 -0.0701196
    -0.00445633 -0.15435925  0.11863437  0.00131327 -0.11252698
     0.03057125 -0.1706302 ]
   [ 0.04246201  0.17604002  0.16577896 -0.08972622  0.12966734
    -0.13265513 -0.07044198 -0.06966381  0.13106075 -0.04824127
    -0.17587231  0.13318092]]

  [[-0.149724   -0.16306846  0.15576628 -0.11480964 -0.125439
    -0.08020585 -0.13739671 -0.15037869  0.1251029  -0.0688603
     0.00042777  0.11345032]
   [-0.04295985 -0.11219145 -0.12241077  0.03289801 -0.10260122
     0.13268432  0.11156824 -0.12337307 -0.05396296  0.00168405
     0.00287993  0.14832881]
   [ 0.17649949  0.16585815 -0.00368504  0.11262512 -0.12305779
    -0.13108316  0.13781267  0.14677    -0.14940912 -0.00470275
    -0.16676094 -0.1539455 ]
   [ 0.07559922 -0.00847141 -0.12584174  0.11906025 -0.12449147
    -0.10669234 -0.06631968 -0.0971502   0.13892183 -0.05235694
    -0.00853905 -0.07736192]
   [ 0.02714691 -0.07452317 -0.10216718  0.03328098  0.1541279
     0.02069186 -0.07870327 -0.04852499  0.06815207 -0.01593499
     0.04242283  0.07055816]
   [ 0.1605573   0.12233874 -0.06221154  0.02228062  0.15438613
     0.05162178  0.01655267 -0.06623746  0.13574421 -0.09086155
     0.0236557   0.02859773]
   [ 0.13703337 -0.05576724 -0.13737446  0.01504844  0.1433194
    -0.03262897  0.13943109  0.105726   -0.12125129 -0.15161839
     0.12532347 -0.01015425]
   [ 0.14935446  0.07599705 -0.13639893 -0.02344641  0.1661376
     0.1790834  -0.10383779  0.06925443  0.14677387  0.00887536
    -0.14727148 -0.1225199 ]]]


 [[[ 0.08690277  0.07914543 -0.15461037 -0.08854863  0.1325858
    -0.14543992  0.12536421  0.07382515  0.13530758 -0.17001143
    -0.17288631 -0.00084428]
   [ 0.0331575  -0.06440558  0.10753492 -0.13305032 -0.07678533
     0.15860131  0.03449053  0.03005405 -0.04399    -0.17972463
    -0.09493797 -0.04083233]
   [-0.13266248  0.17444748  0.1646291  -0.02158798  0.17962435
     0.08676407 -0.07608835  0.02457085 -0.09940366  0.0213269
    -0.1522625   0.13897747]
   [ 0.105248   -0.15250665 -0.01152706  0.11495674  0.11817232
     0.07233223 -0.1517842   0.18233708  0.00559153  0.1156646
     0.00242858 -0.02450508]
   [ 0.06075171  0.06678954 -0.01897672  0.13121659 -0.02173677
    -0.11848706 -0.17358448  0.14516088  0.05144893  0.1815297
     0.10963795 -0.14736494]
   [ 0.01234968 -0.13321683 -0.11654684 -0.10812627  0.05450389
    -0.110727   -0.05026138 -0.09740645 -0.05257837  0.04030357
     0.03046601 -0.03633603]
   [-0.11977078  0.12270826 -0.07324625  0.11627778 -0.11301333
    -0.09750235 -0.01998885 -0.06206828 -0.12869693 -0.02628499
    -0.09831181 -0.09212886]
   [-0.028267    0.1307249  -0.1411678  -0.09724304  0.14547867
    -0.02251451 -0.10938752  0.08652261  0.0546643   0.05544512
     0.08423233 -0.17302781]]

  [[-0.0969356   0.16639069  0.00903445  0.12124655  0.11096299
    -0.0502215   0.1268337  -0.0518447  -0.0869936  -0.12684813
    -0.02829826  0.12560481]
   [ 0.05448918 -0.01010571 -0.0015455  -0.11412192 -0.1473182
    -0.105917   -0.15637246  0.1481184   0.03666584 -0.11196471
     0.07034796 -0.12342339]
   [ 0.05956937 -0.11594623  0.02807012  0.10259852  0.08537623
     0.04238051  0.00583033 -0.02851006 -0.14621177  0.05152363
     0.00267015 -0.13906083]
   [-0.00695124 -0.1662462   0.09951183  0.02938905  0.10805166
    -0.13024692  0.1786184  -0.17512314  0.04930329 -0.11128496
     0.04429345 -0.01898125]
   [ 0.08401659  0.08375797  0.17344242 -0.06385633 -0.13125074
     0.13610828 -0.05861978 -0.13944775 -0.13796455 -0.01041172
    -0.15883416  0.08480588]
   [-0.17836784 -0.06331091  0.09013551  0.12217355  0.17736953
     0.10450462  0.0891923   0.14261702 -0.09979385  0.02708004
     0.0160954   0.0553863 ]
   [-0.13583528  0.04926099  0.15815386  0.02373318 -0.05493522
    -0.07464871 -0.11567743  0.08134958  0.13047448  0.16236532
     0.04675972 -0.08400176]
   [ 0.14132822 -0.11845729  0.08288163  0.01401514 -0.0827086
    -0.1302554  -0.16167727  0.00424534  0.15668848 -0.14327565
     0.18025157 -0.06677796]]

  [[ 0.00996119  0.05124068  0.08174083 -0.06027571  0.01895653
    -0.14000136 -0.15161608 -0.07040885  0.05361411  0.07408515
    -0.08537066  0.05772905]
   [-0.01783982 -0.18102303 -0.05917874 -0.16835132 -0.10854332
    -0.06172118  0.12692726  0.10717529 -0.02146284  0.06645715
    -0.0305723   0.04664363]
   [ 0.01061796  0.16491926  0.04819965 -0.08490603 -0.09749007
     0.03105043 -0.13794965 -0.04462388 -0.00235657 -0.00384919
    -0.02621979 -0.07399046]
   [-0.02890596  0.11221218  0.12140787 -0.09054857  0.06084873
    -0.05749147 -0.01934746  0.13787422  0.13169673 -0.03373447
    -0.14206567  0.18106252]
   [-0.15734582 -0.07863828 -0.15978563  0.16748792  0.09819472
     0.07804564  0.1069923   0.05432098  0.04688396  0.15722099
    -0.1563019   0.05468689]
   [-0.1552464   0.00582105 -0.09532346 -0.05367431  0.13096851
    -0.12132242 -0.09905377 -0.01357898 -0.13479537  0.11862883
    -0.07451273  0.07148498]
   [-0.02491012  0.05238037 -0.07416745 -0.12731376  0.00819744
    -0.07992322 -0.05463322 -0.10907163  0.09377861 -0.08809053
     0.07627934  0.05398458]
   [ 0.15010044 -0.06883832 -0.17250055 -0.12687242  0.17276141
    -0.06368174 -0.09499603  0.04803482 -0.01962195 -0.11780322
     0.08368304  0.05055697]]]


 [[[ 0.11643156  0.0567368  -0.17942023 -0.05440526  0.1456916
    -0.11583209 -0.14304513  0.15024787 -0.06825394  0.11655864
     0.16432819  0.00432727]
   [ 0.04469056 -0.03388016 -0.11816817 -0.08976806  0.1808742
    -0.06523328 -0.08998335 -0.05853825  0.09652793  0.15488303
     0.03384921 -0.09834734]
   [ 0.03652473 -0.16923705 -0.11928948 -0.1572608   0.15222946
     0.13903731 -0.0904408  -0.04494186  0.07628998  0.04974425
     0.16865999  0.00345482]
   [-0.06642206  0.1702959  -0.1524663  -0.0055315  -0.11737546
     0.12727061 -0.01581368  0.11005256  0.04878874 -0.13449414
    -0.1246103   0.07915163]
   [-0.03541252 -0.12473183 -0.15584202  0.03833048 -0.01549643
    -0.17340818  0.17247412  0.10515797 -0.07020026 -0.12558378
    -0.00354971 -0.15679635]
   [-0.041558    0.02415159  0.0253301  -0.01150656  0.09931266
    -0.10713098  0.12059     0.14507908  0.1644848  -0.01074119
     0.01691183  0.05637516]
   [-0.0344732  -0.12655556 -0.01825336  0.02369244 -0.15139021
     0.06799781  0.14937761  0.0121861  -0.0878772   0.12164685
    -0.12441176 -0.07904223]
   [ 0.01642783 -0.14028507 -0.16187589  0.05286893 -0.1399072
    -0.02981667  0.17153561  0.16841161  0.15302074 -0.04712741
    -0.1750242  -0.17049451]]

  [[-0.12354083 -0.0308481  -0.00214998 -0.0514296   0.1479626
     0.06681965  0.13161618 -0.10505886  0.02275787  0.05458534
     0.17628163  0.10589343]
   [ 0.11664984  0.06740099  0.00524478 -0.04391967  0.04904722
    -0.04066887 -0.11508092  0.12204033  0.12688488  0.03408949
     0.09160438  0.06628412]
   [-0.06139907 -0.12732312  0.02119118 -0.09209608  0.16312334
     0.13874963 -0.13361938 -0.05338846  0.0894312   0.11252114
    -0.06264082 -0.11746409]
   [ 0.0701451   0.13638023  0.02768441 -0.03128713 -0.13058728
    -0.06195185 -0.157456   -0.14446917 -0.04518884 -0.11948823
    -0.04098703  0.0509191 ]
   [ 0.06561251 -0.01597992 -0.01422766 -0.0643516   0.08685404
     0.13988897 -0.17041329  0.16628805  0.10287571  0.02797043
    -0.0098471  -0.1274009 ]
   [-0.12054085 -0.12070522  0.15125501 -0.05925182 -0.02661224
    -0.06200565  0.1340214   0.09506723  0.01964128 -0.1665591
     0.09678724 -0.07593165]
   [-0.07869761 -0.11691453 -0.12635908  0.15639153 -0.06550212
    -0.14904417  0.03029646  0.07874575 -0.00485018 -0.04073925
    -0.0383426  -0.05487533]
   [-0.0131948   0.09338385  0.09477612  0.1425302  -0.11402137
     0.06401582 -0.1141735  -0.03531532 -0.09604469 -0.07974105
    -0.14283387  0.08409777]]

  [[ 0.15424669  0.08251172 -0.10785065  0.14765146 -0.1197679
     0.03482778  0.17901456  0.10200405  0.10470453 -0.12348621
    -0.08547361  0.07196406]
   [-0.04998048 -0.15162718 -0.09795753 -0.01603489  0.1543414
     0.12120667 -0.15852045  0.08770329 -0.11070219 -0.0403619
    -0.17405693 -0.02336615]
   [-0.10007331 -0.0538258   0.16218913 -0.10051534  0.05636027
     0.17108247  0.10138139  0.08886483 -0.1659876   0.17117038
    -0.09694387  0.12497249]
   [-0.11477895  0.0004638   0.16630024  0.00585827 -0.0676434
    -0.0986116  -0.15713605  0.17593992 -0.0146784   0.02618147
    -0.10695978 -0.00949064]
   [ 0.0784165  -0.16830966  0.02304938  0.10958418 -0.11967397
     0.00674553  0.13981521  0.15256324  0.14185405  0.07340753
    -0.07689629  0.13502699]
   [ 0.0446675   0.10599482  0.08650911  0.09892297 -0.11669941
     0.16521332  0.14153719 -0.00816044  0.16654417 -0.02246083
    -0.05054331 -0.1806455 ]
   [ 0.10781962  0.18135089 -0.17763089  0.06351224  0.04275426
     0.0079481   0.08275431 -0.0919096   0.10140586 -0.08090241
     0.12308055 -0.0725971 ]
   [ 0.01773575 -0.06330407  0.091984    0.1549691  -0.10822051
    -0.00931448 -0.02829269  0.16291133 -0.0294022   0.05629037
    -0.01556844 -0.14952347]]]]: "
2018-04-20 23:35:52,369 (dqn_agent.py:161) DEBUG: "var_name: q/Conv_1/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 23:35:52,376 (dqn_agent.py:161) DEBUG: "var_name: q/Conv_2/weights:0, var_value [[[[ 0.13862939  0.0618584   0.00359096 ... -0.04008098  0.03705396
     0.14299755]
   [ 0.01100121 -0.14269373 -0.07848229 ...  0.05848046  0.08479381
     0.05755396]
   [-0.00496328 -0.00440247  0.0634238  ...  0.0002204  -0.04533082
     0.1537147 ]
   ...
   [ 0.04170223  0.03231759 -0.1184358  ... -0.08037654  0.11220951
    -0.08884753]
   [ 0.03263909 -0.05080333  0.14919086 ... -0.12088468  0.14430903
     0.02769122]
   [ 0.02673481  0.04977453 -0.03799208 ... -0.0534427   0.00445586
    -0.12337568]]

  [[ 0.05653594 -0.10917411 -0.12811132 ... -0.09827793  0.05210385
    -0.09262199]
   [ 0.11036916  0.05121742 -0.06021754 ... -0.02024373  0.10516562
     0.02838118]
   [ 0.02409169 -0.11139637 -0.07897401 ... -0.02318756  0.08121058
     0.00741179]
   ...
   [-0.00528106  0.12006344 -0.07935499 ...  0.13157602 -0.0440549
     0.07489057]
   [ 0.15343629 -0.02114624  0.02969491 ...  0.09409578  0.09823774
     0.03101431]
   [ 0.0145088  -0.03979244 -0.1371606  ...  0.01073974  0.02883318
    -0.06560559]]

  [[ 0.1302342   0.09559919  0.15165983 ... -0.08032188  0.03809048
     0.13246186]
   [-0.07804374 -0.11769311 -0.08956889 ...  0.08438751 -0.14458637
     0.0709563 ]
   [-0.14326948  0.13972281  0.01663217 ...  0.05641443  0.13111417
    -0.13171773]
   ...
   [ 0.1472732   0.0120846  -0.12561141 ... -0.09510909  0.13987027
     0.01141846]
   [ 0.10515468 -0.14018121 -0.00040324 ... -0.12457529  0.00027463
    -0.02508572]
   [ 0.10278709 -0.14117005 -0.05431923 ...  0.10310425  0.08153583
     0.00722016]]]


 [[[-0.00635295 -0.04295555 -0.11319219 ... -0.08138548 -0.01086642
    -0.12211015]
   [ 0.11309163 -0.10317813 -0.13100722 ... -0.07179538 -0.08983804
    -0.15257947]
   [ 0.02325523 -0.04964492 -0.07020095 ...  0.12276126  0.0663038
    -0.09110831]
   ...
   [-0.12847638  0.03430068  0.07079266 ...  0.1236008  -0.13222376
     0.12144394]
   [-0.02579038 -0.06945506 -0.01141365 ...  0.15284969 -0.11516398
    -0.07472745]
   [ 0.06979322 -0.06279857  0.03284374 ...  0.03379054 -0.06894726
    -0.14827794]]

  [[-0.1007089   0.00559926 -0.09329452 ...  0.12441967  0.14473404
     0.05293547]
   [ 0.1006922   0.02704065  0.0066839  ... -0.14480041  0.09607281
    -0.13959892]
   [-0.11475012  0.05574144  0.10360368 ... -0.06692488 -0.13205372
    -0.01193458]
   ...
   [ 0.03980069 -0.10872702 -0.0946364  ...  0.14228602  0.08011042
     0.07908225]
   [-0.13804172  0.08520883  0.12563427 ... -0.01032643  0.02052428
    -0.0667371 ]
   [-0.05498996  0.13551779  0.10070489 ... -0.12125607 -0.02379473
     0.11219911]]

  [[-0.02441829 -0.02414754 -0.13116531 ...  0.02331667 -0.0163087
     0.02596626]
   [ 0.01582178 -0.05865619  0.12508993 ... -0.03653862  0.12592746
    -0.00310111]
   [-0.1414698   0.05472612  0.00663584 ... -0.09624767  0.02567279
     0.09734656]
   ...
   [-0.08650972 -0.12847689  0.12138931 ...  0.07422984 -0.11917606
     0.02429377]
   [ 0.00966699 -0.11160713 -0.01302275 ... -0.08625433 -0.11847788
    -0.05292317]
   [-0.03942717 -0.12013276  0.12476434 ...  0.03556743  0.13480575
    -0.05105563]]]


 [[[-0.04907308 -0.07447261 -0.12928246 ...  0.13439037 -0.04434469
     0.04618813]
   [-0.1334546  -0.05595387 -0.08999567 ...  0.02999537  0.15332521
     0.0518073 ]
   [-0.15271872 -0.10457956 -0.03982306 ...  0.1233073  -0.01672326
     0.15170382]
   ...
   [-0.13118996 -0.07562697 -0.01606435 ... -0.01001969 -0.07054839
     0.13158418]
   [ 0.09599154  0.13463156 -0.13907158 ...  0.03257304 -0.13910665
     0.0984305 ]
   [-0.13626724 -0.01965128 -0.01778848 ...  0.13035913  0.12343745
    -0.09650597]]

  [[-0.07004372  0.06750228 -0.12161189 ... -0.11584076 -0.05434307
     0.12766393]
   [-0.11440974  0.14251153 -0.00433728 ... -0.11922845  0.12514557
     0.05618685]
   [-0.10911764 -0.01026481  0.10391827 ... -0.0720565  -0.00960386
     0.03389767]
   ...
   [ 0.10551892 -0.0583454   0.04769792 ...  0.0456288   0.00925238
     0.1054648 ]
   [-0.04099478 -0.1135696  -0.03642984 ...  0.14294074  0.08230852
    -0.02839473]
   [ 0.01468663  0.050796   -0.10447953 ...  0.06245808  0.04956307
    -0.00662629]]

  [[-0.00796257  0.09806056 -0.11828857 ... -0.1389561   0.12159269
    -0.06019013]
   [-0.04513344  0.00189039 -0.06958658 ...  0.01155271 -0.12949848
    -0.06986194]
   [ 0.15311025  0.08195239  0.08679608 ...  0.05311631  0.02386738
     0.00230996]
   ...
   [ 0.12789203 -0.13903561  0.01612011 ... -0.11376929 -0.12107642
    -0.12341671]
   [-0.00072761  0.09439664 -0.02422744 ...  0.10257189  0.14365844
     0.10456146]
   [-0.04516637  0.04562066  0.06664914 ... -0.11762814 -0.09364568
     0.08500546]]]]: "
2018-04-20 23:35:52,381 (dqn_agent.py:161) DEBUG: "var_name: q/Conv_2/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 23:35:52,385 (dqn_agent.py:161) DEBUG: "var_name: q/fully_connected/weights:0, var_value [[ 0.09208832 -0.04990041 -0.08254486 ...  0.05053981 -0.04556819
  -0.08938361]
 [-0.01819749 -0.07197729  0.04242028 ...  0.00696088 -0.00177046
  -0.06598634]
 [ 0.0545522   0.00306828 -0.03477501 ...  0.05089072 -0.05015313
  -0.01998796]
 ...
 [ 0.04571497  0.04763388 -0.00164858 ...  0.00891878 -0.06794402
  -0.04159374]
 [-0.02224246  0.0701397   0.02866688 ...  0.02703989 -0.0402051
   0.01816725]
 [-0.03171723 -0.00958906 -0.00090716 ...  0.01429334  0.07384021
  -0.02617542]]: "
2018-04-20 23:35:52,390 (dqn_agent.py:161) DEBUG: "var_name: q/fully_connected/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 23:35:52,401 (dqn_agent.py:161) DEBUG: "var_name: q/fully_connected_1/weights:0, var_value [[ 9.41843987e-02 -2.64844894e-02 -1.15831248e-01 -4.68495935e-02
   1.45739883e-01]
 [ 1.40278667e-01  1.25893116e-01 -7.60687739e-02 -2.49339640e-03
  -7.59467781e-02]
 [ 9.24690068e-02  9.15719271e-02  1.64508939e-01 -2.03239173e-01
   1.79867595e-02]
 [ 4.36149836e-02 -1.38565123e-01  1.23988330e-01  5.96751273e-03
   9.38590467e-02]
 [ 2.00166523e-01 -1.90578580e-01 -1.72439784e-01  1.24286711e-02
  -1.09387316e-01]
 [ 2.04671979e-01 -3.10925394e-02 -2.82411277e-03 -1.69391140e-01
   8.36910903e-02]
 [ 2.07587540e-01 -8.08461010e-02  1.18084520e-01  3.98486257e-02
  -1.60584569e-01]
 [ 1.19697750e-02 -4.04432267e-02 -1.84398890e-02 -1.33473366e-01
   1.84244215e-01]
 [-2.11726576e-02 -1.52533129e-01 -1.42890900e-01  7.44301081e-02
   1.68363452e-01]
 [-2.04355583e-01 -6.16494566e-02 -6.99329227e-02 -4.18539494e-02
  -1.26879543e-01]
 [-7.25771636e-02 -1.32343143e-01  3.38886976e-02  1.97165161e-02
  -1.48653328e-01]
 [-1.76388517e-01 -2.07418099e-01 -1.21249683e-01  4.65998352e-02
   7.75591433e-02]
 [ 1.18879408e-01 -1.82789564e-02  3.65058035e-02 -6.44914955e-02
   1.96717858e-01]
 [ 1.22683078e-01  8.85179341e-02  4.03122902e-02 -1.16942383e-01
   1.14848495e-01]
 [-1.81378588e-01  5.76466918e-02 -1.29786760e-01  8.55743289e-02
   7.28405416e-02]
 [-2.01203004e-01  1.33337408e-01  1.28473520e-01  3.07281315e-02
   1.06338978e-01]
 [-5.20898700e-02  1.19247556e-01  6.65053725e-03  1.44633621e-01
   8.10627639e-03]
 [ 1.20503902e-02 -7.61623532e-02  2.02923179e-01 -4.26714122e-03
  -6.22483641e-02]
 [-1.90976247e-01  3.05627435e-02 -8.35706145e-02  3.19496542e-02
   8.69476497e-02]
 [-1.76947072e-01 -1.17018797e-01 -1.43039986e-01  2.07254589e-02
  -2.81208605e-02]
 [-1.91166967e-01  1.02415502e-01 -2.11974502e-01 -9.13537070e-02
  -1.80031627e-01]
 [ 8.82156193e-02 -8.51838887e-02  2.11607516e-02 -8.40177536e-02
   1.37838304e-01]
 [ 2.39466429e-02 -1.05237253e-01 -1.58066511e-01 -2.01483861e-01
   1.58588260e-01]
 [ 1.40294522e-01  9.49476659e-03 -6.17837012e-02 -1.42307892e-01
   1.24672502e-02]
 [-2.79974937e-02  4.24382687e-02  2.11029559e-01 -1.12127878e-01
  -1.04633175e-01]
 [ 1.93760782e-01 -1.33343473e-01 -4.33564186e-02 -1.79411292e-01
  -6.15584105e-02]
 [ 8.52917135e-02 -2.03932941e-01  1.46929145e-01 -4.15806025e-02
  -3.60316634e-02]
 [ 1.74091011e-01  1.88509762e-01 -7.03749508e-02  1.54687881e-01
  -9.42196548e-02]
 [-1.52078643e-01 -1.79566294e-02  1.20080024e-01 -4.94227856e-02
  -1.17306836e-01]
 [ 7.87903965e-02  1.33114845e-01 -1.37073487e-01  6.50296509e-02
   2.68231183e-02]
 [ 1.31966442e-01 -1.10711537e-01 -2.03426033e-01 -5.30279726e-02
   1.03792548e-01]
 [ 1.73460841e-01  4.16221321e-02 -1.49355039e-01 -6.60649240e-02
  -9.12678763e-02]
 [-2.76821107e-02  1.15818083e-01  9.17750597e-03  1.25434250e-02
  -9.11471993e-02]
 [-1.31511793e-01 -1.21460445e-01  1.62447542e-01 -1.42836720e-01
  -1.76378787e-01]
 [ 5.45965731e-02  1.03324503e-01 -1.74675584e-02  9.19644833e-02
  -6.77635223e-02]
 [ 7.08636642e-02 -9.83117893e-02  1.95997924e-01  9.50899720e-03
   1.61655933e-01]
 [-1.40483290e-01 -2.89529115e-02  1.42150044e-01  1.05851918e-01
   1.00489855e-01]
 [-1.71153799e-01  1.93017840e-01 -2.01614797e-02 -1.49661422e-01
   9.78524983e-02]
 [-1.93590522e-02 -6.11737520e-02  2.08739281e-01  5.22648394e-02
   5.03803790e-02]
 [ 1.81646645e-02  9.37536061e-02 -8.08738023e-02 -5.89879453e-02
  -1.64468110e-01]
 [ 8.43631625e-02  1.27567768e-01  6.03376031e-02  1.09717995e-01
  -5.76914251e-02]
 [ 1.86725974e-01  1.11497670e-01  3.47631425e-02  7.50306547e-02
   1.95929050e-01]
 [ 1.90506458e-01 -1.59306273e-01  1.96017623e-01  5.09883761e-02
   3.00376564e-02]
 [ 2.02566743e-01  1.46912038e-01  1.28696948e-01  6.24190271e-02
  -1.32516474e-01]
 [ 1.28966868e-02 -1.91034287e-01 -7.97865689e-02 -6.20825738e-02
   1.57503396e-01]
 [-5.30101955e-02 -9.00521204e-02 -1.22935019e-01 -1.44250929e-01
  -1.82731166e-01]
 [ 1.31250948e-01  5.88699579e-02  6.61057234e-02 -1.13903202e-01
  -2.05784827e-01]
 [-1.97580010e-01 -1.65807426e-01 -9.29367542e-02 -1.42638668e-01
  -1.89123705e-01]
 [-1.31524801e-01  4.68009710e-02 -7.13889599e-02 -4.04773653e-02
   1.10230982e-01]
 [ 6.44470751e-02 -2.09957227e-01  2.04735279e-01 -1.44003242e-01
   2.05982357e-01]
 [ 9.58260000e-02 -1.64768010e-01 -9.60356370e-02 -1.31485403e-01
  -7.57715106e-03]
 [ 1.12183839e-01 -1.29488990e-01 -1.85785040e-01  9.10305679e-02
  -1.47022933e-01]
 [ 1.88098758e-01 -1.98731899e-01 -1.43483698e-01  2.69821286e-02
  -1.54186159e-01]
 [-1.67629242e-01  5.93566597e-02  1.60063326e-01  5.96368313e-02
   8.38646889e-02]
 [-3.18143070e-02 -1.72506034e-01  9.50035453e-02  1.30044103e-01
   9.10023153e-02]
 [-7.80989230e-03 -5.05337119e-03  1.28698647e-01 -2.01229095e-01
  -5.98277003e-02]
 [ 1.32370025e-01  5.68467379e-02  9.63126421e-02  1.76570773e-01
   3.77829373e-02]
 [ 9.50622857e-02 -1.68551743e-01  2.05425441e-01 -1.68950737e-01
  -9.54200178e-02]
 [-1.72950089e-01  8.35857391e-02 -7.92471021e-02  1.67236924e-01
  -1.39760673e-02]
 [-3.24919671e-02  7.95708597e-02 -2.38159895e-02  1.70458525e-01
  -1.94283068e-01]
 [ 6.37698472e-02 -8.46521705e-02  7.02268779e-02 -1.44052058e-01
   5.62299490e-02]
 [ 8.36951435e-02 -2.31018215e-02 -8.50139856e-02  3.36380899e-02
   1.55538291e-01]
 [-1.13002658e-02  1.74219280e-01  2.09914267e-01  1.94097579e-01
  -2.99056023e-02]
 [ 3.00183892e-04  5.88477254e-02  1.03026181e-02 -1.01839796e-01
  -8.25441927e-02]
 [-3.33083272e-02 -1.39377773e-01 -1.14709839e-01  9.65727270e-02
  -1.26399323e-01]
 [-1.62046015e-01 -8.14749449e-02  2.64911652e-02 -1.41018152e-01
   1.87464535e-01]
 [ 3.97706926e-02  1.17448360e-01  1.71435624e-02  1.31974190e-01
   1.71311080e-01]
 [-7.79372603e-02  1.91266328e-01 -1.14035368e-01  4.22566831e-02
   5.37168086e-02]
 [ 5.27322292e-02 -2.94049233e-02 -2.69012004e-02  9.68015194e-03
   4.97378111e-02]
 [ 1.13461018e-01  7.77906775e-02 -3.18808854e-02 -1.58268929e-01
   1.70776933e-01]
 [ 2.94875652e-02  1.23611093e-03  7.88461566e-02 -9.10558999e-02
  -1.05753422e-01]
 [ 5.91489673e-02 -1.01190902e-01 -1.43538684e-01 -2.03389019e-01
   1.01198554e-02]
 [ 1.63611710e-01 -1.74926192e-01 -1.59974873e-01  2.44255364e-02
  -9.51495990e-02]
 [ 9.12444293e-03  5.74809611e-02  1.62916780e-01  3.12701315e-02
  -8.91739801e-02]
 [-8.46979022e-02  7.36199319e-02  9.43228006e-02  2.44632363e-04
   5.59854805e-02]
 [ 1.93013489e-01 -1.78983182e-01 -7.89469182e-02  1.77052796e-01
   1.39967203e-02]
 [ 1.56567544e-01  2.05590308e-01  2.09305286e-01  3.35833430e-02
   2.81270295e-02]
 [ 6.87540472e-02  1.84742838e-01 -1.60194486e-01  1.77264184e-01
   1.56694949e-02]
 [-1.40035838e-01  1.37729973e-01  7.60086477e-02  5.33849299e-02
  -1.28391981e-02]
 [-1.86731339e-01  5.89225590e-02 -3.43127996e-02 -8.98831338e-02
   1.30436510e-01]
 [-1.54017180e-01 -1.39273614e-01 -1.97151244e-01 -1.61650836e-01
  -1.46606386e-01]
 [-1.35419339e-01  1.78630084e-01 -3.07579041e-02 -1.90831214e-01
  -7.22976923e-02]
 [ 1.75946444e-01  1.69933438e-01  4.58082259e-02  6.06953204e-02
  -1.89444155e-01]
 [ 1.04298145e-01 -9.59210396e-02  1.94479138e-01 -1.67582482e-02
   2.72818059e-02]
 [ 7.98933208e-02 -3.00746858e-02 -1.84062779e-01 -2.01386735e-01
   7.51195252e-02]
 [ 5.33570349e-02 -1.60957679e-01 -5.67541271e-02 -1.35746166e-01
   5.46709299e-02]
 [-9.40005854e-02  1.35951400e-01  1.94575459e-01 -1.24612913e-01
   7.42363632e-02]
 [ 1.41471744e-01 -2.00529709e-01 -1.64302975e-01  5.54084480e-02
  -1.07956648e-01]
 [ 2.06234902e-01 -6.60274029e-02  7.96467066e-02  4.74537909e-03
   1.56511426e-01]
 [-1.72948569e-01 -1.31976604e-03  5.92384040e-02 -1.01763278e-01
  -5.51839024e-02]
 [ 9.81533229e-02  2.68353522e-03 -1.09362908e-01  1.06566846e-01
   1.32747382e-01]
 [-1.20271735e-01  8.35888386e-02  1.69129580e-01 -4.15137559e-02
   1.68211997e-01]
 [ 5.25202453e-02  1.38966590e-01  8.90348852e-02  1.47723228e-01
  -8.19433033e-02]
 [ 1.05392456e-01  9.36476886e-03  1.02914780e-01  9.76723135e-02
   1.95133865e-01]
 [-1.22557700e-01  2.20555514e-02 -1.48119032e-01  4.52690721e-02
   6.15100563e-02]
 [-1.29358396e-01 -1.17850199e-01 -3.21504474e-02  3.05366218e-02
  -1.99104056e-01]
 [ 1.33253187e-01 -1.61816627e-01 -3.95215452e-02 -1.43144712e-01
  -1.45322919e-01]
 [ 2.02819437e-01 -1.61296248e-01  5.00053465e-02  9.15070474e-02
   8.37028027e-04]
 [ 1.76459402e-01  1.09067112e-01 -1.00024417e-01  8.25926065e-02
   1.77250087e-01]
 [-1.36041701e-01  3.85475755e-02  1.67484611e-01  1.49927169e-01
  -2.90879160e-02]
 [ 1.16280466e-01  1.12362057e-02 -8.33821297e-02 -1.29254490e-01
  -4.61813509e-02]
 [ 1.33447587e-01  3.27080488e-05 -2.07371876e-01  1.31088078e-01
  -3.08701843e-02]
 [-4.89011407e-03 -8.64779353e-02 -1.11787632e-01  1.46367252e-01
  -6.27700090e-02]
 [ 4.38854694e-02 -2.79776007e-02 -1.75280005e-01 -1.69479847e-03
   6.24385774e-02]
 [ 1.26013756e-01 -1.55174747e-01 -1.88947931e-01  6.40135705e-02
  -7.95145929e-02]
 [-3.49390656e-02 -1.00915521e-01 -1.75704375e-01  3.83919775e-02
  -1.40991464e-01]
 [ 1.56704664e-01  4.58392203e-02 -1.89413920e-01 -1.97497964e-01
   1.93228185e-01]
 [-1.93983018e-01 -1.58940256e-01 -1.57568127e-01  1.57044381e-02
   9.65109468e-02]
 [-1.28197998e-01 -7.10884631e-02  1.03994548e-01  1.71612591e-01
   9.34025347e-02]
 [ 1.42444760e-01 -1.00877188e-01 -1.26483321e-01  1.04141712e-01
  -2.16393173e-03]
 [-7.79948980e-02 -3.59653234e-02 -9.14122015e-02 -1.29268110e-01
  -1.26362965e-01]
 [ 1.65331870e-01  1.17218912e-01 -1.06737554e-01  8.11842680e-02
  -1.71901554e-01]
 [ 1.27584040e-01  1.80365294e-01 -1.61782444e-01  1.81487143e-01
  -3.61197293e-02]
 [-5.02271503e-02 -1.38750374e-02  1.66606575e-01 -3.34460586e-02
  -5.44165522e-02]
 [-8.07016343e-02 -3.04877013e-02  1.28324777e-01  1.56117231e-02
  -1.25438586e-01]
 [-1.85010463e-01  6.54385090e-02 -1.63126111e-01  1.67328894e-01
   1.31394953e-01]
 [-1.15119457e-01 -1.00164182e-01  1.49016976e-01 -1.28753856e-01
  -6.59464300e-02]
 [-1.60031989e-01 -1.92502573e-01 -3.72654945e-02 -1.19228356e-01
  -9.79620218e-02]
 [-1.41624808e-01  2.03999668e-01  1.05763644e-01  1.32561505e-01
  -7.75281936e-02]
 [ 4.05908823e-02  1.81352258e-01  3.61457616e-02 -1.58288971e-01
  -1.17697619e-01]
 [-1.57264993e-01 -1.08807497e-01  1.99052393e-02  7.65399039e-02
  -9.54790115e-02]
 [-2.11821213e-01  2.07513154e-01  8.24109018e-02  1.53677434e-01
  -9.82628688e-02]
 [ 4.50119376e-02  2.52357721e-02 -1.65888652e-01  1.16438687e-01
   2.07253337e-01]
 [ 1.88082665e-01  1.15992248e-01  1.81157649e-01 -1.45411044e-02
   1.01934850e-01]
 [-1.47524565e-01 -1.77946597e-01 -1.19411469e-01  8.66018534e-02
   9.19072032e-02]
 [-2.74482667e-02 -2.08221555e-01 -3.40739936e-02 -9.36670229e-02
  -8.30225646e-03]
 [ 1.31137609e-01 -9.49288607e-02 -5.27300537e-02  1.62269652e-01
   2.03222096e-01]
 [-1.81248039e-01  4.24956977e-02 -2.00731397e-01 -2.01674864e-01
  -8.27179998e-02]]: "
2018-04-20 23:35:52,407 (dqn_agent.py:161) DEBUG: "var_name: q/fully_connected_1/biases:0, var_value [0. 0. 0. 0. 0.]: "
2018-04-20 23:35:52,412 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv/weights:0, var_value [[[[ 0.10241663  0.29239368  0.5257293   0.58401763 -0.34008738
    -0.31810182  0.04391998  0.24438548]
   [-0.491535    0.57338285  0.48198736 -0.08004802 -0.27636507
    -0.15062743 -0.03651714 -0.0926128 ]]]]: "
2018-04-20 23:35:52,417 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 23:35:52,426 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv_1/weights:0, var_value [[[[ 0.04930386  0.12817636 -0.11733994 -0.11633207  0.08124065
    -0.05393888  0.12567046  0.09253716  0.07434395 -0.06923138
    -0.12568355 -0.09801546]
   [ 0.03628519  0.13854635  0.0221318   0.03164782 -0.04159643
    -0.13146052 -0.08889138 -0.14103474 -0.0840869  -0.0276639
    -0.03240192 -0.12190853]
   [ 0.03637007  0.18111295 -0.09941057  0.16764653  0.12172431
     0.02495553  0.13351104  0.06918329  0.14316666  0.06112684
    -0.00468208 -0.05249912]
   [-0.15472028 -0.13117039 -0.04071204 -0.11561336  0.11802879
    -0.16008702 -0.06079171  0.14545229  0.05294655 -0.1557248
    -0.02105275 -0.0954735 ]
   [-0.00761166  0.15885246  0.18038297 -0.12466267 -0.07105447
     0.17095837  0.0339199   0.08222952  0.12004289  0.11260402
    -0.09738356  0.02347144]
   [-0.00072576  0.17090365 -0.01647083 -0.01948735  0.13146487
     0.10526097  0.11121091  0.06537576  0.01257455 -0.03569977
     0.10423768 -0.15204567]
   [-0.02817036 -0.17417672 -0.00271861 -0.07032075  0.03263432
    -0.12569818  0.09931311 -0.02668889  0.17801747 -0.13491593
     0.02288054 -0.15480594]
   [ 0.0971145   0.07676029  0.16635007 -0.15773004  0.11000153
     0.15267178  0.15063205  0.02473505  0.16039792 -0.05975929
     0.01746325  0.05617659]]

  [[ 0.17118192  0.03445004 -0.1120424   0.01886515  0.10690111
    -0.0842981   0.0659533   0.01078963  0.00022839  0.07171023
    -0.18238257  0.14260131]
   [-0.17997828  0.07640624  0.09656751 -0.16016777 -0.05659795
     0.14622548 -0.09387237  0.15776375 -0.13030604  0.15649849
    -0.1255682   0.13553748]
   [-0.12823749  0.17772081 -0.13765387  0.13081616 -0.01589085
     0.08820465  0.01142725 -0.08194658 -0.08645985 -0.16708793
     0.13487098 -0.03955121]
   [-0.1144127  -0.16522297  0.11244217 -0.08786218  0.1654993
     0.1444276   0.10303083  0.15279597  0.01858792 -0.0032538
     0.13266277 -0.00460333]
   [-0.11746065 -0.12050555 -0.02894889  0.02036403  0.03973714
     0.0679605   0.06814089 -0.12096609  0.10359436 -0.05359387
     0.02096626  0.03899792]
   [ 0.06977895 -0.01037851  0.0242558  -0.00625865  0.02624768
     0.14819959  0.0507213   0.06339152  0.01664317 -0.14396366
     0.06176873 -0.0506587 ]
   [-0.08511114  0.09721816 -0.00501646  0.07871625 -0.0701196
    -0.00445633 -0.15435925  0.11863437  0.00131327 -0.11252698
     0.03057125 -0.1706302 ]
   [ 0.04246201  0.17604002  0.16577896 -0.08972622  0.12966734
    -0.13265513 -0.07044198 -0.06966381  0.13106075 -0.04824127
    -0.17587231  0.13318092]]

  [[-0.149724   -0.16306846  0.15576628 -0.11480964 -0.125439
    -0.08020585 -0.13739671 -0.15037869  0.1251029  -0.0688603
     0.00042777  0.11345032]
   [-0.04295985 -0.11219145 -0.12241077  0.03289801 -0.10260122
     0.13268432  0.11156824 -0.12337307 -0.05396296  0.00168405
     0.00287993  0.14832881]
   [ 0.17649949  0.16585815 -0.00368504  0.11262512 -0.12305779
    -0.13108316  0.13781267  0.14677    -0.14940912 -0.00470275
    -0.16676094 -0.1539455 ]
   [ 0.07559922 -0.00847141 -0.12584174  0.11906025 -0.12449147
    -0.10669234 -0.06631968 -0.0971502   0.13892183 -0.05235694
    -0.00853905 -0.07736192]
   [ 0.02714691 -0.07452317 -0.10216718  0.03328098  0.1541279
     0.02069186 -0.07870327 -0.04852499  0.06815207 -0.01593499
     0.04242283  0.07055816]
   [ 0.1605573   0.12233874 -0.06221154  0.02228062  0.15438613
     0.05162178  0.01655267 -0.06623746  0.13574421 -0.09086155
     0.0236557   0.02859773]
   [ 0.13703337 -0.05576724 -0.13737446  0.01504844  0.1433194
    -0.03262897  0.13943109  0.105726   -0.12125129 -0.15161839
     0.12532347 -0.01015425]
   [ 0.14935446  0.07599705 -0.13639893 -0.02344641  0.1661376
     0.1790834  -0.10383779  0.06925443  0.14677387  0.00887536
    -0.14727148 -0.1225199 ]]]


 [[[ 0.08690277  0.07914543 -0.15461037 -0.08854863  0.1325858
    -0.14543992  0.12536421  0.07382515  0.13530758 -0.17001143
    -0.17288631 -0.00084428]
   [ 0.0331575  -0.06440558  0.10753492 -0.13305032 -0.07678533
     0.15860131  0.03449053  0.03005405 -0.04399    -0.17972463
    -0.09493797 -0.04083233]
   [-0.13266248  0.17444748  0.1646291  -0.02158798  0.17962435
     0.08676407 -0.07608835  0.02457085 -0.09940366  0.0213269
    -0.1522625   0.13897747]
   [ 0.105248   -0.15250665 -0.01152706  0.11495674  0.11817232
     0.07233223 -0.1517842   0.18233708  0.00559153  0.1156646
     0.00242858 -0.02450508]
   [ 0.06075171  0.06678954 -0.01897672  0.13121659 -0.02173677
    -0.11848706 -0.17358448  0.14516088  0.05144893  0.1815297
     0.10963795 -0.14736494]
   [ 0.01234968 -0.13321683 -0.11654684 -0.10812627  0.05450389
    -0.110727   -0.05026138 -0.09740645 -0.05257837  0.04030357
     0.03046601 -0.03633603]
   [-0.11977078  0.12270826 -0.07324625  0.11627778 -0.11301333
    -0.09750235 -0.01998885 -0.06206828 -0.12869693 -0.02628499
    -0.09831181 -0.09212886]
   [-0.028267    0.1307249  -0.1411678  -0.09724304  0.14547867
    -0.02251451 -0.10938752  0.08652261  0.0546643   0.05544512
     0.08423233 -0.17302781]]

  [[-0.0969356   0.16639069  0.00903445  0.12124655  0.11096299
    -0.0502215   0.1268337  -0.0518447  -0.0869936  -0.12684813
    -0.02829826  0.12560481]
   [ 0.05448918 -0.01010571 -0.0015455  -0.11412192 -0.1473182
    -0.105917   -0.15637246  0.1481184   0.03666584 -0.11196471
     0.07034796 -0.12342339]
   [ 0.05956937 -0.11594623  0.02807012  0.10259852  0.08537623
     0.04238051  0.00583033 -0.02851006 -0.14621177  0.05152363
     0.00267015 -0.13906083]
   [-0.00695124 -0.1662462   0.09951183  0.02938905  0.10805166
    -0.13024692  0.1786184  -0.17512314  0.04930329 -0.11128496
     0.04429345 -0.01898125]
   [ 0.08401659  0.08375797  0.17344242 -0.06385633 -0.13125074
     0.13610828 -0.05861978 -0.13944775 -0.13796455 -0.01041172
    -0.15883416  0.08480588]
   [-0.17836784 -0.06331091  0.09013551  0.12217355  0.17736953
     0.10450462  0.0891923   0.14261702 -0.09979385  0.02708004
     0.0160954   0.0553863 ]
   [-0.13583528  0.04926099  0.15815386  0.02373318 -0.05493522
    -0.07464871 -0.11567743  0.08134958  0.13047448  0.16236532
     0.04675972 -0.08400176]
   [ 0.14132822 -0.11845729  0.08288163  0.01401514 -0.0827086
    -0.1302554  -0.16167727  0.00424534  0.15668848 -0.14327565
     0.18025157 -0.06677796]]

  [[ 0.00996119  0.05124068  0.08174083 -0.06027571  0.01895653
    -0.14000136 -0.15161608 -0.07040885  0.05361411  0.07408515
    -0.08537066  0.05772905]
   [-0.01783982 -0.18102303 -0.05917874 -0.16835132 -0.10854332
    -0.06172118  0.12692726  0.10717529 -0.02146284  0.06645715
    -0.0305723   0.04664363]
   [ 0.01061796  0.16491926  0.04819965 -0.08490603 -0.09749007
     0.03105043 -0.13794965 -0.04462388 -0.00235657 -0.00384919
    -0.02621979 -0.07399046]
   [-0.02890596  0.11221218  0.12140787 -0.09054857  0.06084873
    -0.05749147 -0.01934746  0.13787422  0.13169673 -0.03373447
    -0.14206567  0.18106252]
   [-0.15734582 -0.07863828 -0.15978563  0.16748792  0.09819472
     0.07804564  0.1069923   0.05432098  0.04688396  0.15722099
    -0.1563019   0.05468689]
   [-0.1552464   0.00582105 -0.09532346 -0.05367431  0.13096851
    -0.12132242 -0.09905377 -0.01357898 -0.13479537  0.11862883
    -0.07451273  0.07148498]
   [-0.02491012  0.05238037 -0.07416745 -0.12731376  0.00819744
    -0.07992322 -0.05463322 -0.10907163  0.09377861 -0.08809053
     0.07627934  0.05398458]
   [ 0.15010044 -0.06883832 -0.17250055 -0.12687242  0.17276141
    -0.06368174 -0.09499603  0.04803482 -0.01962195 -0.11780322
     0.08368304  0.05055697]]]


 [[[ 0.11643156  0.0567368  -0.17942023 -0.05440526  0.1456916
    -0.11583209 -0.14304513  0.15024787 -0.06825394  0.11655864
     0.16432819  0.00432727]
   [ 0.04469056 -0.03388016 -0.11816817 -0.08976806  0.1808742
    -0.06523328 -0.08998335 -0.05853825  0.09652793  0.15488303
     0.03384921 -0.09834734]
   [ 0.03652473 -0.16923705 -0.11928948 -0.1572608   0.15222946
     0.13903731 -0.0904408  -0.04494186  0.07628998  0.04974425
     0.16865999  0.00345482]
   [-0.06642206  0.1702959  -0.1524663  -0.0055315  -0.11737546
     0.12727061 -0.01581368  0.11005256  0.04878874 -0.13449414
    -0.1246103   0.07915163]
   [-0.03541252 -0.12473183 -0.15584202  0.03833048 -0.01549643
    -0.17340818  0.17247412  0.10515797 -0.07020026 -0.12558378
    -0.00354971 -0.15679635]
   [-0.041558    0.02415159  0.0253301  -0.01150656  0.09931266
    -0.10713098  0.12059     0.14507908  0.1644848  -0.01074119
     0.01691183  0.05637516]
   [-0.0344732  -0.12655556 -0.01825336  0.02369244 -0.15139021
     0.06799781  0.14937761  0.0121861  -0.0878772   0.12164685
    -0.12441176 -0.07904223]
   [ 0.01642783 -0.14028507 -0.16187589  0.05286893 -0.1399072
    -0.02981667  0.17153561  0.16841161  0.15302074 -0.04712741
    -0.1750242  -0.17049451]]

  [[-0.12354083 -0.0308481  -0.00214998 -0.0514296   0.1479626
     0.06681965  0.13161618 -0.10505886  0.02275787  0.05458534
     0.17628163  0.10589343]
   [ 0.11664984  0.06740099  0.00524478 -0.04391967  0.04904722
    -0.04066887 -0.11508092  0.12204033  0.12688488  0.03408949
     0.09160438  0.06628412]
   [-0.06139907 -0.12732312  0.02119118 -0.09209608  0.16312334
     0.13874963 -0.13361938 -0.05338846  0.0894312   0.11252114
    -0.06264082 -0.11746409]
   [ 0.0701451   0.13638023  0.02768441 -0.03128713 -0.13058728
    -0.06195185 -0.157456   -0.14446917 -0.04518884 -0.11948823
    -0.04098703  0.0509191 ]
   [ 0.06561251 -0.01597992 -0.01422766 -0.0643516   0.08685404
     0.13988897 -0.17041329  0.16628805  0.10287571  0.02797043
    -0.0098471  -0.1274009 ]
   [-0.12054085 -0.12070522  0.15125501 -0.05925182 -0.02661224
    -0.06200565  0.1340214   0.09506723  0.01964128 -0.1665591
     0.09678724 -0.07593165]
   [-0.07869761 -0.11691453 -0.12635908  0.15639153 -0.06550212
    -0.14904417  0.03029646  0.07874575 -0.00485018 -0.04073925
    -0.0383426  -0.05487533]
   [-0.0131948   0.09338385  0.09477612  0.1425302  -0.11402137
     0.06401582 -0.1141735  -0.03531532 -0.09604469 -0.07974105
    -0.14283387  0.08409777]]

  [[ 0.15424669  0.08251172 -0.10785065  0.14765146 -0.1197679
     0.03482778  0.17901456  0.10200405  0.10470453 -0.12348621
    -0.08547361  0.07196406]
   [-0.04998048 -0.15162718 -0.09795753 -0.01603489  0.1543414
     0.12120667 -0.15852045  0.08770329 -0.11070219 -0.0403619
    -0.17405693 -0.02336615]
   [-0.10007331 -0.0538258   0.16218913 -0.10051534  0.05636027
     0.17108247  0.10138139  0.08886483 -0.1659876   0.17117038
    -0.09694387  0.12497249]
   [-0.11477895  0.0004638   0.16630024  0.00585827 -0.0676434
    -0.0986116  -0.15713605  0.17593992 -0.0146784   0.02618147
    -0.10695978 -0.00949064]
   [ 0.0784165  -0.16830966  0.02304938  0.10958418 -0.11967397
     0.00674553  0.13981521  0.15256324  0.14185405  0.07340753
    -0.07689629  0.13502699]
   [ 0.0446675   0.10599482  0.08650911  0.09892297 -0.11669941
     0.16521332  0.14153719 -0.00816044  0.16654417 -0.02246083
    -0.05054331 -0.1806455 ]
   [ 0.10781962  0.18135089 -0.17763089  0.06351224  0.04275426
     0.0079481   0.08275431 -0.0919096   0.10140586 -0.08090241
     0.12308055 -0.0725971 ]
   [ 0.01773575 -0.06330407  0.091984    0.1549691  -0.10822051
    -0.00931448 -0.02829269  0.16291133 -0.0294022   0.05629037
    -0.01556844 -0.14952347]]]]: "
2018-04-20 23:35:52,431 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv_1/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 23:35:52,440 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv_2/weights:0, var_value [[[[ 0.13862939  0.0618584   0.00359096 ... -0.04008098  0.03705396
     0.14299755]
   [ 0.01100121 -0.14269373 -0.07848229 ...  0.05848046  0.08479381
     0.05755396]
   [-0.00496328 -0.00440247  0.0634238  ...  0.0002204  -0.04533082
     0.1537147 ]
   ...
   [ 0.04170223  0.03231759 -0.1184358  ... -0.08037654  0.11220951
    -0.08884753]
   [ 0.03263909 -0.05080333  0.14919086 ... -0.12088468  0.14430903
     0.02769122]
   [ 0.02673481  0.04977453 -0.03799208 ... -0.0534427   0.00445586
    -0.12337568]]

  [[ 0.05653594 -0.10917411 -0.12811132 ... -0.09827793  0.05210385
    -0.09262199]
   [ 0.11036916  0.05121742 -0.06021754 ... -0.02024373  0.10516562
     0.02838118]
   [ 0.02409169 -0.11139637 -0.07897401 ... -0.02318756  0.08121058
     0.00741179]
   ...
   [-0.00528106  0.12006344 -0.07935499 ...  0.13157602 -0.0440549
     0.07489057]
   [ 0.15343629 -0.02114624  0.02969491 ...  0.09409578  0.09823774
     0.03101431]
   [ 0.0145088  -0.03979244 -0.1371606  ...  0.01073974  0.02883318
    -0.06560559]]

  [[ 0.1302342   0.09559919  0.15165983 ... -0.08032188  0.03809048
     0.13246186]
   [-0.07804374 -0.11769311 -0.08956889 ...  0.08438751 -0.14458637
     0.0709563 ]
   [-0.14326948  0.13972281  0.01663217 ...  0.05641443  0.13111417
    -0.13171773]
   ...
   [ 0.1472732   0.0120846  -0.12561141 ... -0.09510909  0.13987027
     0.01141846]
   [ 0.10515468 -0.14018121 -0.00040324 ... -0.12457529  0.00027463
    -0.02508572]
   [ 0.10278709 -0.14117005 -0.05431923 ...  0.10310425  0.08153583
     0.00722016]]]


 [[[-0.00635295 -0.04295555 -0.11319219 ... -0.08138548 -0.01086642
    -0.12211015]
   [ 0.11309163 -0.10317813 -0.13100722 ... -0.07179538 -0.08983804
    -0.15257947]
   [ 0.02325523 -0.04964492 -0.07020095 ...  0.12276126  0.0663038
    -0.09110831]
   ...
   [-0.12847638  0.03430068  0.07079266 ...  0.1236008  -0.13222376
     0.12144394]
   [-0.02579038 -0.06945506 -0.01141365 ...  0.15284969 -0.11516398
    -0.07472745]
   [ 0.06979322 -0.06279857  0.03284374 ...  0.03379054 -0.06894726
    -0.14827794]]

  [[-0.1007089   0.00559926 -0.09329452 ...  0.12441967  0.14473404
     0.05293547]
   [ 0.1006922   0.02704065  0.0066839  ... -0.14480041  0.09607281
    -0.13959892]
   [-0.11475012  0.05574144  0.10360368 ... -0.06692488 -0.13205372
    -0.01193458]
   ...
   [ 0.03980069 -0.10872702 -0.0946364  ...  0.14228602  0.08011042
     0.07908225]
   [-0.13804172  0.08520883  0.12563427 ... -0.01032643  0.02052428
    -0.0667371 ]
   [-0.05498996  0.13551779  0.10070489 ... -0.12125607 -0.02379473
     0.11219911]]

  [[-0.02441829 -0.02414754 -0.13116531 ...  0.02331667 -0.0163087
     0.02596626]
   [ 0.01582178 -0.05865619  0.12508993 ... -0.03653862  0.12592746
    -0.00310111]
   [-0.1414698   0.05472612  0.00663584 ... -0.09624767  0.02567279
     0.09734656]
   ...
   [-0.08650972 -0.12847689  0.12138931 ...  0.07422984 -0.11917606
     0.02429377]
   [ 0.00966699 -0.11160713 -0.01302275 ... -0.08625433 -0.11847788
    -0.05292317]
   [-0.03942717 -0.12013276  0.12476434 ...  0.03556743  0.13480575
    -0.05105563]]]


 [[[-0.04907308 -0.07447261 -0.12928246 ...  0.13439037 -0.04434469
     0.04618813]
   [-0.1334546  -0.05595387 -0.08999567 ...  0.02999537  0.15332521
     0.0518073 ]
   [-0.15271872 -0.10457956 -0.03982306 ...  0.1233073  -0.01672326
     0.15170382]
   ...
   [-0.13118996 -0.07562697 -0.01606435 ... -0.01001969 -0.07054839
     0.13158418]
   [ 0.09599154  0.13463156 -0.13907158 ...  0.03257304 -0.13910665
     0.0984305 ]
   [-0.13626724 -0.01965128 -0.01778848 ...  0.13035913  0.12343745
    -0.09650597]]

  [[-0.07004372  0.06750228 -0.12161189 ... -0.11584076 -0.05434307
     0.12766393]
   [-0.11440974  0.14251153 -0.00433728 ... -0.11922845  0.12514557
     0.05618685]
   [-0.10911764 -0.01026481  0.10391827 ... -0.0720565  -0.00960386
     0.03389767]
   ...
   [ 0.10551892 -0.0583454   0.04769792 ...  0.0456288   0.00925238
     0.1054648 ]
   [-0.04099478 -0.1135696  -0.03642984 ...  0.14294074  0.08230852
    -0.02839473]
   [ 0.01468663  0.050796   -0.10447953 ...  0.06245808  0.04956307
    -0.00662629]]

  [[-0.00796257  0.09806056 -0.11828857 ... -0.1389561   0.12159269
    -0.06019013]
   [-0.04513344  0.00189039 -0.06958658 ...  0.01155271 -0.12949848
    -0.06986194]
   [ 0.15311025  0.08195239  0.08679608 ...  0.05311631  0.02386738
     0.00230996]
   ...
   [ 0.12789203 -0.13903561  0.01612011 ... -0.11376929 -0.12107642
    -0.12341671]
   [-0.00072761  0.09439664 -0.02422744 ...  0.10257189  0.14365844
     0.10456146]
   [-0.04516637  0.04562066  0.06664914 ... -0.11762814 -0.09364568
     0.08500546]]]]: "
2018-04-20 23:35:52,445 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv_2/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 23:35:52,449 (dqn_agent.py:161) DEBUG: "var_name: target_q/fully_connected/weights:0, var_value [[ 0.09208832 -0.04990041 -0.08254486 ...  0.05053981 -0.04556819
  -0.08938361]
 [-0.01819749 -0.07197729  0.04242028 ...  0.00696088 -0.00177046
  -0.06598634]
 [ 0.0545522   0.00306828 -0.03477501 ...  0.05089072 -0.05015313
  -0.01998796]
 ...
 [ 0.04571497  0.04763388 -0.00164858 ...  0.00891878 -0.06794402
  -0.04159374]
 [-0.02224246  0.0701397   0.02866688 ...  0.02703989 -0.0402051
   0.01816725]
 [-0.03171723 -0.00958906 -0.00090716 ...  0.01429334  0.07384021
  -0.02617542]]: "
2018-04-20 23:35:52,456 (dqn_agent.py:161) DEBUG: "var_name: target_q/fully_connected/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 23:35:52,466 (dqn_agent.py:161) DEBUG: "var_name: target_q/fully_connected_1/weights:0, var_value [[ 9.41843987e-02 -2.64844894e-02 -1.15831248e-01 -4.68495935e-02
   1.45739883e-01]
 [ 1.40278667e-01  1.25893116e-01 -7.60687739e-02 -2.49339640e-03
  -7.59467781e-02]
 [ 9.24690068e-02  9.15719271e-02  1.64508939e-01 -2.03239173e-01
   1.79867595e-02]
 [ 4.36149836e-02 -1.38565123e-01  1.23988330e-01  5.96751273e-03
   9.38590467e-02]
 [ 2.00166523e-01 -1.90578580e-01 -1.72439784e-01  1.24286711e-02
  -1.09387316e-01]
 [ 2.04671979e-01 -3.10925394e-02 -2.82411277e-03 -1.69391140e-01
   8.36910903e-02]
 [ 2.07587540e-01 -8.08461010e-02  1.18084520e-01  3.98486257e-02
  -1.60584569e-01]
 [ 1.19697750e-02 -4.04432267e-02 -1.84398890e-02 -1.33473366e-01
   1.84244215e-01]
 [-2.11726576e-02 -1.52533129e-01 -1.42890900e-01  7.44301081e-02
   1.68363452e-01]
 [-2.04355583e-01 -6.16494566e-02 -6.99329227e-02 -4.18539494e-02
  -1.26879543e-01]
 [-7.25771636e-02 -1.32343143e-01  3.38886976e-02  1.97165161e-02
  -1.48653328e-01]
 [-1.76388517e-01 -2.07418099e-01 -1.21249683e-01  4.65998352e-02
   7.75591433e-02]
 [ 1.18879408e-01 -1.82789564e-02  3.65058035e-02 -6.44914955e-02
   1.96717858e-01]
 [ 1.22683078e-01  8.85179341e-02  4.03122902e-02 -1.16942383e-01
   1.14848495e-01]
 [-1.81378588e-01  5.76466918e-02 -1.29786760e-01  8.55743289e-02
   7.28405416e-02]
 [-2.01203004e-01  1.33337408e-01  1.28473520e-01  3.07281315e-02
   1.06338978e-01]
 [-5.20898700e-02  1.19247556e-01  6.65053725e-03  1.44633621e-01
   8.10627639e-03]
 [ 1.20503902e-02 -7.61623532e-02  2.02923179e-01 -4.26714122e-03
  -6.22483641e-02]
 [-1.90976247e-01  3.05627435e-02 -8.35706145e-02  3.19496542e-02
   8.69476497e-02]
 [-1.76947072e-01 -1.17018797e-01 -1.43039986e-01  2.07254589e-02
  -2.81208605e-02]
 [-1.91166967e-01  1.02415502e-01 -2.11974502e-01 -9.13537070e-02
  -1.80031627e-01]
 [ 8.82156193e-02 -8.51838887e-02  2.11607516e-02 -8.40177536e-02
   1.37838304e-01]
 [ 2.39466429e-02 -1.05237253e-01 -1.58066511e-01 -2.01483861e-01
   1.58588260e-01]
 [ 1.40294522e-01  9.49476659e-03 -6.17837012e-02 -1.42307892e-01
   1.24672502e-02]
 [-2.79974937e-02  4.24382687e-02  2.11029559e-01 -1.12127878e-01
  -1.04633175e-01]
 [ 1.93760782e-01 -1.33343473e-01 -4.33564186e-02 -1.79411292e-01
  -6.15584105e-02]
 [ 8.52917135e-02 -2.03932941e-01  1.46929145e-01 -4.15806025e-02
  -3.60316634e-02]
 [ 1.74091011e-01  1.88509762e-01 -7.03749508e-02  1.54687881e-01
  -9.42196548e-02]
 [-1.52078643e-01 -1.79566294e-02  1.20080024e-01 -4.94227856e-02
  -1.17306836e-01]
 [ 7.87903965e-02  1.33114845e-01 -1.37073487e-01  6.50296509e-02
   2.68231183e-02]
 [ 1.31966442e-01 -1.10711537e-01 -2.03426033e-01 -5.30279726e-02
   1.03792548e-01]
 [ 1.73460841e-01  4.16221321e-02 -1.49355039e-01 -6.60649240e-02
  -9.12678763e-02]
 [-2.76821107e-02  1.15818083e-01  9.17750597e-03  1.25434250e-02
  -9.11471993e-02]
 [-1.31511793e-01 -1.21460445e-01  1.62447542e-01 -1.42836720e-01
  -1.76378787e-01]
 [ 5.45965731e-02  1.03324503e-01 -1.74675584e-02  9.19644833e-02
  -6.77635223e-02]
 [ 7.08636642e-02 -9.83117893e-02  1.95997924e-01  9.50899720e-03
   1.61655933e-01]
 [-1.40483290e-01 -2.89529115e-02  1.42150044e-01  1.05851918e-01
   1.00489855e-01]
 [-1.71153799e-01  1.93017840e-01 -2.01614797e-02 -1.49661422e-01
   9.78524983e-02]
 [-1.93590522e-02 -6.11737520e-02  2.08739281e-01  5.22648394e-02
   5.03803790e-02]
 [ 1.81646645e-02  9.37536061e-02 -8.08738023e-02 -5.89879453e-02
  -1.64468110e-01]
 [ 8.43631625e-02  1.27567768e-01  6.03376031e-02  1.09717995e-01
  -5.76914251e-02]
 [ 1.86725974e-01  1.11497670e-01  3.47631425e-02  7.50306547e-02
   1.95929050e-01]
 [ 1.90506458e-01 -1.59306273e-01  1.96017623e-01  5.09883761e-02
   3.00376564e-02]
 [ 2.02566743e-01  1.46912038e-01  1.28696948e-01  6.24190271e-02
  -1.32516474e-01]
 [ 1.28966868e-02 -1.91034287e-01 -7.97865689e-02 -6.20825738e-02
   1.57503396e-01]
 [-5.30101955e-02 -9.00521204e-02 -1.22935019e-01 -1.44250929e-01
  -1.82731166e-01]
 [ 1.31250948e-01  5.88699579e-02  6.61057234e-02 -1.13903202e-01
  -2.05784827e-01]
 [-1.97580010e-01 -1.65807426e-01 -9.29367542e-02 -1.42638668e-01
  -1.89123705e-01]
 [-1.31524801e-01  4.68009710e-02 -7.13889599e-02 -4.04773653e-02
   1.10230982e-01]
 [ 6.44470751e-02 -2.09957227e-01  2.04735279e-01 -1.44003242e-01
   2.05982357e-01]
 [ 9.58260000e-02 -1.64768010e-01 -9.60356370e-02 -1.31485403e-01
  -7.57715106e-03]
 [ 1.12183839e-01 -1.29488990e-01 -1.85785040e-01  9.10305679e-02
  -1.47022933e-01]
 [ 1.88098758e-01 -1.98731899e-01 -1.43483698e-01  2.69821286e-02
  -1.54186159e-01]
 [-1.67629242e-01  5.93566597e-02  1.60063326e-01  5.96368313e-02
   8.38646889e-02]
 [-3.18143070e-02 -1.72506034e-01  9.50035453e-02  1.30044103e-01
   9.10023153e-02]
 [-7.80989230e-03 -5.05337119e-03  1.28698647e-01 -2.01229095e-01
  -5.98277003e-02]
 [ 1.32370025e-01  5.68467379e-02  9.63126421e-02  1.76570773e-01
   3.77829373e-02]
 [ 9.50622857e-02 -1.68551743e-01  2.05425441e-01 -1.68950737e-01
  -9.54200178e-02]
 [-1.72950089e-01  8.35857391e-02 -7.92471021e-02  1.67236924e-01
  -1.39760673e-02]
 [-3.24919671e-02  7.95708597e-02 -2.38159895e-02  1.70458525e-01
  -1.94283068e-01]
 [ 6.37698472e-02 -8.46521705e-02  7.02268779e-02 -1.44052058e-01
   5.62299490e-02]
 [ 8.36951435e-02 -2.31018215e-02 -8.50139856e-02  3.36380899e-02
   1.55538291e-01]
 [-1.13002658e-02  1.74219280e-01  2.09914267e-01  1.94097579e-01
  -2.99056023e-02]
 [ 3.00183892e-04  5.88477254e-02  1.03026181e-02 -1.01839796e-01
  -8.25441927e-02]
 [-3.33083272e-02 -1.39377773e-01 -1.14709839e-01  9.65727270e-02
  -1.26399323e-01]
 [-1.62046015e-01 -8.14749449e-02  2.64911652e-02 -1.41018152e-01
   1.87464535e-01]
 [ 3.97706926e-02  1.17448360e-01  1.71435624e-02  1.31974190e-01
   1.71311080e-01]
 [-7.79372603e-02  1.91266328e-01 -1.14035368e-01  4.22566831e-02
   5.37168086e-02]
 [ 5.27322292e-02 -2.94049233e-02 -2.69012004e-02  9.68015194e-03
   4.97378111e-02]
 [ 1.13461018e-01  7.77906775e-02 -3.18808854e-02 -1.58268929e-01
   1.70776933e-01]
 [ 2.94875652e-02  1.23611093e-03  7.88461566e-02 -9.10558999e-02
  -1.05753422e-01]
 [ 5.91489673e-02 -1.01190902e-01 -1.43538684e-01 -2.03389019e-01
   1.01198554e-02]
 [ 1.63611710e-01 -1.74926192e-01 -1.59974873e-01  2.44255364e-02
  -9.51495990e-02]
 [ 9.12444293e-03  5.74809611e-02  1.62916780e-01  3.12701315e-02
  -8.91739801e-02]
 [-8.46979022e-02  7.36199319e-02  9.43228006e-02  2.44632363e-04
   5.59854805e-02]
 [ 1.93013489e-01 -1.78983182e-01 -7.89469182e-02  1.77052796e-01
   1.39967203e-02]
 [ 1.56567544e-01  2.05590308e-01  2.09305286e-01  3.35833430e-02
   2.81270295e-02]
 [ 6.87540472e-02  1.84742838e-01 -1.60194486e-01  1.77264184e-01
   1.56694949e-02]
 [-1.40035838e-01  1.37729973e-01  7.60086477e-02  5.33849299e-02
  -1.28391981e-02]
 [-1.86731339e-01  5.89225590e-02 -3.43127996e-02 -8.98831338e-02
   1.30436510e-01]
 [-1.54017180e-01 -1.39273614e-01 -1.97151244e-01 -1.61650836e-01
  -1.46606386e-01]
 [-1.35419339e-01  1.78630084e-01 -3.07579041e-02 -1.90831214e-01
  -7.22976923e-02]
 [ 1.75946444e-01  1.69933438e-01  4.58082259e-02  6.06953204e-02
  -1.89444155e-01]
 [ 1.04298145e-01 -9.59210396e-02  1.94479138e-01 -1.67582482e-02
   2.72818059e-02]
 [ 7.98933208e-02 -3.00746858e-02 -1.84062779e-01 -2.01386735e-01
   7.51195252e-02]
 [ 5.33570349e-02 -1.60957679e-01 -5.67541271e-02 -1.35746166e-01
   5.46709299e-02]
 [-9.40005854e-02  1.35951400e-01  1.94575459e-01 -1.24612913e-01
   7.42363632e-02]
 [ 1.41471744e-01 -2.00529709e-01 -1.64302975e-01  5.54084480e-02
  -1.07956648e-01]
 [ 2.06234902e-01 -6.60274029e-02  7.96467066e-02  4.74537909e-03
   1.56511426e-01]
 [-1.72948569e-01 -1.31976604e-03  5.92384040e-02 -1.01763278e-01
  -5.51839024e-02]
 [ 9.81533229e-02  2.68353522e-03 -1.09362908e-01  1.06566846e-01
   1.32747382e-01]
 [-1.20271735e-01  8.35888386e-02  1.69129580e-01 -4.15137559e-02
   1.68211997e-01]
 [ 5.25202453e-02  1.38966590e-01  8.90348852e-02  1.47723228e-01
  -8.19433033e-02]
 [ 1.05392456e-01  9.36476886e-03  1.02914780e-01  9.76723135e-02
   1.95133865e-01]
 [-1.22557700e-01  2.20555514e-02 -1.48119032e-01  4.52690721e-02
   6.15100563e-02]
 [-1.29358396e-01 -1.17850199e-01 -3.21504474e-02  3.05366218e-02
  -1.99104056e-01]
 [ 1.33253187e-01 -1.61816627e-01 -3.95215452e-02 -1.43144712e-01
  -1.45322919e-01]
 [ 2.02819437e-01 -1.61296248e-01  5.00053465e-02  9.15070474e-02
   8.37028027e-04]
 [ 1.76459402e-01  1.09067112e-01 -1.00024417e-01  8.25926065e-02
   1.77250087e-01]
 [-1.36041701e-01  3.85475755e-02  1.67484611e-01  1.49927169e-01
  -2.90879160e-02]
 [ 1.16280466e-01  1.12362057e-02 -8.33821297e-02 -1.29254490e-01
  -4.61813509e-02]
 [ 1.33447587e-01  3.27080488e-05 -2.07371876e-01  1.31088078e-01
  -3.08701843e-02]
 [-4.89011407e-03 -8.64779353e-02 -1.11787632e-01  1.46367252e-01
  -6.27700090e-02]
 [ 4.38854694e-02 -2.79776007e-02 -1.75280005e-01 -1.69479847e-03
   6.24385774e-02]
 [ 1.26013756e-01 -1.55174747e-01 -1.88947931e-01  6.40135705e-02
  -7.95145929e-02]
 [-3.49390656e-02 -1.00915521e-01 -1.75704375e-01  3.83919775e-02
  -1.40991464e-01]
 [ 1.56704664e-01  4.58392203e-02 -1.89413920e-01 -1.97497964e-01
   1.93228185e-01]
 [-1.93983018e-01 -1.58940256e-01 -1.57568127e-01  1.57044381e-02
   9.65109468e-02]
 [-1.28197998e-01 -7.10884631e-02  1.03994548e-01  1.71612591e-01
   9.34025347e-02]
 [ 1.42444760e-01 -1.00877188e-01 -1.26483321e-01  1.04141712e-01
  -2.16393173e-03]
 [-7.79948980e-02 -3.59653234e-02 -9.14122015e-02 -1.29268110e-01
  -1.26362965e-01]
 [ 1.65331870e-01  1.17218912e-01 -1.06737554e-01  8.11842680e-02
  -1.71901554e-01]
 [ 1.27584040e-01  1.80365294e-01 -1.61782444e-01  1.81487143e-01
  -3.61197293e-02]
 [-5.02271503e-02 -1.38750374e-02  1.66606575e-01 -3.34460586e-02
  -5.44165522e-02]
 [-8.07016343e-02 -3.04877013e-02  1.28324777e-01  1.56117231e-02
  -1.25438586e-01]
 [-1.85010463e-01  6.54385090e-02 -1.63126111e-01  1.67328894e-01
   1.31394953e-01]
 [-1.15119457e-01 -1.00164182e-01  1.49016976e-01 -1.28753856e-01
  -6.59464300e-02]
 [-1.60031989e-01 -1.92502573e-01 -3.72654945e-02 -1.19228356e-01
  -9.79620218e-02]
 [-1.41624808e-01  2.03999668e-01  1.05763644e-01  1.32561505e-01
  -7.75281936e-02]
 [ 4.05908823e-02  1.81352258e-01  3.61457616e-02 -1.58288971e-01
  -1.17697619e-01]
 [-1.57264993e-01 -1.08807497e-01  1.99052393e-02  7.65399039e-02
  -9.54790115e-02]
 [-2.11821213e-01  2.07513154e-01  8.24109018e-02  1.53677434e-01
  -9.82628688e-02]
 [ 4.50119376e-02  2.52357721e-02 -1.65888652e-01  1.16438687e-01
   2.07253337e-01]
 [ 1.88082665e-01  1.15992248e-01  1.81157649e-01 -1.45411044e-02
   1.01934850e-01]
 [-1.47524565e-01 -1.77946597e-01 -1.19411469e-01  8.66018534e-02
   9.19072032e-02]
 [-2.74482667e-02 -2.08221555e-01 -3.40739936e-02 -9.36670229e-02
  -8.30225646e-03]
 [ 1.31137609e-01 -9.49288607e-02 -5.27300537e-02  1.62269652e-01
   2.03222096e-01]
 [-1.81248039e-01  4.24956977e-02 -2.00731397e-01 -2.01674864e-01
  -8.27179998e-02]]: "
2018-04-20 23:35:52,471 (dqn_agent.py:161) DEBUG: "var_name: target_q/fully_connected_1/biases:0, var_value [0. 0. 0. 0. 0.]: "

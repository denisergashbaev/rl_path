2018-04-20 00:09:43,744 (dqn_main.py:61) DEBUG: ">>>> RUNNING data_file=7_17.npy,reuse_weights=None,test=False<<<<"
2018-04-20 00:09:44,064 (tf_logging.py:160) Level 1: "Registering Batch (<function _BatchGrad at 0x7f16fc834378>) in gradient."
2018-04-20 00:09:44,064 (tf_logging.py:160) Level 1: "Registering Unbatch (<function _UnbatchGrad at 0x7f16fc834e18>) in gradient."
2018-04-20 00:09:44,067 (tf_logging.py:160) Level 1: "Registering ZeroInitializer (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,081 (tf_logging.py:160) Level 1: "Registering SparseFeatureCross (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,083 (tf_logging.py:160) Level 1: "Registering SparseFeatureCrossV2 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,085 (tf_logging.py:160) Level 1: "Registering SparseFeatureCross (None) in gradient."
2018-04-20 00:09:44,086 (tf_logging.py:160) Level 1: "Registering SparseFeatureCrossV2 (None) in gradient."
2018-04-20 00:09:44,089 (tf_logging.py:160) Level 1: "Registering GDNLowerBound (<function GDN._lower_bound_grad at 0x7f16f81de6a8>) in gradient."
2018-04-20 00:09:44,105 (tf_logging.py:160) Level 1: "Registering ObtainNext (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,113 (tf_logging.py:160) Level 1: "Registering hparams ((<class 'tensorflow.contrib.training.python.training.hparam_pb2.HParamDef'>, <function HParams.to_proto at 0x7f16f02c1620>, <function HParams.from_proto at 0x7f16f02c16a8>)) in proto functions."
2018-04-20 00:09:44,119 (tf_logging.py:160) Level 1: "Registering GRUBlockCell (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,121 (tf_logging.py:160) Level 1: "Registering GRUBlockCellGrad (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,122 (tf_logging.py:160) Level 1: "Registering GRUBlockCell (<function _GRUBlockCellGrad at 0x7f16f0259b70>) in gradient."
2018-04-20 00:09:44,124 (tf_logging.py:160) Level 1: "Registering BlockLSTM (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,125 (tf_logging.py:160) Level 1: "Registering BlockLSTMGrad (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,125 (tf_logging.py:160) Level 1: "Registering LSTMBlockCell (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,126 (tf_logging.py:160) Level 1: "Registering LSTMBlockCellGrad (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,128 (tf_logging.py:160) Level 1: "Registering LSTMBlockCell (<function _LSTMBlockCellGrad at 0x7f16f0221d90>) in gradient."
2018-04-20 00:09:44,129 (tf_logging.py:160) Level 1: "Registering BlockLSTM (<function _BlockLSTMGrad at 0x7f16f0221e18>) in gradient."
2018-04-20 00:09:44,132 (tf_logging.py:160) Level 1: "Registering KMC2ChainInitialization (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,133 (tf_logging.py:160) Level 1: "Registering KmeansPlusPlusInitialization (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,134 (tf_logging.py:160) Level 1: "Registering NearestNeighbors (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,137 (tf_logging.py:160) Level 1: "Registering MaskedMatmul (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,138 (tf_logging.py:160) Level 1: "Registering WALSComputePartialLhsAndRhs (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,148 (tf_logging.py:160) Level 1: "Registering ConfigureDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,149 (tf_logging.py:160) Level 1: "Registering CrossReplicaSum (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,149 (tf_logging.py:160) Level 1: "Registering InfeedDequeue (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,150 (tf_logging.py:160) Level 1: "Registering InfeedDequeueTuple (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,150 (tf_logging.py:160) Level 1: "Registering InfeedEnqueue (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,151 (tf_logging.py:160) Level 1: "Registering InfeedEnqueueTuple (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,151 (tf_logging.py:160) Level 1: "Registering OutfeedDequeue (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,151 (tf_logging.py:160) Level 1: "Registering OutfeedDequeueTuple (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,152 (tf_logging.py:160) Level 1: "Registering OutfeedEnqueue (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,152 (tf_logging.py:160) Level 1: "Registering OutfeedEnqueueTuple (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,153 (tf_logging.py:160) Level 1: "Registering ShutdownDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,153 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingActivations (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,154 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingEnqueueSparseBatch (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,154 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingLoadAdagradParameters (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,155 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingLoadGradientDescentParameters (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,155 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingReceiveActivations (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,156 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingRetrieveAdagradParameters (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,157 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingRetrieveGradientDescentParameters (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,157 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingSendGradients (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,158 (tf_logging.py:160) Level 1: "Registering TPUReplicate (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,158 (tf_logging.py:160) Level 1: "Registering TPUReplicateMetadata (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,159 (tf_logging.py:160) Level 1: "Registering TPUReplicatedInput (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,159 (tf_logging.py:160) Level 1: "Registering TPUReplicatedOutput (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,163 (tf_logging.py:160) Level 1: "Registering _ConfigureDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,164 (tf_logging.py:160) Level 1: "Registering _WaitForDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,165 (tf_logging.py:160) Level 1: "Registering _SetGlobalTPUArray (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,165 (tf_logging.py:160) Level 1: "Registering _ShutdownDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,166 (tf_logging.py:160) Level 1: "Registering _InitializeHostForDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,166 (tf_logging.py:160) Level 1: "Registering _DisconnectHostFromDistributedTPUSystem (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,168 (tf_logging.py:160) Level 1: "Registering CrossReplicaSum (<function _cross_replica_sum_grad at 0x7f16f00da400>) in gradient."
2018-04-20 00:09:44,172 (tf_logging.py:160) Level 1: "Registering CloseSummaryWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,173 (tf_logging.py:160) Level 1: "Registering CreateSummaryDbWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,174 (tf_logging.py:160) Level 1: "Registering CreateSummaryFileWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,175 (tf_logging.py:160) Level 1: "Registering FlushSummaryWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,175 (tf_logging.py:160) Level 1: "Registering ImportEvent (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,176 (tf_logging.py:160) Level 1: "Registering SummaryWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,177 (tf_logging.py:160) Level 1: "Registering WriteAudioSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,177 (tf_logging.py:160) Level 1: "Registering WriteGraphSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,178 (tf_logging.py:160) Level 1: "Registering WriteHistogramSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,179 (tf_logging.py:160) Level 1: "Registering WriteImageSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,179 (tf_logging.py:160) Level 1: "Registering WriteScalarSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,180 (tf_logging.py:160) Level 1: "Registering WriteSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,207 (tf_logging.py:160) Level 1: "Registering BigQueryReader (None) in gradient."
2018-04-20 00:09:44,220 (tf_logging.py:160) Level 1: "Registering RangeDecode (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,221 (tf_logging.py:160) Level 1: "Registering RangeEncode (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,273 (tf_logging.py:160) Level 1: "Registering CudnnRNN (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,274 (tf_logging.py:160) Level 1: "Registering CudnnRNNBackprop (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,275 (tf_logging.py:160) Level 1: "Registering CudnnRNNCanonicalToParams (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,275 (tf_logging.py:160) Level 1: "Registering CudnnRNNParamsSize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,276 (tf_logging.py:160) Level 1: "Registering CudnnRNNParamsToCanonical (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,282 (tf_logging.py:160) Level 1: "Registering CudnnRNN (<function _cudnn_rnn_backward at 0x7f16e14d46a8>) in gradient."
2018-04-20 00:09:44,283 (tf_logging.py:160) Level 1: "Registering CudnnRNNParamsSize (<function call_cpp_shape_fn at 0x7f1767fa7840>) in shape functions."
2018-04-20 00:09:44,283 (tf_logging.py:160) Level 1: "Registering CudnnRNNParamsToCanonical (<function call_cpp_shape_fn at 0x7f1767fa7840>) in shape functions."
2018-04-20 00:09:44,283 (tf_logging.py:160) Level 1: "Registering CudnnRNNCanonicalToParams (<function call_cpp_shape_fn at 0x7f1767fa7840>) in shape functions."
2018-04-20 00:09:44,284 (tf_logging.py:160) Level 1: "Registering CudnnRNN (<function call_cpp_shape_fn at 0x7f1767fa7840>) in shape functions."
2018-04-20 00:09:44,284 (tf_logging.py:160) Level 1: "Registering CudnnRNNBackprop (<function call_cpp_shape_fn at 0x7f1767fa7840>) in shape functions."
2018-04-20 00:09:44,312 (tf_logging.py:160) Level 1: "Registering AdjustHsvInYiq (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,315 (tf_logging.py:160) Level 1: "Registering BipartiteMatch (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,315 (tf_logging.py:160) Level 1: "Registering ImageConnectedComponents (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,316 (tf_logging.py:160) Level 1: "Registering ImageProjectiveTransform (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,318 (tf_logging.py:160) Level 1: "Registering ImageConnectedComponents (<function call_cpp_shape_fn at 0x7f1767fa7840>) in shape functions."
2018-04-20 00:09:44,319 (tf_logging.py:160) Level 1: "Registering ImageProjectiveTransform (<function call_cpp_shape_fn at 0x7f1767fa7840>) in shape functions."
2018-04-20 00:09:44,319 (tf_logging.py:160) Level 1: "Registering ImageProjectiveTransform (<function _image_projective_transform_grad at 0x7f16e0df4b70>) in gradient."
2018-04-20 00:09:44,319 (tf_logging.py:160) Level 1: "Registering BipartiteMatch (None) in gradient."
2018-04-20 00:09:44,320 (tf_logging.py:160) Level 1: "Registering ImageConnectedComponents (None) in gradient."
2018-04-20 00:09:44,320 (tf_logging.py:160) Level 1: "Registering SingleImageRandomDotStereograms (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,325 (tf_logging.py:160) Level 1: "Registering SingleImageRandomDotStereograms (None) in gradient."
2018-04-20 00:09:44,355 (tf_logging.py:160) Level 1: "Registering BytesInUse (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,355 (tf_logging.py:160) Level 1: "Registering BytesLimit (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,356 (tf_logging.py:160) Level 1: "Registering MaxBytesInUse (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,360 (tf_logging.py:160) Level 1: "Registering NcclAllReduce (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,360 (tf_logging.py:160) Level 1: "Registering NcclBroadcast (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,361 (tf_logging.py:160) Level 1: "Registering NcclReduce (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,363 (tf_logging.py:160) Level 1: "Registering _NcclReduceSend (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,363 (tf_logging.py:160) Level 1: "Registering _NcclReduceRecv (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,364 (tf_logging.py:160) Level 1: "Registering _NcclBroadcastSend (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,364 (tf_logging.py:160) Level 1: "Registering _NcclBroadcastRecv (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,364 (tf_logging.py:160) Level 1: "Registering NcclAllReduce (<function _all_sum_grad at 0x7f16e04a8950>) in gradient."
2018-04-20 00:09:44,365 (tf_logging.py:160) Level 1: "Registering NcclReduce (<function _reduce_sum_grad at 0x7f16e04a8bf8>) in gradient."
2018-04-20 00:09:44,365 (tf_logging.py:160) Level 1: "Registering NcclBroadcast (<function _broadcast_grad at 0x7f16e04a8d90>) in gradient."
2018-04-20 00:09:44,366 (tf_logging.py:160) Level 1: "Registering PeriodicResample (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,373 (tf_logging.py:160) Level 1: "Registering FoldFusedBatchNormGrad (<function _FoldFusedBatchNormGrad at 0x7f16e01ed048>) in gradient."
2018-04-20 00:09:44,377 (tf_logging.py:160) Level 1: "Registering Resampler (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,378 (tf_logging.py:160) Level 1: "Registering ResamplerGrad (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,380 (tf_logging.py:160) Level 1: "Registering Resampler (<function _resampler_grad at 0x7f16e0195c80>) in gradient."
2018-04-20 00:09:44,381 (tf_logging.py:160) Level 1: "Registering ResamplerGrad (None) in gradient."
2018-04-20 00:09:44,385 (tf_logging.py:160) Level 1: "Registering GatherTree (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,394 (tf_logging.py:160) Level 1: "Registering StatelessRandomNormal (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,395 (tf_logging.py:160) Level 1: "Registering StatelessRandomUniform (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,395 (tf_logging.py:160) Level 1: "Registering StatelessTruncatedNormal (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,396 (tf_logging.py:160) Level 1: "Registering StatelessRandomNormal (None) in gradient."
2018-04-20 00:09:44,396 (tf_logging.py:160) Level 1: "Registering StatelessRandomUniform (None) in gradient."
2018-04-20 00:09:44,397 (tf_logging.py:160) Level 1: "Registering StatelessTruncatedNormal (None) in gradient."
2018-04-20 00:09:44,402 (tf_logging.py:160) Level 1: "Registering ReinterpretStringToFloat (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,403 (tf_logging.py:160) Level 1: "Registering ScatterAddNdim (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,410 (tf_logging.py:160) Level 1: "Registering CreateTreeVariable (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,411 (tf_logging.py:160) Level 1: "Registering DecisionTreeResourceHandleOp (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,411 (tf_logging.py:160) Level 1: "Registering FeatureUsageCounts (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,412 (tf_logging.py:160) Level 1: "Registering TraverseTreeV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,413 (tf_logging.py:160) Level 1: "Registering TreeDeserialize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,413 (tf_logging.py:160) Level 1: "Registering TreeIsInitializedOp (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,414 (tf_logging.py:160) Level 1: "Registering TreePredictionsV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,415 (tf_logging.py:160) Level 1: "Registering TreeSerialize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,416 (tf_logging.py:160) Level 1: "Registering TreeSize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,416 (tf_logging.py:160) Level 1: "Registering UpdateModelV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,420 (tf_logging.py:160) Level 1: "Registering TreeVariable (None) in gradient."
2018-04-20 00:09:44,421 (tf_logging.py:160) Level 1: "Registering TreeSerialize (None) in gradient."
2018-04-20 00:09:44,421 (tf_logging.py:160) Level 1: "Registering TreeDeserialize (None) in gradient."
2018-04-20 00:09:44,422 (tf_logging.py:160) Level 1: "Registering TreeSize (None) in gradient."
2018-04-20 00:09:44,422 (tf_logging.py:160) Level 1: "Registering TreePredictionsV4 (None) in gradient."
2018-04-20 00:09:44,423 (tf_logging.py:160) Level 1: "Registering FeatureUsageCounts (None) in gradient."
2018-04-20 00:09:44,424 (tf_logging.py:160) Level 1: "Registering CreateFertileStatsVariable (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,425 (tf_logging.py:160) Level 1: "Registering FertileStatsDeserialize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,425 (tf_logging.py:160) Level 1: "Registering FertileStatsIsInitializedOp (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,426 (tf_logging.py:160) Level 1: "Registering FertileStatsResourceHandleOp (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,427 (tf_logging.py:160) Level 1: "Registering FertileStatsSerialize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,427 (tf_logging.py:160) Level 1: "Registering FinalizeTree (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,428 (tf_logging.py:160) Level 1: "Registering GrowTreeV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,429 (tf_logging.py:160) Level 1: "Registering ProcessInputV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,457 (tf_logging.py:160) Level 1: "Registering FertileStatsVariable (None) in gradient."
2018-04-20 00:09:44,467 (tf_logging.py:160) Level 1: "Registering FertileStatsSerialize (None) in gradient."
2018-04-20 00:09:44,468 (tf_logging.py:160) Level 1: "Registering FertileStatsDeserialize (None) in gradient."
2018-04-20 00:09:44,468 (tf_logging.py:160) Level 1: "Registering GrowTreeV4 (None) in gradient."
2018-04-20 00:09:44,469 (tf_logging.py:160) Level 1: "Registering ProcessInputV4 (None) in gradient."
2018-04-20 00:09:44,469 (tf_logging.py:160) Level 1: "Registering FinalizeTree (None) in gradient."
2018-04-20 00:09:44,489 (tf_logging.py:160) Level 1: "Registering FunctionBufferingResource (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,493 (tf_logging.py:160) Level 1: "Registering FunctionBufferingResourceGetNext (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,519 (tf_logging.py:160) Level 1: "Registering RemoteFusedGraphExecute (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f1767fa7950>) in default shape functions."
2018-04-20 00:09:44,522 (tf_logging.py:160) Level 1: "Registering RemoteFusedGraphExecute (None) in gradient."
2018-04-20 00:09:44,538 (tf_logging.py:160) Level 1: "Created variable q/Conv/weights:0 with shape (1, 1, 2, 8) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f16f81d5510>"
2018-04-20 00:09:44,542 (tf_logging.py:160) Level 1: "Created variable q/Conv/biases:0 with shape (8,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16f81d9208>"
2018-04-20 00:09:44,552 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/weights:0 with shape (3, 3, 8, 12) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f16f81d5510>"
2018-04-20 00:09:44,557 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/biases:0 with shape (12,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16f81d9208>"
2018-04-20 00:09:44,565 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/weights:0 with shape (3, 3, 12, 16) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f16f81d5510>"
2018-04-20 00:09:44,569 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/biases:0 with shape (16,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16f81d9208>"
2018-04-20 00:09:44,582 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/weights:0 with shape (576, 128) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f16f81de2f0>"
2018-04-20 00:09:44,586 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/biases:0 with shape (128,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16f81d95f8>"
2018-04-20 00:09:44,593 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/weights:0 with shape (128, 5) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f16f81de2f0>"
2018-04-20 00:09:44,597 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/biases:0 with shape (5,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16f81d95f8>"
2018-04-20 00:09:44,605 (tf_logging.py:160) Level 1: "Created variable target_q/Conv/weights:0 with shape (1, 1, 2, 8) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f16f81d5510>"
2018-04-20 00:09:44,609 (tf_logging.py:160) Level 1: "Created variable target_q/Conv/biases:0 with shape (8,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16f81d9208>"
2018-04-20 00:09:44,616 (tf_logging.py:160) Level 1: "Created variable target_q/Conv_1/weights:0 with shape (3, 3, 8, 12) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f16f81d5510>"
2018-04-20 00:09:44,620 (tf_logging.py:160) Level 1: "Created variable target_q/Conv_1/biases:0 with shape (12,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16f81d9208>"
2018-04-20 00:09:44,626 (tf_logging.py:160) Level 1: "Created variable target_q/Conv_2/weights:0 with shape (3, 3, 12, 16) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f16f81d5510>"
2018-04-20 00:09:44,631 (tf_logging.py:160) Level 1: "Created variable target_q/Conv_2/biases:0 with shape (16,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16f81d9208>"
2018-04-20 00:09:44,640 (tf_logging.py:160) Level 1: "Created variable target_q/fully_connected/weights:0 with shape (576, 128) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f16f81de2f0>"
2018-04-20 00:09:44,644 (tf_logging.py:160) Level 1: "Created variable target_q/fully_connected/biases:0 with shape (128,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16f81d95f8>"
2018-04-20 00:09:44,650 (tf_logging.py:160) Level 1: "Created variable target_q/fully_connected_1/weights:0 with shape (128, 5) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f16f81de2f0>"
2018-04-20 00:09:44,653 (tf_logging.py:160) Level 1: "Created variable target_q/fully_connected_1/biases:0 with shape (5,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16f81d95f8>"
2018-04-20 00:09:44,675 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/value'"
2018-04-20 00:09:44,676 (tf_logging.py:160) Level 1: "  in  --> gradients/Fill:0"
2018-04-20 00:09:44,676 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/value_grad/tuple/control_dependency:0, gradients/mean_squared_error/value_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,682 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/div'"
2018-04-20 00:09:44,682 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/value_grad/tuple/control_dependency:0"
2018-04-20 00:09:44,682 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/div_grad/tuple/control_dependency:0, gradients/mean_squared_error/div_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,684 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/Sum_1'"
2018-04-20 00:09:44,685 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/div_grad/tuple/control_dependency:0"
2018-04-20 00:09:44,685 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/Sum_1_grad/Tile:0"
2018-04-20 00:09:44,688 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/Select'"
2018-04-20 00:09:44,688 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/div_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,689 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/Select_grad/tuple/control_dependency:0, gradients/mean_squared_error/Select_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,693 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/Sum'"
2018-04-20 00:09:44,693 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/Sum_1_grad/Tile:0"
2018-04-20 00:09:44,693 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/Sum_grad/Tile:0"
2018-04-20 00:09:44,700 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/Mul'"
2018-04-20 00:09:44,701 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/Sum_grad/Tile:0"
2018-04-20 00:09:44,701 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/Mul_grad/tuple/control_dependency:0, gradients/mean_squared_error/Mul_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,704 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/num_present'"
2018-04-20 00:09:44,704 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/Select_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,704 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/num_present_grad/Tile:0"
2018-04-20 00:09:44,710 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/num_present/broadcast_weights'"
2018-04-20 00:09:44,711 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/num_present_grad/Tile:0"
2018-04-20 00:09:44,711 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/num_present/broadcast_weights_grad/tuple/control_dependency:0, gradients/mean_squared_error/num_present/broadcast_weights_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,712 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/num_present/broadcast_weights/ones_like'"
2018-04-20 00:09:44,713 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/num_present/broadcast_weights_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,713 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/num_present/broadcast_weights/ones_like_grad/Sum:0"
2018-04-20 00:09:44,719 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/SquaredDifference'"
2018-04-20 00:09:44,720 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/Mul_grad/tuple/control_dependency:0"
2018-04-20 00:09:44,720 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/SquaredDifference_grad/tuple/control_dependency:0, gradients/mean_squared_error/SquaredDifference_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,727 (tf_logging.py:160) Level 1: "Gradient for 'Sum'"
2018-04-20 00:09:44,728 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/SquaredDifference_grad/tuple/control_dependency:0"
2018-04-20 00:09:44,728 (tf_logging.py:160) Level 1: "  out --> gradients/Sum_grad/Tile:0"
2018-04-20 00:09:44,734 (tf_logging.py:160) Level 1: "Gradient for 'mul'"
2018-04-20 00:09:44,734 (tf_logging.py:160) Level 1: "  in  --> gradients/Sum_grad/Tile:0"
2018-04-20 00:09:44,734 (tf_logging.py:160) Level 1: "  out --> gradients/mul_grad/tuple/control_dependency:0, gradients/mul_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,736 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected_1/BiasAdd'"
2018-04-20 00:09:44,736 (tf_logging.py:160) Level 1: "  in  --> gradients/mul_grad/tuple/control_dependency:0"
2018-04-20 00:09:44,737 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency:0, gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,739 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected_1/MatMul'"
2018-04-20 00:09:44,739 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 00:09:44,740 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency:0, gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,740 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected_1/biases/read'"
2018-04-20 00:09:44,740 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,741 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,741 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/Relu'"
2018-04-20 00:09:44,742 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency:0"
2018-04-20 00:09:44,742 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/Relu_grad/ReluGrad:0"
2018-04-20 00:09:44,742 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected_1/weights/read'"
2018-04-20 00:09:44,743 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,743 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,745 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/BiasAdd'"
2018-04-20 00:09:44,745 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/Relu_grad/ReluGrad:0"
2018-04-20 00:09:44,745 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency:0, gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,748 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/MatMul'"
2018-04-20 00:09:44,748 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 00:09:44,748 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/MatMul_grad/tuple/control_dependency:0, gradients/q/fully_connected/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,749 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/biases/read'"
2018-04-20 00:09:44,749 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,749 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,750 (tf_logging.py:160) Level 1: "Gradient for 'q/Flatten/flatten/Reshape'"
2018-04-20 00:09:44,750 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/MatMul_grad/tuple/control_dependency:0"
2018-04-20 00:09:44,750 (tf_logging.py:160) Level 1: "  out --> gradients/q/Flatten/flatten/Reshape_grad/Reshape:0"
2018-04-20 00:09:44,751 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/weights/read'"
2018-04-20 00:09:44,751 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,751 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,752 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/Relu'"
2018-04-20 00:09:44,752 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Flatten/flatten/Reshape_grad/Reshape:0"
2018-04-20 00:09:44,752 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/Relu_grad/ReluGrad:0"
2018-04-20 00:09:44,754 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/BiasAdd'"
2018-04-20 00:09:44,754 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/Relu_grad/ReluGrad:0"
2018-04-20 00:09:44,754 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency:0, gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,758 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/Conv2D'"
2018-04-20 00:09:44,758 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 00:09:44,758 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency:0, gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,758 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/biases/read'"
2018-04-20 00:09:44,758 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,759 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,759 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/Relu'"
2018-04-20 00:09:44,759 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency:0"
2018-04-20 00:09:44,759 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/Relu_grad/ReluGrad:0"
2018-04-20 00:09:44,760 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/weights/read'"
2018-04-20 00:09:44,760 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,760 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,761 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/BiasAdd'"
2018-04-20 00:09:44,761 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/Relu_grad/ReluGrad:0"
2018-04-20 00:09:44,762 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency:0, gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,765 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/Conv2D'"
2018-04-20 00:09:44,765 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 00:09:44,765 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency:0, gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,766 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/biases/read'"
2018-04-20 00:09:44,766 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,766 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,767 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/Relu'"
2018-04-20 00:09:44,767 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency:0"
2018-04-20 00:09:44,767 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/Relu_grad/ReluGrad:0"
2018-04-20 00:09:44,767 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/weights/read'"
2018-04-20 00:09:44,767 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,767 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,769 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/BiasAdd'"
2018-04-20 00:09:44,769 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv/Relu_grad/ReluGrad:0"
2018-04-20 00:09:44,769 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/BiasAdd_grad/tuple/control_dependency:0, gradients/q/Conv/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,773 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/Conv2D'"
2018-04-20 00:09:44,773 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 00:09:44,773 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/Conv2D_grad/tuple/control_dependency:0, gradients/q/Conv/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,774 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/biases/read'"
2018-04-20 00:09:44,774 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,774 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,774 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/weights/read'"
2018-04-20 00:09:44,774 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,775 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 00:09:44,858 (tf_logging.py:126) WARNING: "From /home/syedeqbal/.local/lib/python3.5/site-packages/tensorflow/python/ops/clip_ops.py:113: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead"
2018-04-20 00:09:44,889 (tf_logging.py:160) Level 1: "Created variable q/Conv/weights/Adam:0 with shape (1, 1, 2, 8) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16befed358>"
2018-04-20 00:09:44,891 (tf_logging.py:160) Level 1: "Created variable q/Conv/weights/Adam_1:0 with shape (1, 1, 2, 8) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16befed358>"
2018-04-20 00:09:44,894 (tf_logging.py:160) Level 1: "Created variable q/Conv/biases/Adam:0 with shape (8,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16befed358>"
2018-04-20 00:09:44,897 (tf_logging.py:160) Level 1: "Created variable q/Conv/biases/Adam_1:0 with shape (8,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16befed358>"
2018-04-20 00:09:44,899 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/weights/Adam:0 with shape (3, 3, 8, 12) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16befed358>"
2018-04-20 00:09:44,902 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/weights/Adam_1:0 with shape (3, 3, 8, 12) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16befed358>"
2018-04-20 00:09:44,905 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/biases/Adam:0 with shape (12,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16befed358>"
2018-04-20 00:09:44,907 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/biases/Adam_1:0 with shape (12,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16befed358>"
2018-04-20 00:09:44,910 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/weights/Adam:0 with shape (3, 3, 12, 16) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16befed358>"
2018-04-20 00:09:44,913 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/weights/Adam_1:0 with shape (3, 3, 12, 16) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16bf01cf28>"
2018-04-20 00:09:44,916 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/biases/Adam:0 with shape (16,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16bf01cf28>"
2018-04-20 00:09:44,918 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/biases/Adam_1:0 with shape (16,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16bf01cf28>"
2018-04-20 00:09:44,921 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/weights/Adam:0 with shape (576, 128) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16bf01cf28>"
2018-04-20 00:09:44,924 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/weights/Adam_1:0 with shape (576, 128) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16bf01cf28>"
2018-04-20 00:09:44,926 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/biases/Adam:0 with shape (128,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16bf01cf28>"
2018-04-20 00:09:44,929 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/biases/Adam_1:0 with shape (128,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16bf01cf28>"
2018-04-20 00:09:44,932 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/weights/Adam:0 with shape (128, 5) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16bf01cf28>"
2018-04-20 00:09:44,935 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/weights/Adam_1:0 with shape (128, 5) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16bf01cf28>"
2018-04-20 00:09:44,938 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/biases/Adam:0 with shape (5,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16bf01cf28>"
2018-04-20 00:09:44,941 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/biases/Adam_1:0 with shape (5,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f16bf01cf28>"
2018-04-20 00:09:45,102 (dqn_agent.py:161) DEBUG: "var_name: q/Conv/weights:0, var_value [[[[-0.45437422  0.09241241 -0.4031417   0.20321494 -0.16378003
    -0.14166075 -0.6734322   0.43192756]
   [ 0.54498637  0.03903526  0.5607197  -0.48249277  0.35027182
    -0.5211806  -0.7130368   0.5883169 ]]]]: "
2018-04-20 00:09:45,109 (dqn_agent.py:161) DEBUG: "var_name: q/Conv/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 00:09:45,129 (dqn_agent.py:161) DEBUG: "var_name: q/Conv_1/weights:0, var_value [[[[-0.01466241  0.05850556 -0.02121381  0.12007976  0.17141369
    -0.02536257  0.10543251  0.04181224  0.09713131  0.1067071
     0.08750033  0.13686469]
   [-0.13607019  0.14534569 -0.07360096 -0.08263129  0.10095194
     0.17122132 -0.17606041  0.08580339 -0.1452238   0.00371042
    -0.1557769  -0.09631909]
   [ 0.08883604  0.18050572 -0.04877298 -0.03218353 -0.05961033
    -0.06289382  0.11775747 -0.00884241 -0.00773033 -0.05212864
    -0.16727336  0.12815186]
   [ 0.11595932  0.16943693  0.13994163  0.1036067   0.04620007
    -0.1540871   0.0192927   0.12014189 -0.09592968 -0.15637033
    -0.05390354  0.17530632]
   [-0.07557636  0.08791155  0.1331468   0.01842286  0.06721978
     0.17661545 -0.00288388  0.03301768 -0.12310915  0.05204898
    -0.06071501 -0.14016119]
   [-0.11692846 -0.16908447  0.11855218 -0.02288641 -0.17366879
     0.1013779   0.1591393   0.01173401 -0.13761348 -0.03117806
    -0.1557847  -0.00268583]
   [-0.17106453  0.16602117  0.025399   -0.03741346  0.14993021
    -0.17943686 -0.021634   -0.08604149  0.00401068  0.16467047
    -0.0994057  -0.13315158]
   [-0.14518179  0.10588831 -0.14631498  0.12457117 -0.01658358
    -0.10606639 -0.15731038  0.01483493 -0.00218403 -0.1075109
    -0.17891935 -0.07590918]]

  [[-0.01333256  0.1740242   0.07614797 -0.05813996 -0.17304093
     0.12749454  0.17430508 -0.15049408 -0.12419246  0.04585683
    -0.08201022  0.16711304]
   [ 0.03648023  0.02337807 -0.12276632  0.08584508 -0.0518266
    -0.00043355 -0.1442396  -0.11551877  0.1594108   0.12146437
    -0.07694382  0.1417476 ]
   [ 0.15309837  0.14997703 -0.0314606  -0.16766238  0.03715721
     0.09037656 -0.16108304 -0.16444837  0.01136026  0.11861974
    -0.05405244  0.11663139]
   [ 0.13407314 -0.15358482  0.04635908  0.07625258  0.1136378
    -0.12670888 -0.01294258 -0.17408831  0.06679799  0.13880342
     0.15530473 -0.0765616 ]
   [-0.1327855   0.12211311 -0.15656626 -0.06900856 -0.11279089
     0.03097981 -0.10999297 -0.02160509 -0.01772265  0.12285644
    -0.10395113 -0.10794454]
   [-0.01922117  0.11961403  0.05933566  0.06834012  0.07574412
    -0.17862383 -0.01404008  0.14127192 -0.09762575  0.17321154
     0.09610689 -0.01100537]
   [-0.05330914  0.13111311 -0.04512776 -0.11598005 -0.01563795
    -0.14568633 -0.17443912 -0.07030447  0.14984336  0.05552343
     0.03977296 -0.05611438]
   [-0.13787618 -0.16749157 -0.09924342  0.12353513  0.09741321
    -0.08098002 -0.00868562  0.07680324  0.00490603  0.00120288
    -0.03632802  0.02839328]]

  [[ 0.04877546 -0.03812329  0.06513944  0.12940246 -0.10367812
    -0.13032344  0.01147853  0.16639602  0.15375596 -0.058024
     0.18119892 -0.15170655]
   [ 0.13204837  0.10922822 -0.1737666   0.13117331  0.00372839
    -0.06782135  0.16924846 -0.14124072  0.00763774 -0.15902525
    -0.07066088 -0.02490115]
   [-0.12640604  0.03605348  0.13907462  0.12396351 -0.05497976
     0.09312224 -0.15864168  0.07145956 -0.0708081   0.14016694
     0.01189519 -0.13005361]
   [-0.15416576 -0.06358641  0.03356549 -0.02790079 -0.06227248
     0.18057421  0.14865828 -0.13827774  0.1314114   0.15134072
     0.13974035 -0.05316563]
   [-0.1423928  -0.03416494 -0.12294888 -0.00292815 -0.08575132
    -0.05901742 -0.08555344  0.16854623  0.13293344  0.17930493
     0.04580817 -0.03104937]
   [ 0.10880136  0.00361566 -0.10198963 -0.09792419 -0.1515167
     0.13225156  0.02701871  0.12189987  0.15916237 -0.08133247
     0.04811221  0.01869866]
   [-0.07182685  0.03867745  0.18253401  0.01392335  0.1608679
     0.07485074 -0.10170095 -0.0306329   0.13777822 -0.1663074
    -0.11913121 -0.11220273]
   [ 0.03737789  0.17200816  0.03748028  0.1132786   0.04067257
     0.11394405  0.08071089  0.1346007  -0.11249515  0.02093334
     0.01518773  0.15978548]]]


 [[[-0.09711798  0.12095186 -0.18033461  0.07197481 -0.12435444
    -0.16174373 -0.17205203 -0.03097586 -0.17449313 -0.14949012
     0.16603026  0.13275442]
   [-0.10304103 -0.13372284  0.16245231 -0.03266169  0.10227737
     0.14526805 -0.07895361 -0.12290309  0.06942195 -0.00308286
    -0.00142889  0.01682882]
   [-0.16460398  0.18009877  0.04248498 -0.09288578 -0.08978438
     0.17851126 -0.02766979 -0.12828812 -0.08642367  0.03198847
     0.14432576 -0.10928519]
   [-0.04919243  0.04991871  0.07239917  0.18044013  0.13450849
     0.17717206 -0.02298875 -0.08162159  0.07165939 -0.05454685
    -0.04493006 -0.1249651 ]
   [ 0.0137057   0.11937758  0.07023516  0.00343958 -0.09185728
    -0.05500509 -0.1392392  -0.02637157 -0.10415751  0.11168638
    -0.0851353   0.01113935]
   [-0.04140042 -0.07588407 -0.16345003  0.08287257  0.05111828
     0.09552804 -0.01822284  0.18026441 -0.02794705  0.11909673
     0.04235153 -0.0785642 ]
   [ 0.07920724 -0.00274529  0.06485868 -0.03334846  0.06625217
     0.13307175 -0.17441075  0.05304432 -0.09459343 -0.11465428
    -0.13867776  0.02053772]
   [ 0.08871722  0.13296005 -0.16012724 -0.02379934 -0.1343044
     0.04384091 -0.086555    0.09754524 -0.16061054 -0.0963366
     0.10912845  0.12435153]]

  [[-0.04925089  0.00873929  0.14807117  0.1325534  -0.12621722
    -0.03693655  0.06350462 -0.11509524 -0.06725591 -0.0896571
     0.11077985  0.02153628]
   [-0.12957017 -0.079065   -0.05105133 -0.1692932   0.08707368
     0.04464199 -0.09839739  0.05348392 -0.14870363  0.09071094
    -0.08592553  0.01773654]
   [-0.18215217 -0.10857836 -0.17412184 -0.11928429 -0.11099514
    -0.07311845  0.15416324  0.05049147  0.06907451  0.16530386
     0.15430179 -0.00327104]
   [ 0.11380634  0.04600358  0.04465801 -0.0428791  -0.1160073
    -0.15509698  0.09838989  0.08397385  0.07401916  0.15863878
     0.17510185 -0.019881  ]
   [ 0.10233834  0.03508291 -0.12254889 -0.09592233  0.17196506
    -0.13716243 -0.06233124  0.09376338 -0.1497557  -0.0764348
     0.03716417 -0.17782633]
   [ 0.1710994   0.10975549  0.13816503 -0.00569904  0.1750032
     0.14428678 -0.05615011 -0.0253364   0.05387467 -0.07739335
    -0.13125327  0.1331723 ]
   [-0.04720381 -0.03753473  0.03489865  0.02259028 -0.14662257
     0.09675616  0.08911821  0.17121378  0.04895672 -0.02772637
    -0.0867928  -0.01295024]
   [ 0.00947301 -0.01002309 -0.00651051 -0.07714523 -0.08588622
     0.06352738  0.15263718 -0.0196307  -0.15290502  0.14769417
     0.09335217 -0.07713292]]

  [[ 0.07333118 -0.03735948  0.01542309  0.03733228  0.05957991
     0.02390721  0.02595608  0.0621644  -0.07231329  0.12799668
    -0.03680509  0.17074442]
   [-0.10140085  0.06354627 -0.13662246  0.08991715 -0.07954012
    -0.02399558 -0.01637429 -0.07357197  0.00909196  0.14505047
    -0.14007545 -0.07018145]
   [-0.08556115  0.07365611  0.16732678 -0.05895931  0.07251701
     0.11456421 -0.13488247 -0.08253618 -0.15309507 -0.00558078
     0.11341459 -0.07041386]
   [ 0.11344743 -0.10803007 -0.07666746 -0.14819688  0.1439592
    -0.04249112  0.05444121 -0.09240205  0.04306436 -0.03621688
    -0.01520254 -0.04023832]
   [-0.0823188  -0.15016177  0.08762142 -0.00075614  0.06591508
     0.12297022 -0.11480093 -0.09847195  0.11489156 -0.04070631
    -0.08099412 -0.04146218]
   [-0.15724744 -0.14397404 -0.11141437  0.17407519  0.09058154
     0.06041719 -0.07250638  0.0198715   0.14399496 -0.03132552
     0.08252391 -0.18137144]
   [ 0.07579848  0.09563783 -0.03113016 -0.01049717 -0.03869787
    -0.1402896   0.05172879  0.16654548 -0.02835602 -0.02578184
     0.17120874 -0.06828938]
   [-0.06846897  0.07873088 -0.08821677  0.14310127  0.16859818
     0.05140898 -0.0893107   0.12624368 -0.02682288  0.04080437
     0.0106688   0.08510935]]]


 [[[-0.10897526  0.13367662  0.15619364 -0.06999423 -0.02717434
    -0.11035156 -0.10835454  0.15969238 -0.08526637  0.14704192
    -0.09030451  0.17456818]
   [ 0.16563424  0.06151494 -0.16206598  0.08341992  0.04689771
     0.054217   -0.13138294  0.17479184 -0.03726193 -0.04269153
     0.11002967 -0.06969532]
   [-0.08868501  0.07564074  0.14892909  0.12079281 -0.09101778
     0.07109585 -0.05553997 -0.11530644  0.03784631 -0.01577654
    -0.07192009 -0.15675117]
   [-0.0735314  -0.1652137   0.02120845  0.0183654   0.17537561
     0.15261787  0.0069741   0.14271334  0.0050263   0.0354698
     0.09023002  0.06579477]
   [-0.06095969  0.05041076  0.01524849  0.00169246 -0.1525096
     0.12067726  0.11791995  0.03120604  0.09408206 -0.02889447
    -0.12880825  0.15582225]
   [-0.127826   -0.1494274  -0.03031504  0.00710647  0.01140636
    -0.05398986  0.01549983 -0.04401264  0.15839073  0.0254239
     0.04430681  0.10316274]
   [-0.04401442 -0.08693401 -0.04611614 -0.15874441 -0.02085574
     0.12584922 -0.07778938  0.07651812  0.01063828  0.14573783
    -0.017022   -0.0256664 ]
   [-0.04349761  0.10638207  0.1078729   0.1765739  -0.06204543
     0.14214712  0.11837754 -0.01438841 -0.07388486  0.08071905
    -0.14853379  0.06661451]]

  [[ 0.07779527 -0.11770336  0.10445264  0.10759658 -0.03735299
     0.01196928  0.14848569  0.13723698 -0.00261371 -0.01220721
    -0.02871208  0.12323365]
   [-0.06835105  0.16196147  0.14300656  0.02209666 -0.0643042
    -0.09489992  0.15379405 -0.13700852  0.13039896  0.10075757
    -0.14659409  0.09277135]
   [-0.05200654  0.00612023 -0.06426646 -0.075417    0.03244644
     0.0147413   0.04503044 -0.09471135  0.13704303 -0.11523192
    -0.07149107 -0.05435149]
   [ 0.08963063  0.02480608 -0.05215319  0.02542682 -0.15885001
    -0.17714758  0.01799679 -0.02272409  0.0497079  -0.1736505
    -0.02113354  0.04501721]
   [-0.07498924  0.01818036  0.04811095  0.13194507  0.03520149
    -0.14354797  0.1643706  -0.14866398 -0.13641517  0.14522159
     0.06691878  0.06758699]
   [-0.01079722 -0.07063206  0.00471407  0.16985306 -0.14888489
     0.11848301  0.16788247 -0.12660371 -0.01320224  0.14040408
     0.16058648  0.06816941]
   [-0.10741661 -0.02724394 -0.0822233   0.08925724  0.09258765
     0.06231165  0.0498044  -0.13713339 -0.13286063  0.17867482
    -0.05096972 -0.00895812]
   [ 0.02829708 -0.08036517  0.04478677 -0.16197905 -0.0109954
    -0.07474104 -0.14697593  0.02370255  0.0876936   0.01851954
     0.09659082 -0.0992752 ]]

  [[ 0.07054719  0.03664042  0.17328823  0.1551832  -0.02233982
    -0.1800142   0.02474132 -0.06799451  0.06863508  0.09027073
    -0.00181633 -0.07467387]
   [-0.01741277 -0.004581   -0.12157645 -0.01688723  0.11161086
    -0.02841021 -0.09768213 -0.04028572  0.01998416  0.00660427
    -0.17724048 -0.14708376]
   [ 0.04511471 -0.15401018 -0.01555946 -0.03063032 -0.11404274
     0.1064834  -0.08018744  0.02472408 -0.07646235 -0.10636378
    -0.148667    0.07533795]
   [ 0.04659531 -0.02630559  0.14988288 -0.02543582 -0.0281446
    -0.05474138 -0.04716301  0.15032604  0.15306407 -0.02251659
    -0.12148735 -0.12412669]
   [ 0.13318762  0.18038425  0.02371864  0.12804452  0.18000343
    -0.02104762  0.04726039 -0.15654784 -0.09428968  0.14436075
    -0.01856154 -0.08612794]
   [-0.0541607  -0.09237941  0.06004162 -0.13420218 -0.11275276
    -0.09002075  0.14222795  0.06486289  0.06487805  0.03626904
     0.11652446 -0.10532191]
   [-0.06088612 -0.02427961 -0.07980164 -0.0209693   0.05309759
    -0.09637764  0.02788343 -0.1616983   0.07265839 -0.0316944
    -0.06968196 -0.06994962]
   [-0.13647963  0.09382018  0.05407822  0.13661614  0.16818133
    -0.1110708   0.02397725 -0.12108409  0.07832575  0.03426287
    -0.11895713  0.04951768]]]]: "
2018-04-20 00:09:45,177 (dqn_agent.py:161) DEBUG: "var_name: q/Conv_1/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 00:09:45,195 (dqn_agent.py:161) DEBUG: "var_name: q/Conv_2/weights:0, var_value [[[[-0.0797774   0.01873627  0.1385109  ...  0.01415014  0.05313519
    -0.11567675]
   [ 0.0371282  -0.01852378 -0.01220277 ...  0.07838745 -0.15200189
    -0.02942897]
   [-0.11219987  0.02653207  0.13914661 ... -0.02268051  0.01884557
    -0.10662605]
   ...
   [-0.01931754  0.10785471 -0.0738834  ...  0.05605897 -0.02745824
    -0.14945176]
   [-0.00934859  0.06111154 -0.06048029 ... -0.01047826  0.08065607
    -0.01911066]
   [ 0.0869908  -0.03158921  0.07200363 ... -0.00325014  0.10848556
    -0.11243635]]

  [[ 0.10402112 -0.08505578  0.03061622 ... -0.14676416 -0.09480286
     0.11201669]
   [ 0.01366302  0.0022932  -0.01384506 ... -0.02880698 -0.08913184
    -0.11579804]
   [-0.09752969 -0.06275689  0.12859626 ...  0.08642426  0.10306172
    -0.09605898]
   ...
   [-0.03521162  0.0527986   0.02938788 ...  0.03956902 -0.11750452
    -0.11807732]
   [-0.10061806 -0.05139725 -0.05516935 ...  0.05418053 -0.08568631
    -0.0906323 ]
   [ 0.03504129  0.02396856 -0.08887803 ... -0.03232042 -0.00468104
     0.07404447]]

  [[ 0.1541829  -0.1045125  -0.11529106 ... -0.10019596 -0.14190017
    -0.07995395]
   [ 0.02162334  0.00685629  0.0875206  ... -0.01866394  0.06448419
     0.10108863]
   [ 0.11919345  0.14987867 -0.06624336 ... -0.08187944 -0.11034374
     0.0748125 ]
   ...
   [-0.13684542 -0.05107023 -0.0037633  ...  0.06076154 -0.14174308
     0.0386741 ]
   [ 0.14700033  0.08633758 -0.15287624 ... -0.13077605 -0.00711119
     0.05512314]
   [ 0.12159131  0.05729982  0.08275715 ...  0.0526921   0.14226906
    -0.06211813]]]


 [[[-0.01202865 -0.00967431  0.02385871 ...  0.02471659  0.04241538
    -0.01958933]
   [ 0.12125929  0.01211418  0.13327138 ... -0.12111421  0.10108043
    -0.10277212]
   [ 0.0984657  -0.0080872   0.11509134 ...  0.08291644 -0.01644051
     0.11152099]
   ...
   [ 0.03221072  0.13378079 -0.06361223 ...  0.12784235 -0.10977568
    -0.05360178]
   [-0.10839099 -0.13388881 -0.02110647 ... -0.09940819 -0.04715988
    -0.00712647]
   [ 0.06567498 -0.03493702 -0.01443522 ...  0.15022798  0.00903827
     0.10069202]]

  [[ 0.07153139 -0.13819873 -0.04929683 ...  0.11265786  0.08069491
    -0.12779906]
   [ 0.12745853  0.00370216 -0.02454191 ...  0.09623154  0.0001775
     0.04350774]
   [ 0.07256651  0.05599676  0.14617844 ... -0.01220372  0.14148615
    -0.07017564]
   ...
   [-0.13294595  0.05087757 -0.00388417 ... -0.08877664 -0.11591922
    -0.07819052]
   [ 0.11482559 -0.04780306  0.14269985 ... -0.02060565 -0.05782322
    -0.10979146]
   [-0.08152399 -0.12382263 -0.06542066 ...  0.12074052 -0.12256813
    -0.14660501]]

  [[ 0.05660661  0.04520389  0.05418664 ...  0.13390882  0.09029326
     0.12069909]
   [ 0.07769762  0.02919297  0.10366435 ... -0.02221252  0.14408077
     0.07060909]
   [ 0.0815248  -0.13238297  0.11402886 ... -0.13921385 -0.09824571
    -0.11210467]
   ...
   [-0.038612   -0.07993986  0.09361216 ... -0.13619772  0.12755702
     0.13634567]
   [ 0.02829695  0.0308069  -0.13810375 ... -0.01558612 -0.09937266
     0.03809218]
   [-0.07015412 -0.05846588 -0.120064   ...  0.13161443 -0.05718276
    -0.10728085]]]


 [[[ 0.030435   -0.06333458  0.02243446 ...  0.13593231 -0.13051705
    -0.02433604]
   [-0.02924481  0.01935621  0.12169908 ... -0.0406849  -0.12146281
     0.14411007]
   [ 0.07565585 -0.05887306 -0.12136301 ... -0.07856981 -0.02397165
     0.02643587]
   ...
   [ 0.1533375   0.04228702 -0.09097724 ...  0.10271607  0.13476925
    -0.02679199]
   [ 0.03572099  0.04462653 -0.02515885 ...  0.02842607 -0.1516429
     0.0448923 ]
   [ 0.00234838 -0.03872756  0.11498405 ... -0.03516199 -0.04284337
     0.07417628]]

  [[-0.06454548  0.0776455   0.03432643 ...  0.08143765 -0.04530789
     0.01492421]
   [-0.12865528  0.02481234 -0.11718009 ... -0.04410365  0.00359632
     0.04930131]
   [ 0.12103857  0.03000383 -0.08107848 ... -0.03966247  0.145406
     0.05948658]
   ...
   [-0.12647136  0.02175365 -0.02808857 ...  0.13086133  0.02426165
    -0.02675097]
   [-0.13547882  0.09986694 -0.0996836  ... -0.03389531 -0.07216095
     0.13954224]
   [-0.04688683  0.04190913  0.12469019 ... -0.11713892  0.05286431
    -0.03286828]]

  [[ 0.13387235  0.00517166 -0.06660926 ...  0.14508961 -0.11595403
    -0.08661048]
   [-0.08677559  0.11258914  0.06776421 ... -0.05621794 -0.01255502
     0.12493841]
   [-0.10320002 -0.13903755  0.03457987 ...  0.02658622 -0.03870077
     0.00746298]
   ...
   [-0.12197867 -0.10988932 -0.07672408 ...  0.01115187  0.02591468
    -0.13302387]
   [-0.15196793 -0.02575892  0.10223298 ...  0.09138496  0.04587485
    -0.08367073]
   [ 0.04596645 -0.00647435  0.02616249 ...  0.02018991  0.00734271
     0.15340148]]]]: "
2018-04-20 00:09:45,208 (dqn_agent.py:161) DEBUG: "var_name: q/Conv_2/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 00:09:45,221 (dqn_agent.py:161) DEBUG: "var_name: q/fully_connected/weights:0, var_value [[-0.06105846  0.02842958 -0.06607082 ...  0.08143545  0.02440361
  -0.00027925]
 [-0.01322457  0.04913994 -0.07371138 ... -0.00715099  0.05188406
  -0.08400482]
 [ 0.0208477   0.06453959  0.03748194 ... -0.08069795  0.08146083
  -0.0542092 ]
 ...
 [-0.05078364 -0.06910589 -0.07922482 ...  0.00789656  0.04588784
   0.06274114]
 [-0.08737447  0.08850712 -0.0916521  ... -0.04621189  0.02897456
  -0.02463267]
 [-0.08712668  0.0145384   0.02659321 ... -0.08777002 -0.0797758
  -0.09084145]]: "
2018-04-20 00:09:45,238 (dqn_agent.py:161) DEBUG: "var_name: q/fully_connected/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 00:09:45,260 (dqn_agent.py:161) DEBUG: "var_name: q/fully_connected_1/weights:0, var_value [[-1.33332372e-01 -1.21349141e-01 -5.98904490e-03  9.78068113e-02
  -1.72639668e-01]
 [ 2.19879001e-02  1.17726624e-01  5.87365031e-02 -1.50980830e-01
   1.43375307e-01]
 [-3.88857126e-02 -1.21027328e-01  5.75172305e-02 -1.40003175e-01
   1.91109031e-01]
 [-1.64104626e-01 -1.37330830e-01  7.63312280e-02 -4.93871868e-02
   1.40498400e-01]
 [-6.21345341e-02 -2.12296918e-01  1.88643992e-01 -1.62010074e-01
   2.89283544e-02]
 [ 7.92510211e-02  6.57981932e-02  8.34364593e-02  1.93149596e-01
  -5.63380271e-02]
 [ 8.33594501e-02  1.30414516e-02 -1.72245502e-03 -2.02637374e-01
  -3.33143026e-02]
 [-1.03909835e-01 -1.39290273e-01  9.87536311e-02  7.15075135e-02
   1.76905304e-01]
 [ 1.52604789e-01 -1.41019076e-02  1.11094624e-01 -6.31067157e-02
   1.23259515e-01]
 [ 2.49368399e-02 -4.09058183e-02  9.59849358e-02 -1.94948867e-01
   1.39712423e-01]
 [ 2.74312943e-02  2.62325555e-02  1.07461601e-01 -2.02591240e-01
   2.20338255e-02]
 [ 1.25593185e-01  5.53655922e-02  1.29744053e-01  3.81451845e-03
   1.52154148e-01]
 [-4.18858975e-02  1.42774522e-01  1.27843171e-02  1.15700305e-01
   8.67719054e-02]
 [-3.30982208e-02 -2.43003517e-02  1.51905507e-01  7.35116303e-02
   2.28226185e-04]
 [ 2.11443812e-01  1.20608777e-01 -1.78808883e-01 -2.39927620e-02
   1.83877409e-01]
 [ 3.56259942e-03 -1.89073563e-01  1.82523966e-01 -1.20623223e-01
  -1.48555189e-02]
 [ 1.20509446e-01  1.11306667e-01 -5.10512292e-03 -3.31417173e-02
  -9.28477272e-02]
 [-1.40883401e-01  2.00892031e-01 -1.62269041e-01  1.05588526e-01
  -3.88249755e-04]
 [ 1.83306038e-02 -1.13561690e-01  4.76567447e-02  2.08044112e-01
   2.57307142e-02]
 [-4.58348244e-02 -1.89173222e-01 -1.69141382e-01  1.63844138e-01
  -1.06254801e-01]
 [ 1.69571042e-02  1.90918118e-01 -4.01447564e-02  1.58081055e-01
   3.56156081e-02]
 [-1.26972407e-01 -1.17496997e-02  1.40221298e-01 -1.63462922e-01
  -1.27168477e-01]
 [-1.33166790e-01 -7.77329803e-02 -4.70646024e-02 -5.45788556e-02
   7.29191005e-02]
 [ 1.58559740e-01 -2.13138312e-02  7.36537576e-03  1.61597759e-01
   1.71119511e-01]
 [-6.78443909e-03 -1.45141169e-01 -1.38303190e-02 -5.31578064e-03
   3.53223532e-02]
 [ 4.64116037e-02  1.79639637e-01  1.42013669e-01  3.87872756e-02
  -7.78463632e-02]
 [-1.25575006e-01 -1.79828703e-01 -2.10043862e-01 -2.00302690e-01
  -1.76701576e-01]
 [-1.25143468e-01  9.25613642e-02  8.50352645e-02  1.86021179e-01
   8.28426182e-02]
 [ 2.03106403e-01 -1.26479864e-02 -1.94376245e-01  3.41293365e-02
   4.27161753e-02]
 [-1.91581905e-01 -6.36603087e-02 -1.67869419e-01  1.46228194e-01
   1.24100477e-01]
 [ 3.45172435e-02  7.85651505e-02  8.66160691e-02  7.83444047e-02
  -3.56978476e-02]
 [-1.83149099e-01  4.07444835e-02  1.18230343e-01 -1.06956519e-01
   6.45250678e-02]
 [ 1.66767716e-01 -1.19897857e-01 -4.49884832e-02 -1.47899061e-01
   1.28830642e-01]
 [-1.30647019e-01  1.52333468e-01  6.11083806e-02  5.36487997e-02
  -9.23249274e-02]
 [-8.76322091e-02  1.70817107e-01 -7.91828930e-02  8.18712413e-02
   1.22866154e-01]
 [-1.55784488e-01  9.03639495e-02  1.61848694e-01 -1.07190721e-01
  -1.45900160e-01]
 [-6.51546270e-02 -5.38187623e-02 -2.56687403e-03 -1.45303980e-01
   1.80245012e-01]
 [-2.10296005e-01  1.65432751e-01 -1.96618468e-01 -4.83155251e-04
  -1.97427124e-01]
 [ 1.44576877e-02  2.10917145e-01  5.70272207e-02  1.49710089e-01
  -1.44896537e-01]
 [ 1.72353417e-01 -1.22898862e-01 -1.07862204e-01  7.61069357e-02
  -1.64051145e-01]
 [ 2.54404992e-02 -3.45092416e-02  1.22068584e-01 -4.28612232e-02
   5.47040403e-02]
 [-7.95610696e-02  5.46818972e-02  4.17655706e-02 -1.28726810e-02
  -1.42941996e-01]
 [ 1.31037205e-01 -8.53326917e-03  1.52641445e-01 -2.08379090e-01
  -6.94002509e-02]
 [-4.83085662e-02  1.05872273e-01  1.96069390e-01 -7.71625340e-03
   3.70381325e-02]
 [-8.26944411e-02  1.81950063e-01  1.04183048e-01  1.86633199e-01
   1.09252572e-01]
 [-8.32722485e-02  2.21315175e-02  1.10602826e-02  1.12895221e-01
  -8.20102096e-02]
 [ 1.59277260e-01  1.74249232e-01  1.44925863e-01  2.00162113e-01
   9.39865112e-02]
 [-1.73819810e-02 -1.66694582e-01 -1.82291821e-01 -5.25571257e-02
  -1.95269167e-01]
 [ 2.10287333e-01 -5.10967821e-02 -1.80516496e-01 -1.15478694e-01
   1.39438659e-01]
 [-3.89538705e-02 -2.62869895e-02 -1.35155961e-01 -8.16502124e-02
  -1.04703464e-01]
 [ 6.32601082e-02  1.79905772e-01  2.08012551e-01 -1.13431491e-01
   1.73217356e-01]
 [-5.87642193e-02  1.56381488e-01 -1.13846228e-01 -1.28444701e-01
  -4.73091453e-02]
 [ 3.96845639e-02  8.60593915e-02 -1.79569587e-01 -1.95884392e-01
  -5.57826608e-02]
 [ 1.54591978e-01 -1.92236260e-01 -3.72524559e-03 -1.16627149e-01
   1.81555867e-01]
 [-2.44139880e-02  3.47475410e-02  2.02982575e-01 -7.77329355e-02
   1.61969751e-01]
 [-2.71016806e-02  1.52809560e-01 -1.67976022e-02 -8.15618485e-02
   1.84121370e-01]
 [ 6.86028600e-03 -1.21316321e-01  4.07213569e-02  1.51968658e-01
   1.35954291e-01]
 [-1.17039412e-01 -8.46014768e-02  4.84654903e-02  1.69804543e-02
   4.88846898e-02]
 [ 4.18361723e-02 -1.78853959e-01 -1.45407289e-01 -1.25650868e-01
   1.17502093e-01]
 [-2.06809878e-01 -8.18790495e-02  5.74409068e-02 -1.80485308e-01
   1.30008459e-02]
 [ 1.05592281e-01  2.04155952e-01  9.08307433e-02  3.57435793e-02
  -1.28867894e-01]
 [ 1.47449464e-01 -1.95517704e-01  2.64264494e-02 -1.46879628e-01
  -9.44144651e-02]
 [-7.73212314e-02  1.50754929e-01  1.16665930e-01  8.31313133e-02
  -1.51184201e-01]
 [ 7.02056289e-02 -3.86433452e-02 -2.00528488e-01 -1.67933837e-01
  -6.42767549e-03]
 [-9.73364711e-02  1.68140709e-01  1.46741629e-01 -4.84089404e-02
   1.64870650e-01]
 [-1.96861371e-01 -3.66970152e-02 -2.90136337e-02 -1.72180921e-01
  -1.18585385e-01]
 [ 1.56324774e-01 -1.72880769e-01 -1.79759443e-01  2.02931434e-01
   2.05285013e-01]
 [-1.14409700e-01 -6.00090325e-02 -6.00715727e-02 -1.48965329e-01
  -6.92888945e-02]
 [-7.44006932e-02  8.93048346e-02  1.00024372e-01  1.93319649e-01
   2.11270094e-01]
 [-2.13102847e-02 -1.57896727e-01 -1.83345631e-01 -7.51146674e-03
  -1.38531625e-02]
 [ 2.19836384e-02  1.52192324e-01 -5.66162914e-02  2.17455924e-02
  -6.32507354e-02]
 [-1.75569370e-01  1.75910234e-01 -1.22227125e-01 -1.01274356e-01
   5.80603778e-02]
 [ 4.43098247e-02  5.88109195e-02  2.02916294e-01 -1.05794795e-01
  -6.80513084e-02]
 [-1.26083687e-01  1.56830668e-01 -5.63588440e-02  4.55490649e-02
   1.47138834e-02]
 [ 8.71114433e-02  3.84750366e-02 -1.47621244e-01 -1.96559876e-01
  -1.48402765e-01]
 [ 1.37743682e-01 -8.18346441e-02 -1.76512688e-01 -1.57841012e-01
  -1.42260045e-01]
 [-1.95939839e-03  5.35142124e-02 -1.31175667e-02  1.77288383e-01
   1.00596696e-01]
 [ 2.02702492e-01 -1.70870826e-01 -1.89399689e-01 -1.96021214e-01
  -1.11866273e-01]
 [ 5.80630004e-02  6.27471805e-02  1.08344853e-01 -1.05071068e-02
  -1.03693604e-02]
 [ 5.66751361e-02 -8.86138529e-02 -1.07130565e-01  9.31333303e-02
   6.72780573e-02]
 [ 2.83122063e-06  1.89666450e-02 -8.52186829e-02 -1.19457550e-01
  -1.03126593e-01]
 [-1.10526860e-01 -1.05703190e-01  1.77719027e-01 -1.15153342e-02
  -1.06111541e-01]
 [ 1.04258657e-01  6.74642920e-02 -1.85029387e-01 -8.57597589e-02
   3.71636599e-02]
 [-7.52004534e-02  1.67274922e-01  4.62332666e-02 -1.41756773e-01
   1.65151030e-01]
 [ 2.56775022e-02 -1.75179645e-01 -1.96602911e-01  4.48317528e-02
   1.57505721e-01]
 [-7.31959343e-02 -2.08361015e-01 -1.62833571e-01 -2.67283171e-02
  -1.27656490e-01]
 [ 6.40900731e-02 -1.70506120e-01  6.44489527e-02  1.06842071e-01
   1.33804083e-01]
 [ 3.87928784e-02 -7.65558630e-02  1.96308583e-01 -2.05414906e-01
   1.08516216e-01]
 [-8.95004570e-02  9.48854685e-02 -1.34641975e-01 -3.70140672e-02
   1.27068937e-01]
 [ 7.14562237e-02 -1.33513927e-01  7.49334693e-02  1.65760338e-01
  -7.71780759e-02]
 [ 4.13779914e-02  2.11308092e-01 -1.88402444e-01  1.29697889e-01
  -1.62390530e-01]
 [-8.18880647e-02 -9.55564901e-02  7.28605986e-02 -1.60114616e-02
   1.19657516e-01]
 [ 1.29042089e-01  1.25617534e-01 -1.48041159e-01 -1.77534938e-01
  -1.14387773e-01]
 [-7.82036334e-02  1.44397676e-01 -7.22879171e-02  2.08964586e-01
   8.45837593e-03]
 [-1.74476475e-01 -3.87125164e-02  1.30463243e-01 -1.62515491e-02
  -5.79580814e-02]
 [-9.36988816e-02 -3.44815403e-02  4.77618575e-02 -6.10817373e-02
  -1.52989239e-01]
 [-1.39445081e-01  1.81519777e-01  3.26515287e-02  7.57436454e-03
   1.85713232e-01]
 [ 1.19170129e-01 -7.29819387e-02 -1.92039177e-01 -9.55184102e-02
  -1.90760478e-01]
 [ 3.02956700e-02 -1.46895796e-02 -9.13210437e-02  8.34646225e-02
  -4.54191267e-02]
 [-8.38156044e-02 -5.32496274e-02  1.15667015e-01 -5.57486862e-02
  -5.41878194e-02]
 [ 1.50856614e-01 -1.75100341e-01 -1.18969433e-01 -9.78152677e-02
  -6.72666430e-02]
 [ 1.42697603e-01 -3.07936668e-02 -4.56988513e-02  1.10326022e-01
   1.67318612e-01]
 [-2.04904377e-02 -8.31899047e-02  4.74621356e-02  1.21553570e-01
   1.75197929e-01]
 [-2.57045329e-02  1.64978117e-01 -1.25101775e-01 -1.60598904e-01
  -1.42539710e-01]
 [ 1.89972311e-01  7.19270706e-02  2.01232076e-01 -5.36444038e-02
  -2.05520287e-01]
 [-7.36287981e-02 -1.83466449e-01  1.89967155e-02 -8.38266015e-02
   1.08603150e-01]
 [-1.69596985e-01  1.80198848e-02 -1.18377253e-01 -3.07594240e-03
   6.10244572e-02]
 [ 1.34180099e-01  7.04799294e-02 -9.25011039e-02  1.23018324e-01
  -7.09713995e-03]
 [ 1.52822375e-01 -7.20094144e-03  1.81729376e-01 -1.33396089e-01
   4.68405783e-02]
 [-9.41604078e-02  6.97126985e-02  8.21819305e-02  8.86453986e-02
  -1.93376839e-03]
 [ 1.47830695e-01 -2.05642134e-02  4.93700802e-03 -1.73537299e-01
  -6.39557391e-02]
 [-6.12229109e-04 -1.02399617e-01 -1.80691212e-01  9.89547074e-02
   4.43066657e-02]
 [-6.52963221e-02  3.80224586e-02  7.80207813e-02 -1.41674191e-01
   9.97964740e-02]
 [ 1.21713787e-01  7.33523071e-02  1.05053544e-01  2.16308832e-02
   1.32878900e-01]
 [-5.92103601e-03  2.03366190e-01  7.00026453e-02  9.40120816e-02
   1.29161954e-01]
 [-2.51051635e-02  1.53929323e-01 -3.58356386e-02 -4.51561511e-02
  -1.56033233e-01]
 [-1.96996436e-01 -1.58153310e-01  1.48793966e-01 -1.00975931e-01
  -1.05046041e-01]
 [ 6.47329986e-02 -1.06125318e-01  7.41723180e-02  9.74582136e-02
   2.55825967e-02]
 [-2.42102593e-02 -9.21168998e-02  1.16180867e-01 -1.86484620e-01
   2.13188976e-02]
 [-1.86951011e-01 -7.34149516e-02 -7.33887255e-02  1.31130129e-01
   2.72764862e-02]
 [ 1.47147447e-01 -1.83533430e-02 -8.10547173e-03 -1.66236803e-01
  -1.35311171e-01]
 [ 6.97261095e-02  1.21982634e-01 -1.16987303e-01 -1.33938432e-01
   2.19946355e-02]
 [ 1.41777039e-01 -1.88485950e-01 -6.29267395e-02 -1.16352379e-01
  -8.35455954e-02]
 [-5.08670360e-02 -2.76563317e-02 -3.30282897e-02 -2.07740784e-01
   1.70364022e-01]
 [ 1.50674433e-02  1.58690661e-02 -1.78512082e-01  5.01784980e-02
  -2.02114224e-01]
 [-1.93267643e-01 -6.17783368e-02 -2.07096592e-01 -5.04980683e-02
  -9.29170027e-02]
 [-2.36701965e-02  1.18253976e-02  1.02882981e-01 -1.89824909e-01
  -1.48974508e-02]
 [-2.05038399e-01  1.69189543e-01 -9.32534039e-02  6.71012104e-02
   1.25466853e-01]]: "
2018-04-20 00:09:45,269 (dqn_agent.py:161) DEBUG: "var_name: q/fully_connected_1/biases:0, var_value [0. 0. 0. 0. 0.]: "
2018-04-20 00:09:45,277 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv/weights:0, var_value [[[[-0.45437422  0.09241241 -0.4031417   0.20321494 -0.16378003
    -0.14166075 -0.6734322   0.43192756]
   [ 0.54498637  0.03903526  0.5607197  -0.48249277  0.35027182
    -0.5211806  -0.7130368   0.5883169 ]]]]: "
2018-04-20 00:09:45,285 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 00:09:45,305 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv_1/weights:0, var_value [[[[-0.01466241  0.05850556 -0.02121381  0.12007976  0.17141369
    -0.02536257  0.10543251  0.04181224  0.09713131  0.1067071
     0.08750033  0.13686469]
   [-0.13607019  0.14534569 -0.07360096 -0.08263129  0.10095194
     0.17122132 -0.17606041  0.08580339 -0.1452238   0.00371042
    -0.1557769  -0.09631909]
   [ 0.08883604  0.18050572 -0.04877298 -0.03218353 -0.05961033
    -0.06289382  0.11775747 -0.00884241 -0.00773033 -0.05212864
    -0.16727336  0.12815186]
   [ 0.11595932  0.16943693  0.13994163  0.1036067   0.04620007
    -0.1540871   0.0192927   0.12014189 -0.09592968 -0.15637033
    -0.05390354  0.17530632]
   [-0.07557636  0.08791155  0.1331468   0.01842286  0.06721978
     0.17661545 -0.00288388  0.03301768 -0.12310915  0.05204898
    -0.06071501 -0.14016119]
   [-0.11692846 -0.16908447  0.11855218 -0.02288641 -0.17366879
     0.1013779   0.1591393   0.01173401 -0.13761348 -0.03117806
    -0.1557847  -0.00268583]
   [-0.17106453  0.16602117  0.025399   -0.03741346  0.14993021
    -0.17943686 -0.021634   -0.08604149  0.00401068  0.16467047
    -0.0994057  -0.13315158]
   [-0.14518179  0.10588831 -0.14631498  0.12457117 -0.01658358
    -0.10606639 -0.15731038  0.01483493 -0.00218403 -0.1075109
    -0.17891935 -0.07590918]]

  [[-0.01333256  0.1740242   0.07614797 -0.05813996 -0.17304093
     0.12749454  0.17430508 -0.15049408 -0.12419246  0.04585683
    -0.08201022  0.16711304]
   [ 0.03648023  0.02337807 -0.12276632  0.08584508 -0.0518266
    -0.00043355 -0.1442396  -0.11551877  0.1594108   0.12146437
    -0.07694382  0.1417476 ]
   [ 0.15309837  0.14997703 -0.0314606  -0.16766238  0.03715721
     0.09037656 -0.16108304 -0.16444837  0.01136026  0.11861974
    -0.05405244  0.11663139]
   [ 0.13407314 -0.15358482  0.04635908  0.07625258  0.1136378
    -0.12670888 -0.01294258 -0.17408831  0.06679799  0.13880342
     0.15530473 -0.0765616 ]
   [-0.1327855   0.12211311 -0.15656626 -0.06900856 -0.11279089
     0.03097981 -0.10999297 -0.02160509 -0.01772265  0.12285644
    -0.10395113 -0.10794454]
   [-0.01922117  0.11961403  0.05933566  0.06834012  0.07574412
    -0.17862383 -0.01404008  0.14127192 -0.09762575  0.17321154
     0.09610689 -0.01100537]
   [-0.05330914  0.13111311 -0.04512776 -0.11598005 -0.01563795
    -0.14568633 -0.17443912 -0.07030447  0.14984336  0.05552343
     0.03977296 -0.05611438]
   [-0.13787618 -0.16749157 -0.09924342  0.12353513  0.09741321
    -0.08098002 -0.00868562  0.07680324  0.00490603  0.00120288
    -0.03632802  0.02839328]]

  [[ 0.04877546 -0.03812329  0.06513944  0.12940246 -0.10367812
    -0.13032344  0.01147853  0.16639602  0.15375596 -0.058024
     0.18119892 -0.15170655]
   [ 0.13204837  0.10922822 -0.1737666   0.13117331  0.00372839
    -0.06782135  0.16924846 -0.14124072  0.00763774 -0.15902525
    -0.07066088 -0.02490115]
   [-0.12640604  0.03605348  0.13907462  0.12396351 -0.05497976
     0.09312224 -0.15864168  0.07145956 -0.0708081   0.14016694
     0.01189519 -0.13005361]
   [-0.15416576 -0.06358641  0.03356549 -0.02790079 -0.06227248
     0.18057421  0.14865828 -0.13827774  0.1314114   0.15134072
     0.13974035 -0.05316563]
   [-0.1423928  -0.03416494 -0.12294888 -0.00292815 -0.08575132
    -0.05901742 -0.08555344  0.16854623  0.13293344  0.17930493
     0.04580817 -0.03104937]
   [ 0.10880136  0.00361566 -0.10198963 -0.09792419 -0.1515167
     0.13225156  0.02701871  0.12189987  0.15916237 -0.08133247
     0.04811221  0.01869866]
   [-0.07182685  0.03867745  0.18253401  0.01392335  0.1608679
     0.07485074 -0.10170095 -0.0306329   0.13777822 -0.1663074
    -0.11913121 -0.11220273]
   [ 0.03737789  0.17200816  0.03748028  0.1132786   0.04067257
     0.11394405  0.08071089  0.1346007  -0.11249515  0.02093334
     0.01518773  0.15978548]]]


 [[[-0.09711798  0.12095186 -0.18033461  0.07197481 -0.12435444
    -0.16174373 -0.17205203 -0.03097586 -0.17449313 -0.14949012
     0.16603026  0.13275442]
   [-0.10304103 -0.13372284  0.16245231 -0.03266169  0.10227737
     0.14526805 -0.07895361 -0.12290309  0.06942195 -0.00308286
    -0.00142889  0.01682882]
   [-0.16460398  0.18009877  0.04248498 -0.09288578 -0.08978438
     0.17851126 -0.02766979 -0.12828812 -0.08642367  0.03198847
     0.14432576 -0.10928519]
   [-0.04919243  0.04991871  0.07239917  0.18044013  0.13450849
     0.17717206 -0.02298875 -0.08162159  0.07165939 -0.05454685
    -0.04493006 -0.1249651 ]
   [ 0.0137057   0.11937758  0.07023516  0.00343958 -0.09185728
    -0.05500509 -0.1392392  -0.02637157 -0.10415751  0.11168638
    -0.0851353   0.01113935]
   [-0.04140042 -0.07588407 -0.16345003  0.08287257  0.05111828
     0.09552804 -0.01822284  0.18026441 -0.02794705  0.11909673
     0.04235153 -0.0785642 ]
   [ 0.07920724 -0.00274529  0.06485868 -0.03334846  0.06625217
     0.13307175 -0.17441075  0.05304432 -0.09459343 -0.11465428
    -0.13867776  0.02053772]
   [ 0.08871722  0.13296005 -0.16012724 -0.02379934 -0.1343044
     0.04384091 -0.086555    0.09754524 -0.16061054 -0.0963366
     0.10912845  0.12435153]]

  [[-0.04925089  0.00873929  0.14807117  0.1325534  -0.12621722
    -0.03693655  0.06350462 -0.11509524 -0.06725591 -0.0896571
     0.11077985  0.02153628]
   [-0.12957017 -0.079065   -0.05105133 -0.1692932   0.08707368
     0.04464199 -0.09839739  0.05348392 -0.14870363  0.09071094
    -0.08592553  0.01773654]
   [-0.18215217 -0.10857836 -0.17412184 -0.11928429 -0.11099514
    -0.07311845  0.15416324  0.05049147  0.06907451  0.16530386
     0.15430179 -0.00327104]
   [ 0.11380634  0.04600358  0.04465801 -0.0428791  -0.1160073
    -0.15509698  0.09838989  0.08397385  0.07401916  0.15863878
     0.17510185 -0.019881  ]
   [ 0.10233834  0.03508291 -0.12254889 -0.09592233  0.17196506
    -0.13716243 -0.06233124  0.09376338 -0.1497557  -0.0764348
     0.03716417 -0.17782633]
   [ 0.1710994   0.10975549  0.13816503 -0.00569904  0.1750032
     0.14428678 -0.05615011 -0.0253364   0.05387467 -0.07739335
    -0.13125327  0.1331723 ]
   [-0.04720381 -0.03753473  0.03489865  0.02259028 -0.14662257
     0.09675616  0.08911821  0.17121378  0.04895672 -0.02772637
    -0.0867928  -0.01295024]
   [ 0.00947301 -0.01002309 -0.00651051 -0.07714523 -0.08588622
     0.06352738  0.15263718 -0.0196307  -0.15290502  0.14769417
     0.09335217 -0.07713292]]

  [[ 0.07333118 -0.03735948  0.01542309  0.03733228  0.05957991
     0.02390721  0.02595608  0.0621644  -0.07231329  0.12799668
    -0.03680509  0.17074442]
   [-0.10140085  0.06354627 -0.13662246  0.08991715 -0.07954012
    -0.02399558 -0.01637429 -0.07357197  0.00909196  0.14505047
    -0.14007545 -0.07018145]
   [-0.08556115  0.07365611  0.16732678 -0.05895931  0.07251701
     0.11456421 -0.13488247 -0.08253618 -0.15309507 -0.00558078
     0.11341459 -0.07041386]
   [ 0.11344743 -0.10803007 -0.07666746 -0.14819688  0.1439592
    -0.04249112  0.05444121 -0.09240205  0.04306436 -0.03621688
    -0.01520254 -0.04023832]
   [-0.0823188  -0.15016177  0.08762142 -0.00075614  0.06591508
     0.12297022 -0.11480093 -0.09847195  0.11489156 -0.04070631
    -0.08099412 -0.04146218]
   [-0.15724744 -0.14397404 -0.11141437  0.17407519  0.09058154
     0.06041719 -0.07250638  0.0198715   0.14399496 -0.03132552
     0.08252391 -0.18137144]
   [ 0.07579848  0.09563783 -0.03113016 -0.01049717 -0.03869787
    -0.1402896   0.05172879  0.16654548 -0.02835602 -0.02578184
     0.17120874 -0.06828938]
   [-0.06846897  0.07873088 -0.08821677  0.14310127  0.16859818
     0.05140898 -0.0893107   0.12624368 -0.02682288  0.04080437
     0.0106688   0.08510935]]]


 [[[-0.10897526  0.13367662  0.15619364 -0.06999423 -0.02717434
    -0.11035156 -0.10835454  0.15969238 -0.08526637  0.14704192
    -0.09030451  0.17456818]
   [ 0.16563424  0.06151494 -0.16206598  0.08341992  0.04689771
     0.054217   -0.13138294  0.17479184 -0.03726193 -0.04269153
     0.11002967 -0.06969532]
   [-0.08868501  0.07564074  0.14892909  0.12079281 -0.09101778
     0.07109585 -0.05553997 -0.11530644  0.03784631 -0.01577654
    -0.07192009 -0.15675117]
   [-0.0735314  -0.1652137   0.02120845  0.0183654   0.17537561
     0.15261787  0.0069741   0.14271334  0.0050263   0.0354698
     0.09023002  0.06579477]
   [-0.06095969  0.05041076  0.01524849  0.00169246 -0.1525096
     0.12067726  0.11791995  0.03120604  0.09408206 -0.02889447
    -0.12880825  0.15582225]
   [-0.127826   -0.1494274  -0.03031504  0.00710647  0.01140636
    -0.05398986  0.01549983 -0.04401264  0.15839073  0.0254239
     0.04430681  0.10316274]
   [-0.04401442 -0.08693401 -0.04611614 -0.15874441 -0.02085574
     0.12584922 -0.07778938  0.07651812  0.01063828  0.14573783
    -0.017022   -0.0256664 ]
   [-0.04349761  0.10638207  0.1078729   0.1765739  -0.06204543
     0.14214712  0.11837754 -0.01438841 -0.07388486  0.08071905
    -0.14853379  0.06661451]]

  [[ 0.07779527 -0.11770336  0.10445264  0.10759658 -0.03735299
     0.01196928  0.14848569  0.13723698 -0.00261371 -0.01220721
    -0.02871208  0.12323365]
   [-0.06835105  0.16196147  0.14300656  0.02209666 -0.0643042
    -0.09489992  0.15379405 -0.13700852  0.13039896  0.10075757
    -0.14659409  0.09277135]
   [-0.05200654  0.00612023 -0.06426646 -0.075417    0.03244644
     0.0147413   0.04503044 -0.09471135  0.13704303 -0.11523192
    -0.07149107 -0.05435149]
   [ 0.08963063  0.02480608 -0.05215319  0.02542682 -0.15885001
    -0.17714758  0.01799679 -0.02272409  0.0497079  -0.1736505
    -0.02113354  0.04501721]
   [-0.07498924  0.01818036  0.04811095  0.13194507  0.03520149
    -0.14354797  0.1643706  -0.14866398 -0.13641517  0.14522159
     0.06691878  0.06758699]
   [-0.01079722 -0.07063206  0.00471407  0.16985306 -0.14888489
     0.11848301  0.16788247 -0.12660371 -0.01320224  0.14040408
     0.16058648  0.06816941]
   [-0.10741661 -0.02724394 -0.0822233   0.08925724  0.09258765
     0.06231165  0.0498044  -0.13713339 -0.13286063  0.17867482
    -0.05096972 -0.00895812]
   [ 0.02829708 -0.08036517  0.04478677 -0.16197905 -0.0109954
    -0.07474104 -0.14697593  0.02370255  0.0876936   0.01851954
     0.09659082 -0.0992752 ]]

  [[ 0.07054719  0.03664042  0.17328823  0.1551832  -0.02233982
    -0.1800142   0.02474132 -0.06799451  0.06863508  0.09027073
    -0.00181633 -0.07467387]
   [-0.01741277 -0.004581   -0.12157645 -0.01688723  0.11161086
    -0.02841021 -0.09768213 -0.04028572  0.01998416  0.00660427
    -0.17724048 -0.14708376]
   [ 0.04511471 -0.15401018 -0.01555946 -0.03063032 -0.11404274
     0.1064834  -0.08018744  0.02472408 -0.07646235 -0.10636378
    -0.148667    0.07533795]
   [ 0.04659531 -0.02630559  0.14988288 -0.02543582 -0.0281446
    -0.05474138 -0.04716301  0.15032604  0.15306407 -0.02251659
    -0.12148735 -0.12412669]
   [ 0.13318762  0.18038425  0.02371864  0.12804452  0.18000343
    -0.02104762  0.04726039 -0.15654784 -0.09428968  0.14436075
    -0.01856154 -0.08612794]
   [-0.0541607  -0.09237941  0.06004162 -0.13420218 -0.11275276
    -0.09002075  0.14222795  0.06486289  0.06487805  0.03626904
     0.11652446 -0.10532191]
   [-0.06088612 -0.02427961 -0.07980164 -0.0209693   0.05309759
    -0.09637764  0.02788343 -0.1616983   0.07265839 -0.0316944
    -0.06968196 -0.06994962]
   [-0.13647963  0.09382018  0.05407822  0.13661614  0.16818133
    -0.1110708   0.02397725 -0.12108409  0.07832575  0.03426287
    -0.11895713  0.04951768]]]]: "
2018-04-20 00:09:45,312 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv_1/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 00:09:45,324 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv_2/weights:0, var_value [[[[-0.0797774   0.01873627  0.1385109  ...  0.01415014  0.05313519
    -0.11567675]
   [ 0.0371282  -0.01852378 -0.01220277 ...  0.07838745 -0.15200189
    -0.02942897]
   [-0.11219987  0.02653207  0.13914661 ... -0.02268051  0.01884557
    -0.10662605]
   ...
   [-0.01931754  0.10785471 -0.0738834  ...  0.05605897 -0.02745824
    -0.14945176]
   [-0.00934859  0.06111154 -0.06048029 ... -0.01047826  0.08065607
    -0.01911066]
   [ 0.0869908  -0.03158921  0.07200363 ... -0.00325014  0.10848556
    -0.11243635]]

  [[ 0.10402112 -0.08505578  0.03061622 ... -0.14676416 -0.09480286
     0.11201669]
   [ 0.01366302  0.0022932  -0.01384506 ... -0.02880698 -0.08913184
    -0.11579804]
   [-0.09752969 -0.06275689  0.12859626 ...  0.08642426  0.10306172
    -0.09605898]
   ...
   [-0.03521162  0.0527986   0.02938788 ...  0.03956902 -0.11750452
    -0.11807732]
   [-0.10061806 -0.05139725 -0.05516935 ...  0.05418053 -0.08568631
    -0.0906323 ]
   [ 0.03504129  0.02396856 -0.08887803 ... -0.03232042 -0.00468104
     0.07404447]]

  [[ 0.1541829  -0.1045125  -0.11529106 ... -0.10019596 -0.14190017
    -0.07995395]
   [ 0.02162334  0.00685629  0.0875206  ... -0.01866394  0.06448419
     0.10108863]
   [ 0.11919345  0.14987867 -0.06624336 ... -0.08187944 -0.11034374
     0.0748125 ]
   ...
   [-0.13684542 -0.05107023 -0.0037633  ...  0.06076154 -0.14174308
     0.0386741 ]
   [ 0.14700033  0.08633758 -0.15287624 ... -0.13077605 -0.00711119
     0.05512314]
   [ 0.12159131  0.05729982  0.08275715 ...  0.0526921   0.14226906
    -0.06211813]]]


 [[[-0.01202865 -0.00967431  0.02385871 ...  0.02471659  0.04241538
    -0.01958933]
   [ 0.12125929  0.01211418  0.13327138 ... -0.12111421  0.10108043
    -0.10277212]
   [ 0.0984657  -0.0080872   0.11509134 ...  0.08291644 -0.01644051
     0.11152099]
   ...
   [ 0.03221072  0.13378079 -0.06361223 ...  0.12784235 -0.10977568
    -0.05360178]
   [-0.10839099 -0.13388881 -0.02110647 ... -0.09940819 -0.04715988
    -0.00712647]
   [ 0.06567498 -0.03493702 -0.01443522 ...  0.15022798  0.00903827
     0.10069202]]

  [[ 0.07153139 -0.13819873 -0.04929683 ...  0.11265786  0.08069491
    -0.12779906]
   [ 0.12745853  0.00370216 -0.02454191 ...  0.09623154  0.0001775
     0.04350774]
   [ 0.07256651  0.05599676  0.14617844 ... -0.01220372  0.14148615
    -0.07017564]
   ...
   [-0.13294595  0.05087757 -0.00388417 ... -0.08877664 -0.11591922
    -0.07819052]
   [ 0.11482559 -0.04780306  0.14269985 ... -0.02060565 -0.05782322
    -0.10979146]
   [-0.08152399 -0.12382263 -0.06542066 ...  0.12074052 -0.12256813
    -0.14660501]]

  [[ 0.05660661  0.04520389  0.05418664 ...  0.13390882  0.09029326
     0.12069909]
   [ 0.07769762  0.02919297  0.10366435 ... -0.02221252  0.14408077
     0.07060909]
   [ 0.0815248  -0.13238297  0.11402886 ... -0.13921385 -0.09824571
    -0.11210467]
   ...
   [-0.038612   -0.07993986  0.09361216 ... -0.13619772  0.12755702
     0.13634567]
   [ 0.02829695  0.0308069  -0.13810375 ... -0.01558612 -0.09937266
     0.03809218]
   [-0.07015412 -0.05846588 -0.120064   ...  0.13161443 -0.05718276
    -0.10728085]]]


 [[[ 0.030435   -0.06333458  0.02243446 ...  0.13593231 -0.13051705
    -0.02433604]
   [-0.02924481  0.01935621  0.12169908 ... -0.0406849  -0.12146281
     0.14411007]
   [ 0.07565585 -0.05887306 -0.12136301 ... -0.07856981 -0.02397165
     0.02643587]
   ...
   [ 0.1533375   0.04228702 -0.09097724 ...  0.10271607  0.13476925
    -0.02679199]
   [ 0.03572099  0.04462653 -0.02515885 ...  0.02842607 -0.1516429
     0.0448923 ]
   [ 0.00234838 -0.03872756  0.11498405 ... -0.03516199 -0.04284337
     0.07417628]]

  [[-0.06454548  0.0776455   0.03432643 ...  0.08143765 -0.04530789
     0.01492421]
   [-0.12865528  0.02481234 -0.11718009 ... -0.04410365  0.00359632
     0.04930131]
   [ 0.12103857  0.03000383 -0.08107848 ... -0.03966247  0.145406
     0.05948658]
   ...
   [-0.12647136  0.02175365 -0.02808857 ...  0.13086133  0.02426165
    -0.02675097]
   [-0.13547882  0.09986694 -0.0996836  ... -0.03389531 -0.07216095
     0.13954224]
   [-0.04688683  0.04190913  0.12469019 ... -0.11713892  0.05286431
    -0.03286828]]

  [[ 0.13387235  0.00517166 -0.06660926 ...  0.14508961 -0.11595403
    -0.08661048]
   [-0.08677559  0.11258914  0.06776421 ... -0.05621794 -0.01255502
     0.12493841]
   [-0.10320002 -0.13903755  0.03457987 ...  0.02658622 -0.03870077
     0.00746298]
   ...
   [-0.12197867 -0.10988932 -0.07672408 ...  0.01115187  0.02591468
    -0.13302387]
   [-0.15196793 -0.02575892  0.10223298 ...  0.09138496  0.04587485
    -0.08367073]
   [ 0.04596645 -0.00647435  0.02616249 ...  0.02018991  0.00734271
     0.15340148]]]]: "
2018-04-20 00:09:45,330 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv_2/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 00:09:45,334 (dqn_agent.py:161) DEBUG: "var_name: target_q/fully_connected/weights:0, var_value [[-0.06105846  0.02842958 -0.06607082 ...  0.08143545  0.02440361
  -0.00027925]
 [-0.01322457  0.04913994 -0.07371138 ... -0.00715099  0.05188406
  -0.08400482]
 [ 0.0208477   0.06453959  0.03748194 ... -0.08069795  0.08146083
  -0.0542092 ]
 ...
 [-0.05078364 -0.06910589 -0.07922482 ...  0.00789656  0.04588784
   0.06274114]
 [-0.08737447  0.08850712 -0.0916521  ... -0.04621189  0.02897456
  -0.02463267]
 [-0.08712668  0.0145384   0.02659321 ... -0.08777002 -0.0797758
  -0.09084145]]: "
2018-04-20 00:09:45,340 (dqn_agent.py:161) DEBUG: "var_name: target_q/fully_connected/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 00:09:45,348 (dqn_agent.py:161) DEBUG: "var_name: target_q/fully_connected_1/weights:0, var_value [[-1.33332372e-01 -1.21349141e-01 -5.98904490e-03  9.78068113e-02
  -1.72639668e-01]
 [ 2.19879001e-02  1.17726624e-01  5.87365031e-02 -1.50980830e-01
   1.43375307e-01]
 [-3.88857126e-02 -1.21027328e-01  5.75172305e-02 -1.40003175e-01
   1.91109031e-01]
 [-1.64104626e-01 -1.37330830e-01  7.63312280e-02 -4.93871868e-02
   1.40498400e-01]
 [-6.21345341e-02 -2.12296918e-01  1.88643992e-01 -1.62010074e-01
   2.89283544e-02]
 [ 7.92510211e-02  6.57981932e-02  8.34364593e-02  1.93149596e-01
  -5.63380271e-02]
 [ 8.33594501e-02  1.30414516e-02 -1.72245502e-03 -2.02637374e-01
  -3.33143026e-02]
 [-1.03909835e-01 -1.39290273e-01  9.87536311e-02  7.15075135e-02
   1.76905304e-01]
 [ 1.52604789e-01 -1.41019076e-02  1.11094624e-01 -6.31067157e-02
   1.23259515e-01]
 [ 2.49368399e-02 -4.09058183e-02  9.59849358e-02 -1.94948867e-01
   1.39712423e-01]
 [ 2.74312943e-02  2.62325555e-02  1.07461601e-01 -2.02591240e-01
   2.20338255e-02]
 [ 1.25593185e-01  5.53655922e-02  1.29744053e-01  3.81451845e-03
   1.52154148e-01]
 [-4.18858975e-02  1.42774522e-01  1.27843171e-02  1.15700305e-01
   8.67719054e-02]
 [-3.30982208e-02 -2.43003517e-02  1.51905507e-01  7.35116303e-02
   2.28226185e-04]
 [ 2.11443812e-01  1.20608777e-01 -1.78808883e-01 -2.39927620e-02
   1.83877409e-01]
 [ 3.56259942e-03 -1.89073563e-01  1.82523966e-01 -1.20623223e-01
  -1.48555189e-02]
 [ 1.20509446e-01  1.11306667e-01 -5.10512292e-03 -3.31417173e-02
  -9.28477272e-02]
 [-1.40883401e-01  2.00892031e-01 -1.62269041e-01  1.05588526e-01
  -3.88249755e-04]
 [ 1.83306038e-02 -1.13561690e-01  4.76567447e-02  2.08044112e-01
   2.57307142e-02]
 [-4.58348244e-02 -1.89173222e-01 -1.69141382e-01  1.63844138e-01
  -1.06254801e-01]
 [ 1.69571042e-02  1.90918118e-01 -4.01447564e-02  1.58081055e-01
   3.56156081e-02]
 [-1.26972407e-01 -1.17496997e-02  1.40221298e-01 -1.63462922e-01
  -1.27168477e-01]
 [-1.33166790e-01 -7.77329803e-02 -4.70646024e-02 -5.45788556e-02
   7.29191005e-02]
 [ 1.58559740e-01 -2.13138312e-02  7.36537576e-03  1.61597759e-01
   1.71119511e-01]
 [-6.78443909e-03 -1.45141169e-01 -1.38303190e-02 -5.31578064e-03
   3.53223532e-02]
 [ 4.64116037e-02  1.79639637e-01  1.42013669e-01  3.87872756e-02
  -7.78463632e-02]
 [-1.25575006e-01 -1.79828703e-01 -2.10043862e-01 -2.00302690e-01
  -1.76701576e-01]
 [-1.25143468e-01  9.25613642e-02  8.50352645e-02  1.86021179e-01
   8.28426182e-02]
 [ 2.03106403e-01 -1.26479864e-02 -1.94376245e-01  3.41293365e-02
   4.27161753e-02]
 [-1.91581905e-01 -6.36603087e-02 -1.67869419e-01  1.46228194e-01
   1.24100477e-01]
 [ 3.45172435e-02  7.85651505e-02  8.66160691e-02  7.83444047e-02
  -3.56978476e-02]
 [-1.83149099e-01  4.07444835e-02  1.18230343e-01 -1.06956519e-01
   6.45250678e-02]
 [ 1.66767716e-01 -1.19897857e-01 -4.49884832e-02 -1.47899061e-01
   1.28830642e-01]
 [-1.30647019e-01  1.52333468e-01  6.11083806e-02  5.36487997e-02
  -9.23249274e-02]
 [-8.76322091e-02  1.70817107e-01 -7.91828930e-02  8.18712413e-02
   1.22866154e-01]
 [-1.55784488e-01  9.03639495e-02  1.61848694e-01 -1.07190721e-01
  -1.45900160e-01]
 [-6.51546270e-02 -5.38187623e-02 -2.56687403e-03 -1.45303980e-01
   1.80245012e-01]
 [-2.10296005e-01  1.65432751e-01 -1.96618468e-01 -4.83155251e-04
  -1.97427124e-01]
 [ 1.44576877e-02  2.10917145e-01  5.70272207e-02  1.49710089e-01
  -1.44896537e-01]
 [ 1.72353417e-01 -1.22898862e-01 -1.07862204e-01  7.61069357e-02
  -1.64051145e-01]
 [ 2.54404992e-02 -3.45092416e-02  1.22068584e-01 -4.28612232e-02
   5.47040403e-02]
 [-7.95610696e-02  5.46818972e-02  4.17655706e-02 -1.28726810e-02
  -1.42941996e-01]
 [ 1.31037205e-01 -8.53326917e-03  1.52641445e-01 -2.08379090e-01
  -6.94002509e-02]
 [-4.83085662e-02  1.05872273e-01  1.96069390e-01 -7.71625340e-03
   3.70381325e-02]
 [-8.26944411e-02  1.81950063e-01  1.04183048e-01  1.86633199e-01
   1.09252572e-01]
 [-8.32722485e-02  2.21315175e-02  1.10602826e-02  1.12895221e-01
  -8.20102096e-02]
 [ 1.59277260e-01  1.74249232e-01  1.44925863e-01  2.00162113e-01
   9.39865112e-02]
 [-1.73819810e-02 -1.66694582e-01 -1.82291821e-01 -5.25571257e-02
  -1.95269167e-01]
 [ 2.10287333e-01 -5.10967821e-02 -1.80516496e-01 -1.15478694e-01
   1.39438659e-01]
 [-3.89538705e-02 -2.62869895e-02 -1.35155961e-01 -8.16502124e-02
  -1.04703464e-01]
 [ 6.32601082e-02  1.79905772e-01  2.08012551e-01 -1.13431491e-01
   1.73217356e-01]
 [-5.87642193e-02  1.56381488e-01 -1.13846228e-01 -1.28444701e-01
  -4.73091453e-02]
 [ 3.96845639e-02  8.60593915e-02 -1.79569587e-01 -1.95884392e-01
  -5.57826608e-02]
 [ 1.54591978e-01 -1.92236260e-01 -3.72524559e-03 -1.16627149e-01
   1.81555867e-01]
 [-2.44139880e-02  3.47475410e-02  2.02982575e-01 -7.77329355e-02
   1.61969751e-01]
 [-2.71016806e-02  1.52809560e-01 -1.67976022e-02 -8.15618485e-02
   1.84121370e-01]
 [ 6.86028600e-03 -1.21316321e-01  4.07213569e-02  1.51968658e-01
   1.35954291e-01]
 [-1.17039412e-01 -8.46014768e-02  4.84654903e-02  1.69804543e-02
   4.88846898e-02]
 [ 4.18361723e-02 -1.78853959e-01 -1.45407289e-01 -1.25650868e-01
   1.17502093e-01]
 [-2.06809878e-01 -8.18790495e-02  5.74409068e-02 -1.80485308e-01
   1.30008459e-02]
 [ 1.05592281e-01  2.04155952e-01  9.08307433e-02  3.57435793e-02
  -1.28867894e-01]
 [ 1.47449464e-01 -1.95517704e-01  2.64264494e-02 -1.46879628e-01
  -9.44144651e-02]
 [-7.73212314e-02  1.50754929e-01  1.16665930e-01  8.31313133e-02
  -1.51184201e-01]
 [ 7.02056289e-02 -3.86433452e-02 -2.00528488e-01 -1.67933837e-01
  -6.42767549e-03]
 [-9.73364711e-02  1.68140709e-01  1.46741629e-01 -4.84089404e-02
   1.64870650e-01]
 [-1.96861371e-01 -3.66970152e-02 -2.90136337e-02 -1.72180921e-01
  -1.18585385e-01]
 [ 1.56324774e-01 -1.72880769e-01 -1.79759443e-01  2.02931434e-01
   2.05285013e-01]
 [-1.14409700e-01 -6.00090325e-02 -6.00715727e-02 -1.48965329e-01
  -6.92888945e-02]
 [-7.44006932e-02  8.93048346e-02  1.00024372e-01  1.93319649e-01
   2.11270094e-01]
 [-2.13102847e-02 -1.57896727e-01 -1.83345631e-01 -7.51146674e-03
  -1.38531625e-02]
 [ 2.19836384e-02  1.52192324e-01 -5.66162914e-02  2.17455924e-02
  -6.32507354e-02]
 [-1.75569370e-01  1.75910234e-01 -1.22227125e-01 -1.01274356e-01
   5.80603778e-02]
 [ 4.43098247e-02  5.88109195e-02  2.02916294e-01 -1.05794795e-01
  -6.80513084e-02]
 [-1.26083687e-01  1.56830668e-01 -5.63588440e-02  4.55490649e-02
   1.47138834e-02]
 [ 8.71114433e-02  3.84750366e-02 -1.47621244e-01 -1.96559876e-01
  -1.48402765e-01]
 [ 1.37743682e-01 -8.18346441e-02 -1.76512688e-01 -1.57841012e-01
  -1.42260045e-01]
 [-1.95939839e-03  5.35142124e-02 -1.31175667e-02  1.77288383e-01
   1.00596696e-01]
 [ 2.02702492e-01 -1.70870826e-01 -1.89399689e-01 -1.96021214e-01
  -1.11866273e-01]
 [ 5.80630004e-02  6.27471805e-02  1.08344853e-01 -1.05071068e-02
  -1.03693604e-02]
 [ 5.66751361e-02 -8.86138529e-02 -1.07130565e-01  9.31333303e-02
   6.72780573e-02]
 [ 2.83122063e-06  1.89666450e-02 -8.52186829e-02 -1.19457550e-01
  -1.03126593e-01]
 [-1.10526860e-01 -1.05703190e-01  1.77719027e-01 -1.15153342e-02
  -1.06111541e-01]
 [ 1.04258657e-01  6.74642920e-02 -1.85029387e-01 -8.57597589e-02
   3.71636599e-02]
 [-7.52004534e-02  1.67274922e-01  4.62332666e-02 -1.41756773e-01
   1.65151030e-01]
 [ 2.56775022e-02 -1.75179645e-01 -1.96602911e-01  4.48317528e-02
   1.57505721e-01]
 [-7.31959343e-02 -2.08361015e-01 -1.62833571e-01 -2.67283171e-02
  -1.27656490e-01]
 [ 6.40900731e-02 -1.70506120e-01  6.44489527e-02  1.06842071e-01
   1.33804083e-01]
 [ 3.87928784e-02 -7.65558630e-02  1.96308583e-01 -2.05414906e-01
   1.08516216e-01]
 [-8.95004570e-02  9.48854685e-02 -1.34641975e-01 -3.70140672e-02
   1.27068937e-01]
 [ 7.14562237e-02 -1.33513927e-01  7.49334693e-02  1.65760338e-01
  -7.71780759e-02]
 [ 4.13779914e-02  2.11308092e-01 -1.88402444e-01  1.29697889e-01
  -1.62390530e-01]
 [-8.18880647e-02 -9.55564901e-02  7.28605986e-02 -1.60114616e-02
   1.19657516e-01]
 [ 1.29042089e-01  1.25617534e-01 -1.48041159e-01 -1.77534938e-01
  -1.14387773e-01]
 [-7.82036334e-02  1.44397676e-01 -7.22879171e-02  2.08964586e-01
   8.45837593e-03]
 [-1.74476475e-01 -3.87125164e-02  1.30463243e-01 -1.62515491e-02
  -5.79580814e-02]
 [-9.36988816e-02 -3.44815403e-02  4.77618575e-02 -6.10817373e-02
  -1.52989239e-01]
 [-1.39445081e-01  1.81519777e-01  3.26515287e-02  7.57436454e-03
   1.85713232e-01]
 [ 1.19170129e-01 -7.29819387e-02 -1.92039177e-01 -9.55184102e-02
  -1.90760478e-01]
 [ 3.02956700e-02 -1.46895796e-02 -9.13210437e-02  8.34646225e-02
  -4.54191267e-02]
 [-8.38156044e-02 -5.32496274e-02  1.15667015e-01 -5.57486862e-02
  -5.41878194e-02]
 [ 1.50856614e-01 -1.75100341e-01 -1.18969433e-01 -9.78152677e-02
  -6.72666430e-02]
 [ 1.42697603e-01 -3.07936668e-02 -4.56988513e-02  1.10326022e-01
   1.67318612e-01]
 [-2.04904377e-02 -8.31899047e-02  4.74621356e-02  1.21553570e-01
   1.75197929e-01]
 [-2.57045329e-02  1.64978117e-01 -1.25101775e-01 -1.60598904e-01
  -1.42539710e-01]
 [ 1.89972311e-01  7.19270706e-02  2.01232076e-01 -5.36444038e-02
  -2.05520287e-01]
 [-7.36287981e-02 -1.83466449e-01  1.89967155e-02 -8.38266015e-02
   1.08603150e-01]
 [-1.69596985e-01  1.80198848e-02 -1.18377253e-01 -3.07594240e-03
   6.10244572e-02]
 [ 1.34180099e-01  7.04799294e-02 -9.25011039e-02  1.23018324e-01
  -7.09713995e-03]
 [ 1.52822375e-01 -7.20094144e-03  1.81729376e-01 -1.33396089e-01
   4.68405783e-02]
 [-9.41604078e-02  6.97126985e-02  8.21819305e-02  8.86453986e-02
  -1.93376839e-03]
 [ 1.47830695e-01 -2.05642134e-02  4.93700802e-03 -1.73537299e-01
  -6.39557391e-02]
 [-6.12229109e-04 -1.02399617e-01 -1.80691212e-01  9.89547074e-02
   4.43066657e-02]
 [-6.52963221e-02  3.80224586e-02  7.80207813e-02 -1.41674191e-01
   9.97964740e-02]
 [ 1.21713787e-01  7.33523071e-02  1.05053544e-01  2.16308832e-02
   1.32878900e-01]
 [-5.92103601e-03  2.03366190e-01  7.00026453e-02  9.40120816e-02
   1.29161954e-01]
 [-2.51051635e-02  1.53929323e-01 -3.58356386e-02 -4.51561511e-02
  -1.56033233e-01]
 [-1.96996436e-01 -1.58153310e-01  1.48793966e-01 -1.00975931e-01
  -1.05046041e-01]
 [ 6.47329986e-02 -1.06125318e-01  7.41723180e-02  9.74582136e-02
   2.55825967e-02]
 [-2.42102593e-02 -9.21168998e-02  1.16180867e-01 -1.86484620e-01
   2.13188976e-02]
 [-1.86951011e-01 -7.34149516e-02 -7.33887255e-02  1.31130129e-01
   2.72764862e-02]
 [ 1.47147447e-01 -1.83533430e-02 -8.10547173e-03 -1.66236803e-01
  -1.35311171e-01]
 [ 6.97261095e-02  1.21982634e-01 -1.16987303e-01 -1.33938432e-01
   2.19946355e-02]
 [ 1.41777039e-01 -1.88485950e-01 -6.29267395e-02 -1.16352379e-01
  -8.35455954e-02]
 [-5.08670360e-02 -2.76563317e-02 -3.30282897e-02 -2.07740784e-01
   1.70364022e-01]
 [ 1.50674433e-02  1.58690661e-02 -1.78512082e-01  5.01784980e-02
  -2.02114224e-01]
 [-1.93267643e-01 -6.17783368e-02 -2.07096592e-01 -5.04980683e-02
  -9.29170027e-02]
 [-2.36701965e-02  1.18253976e-02  1.02882981e-01 -1.89824909e-01
  -1.48974508e-02]
 [-2.05038399e-01  1.69189543e-01 -9.32534039e-02  6.71012104e-02
   1.25466853e-01]]: "
2018-04-20 00:09:45,352 (dqn_agent.py:161) DEBUG: "var_name: target_q/fully_connected_1/biases:0, var_value [0. 0. 0. 0. 0.]: "
2018-04-20 00:09:53,036 (dqn_main.py:212) DEBUG: "Episode 10000, mean reward over last 10000 episodes: -1.3475400000000002"
2018-04-20 00:09:53,036 (dqn_main.py:213) DEBUG: "Epsilon: 0.9954253000001506"
2018-04-20 00:09:53,036 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -1.1, done: True"
2018-04-20 00:09:53,036 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 00:10:43,232 (dqn_main.py:212) DEBUG: "Episode 20000, mean reward over last 10000 episodes: -1.3297800000000002"
2018-04-20 00:10:43,233 (dqn_main.py:213) DEBUG: "Epsilon: 0.9440236000018429"
2018-04-20 00:10:43,233 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -2.3, done: True"
2018-04-20 00:10:43,233 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 00:11:40,850 (dqn_main.py:212) DEBUG: "Episode 30000, mean reward over last 10000 episodes: -1.3363"
2018-04-20 00:11:40,851 (dqn_main.py:213) DEBUG: "Epsilon: 0.8856793000037638"
2018-04-20 00:11:40,851 (dqn_main.py:214) DEBUG: "RL steps: [(2, 4)], reward: -1.4, done: True"
2018-04-20 00:11:40,851 (dqn_main.py:215) DEBUG: "Steps: 1, coords: 40"
2018-04-20 00:12:49,393 (dqn_main.py:212) DEBUG: "Episode 40000, mean reward over last 10000 episodes: -1.30247"
2018-04-20 00:12:49,393 (dqn_main.py:213) DEBUG: "Epsilon: 0.820430200005912"
2018-04-20 00:12:49,393 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -1.9, done: True"
2018-04-20 00:12:49,393 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 00:14:21,475 (dqn_main.py:212) DEBUG: "Episode 50000, mean reward over last 10000 episodes: -1.22463"
2018-04-20 00:14:21,476 (dqn_main.py:213) DEBUG: "Epsilon: 0.7419610000084955"
2018-04-20 00:14:21,476 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -1.5, done: True"
2018-04-20 00:14:21,476 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 00:16:17,414 (dqn_main.py:212) DEBUG: "Episode 60000, mean reward over last 10000 episodes: -1.05072"
2018-04-20 00:16:17,414 (dqn_main.py:213) DEBUG: "Epsilon: 0.6470974000116188"
2018-04-20 00:16:17,414 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -1.5, done: True"
2018-04-20 00:16:17,415 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 00:19:04,223 (dqn_main.py:212) DEBUG: "Episode 70000, mean reward over last 10000 episodes: -0.7993600000000002"
2018-04-20 00:19:04,223 (dqn_main.py:213) DEBUG: "Epsilon: 0.5217031000157472"
2018-04-20 00:19:04,223 (dqn_main.py:214) DEBUG: "RL steps: [(3, 1), (2, 2), (2, 4), (4, 6), (5, 5), (2, 5)], reward: -1.3000000000000003, done: True"
2018-04-20 00:19:04,224 (dqn_main.py:215) DEBUG: "Steps: 6, coords: 40"
2018-04-20 00:23:11,931 (dqn_main.py:212) DEBUG: "Episode 80000, mean reward over last 10000 episodes: -0.7009900000000001"
2018-04-20 00:23:11,932 (dqn_main.py:213) DEBUG: "Epsilon: 0.34840540001210246"
2018-04-20 00:23:11,932 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (2, 2), (4, 5), (2, 7), (2, 6)], reward: -0.3000000000000006, done: True"
2018-04-20 00:23:11,932 (dqn_main.py:215) DEBUG: "Steps: 5, coords: 40"
2018-04-20 00:39:24,811 (dqn_main.py:212) DEBUG: "Episode 90000, mean reward over last 10000 episodes: -1.228019999999999"
2018-04-20 00:39:24,812 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 00:39:24,812 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (2, 2), (2, 4), (2, 5), (3, 5), (3, 6), (4, 6), (4, 8), (4, 7), (5, 7), (6, 5), (6, 6), (5, 5), (4, 5)], reward: -7.399999999999963, done: True"
2018-04-20 00:39:24,812 (dqn_main.py:215) DEBUG: "Steps: 14, coords: 40"
2018-04-20 01:04:04,376 (dqn_main.py:212) DEBUG: "Episode 100000, mean reward over last 10000 episodes: -0.17340999999999343"
2018-04-20 01:04:04,376 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 01:04:04,376 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (2, 2), (2, 3), (2, 4), (3, 3), (3, 4), (4, 4), (4, 6), (4, 5), (3, 5), (6, 5), (3, 6), (2, 7), (5, 6)], reward: -3.7999999999999985, done: True"
2018-04-20 01:04:04,377 (dqn_main.py:215) DEBUG: "Steps: 14, coords: 40"
2018-04-20 01:25:01,515 (dqn_main.py:212) DEBUG: "Episode 110000, mean reward over last 10000 episodes: 7.013570000000007"
2018-04-20 01:25:01,515 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 01:25:01,515 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 2)], reward: 0.30000000000000004, done: True"
2018-04-20 01:25:01,515 (dqn_main.py:215) DEBUG: "Steps: 2, coords: 40"
2018-04-20 01:44:04,370 (dqn_main.py:212) DEBUG: "Episode 120000, mean reward over last 10000 episodes: 11.08757999999999"
2018-04-20 01:44:04,370 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 01:44:04,370 (dqn_main.py:214) DEBUG: "RL steps: [(3, 1), (2, 1), (2, 2), (3, 2), (3, 3)], reward: 3.1999999999999993, done: True"
2018-04-20 01:44:04,370 (dqn_main.py:215) DEBUG: "Steps: 5, coords: 40"
2018-04-20 02:01:45,884 (dqn_main.py:212) DEBUG: "Episode 130000, mean reward over last 10000 episodes: 12.980129999999987"
2018-04-20 02:01:45,884 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 02:01:45,884 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -1.0, done: True"
2018-04-20 02:01:45,884 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 02:25:23,984 (dqn_main.py:212) DEBUG: "Episode 140000, mean reward over last 10000 episodes: 10.55693999999998"
2018-04-20 02:25:23,984 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 02:25:23,984 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (2, 2), (3, 2), (3, 1), (3, 3), (2, 3), (2, 4), (3, 4), (4, 4), (4, 5), (3, 5), (2, 5), (2, 7), (2, 6), (3, 6), (4, 6), (5, 7), (6, 7), (6, 6), (5, 6), (5, 5), (6, 5), (7, 5), (7, 4), (8, 4), (8, 5), (6, 4), (8, 6), (7, 7), (4, 8), (4, 7)], reward: 15.299999999999898, done: True"
2018-04-20 02:25:23,984 (dqn_main.py:215) DEBUG: "Steps: 31, coords: 40"
2018-04-20 02:45:49,996 (dqn_main.py:212) DEBUG: "Episode 150000, mean reward over last 10000 episodes: 13.71269999999998"
2018-04-20 02:45:49,996 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 02:45:49,996 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (2, 2), (3, 1), (3, 2), (3, 3), (2, 3), (2, 4), (3, 4), (4, 4), (4, 5), (3, 5), (2, 5), (2, 6), (2, 7), (3, 6), (4, 6), (4, 7), (5, 7), (6, 7), (6, 6), (5, 6), (5, 5), (6, 5), (6, 4), (7, 4), (7, 5), (8, 5), (8, 6), (9, 5), (9, 4)], reward: 25.099999999999987, done: True"
2018-04-20 02:45:49,996 (dqn_main.py:215) DEBUG: "Steps: 30, coords: 40"
2018-04-20 03:04:12,281 (dqn_main.py:212) DEBUG: "Episode 160000, mean reward over last 10000 episodes: 16.84200999999998"
2018-04-20 03:04:12,281 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 03:04:12,282 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (2, 3), (2, 4), (3, 4), (3, 3), (4, 4), (4, 5), (3, 5), (2, 5), (2, 6), (3, 6), (4, 6), (4, 7), (5, 7), (6, 7), (6, 6), (5, 6), (5, 5), (6, 5), (6, 4), (7, 4)], reward: 19.9, done: True"
2018-04-20 03:04:12,282 (dqn_main.py:215) DEBUG: "Steps: 24, coords: 40"
2018-04-20 03:21:52,607 (dqn_main.py:212) DEBUG: "Episode 170000, mean reward over last 10000 episodes: 18.04867999999998"
2018-04-20 03:21:52,608 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 03:21:52,608 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (3, 3), (2, 3), (2, 2), (2, 4), (3, 4), (4, 4), (4, 5), (3, 5), (2, 5), (2, 6), (3, 6), (4, 6), (4, 7), (5, 7)], reward: 14.000000000000005, done: True"
2018-04-20 03:21:52,608 (dqn_main.py:215) DEBUG: "Steps: 17, coords: 40"
2018-04-20 03:39:16,556 (dqn_main.py:212) DEBUG: "Episode 180000, mean reward over last 10000 episodes: 18.124399999999984"
2018-04-20 03:39:16,557 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 03:39:16,557 (dqn_main.py:214) DEBUG: "RL steps: [(3, 1), (2, 1), (2, 2), (2, 3), (3, 2), (3, 3), (2, 4), (3, 4), (4, 4), (4, 5), (3, 5), (2, 5), (2, 6), (3, 6), (4, 6), (4, 7)], reward: 12.100000000000005, done: True"
2018-04-20 03:39:16,557 (dqn_main.py:215) DEBUG: "Steps: 16, coords: 40"
2018-04-20 03:56:18,055 (dqn_main.py:212) DEBUG: "Episode 190000, mean reward over last 10000 episodes: 18.75642999999998"
2018-04-20 03:56:18,055 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 03:56:18,055 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 2), (3, 1), (2, 2), (2, 3), (3, 3), (3, 4), (2, 4), (4, 4), (4, 5), (3, 5), (2, 5), (2, 6), (2, 7), (3, 6), (4, 6), (4, 7), (5, 7), (6, 6), (6, 7), (5, 6), (5, 5), (6, 5), (6, 4), (7, 4), (7, 5), (8, 6), (8, 5), (9, 5), (8, 4), (9, 4), (9, 3), (8, 3), (7, 3), (7, 6), (7, 7), (3, 7), (3, 8), (4, 8), (5, 8)], reward: 32.89999999999994, done: True"
2018-04-20 03:56:18,055 (dqn_main.py:215) DEBUG: "Steps: 40, coords: 40"
2018-04-20 03:56:18,463 (tsp_computer.py:36) DEBUG: "tour"
2018-04-20 03:56:18,463 (dqn_main.py:217) DEBUG: "tsp_cost 42"
2018-04-20 04:13:02,974 (dqn_main.py:212) DEBUG: "Episode 200000, mean reward over last 10000 episodes: 18.693169999999984"
2018-04-20 04:13:02,974 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 04:13:02,974 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (2, 3), (3, 3), (2, 4), (3, 4), (4, 4), (4, 5), (3, 5), (2, 5), (2, 6), (2, 7), (3, 6), (4, 6), (4, 7), (4, 8), (5, 7), (6, 7), (6, 6), (5, 6), (5, 5), (6, 5), (6, 4), (7, 4), (7, 5), (8, 5), (8, 6), (9, 5), (9, 4), (9, 3), (8, 3), (7, 3), (8, 4), (7, 6), (7, 7), (3, 7), (3, 8), (5, 8)], reward: 33.59999999999996, done: True"
2018-04-20 04:13:02,974 (dqn_main.py:215) DEBUG: "Steps: 40, coords: 40"
2018-04-20 04:13:03,344 (tsp_computer.py:36) DEBUG: "tour"
2018-04-20 04:13:03,345 (dqn_main.py:217) DEBUG: "tsp_cost 42"
2018-04-20 04:30:11,462 (dqn_main.py:212) DEBUG: "Episode 210000, mean reward over last 10000 episodes: 19.04100999999998"
2018-04-20 04:30:11,463 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 04:30:11,463 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (2, 2), (3, 1), (3, 2), (3, 3), (2, 3), (2, 4), (3, 4), (4, 4), (4, 5), (3, 5), (2, 5)], reward: 9.3, done: True"
2018-04-20 04:30:11,463 (dqn_main.py:215) DEBUG: "Steps: 12, coords: 40"
2018-04-20 04:47:10,335 (dqn_main.py:212) DEBUG: "Episode 220000, mean reward over last 10000 episodes: 18.512449999999987"
2018-04-20 04:47:10,336 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 04:47:10,336 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (2, 2), (3, 2), (3, 3), (2, 3), (2, 4), (3, 4), (4, 4), (4, 5), (3, 5), (2, 5), (2, 6), (2, 7), (3, 6), (4, 6), (4, 7)], reward: 13.900000000000004, done: True"
2018-04-20 04:47:10,336 (dqn_main.py:215) DEBUG: "Steps: 17, coords: 40"
2018-04-20 05:04:03,982 (dqn_main.py:212) DEBUG: "Episode 230000, mean reward over last 10000 episodes: 18.875109999999985"
2018-04-20 05:04:03,983 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 05:04:03,983 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (2, 2), (3, 2), (3, 1), (3, 3), (2, 3), (2, 4), (3, 4), (3, 5), (4, 5), (4, 4), (2, 5), (2, 6), (2, 7), (3, 6), (4, 6), (4, 7), (5, 7), (6, 7), (6, 6), (5, 6), (5, 5), (6, 5), (6, 4), (7, 4), (7, 5), (8, 5), (8, 4), (8, 6)], reward: 22.19999999999999, done: True"
2018-04-20 05:04:03,983 (dqn_main.py:215) DEBUG: "Steps: 29, coords: 40"
2018-04-20 05:21:00,731 (dqn_main.py:212) DEBUG: "Episode 240000, mean reward over last 10000 episodes: 18.641769999999983"
2018-04-20 05:21:00,731 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 05:21:00,731 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (2, 3), (3, 3), (2, 4), (3, 4), (4, 4), (4, 5), (3, 5), (2, 5), (2, 6), (3, 6), (4, 6), (2, 7), (4, 7), (5, 7), (6, 7), (6, 6), (5, 6), (5, 5), (6, 5), (6, 4), (8, 4), (7, 5), (8, 6), (8, 5), (9, 5), (9, 4), (9, 3), (8, 3), (7, 3), (7, 4), (7, 6), (7, 7), (3, 7), (3, 8), (4, 8), (5, 8)], reward: 32.89999999999995, done: True"
2018-04-20 05:21:00,731 (dqn_main.py:215) DEBUG: "Steps: 40, coords: 40"
2018-04-20 05:21:00,923 (tsp_computer.py:36) DEBUG: "tour"
2018-04-20 05:21:00,923 (dqn_main.py:217) DEBUG: "tsp_cost 42"
2018-04-20 05:38:31,965 (dqn_main.py:212) DEBUG: "Episode 250000, mean reward over last 10000 episodes: 17.833379999999988"
2018-04-20 05:38:31,965 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 05:38:31,965 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (2, 2), (3, 2), (3, 3), (2, 3), (2, 4), (3, 4), (4, 4), (4, 5), (3, 5), (2, 5), (2, 7), (2, 6), (3, 6), (4, 6), (4, 7), (5, 7), (6, 7), (6, 6), (5, 6), (5, 5), (6, 5), (6, 4), (7, 4), (7, 5), (8, 5), (8, 6), (9, 5)], reward: 24.19999999999999, done: True"
2018-04-20 05:38:31,965 (dqn_main.py:215) DEBUG: "Steps: 29, coords: 40"
2018-04-20 05:55:14,569 (dqn_main.py:212) DEBUG: "Episode 260000, mean reward over last 10000 episodes: 18.95280999999998"
2018-04-20 05:55:14,569 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 05:55:14,569 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (2, 2), (3, 2), (3, 3), (2, 3), (2, 4), (3, 4), (4, 4), (4, 5), (3, 5), (2, 5), (2, 6), (2, 7), (3, 6), (4, 6), (4, 8), (4, 7), (5, 7), (6, 7), (6, 6), (5, 6), (5, 5), (6, 5), (6, 4), (7, 4), (7, 5), (8, 6), (8, 5), (9, 5), (9, 4), (9, 3), (8, 3), (8, 4), (7, 3), (7, 6), (7, 7), (3, 7), (3, 8), (5, 8)], reward: 33.299999999999955, done: True"
2018-04-20 05:55:14,570 (dqn_main.py:215) DEBUG: "Steps: 40, coords: 40"
2018-04-20 05:55:14,778 (tsp_computer.py:36) DEBUG: "tour"
2018-04-20 05:55:14,778 (dqn_main.py:217) DEBUG: "tsp_cost 42"
2018-04-20 06:12:06,151 (dqn_main.py:212) DEBUG: "Episode 270000, mean reward over last 10000 episodes: 19.24135999999998"
2018-04-20 06:12:06,151 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 06:12:06,151 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (3, 3), (2, 3), (2, 2), (2, 4), (3, 4), (4, 4), (4, 5), (4, 6), (3, 5), (2, 5), (2, 6), (2, 7), (3, 6), (4, 7), (3, 7), (5, 7), (5, 6), (5, 5), (6, 5), (6, 6), (6, 7), (6, 4), (7, 4), (7, 5), (8, 6), (8, 5), (9, 5), (9, 4), (9, 3), (8, 3), (8, 4), (7, 3), (7, 6), (7, 7), (4, 8), (3, 8), (5, 8)], reward: 33.89999999999996, done: True"
2018-04-20 06:12:06,151 (dqn_main.py:215) DEBUG: "Steps: 40, coords: 40"
2018-04-20 06:12:06,397 (tsp_computer.py:36) DEBUG: "tour"
2018-04-20 06:12:06,397 (dqn_main.py:217) DEBUG: "tsp_cost 42"
2018-04-20 06:28:54,043 (dqn_main.py:212) DEBUG: "Episode 280000, mean reward over last 10000 episodes: 19.04627999999998"
2018-04-20 06:28:54,043 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 06:28:54,043 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (2, 2), (3, 2), (3, 3), (2, 3), (3, 4), (2, 4), (4, 4), (4, 5), (3, 5), (2, 5), (2, 6), (3, 6), (4, 6), (4, 8), (4, 7), (5, 7), (6, 7), (6, 6), (5, 6), (5, 5), (6, 5), (6, 4), (7, 4), (7, 5), (8, 5), (8, 6), (9, 5), (9, 4), (9, 3), (8, 3), (8, 4), (7, 3), (7, 6), (7, 7), (3, 7), (2, 7), (3, 8), (5, 8)], reward: 33.59999999999996, done: True"
2018-04-20 06:28:54,043 (dqn_main.py:215) DEBUG: "Steps: 40, coords: 40"
2018-04-20 06:28:54,200 (tsp_computer.py:36) DEBUG: "tour"
2018-04-20 06:28:54,200 (dqn_main.py:217) DEBUG: "tsp_cost 42"
2018-04-20 06:45:55,671 (dqn_main.py:212) DEBUG: "Episode 290000, mean reward over last 10000 episodes: 19.165009999999985"
2018-04-20 06:45:55,671 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 06:45:55,671 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (3, 3), (2, 2), (2, 3), (2, 4), (3, 4), (4, 4), (4, 5), (3, 5), (2, 5), (2, 6), (3, 6), (4, 6), (5, 7), (4, 8), (4, 7), (5, 6), (6, 7), (6, 6), (5, 5), (6, 5), (6, 4), (7, 4), (7, 5), (8, 5), (8, 6), (9, 4), (9, 5), (9, 3), (8, 3), (7, 3)], reward: 26.29999999999998, done: True"
2018-04-20 06:45:55,671 (dqn_main.py:215) DEBUG: "Steps: 33, coords: 40"
2018-04-20 07:02:13,457 (dqn_main.py:212) DEBUG: "Episode 300000, mean reward over last 10000 episodes: 19.10059999999998"
2018-04-20 07:02:13,457 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 07:02:13,457 (dqn_main.py:214) DEBUG: "RL steps: [(2, 2), (2, 1), (3, 1), (3, 2), (3, 3), (2, 3), (2, 4), (3, 4), (4, 4), (4, 5), (3, 5), (2, 5), (2, 6), (3, 6), (4, 6), (4, 7), (5, 7), (6, 7), (6, 6), (5, 6), (5, 5), (6, 5), (6, 4), (7, 4), (7, 5), (8, 5), (8, 6), (9, 5), (9, 4), (9, 3), (8, 3), (7, 3), (8, 4), (7, 6), (7, 7), (3, 7), (2, 7), (3, 8), (4, 8), (5, 8)], reward: 34.39999999999996, done: True"
2018-04-20 07:02:13,457 (dqn_main.py:215) DEBUG: "Steps: 40, coords: 40"
2018-04-20 07:02:13,724 (tsp_computer.py:36) DEBUG: "tour"
2018-04-20 07:02:13,724 (dqn_main.py:217) DEBUG: "tsp_cost 42"
2018-04-20 07:19:07,479 (dqn_main.py:212) DEBUG: "Episode 310000, mean reward over last 10000 episodes: 19.244629999999983"
2018-04-20 07:19:07,479 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 07:19:07,479 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (2, 3), (3, 3), (3, 4), (2, 4), (4, 4), (4, 5), (3, 5), (2, 5), (2, 6), (2, 7), (3, 7), (3, 6), (4, 6), (4, 7), (5, 7), (6, 7), (6, 6), (5, 6), (5, 5), (6, 5), (6, 4), (7, 4), (7, 5), (8, 6), (8, 5), (9, 5), (8, 4), (9, 4), (9, 3), (8, 3), (7, 3), (7, 6), (7, 7), (4, 8), (3, 8), (5, 8)], reward: 33.899999999999956, done: True"
2018-04-20 07:19:07,479 (dqn_main.py:215) DEBUG: "Steps: 40, coords: 40"
2018-04-20 07:19:07,725 (tsp_computer.py:36) DEBUG: "tour"
2018-04-20 07:19:07,726 (dqn_main.py:217) DEBUG: "tsp_cost 42"
2018-04-20 07:36:15,257 (dqn_main.py:212) DEBUG: "Episode 320000, mean reward over last 10000 episodes: 19.45722999999998"
2018-04-20 07:36:15,258 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 07:36:15,258 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (2, 2), (3, 2), (3, 3), (2, 3), (2, 4), (3, 4), (4, 4), (4, 6), (4, 5), (3, 5), (2, 5), (2, 6), (2, 7), (3, 7), (3, 6), (4, 7), (5, 7), (6, 7), (6, 6), (5, 6), (5, 5), (6, 5), (6, 4), (7, 4), (7, 5), (7, 6), (8, 6), (8, 5), (9, 5), (9, 4), (9, 3), (8, 3), (8, 4), (7, 3), (7, 7), (4, 8), (3, 8), (5, 8)], reward: 33.899999999999956, done: True"
2018-04-20 07:36:15,258 (dqn_main.py:215) DEBUG: "Steps: 40, coords: 40"
2018-04-20 07:36:15,487 (tsp_computer.py:36) DEBUG: "tour"
2018-04-20 07:36:15,487 (dqn_main.py:217) DEBUG: "tsp_cost 42"
2018-04-20 07:53:28,232 (dqn_main.py:212) DEBUG: "Episode 330000, mean reward over last 10000 episodes: 19.303489999999986"
2018-04-20 07:53:28,232 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 07:53:28,232 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (2, 3), (2, 4), (3, 4), (3, 3), (4, 4), (4, 5), (4, 6), (3, 6), (3, 5), (2, 5), (2, 6), (2, 7), (3, 7), (4, 7), (5, 7), (6, 7), (6, 6), (5, 6), (5, 5), (6, 5), (6, 4), (7, 4), (7, 5), (8, 6), (8, 5), (9, 5), (9, 4), (9, 3), (8, 3), (8, 4), (7, 3), (7, 6), (7, 7), (4, 8), (3, 8), (5, 8)], reward: 33.49999999999996, done: True"
2018-04-20 07:53:28,232 (dqn_main.py:215) DEBUG: "Steps: 40, coords: 40"
2018-04-20 07:53:28,410 (tsp_computer.py:36) DEBUG: "tour"
2018-04-20 07:53:28,410 (dqn_main.py:217) DEBUG: "tsp_cost 42"
2018-04-20 08:10:36,592 (dqn_main.py:212) DEBUG: "Episode 340000, mean reward over last 10000 episodes: 19.434649999999984"
2018-04-20 08:10:36,592 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 08:10:36,592 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (2, 4)], reward: 3.0999999999999996, done: True"
2018-04-20 08:10:36,592 (dqn_main.py:215) DEBUG: "Steps: 5, coords: 40"
2018-04-20 08:27:31,752 (dqn_main.py:212) DEBUG: "Episode 350000, mean reward over last 10000 episodes: 19.531119999999984"
2018-04-20 08:27:31,752 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 08:27:31,752 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2)], reward: 1.4, done: True"
2018-04-20 08:27:31,752 (dqn_main.py:215) DEBUG: "Steps: 3, coords: 40"
2018-04-20 08:44:37,591 (dqn_main.py:212) DEBUG: "Episode 360000, mean reward over last 10000 episodes: 19.642119999999984"
2018-04-20 08:44:37,591 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 08:44:37,591 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (3, 3), (2, 3), (2, 2), (2, 4), (2, 5), (3, 5), (3, 4), (4, 4), (4, 5), (4, 6), (3, 6), (2, 7), (2, 6), (3, 7), (4, 7), (5, 7), (6, 7), (6, 6), (5, 6), (5, 5), (6, 4), (6, 5), (7, 5), (8, 5), (8, 6), (9, 5), (9, 4), (9, 3), (8, 3), (7, 3), (7, 4), (8, 4)], reward: 28.49999999999998, done: True"
2018-04-20 08:44:37,591 (dqn_main.py:215) DEBUG: "Steps: 35, coords: 40"
2018-04-20 09:01:10,341 (dqn_main.py:212) DEBUG: "Episode 370000, mean reward over last 10000 episodes: 19.431319999999985"
2018-04-20 09:01:10,341 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 09:01:10,341 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (2, 2), (3, 2), (3, 3), (2, 3), (2, 4), (2, 5), (3, 5), (3, 4), (4, 4), (4, 5), (4, 6), (3, 6), (2, 6), (2, 7), (3, 7), (4, 7), (5, 7), (6, 7), (5, 6), (5, 5), (6, 6), (6, 5), (6, 4), (7, 4), (7, 5), (7, 6), (8, 6), (8, 5), (9, 5), (9, 4), (8, 4), (9, 3), (8, 3), (7, 3), (7, 7), (5, 8), (4, 8), (3, 8)], reward: 33.89999999999996, done: True"
2018-04-20 09:01:10,341 (dqn_main.py:215) DEBUG: "Steps: 40, coords: 40"
2018-04-20 09:01:10,661 (tsp_computer.py:36) DEBUG: "tour"
2018-04-20 09:01:10,661 (dqn_main.py:217) DEBUG: "tsp_cost 42"
2018-04-20 09:18:07,778 (dqn_main.py:212) DEBUG: "Episode 380000, mean reward over last 10000 episodes: 19.58122999999998"
2018-04-20 09:18:07,779 (dqn_main.py:213) DEBUG: "Epsilon: 0.09999910000958534"
2018-04-20 09:18:07,779 (dqn_main.py:214) DEBUG: "RL steps: [(2, 1), (3, 1), (3, 2), (2, 2), (2, 4), (2, 3), (3, 3), (3, 4), (4, 4), (4, 5), (3, 5), (2, 5), (2, 6), (2, 7), (3, 7), (3, 6), (4, 6), (4, 7), (6, 7), (5, 7), (5, 6), (6, 6), (6, 5), (5, 5), (6, 4), (7, 4), (7, 5), (7, 6), (8, 6), (8, 5), (9, 5), (9, 4), (9, 3), (8, 3), (7, 3), (8, 4), (7, 7), (5, 8), (4, 8), (3, 8)], reward: 33.899999999999956, done: True"
2018-04-20 09:18:07,779 (dqn_main.py:215) DEBUG: "Steps: 40, coords: 40"
2018-04-20 09:18:08,087 (tsp_computer.py:36) DEBUG: "tour"
2018-04-20 09:18:08,087 (dqn_main.py:217) DEBUG: "tsp_cost 42"
2018-04-20 09:27:06,734 (dqn_main.py:61) DEBUG: ">>>> RUNNING data_file=7_17.npy,reuse_weights=None,test=True<<<<"
2018-04-20 09:28:51,955 (dqn_main.py:61) DEBUG: ">>>> RUNNING data_file=7_17.npy,reuse_weights=None,test=True<<<<"
2018-04-20 09:28:52,417 (tf_logging.py:160) Level 1: "Registering Batch (<function _BatchGrad at 0x7f2234134378>) in gradient."
2018-04-20 09:28:52,418 (tf_logging.py:160) Level 1: "Registering Unbatch (<function _UnbatchGrad at 0x7f2234134e18>) in gradient."
2018-04-20 09:28:52,424 (tf_logging.py:160) Level 1: "Registering ZeroInitializer (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,447 (tf_logging.py:160) Level 1: "Registering SparseFeatureCross (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,450 (tf_logging.py:160) Level 1: "Registering SparseFeatureCrossV2 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,456 (tf_logging.py:160) Level 1: "Registering SparseFeatureCross (None) in gradient."
2018-04-20 09:28:52,457 (tf_logging.py:160) Level 1: "Registering SparseFeatureCrossV2 (None) in gradient."
2018-04-20 09:28:52,464 (tf_logging.py:160) Level 1: "Registering GDNLowerBound (<function GDN._lower_bound_grad at 0x7f222c7d76a8>) in gradient."
2018-04-20 09:28:52,490 (tf_logging.py:160) Level 1: "Registering ObtainNext (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,505 (tf_logging.py:160) Level 1: "Registering hparams ((<class 'tensorflow.contrib.training.python.training.hparam_pb2.HParamDef'>, <function HParams.to_proto at 0x7f222c0fd620>, <function HParams.from_proto at 0x7f222c0fd6a8>)) in proto functions."
2018-04-20 09:28:52,515 (tf_logging.py:160) Level 1: "Registering GRUBlockCell (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,517 (tf_logging.py:160) Level 1: "Registering GRUBlockCellGrad (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,520 (tf_logging.py:160) Level 1: "Registering GRUBlockCell (<function _GRUBlockCellGrad at 0x7f222c096b70>) in gradient."
2018-04-20 09:28:52,522 (tf_logging.py:160) Level 1: "Registering BlockLSTM (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,523 (tf_logging.py:160) Level 1: "Registering BlockLSTMGrad (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,524 (tf_logging.py:160) Level 1: "Registering LSTMBlockCell (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,526 (tf_logging.py:160) Level 1: "Registering LSTMBlockCellGrad (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,529 (tf_logging.py:160) Level 1: "Registering LSTMBlockCell (<function _LSTMBlockCellGrad at 0x7f222c05fd90>) in gradient."
2018-04-20 09:28:52,530 (tf_logging.py:160) Level 1: "Registering BlockLSTM (<function _BlockLSTMGrad at 0x7f222c05fe18>) in gradient."
2018-04-20 09:28:52,535 (tf_logging.py:160) Level 1: "Registering KMC2ChainInitialization (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,537 (tf_logging.py:160) Level 1: "Registering KmeansPlusPlusInitialization (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,538 (tf_logging.py:160) Level 1: "Registering NearestNeighbors (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,542 (tf_logging.py:160) Level 1: "Registering MaskedMatmul (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,544 (tf_logging.py:160) Level 1: "Registering WALSComputePartialLhsAndRhs (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,563 (tf_logging.py:160) Level 1: "Registering ConfigureDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,565 (tf_logging.py:160) Level 1: "Registering CrossReplicaSum (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,566 (tf_logging.py:160) Level 1: "Registering InfeedDequeue (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,567 (tf_logging.py:160) Level 1: "Registering InfeedDequeueTuple (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,567 (tf_logging.py:160) Level 1: "Registering InfeedEnqueue (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,568 (tf_logging.py:160) Level 1: "Registering InfeedEnqueueTuple (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,569 (tf_logging.py:160) Level 1: "Registering OutfeedDequeue (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,569 (tf_logging.py:160) Level 1: "Registering OutfeedDequeueTuple (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,570 (tf_logging.py:160) Level 1: "Registering OutfeedEnqueue (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,571 (tf_logging.py:160) Level 1: "Registering OutfeedEnqueueTuple (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,571 (tf_logging.py:160) Level 1: "Registering ShutdownDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,572 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingActivations (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,572 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingEnqueueSparseBatch (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,573 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingLoadAdagradParameters (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,574 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingLoadGradientDescentParameters (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,575 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingReceiveActivations (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,576 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingRetrieveAdagradParameters (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,576 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingRetrieveGradientDescentParameters (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,577 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingSendGradients (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,577 (tf_logging.py:160) Level 1: "Registering TPUReplicate (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,582 (tf_logging.py:160) Level 1: "Registering TPUReplicateMetadata (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,583 (tf_logging.py:160) Level 1: "Registering TPUReplicatedInput (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,583 (tf_logging.py:160) Level 1: "Registering TPUReplicatedOutput (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,589 (tf_logging.py:160) Level 1: "Registering _ConfigureDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,590 (tf_logging.py:160) Level 1: "Registering _WaitForDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,591 (tf_logging.py:160) Level 1: "Registering _SetGlobalTPUArray (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,592 (tf_logging.py:160) Level 1: "Registering _ShutdownDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,592 (tf_logging.py:160) Level 1: "Registering _InitializeHostForDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,593 (tf_logging.py:160) Level 1: "Registering _DisconnectHostFromDistributedTPUSystem (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,595 (tf_logging.py:160) Level 1: "Registering CrossReplicaSum (<function _cross_replica_sum_grad at 0x7f2208116400>) in gradient."
2018-04-20 09:28:52,606 (tf_logging.py:160) Level 1: "Registering CloseSummaryWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,607 (tf_logging.py:160) Level 1: "Registering CreateSummaryDbWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,608 (tf_logging.py:160) Level 1: "Registering CreateSummaryFileWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,609 (tf_logging.py:160) Level 1: "Registering FlushSummaryWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,610 (tf_logging.py:160) Level 1: "Registering ImportEvent (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,610 (tf_logging.py:160) Level 1: "Registering SummaryWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,611 (tf_logging.py:160) Level 1: "Registering WriteAudioSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,612 (tf_logging.py:160) Level 1: "Registering WriteGraphSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,612 (tf_logging.py:160) Level 1: "Registering WriteHistogramSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,613 (tf_logging.py:160) Level 1: "Registering WriteImageSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,614 (tf_logging.py:160) Level 1: "Registering WriteScalarSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,614 (tf_logging.py:160) Level 1: "Registering WriteSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,637 (tf_logging.py:160) Level 1: "Registering BigQueryReader (None) in gradient."
2018-04-20 09:28:52,641 (tf_logging.py:160) Level 1: "Registering RangeDecode (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,642 (tf_logging.py:160) Level 1: "Registering RangeEncode (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,690 (tf_logging.py:160) Level 1: "Registering CudnnRNN (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,692 (tf_logging.py:160) Level 1: "Registering CudnnRNNBackprop (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,692 (tf_logging.py:160) Level 1: "Registering CudnnRNNCanonicalToParams (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,693 (tf_logging.py:160) Level 1: "Registering CudnnRNNParamsSize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,694 (tf_logging.py:160) Level 1: "Registering CudnnRNNParamsToCanonical (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,701 (tf_logging.py:160) Level 1: "Registering CudnnRNN (<function _cudnn_rnn_backward at 0x7f21e65d16a8>) in gradient."
2018-04-20 09:28:52,702 (tf_logging.py:160) Level 1: "Registering CudnnRNNParamsSize (<function call_cpp_shape_fn at 0x7f229f875840>) in shape functions."
2018-04-20 09:28:52,702 (tf_logging.py:160) Level 1: "Registering CudnnRNNParamsToCanonical (<function call_cpp_shape_fn at 0x7f229f875840>) in shape functions."
2018-04-20 09:28:52,702 (tf_logging.py:160) Level 1: "Registering CudnnRNNCanonicalToParams (<function call_cpp_shape_fn at 0x7f229f875840>) in shape functions."
2018-04-20 09:28:52,703 (tf_logging.py:160) Level 1: "Registering CudnnRNN (<function call_cpp_shape_fn at 0x7f229f875840>) in shape functions."
2018-04-20 09:28:52,703 (tf_logging.py:160) Level 1: "Registering CudnnRNNBackprop (<function call_cpp_shape_fn at 0x7f229f875840>) in shape functions."
2018-04-20 09:28:52,741 (tf_logging.py:160) Level 1: "Registering AdjustHsvInYiq (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,745 (tf_logging.py:160) Level 1: "Registering BipartiteMatch (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,745 (tf_logging.py:160) Level 1: "Registering ImageConnectedComponents (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,746 (tf_logging.py:160) Level 1: "Registering ImageProjectiveTransform (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,749 (tf_logging.py:160) Level 1: "Registering ImageConnectedComponents (<function call_cpp_shape_fn at 0x7f229f875840>) in shape functions."
2018-04-20 09:28:52,749 (tf_logging.py:160) Level 1: "Registering ImageProjectiveTransform (<function call_cpp_shape_fn at 0x7f229f875840>) in shape functions."
2018-04-20 09:28:52,749 (tf_logging.py:160) Level 1: "Registering ImageProjectiveTransform (<function _image_projective_transform_grad at 0x7f21e5ef4b70>) in gradient."
2018-04-20 09:28:52,749 (tf_logging.py:160) Level 1: "Registering BipartiteMatch (None) in gradient."
2018-04-20 09:28:52,750 (tf_logging.py:160) Level 1: "Registering ImageConnectedComponents (None) in gradient."
2018-04-20 09:28:52,750 (tf_logging.py:160) Level 1: "Registering SingleImageRandomDotStereograms (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,755 (tf_logging.py:160) Level 1: "Registering SingleImageRandomDotStereograms (None) in gradient."
2018-04-20 09:28:52,798 (tf_logging.py:160) Level 1: "Registering BytesInUse (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,798 (tf_logging.py:160) Level 1: "Registering BytesLimit (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,799 (tf_logging.py:160) Level 1: "Registering MaxBytesInUse (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,805 (tf_logging.py:160) Level 1: "Registering NcclAllReduce (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,805 (tf_logging.py:160) Level 1: "Registering NcclBroadcast (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,806 (tf_logging.py:160) Level 1: "Registering NcclReduce (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,808 (tf_logging.py:160) Level 1: "Registering _NcclReduceSend (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,809 (tf_logging.py:160) Level 1: "Registering _NcclReduceRecv (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,809 (tf_logging.py:160) Level 1: "Registering _NcclBroadcastSend (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,809 (tf_logging.py:160) Level 1: "Registering _NcclBroadcastRecv (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,809 (tf_logging.py:160) Level 1: "Registering NcclAllReduce (<function _all_sum_grad at 0x7f21e55a8950>) in gradient."
2018-04-20 09:28:52,810 (tf_logging.py:160) Level 1: "Registering NcclReduce (<function _reduce_sum_grad at 0x7f21e55a8bf8>) in gradient."
2018-04-20 09:28:52,810 (tf_logging.py:160) Level 1: "Registering NcclBroadcast (<function _broadcast_grad at 0x7f21e55a8d90>) in gradient."
2018-04-20 09:28:52,811 (tf_logging.py:160) Level 1: "Registering PeriodicResample (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,818 (tf_logging.py:160) Level 1: "Registering FoldFusedBatchNormGrad (<function _FoldFusedBatchNormGrad at 0x7f21e52ed048>) in gradient."
2018-04-20 09:28:52,821 (tf_logging.py:160) Level 1: "Registering Resampler (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,823 (tf_logging.py:160) Level 1: "Registering ResamplerGrad (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,825 (tf_logging.py:160) Level 1: "Registering Resampler (<function _resampler_grad at 0x7f21e501ac80>) in gradient."
2018-04-20 09:28:52,825 (tf_logging.py:160) Level 1: "Registering ResamplerGrad (None) in gradient."
2018-04-20 09:28:52,831 (tf_logging.py:160) Level 1: "Registering GatherTree (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,846 (tf_logging.py:160) Level 1: "Registering StatelessRandomNormal (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,847 (tf_logging.py:160) Level 1: "Registering StatelessRandomUniform (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,847 (tf_logging.py:160) Level 1: "Registering StatelessTruncatedNormal (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,848 (tf_logging.py:160) Level 1: "Registering StatelessRandomNormal (None) in gradient."
2018-04-20 09:28:52,848 (tf_logging.py:160) Level 1: "Registering StatelessRandomUniform (None) in gradient."
2018-04-20 09:28:52,849 (tf_logging.py:160) Level 1: "Registering StatelessTruncatedNormal (None) in gradient."
2018-04-20 09:28:52,859 (tf_logging.py:160) Level 1: "Registering ReinterpretStringToFloat (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,861 (tf_logging.py:160) Level 1: "Registering ScatterAddNdim (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,869 (tf_logging.py:160) Level 1: "Registering CreateTreeVariable (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,882 (tf_logging.py:160) Level 1: "Registering DecisionTreeResourceHandleOp (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,897 (tf_logging.py:160) Level 1: "Registering FeatureUsageCounts (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,898 (tf_logging.py:160) Level 1: "Registering TraverseTreeV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,898 (tf_logging.py:160) Level 1: "Registering TreeDeserialize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,899 (tf_logging.py:160) Level 1: "Registering TreeIsInitializedOp (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,899 (tf_logging.py:160) Level 1: "Registering TreePredictionsV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,900 (tf_logging.py:160) Level 1: "Registering TreeSerialize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,901 (tf_logging.py:160) Level 1: "Registering TreeSize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,901 (tf_logging.py:160) Level 1: "Registering UpdateModelV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,907 (tf_logging.py:160) Level 1: "Registering TreeVariable (None) in gradient."
2018-04-20 09:28:52,908 (tf_logging.py:160) Level 1: "Registering TreeSerialize (None) in gradient."
2018-04-20 09:28:52,908 (tf_logging.py:160) Level 1: "Registering TreeDeserialize (None) in gradient."
2018-04-20 09:28:52,908 (tf_logging.py:160) Level 1: "Registering TreeSize (None) in gradient."
2018-04-20 09:28:52,909 (tf_logging.py:160) Level 1: "Registering TreePredictionsV4 (None) in gradient."
2018-04-20 09:28:52,909 (tf_logging.py:160) Level 1: "Registering FeatureUsageCounts (None) in gradient."
2018-04-20 09:28:52,910 (tf_logging.py:160) Level 1: "Registering CreateFertileStatsVariable (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,912 (tf_logging.py:160) Level 1: "Registering FertileStatsDeserialize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,914 (tf_logging.py:160) Level 1: "Registering FertileStatsIsInitializedOp (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,915 (tf_logging.py:160) Level 1: "Registering FertileStatsResourceHandleOp (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,916 (tf_logging.py:160) Level 1: "Registering FertileStatsSerialize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,917 (tf_logging.py:160) Level 1: "Registering FinalizeTree (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,918 (tf_logging.py:160) Level 1: "Registering GrowTreeV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,919 (tf_logging.py:160) Level 1: "Registering ProcessInputV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,924 (tf_logging.py:160) Level 1: "Registering FertileStatsVariable (None) in gradient."
2018-04-20 09:28:52,927 (tf_logging.py:160) Level 1: "Registering FertileStatsSerialize (None) in gradient."
2018-04-20 09:28:52,928 (tf_logging.py:160) Level 1: "Registering FertileStatsDeserialize (None) in gradient."
2018-04-20 09:28:52,929 (tf_logging.py:160) Level 1: "Registering GrowTreeV4 (None) in gradient."
2018-04-20 09:28:52,930 (tf_logging.py:160) Level 1: "Registering ProcessInputV4 (None) in gradient."
2018-04-20 09:28:52,931 (tf_logging.py:160) Level 1: "Registering FinalizeTree (None) in gradient."
2018-04-20 09:28:52,966 (tf_logging.py:160) Level 1: "Registering FunctionBufferingResource (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,967 (tf_logging.py:160) Level 1: "Registering FunctionBufferingResourceGetNext (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,978 (tf_logging.py:160) Level 1: "Registering RemoteFusedGraphExecute (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f229f875950>) in default shape functions."
2018-04-20 09:28:52,979 (tf_logging.py:160) Level 1: "Registering RemoteFusedGraphExecute (None) in gradient."
2018-04-20 09:28:52,990 (tf_logging.py:160) Level 1: "Created variable q/Conv/weights:0 with shape (1, 1, 2, 8) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f222c7ce510>"
2018-04-20 09:28:52,993 (tf_logging.py:160) Level 1: "Created variable q/Conv/biases:0 with shape (8,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f222c7d31d0>"
2018-04-20 09:28:53,001 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/weights:0 with shape (3, 3, 8, 12) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f222c7ce510>"
2018-04-20 09:28:53,005 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/biases:0 with shape (12,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f222c7d31d0>"
2018-04-20 09:28:53,012 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/weights:0 with shape (3, 3, 12, 16) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f222c7ce510>"
2018-04-20 09:28:53,016 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/biases:0 with shape (16,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f222c7d31d0>"
2018-04-20 09:28:53,027 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/weights:0 with shape (576, 128) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f222c7d72f0>"
2018-04-20 09:28:53,030 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/biases:0 with shape (128,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f222c7d35c0>"
2018-04-20 09:28:53,037 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/weights:0 with shape (128, 5) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f222c7d72f0>"
2018-04-20 09:28:53,040 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/biases:0 with shape (5,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f222c7d35c0>"
2018-04-20 09:28:53,047 (tf_logging.py:160) Level 1: "Created variable target_q/Conv/weights:0 with shape (1, 1, 2, 8) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f222c7ce510>"
2018-04-20 09:28:53,051 (tf_logging.py:160) Level 1: "Created variable target_q/Conv/biases:0 with shape (8,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f222c7d31d0>"
2018-04-20 09:28:53,058 (tf_logging.py:160) Level 1: "Created variable target_q/Conv_1/weights:0 with shape (3, 3, 8, 12) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f222c7ce510>"
2018-04-20 09:28:53,062 (tf_logging.py:160) Level 1: "Created variable target_q/Conv_1/biases:0 with shape (12,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f222c7d31d0>"
2018-04-20 09:28:53,069 (tf_logging.py:160) Level 1: "Created variable target_q/Conv_2/weights:0 with shape (3, 3, 12, 16) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f222c7ce510>"
2018-04-20 09:28:53,073 (tf_logging.py:160) Level 1: "Created variable target_q/Conv_2/biases:0 with shape (16,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f222c7d31d0>"
2018-04-20 09:28:53,085 (tf_logging.py:160) Level 1: "Created variable target_q/fully_connected/weights:0 with shape (576, 128) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f222c7d72f0>"
2018-04-20 09:28:53,089 (tf_logging.py:160) Level 1: "Created variable target_q/fully_connected/biases:0 with shape (128,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f222c7d35c0>"
2018-04-20 09:28:53,096 (tf_logging.py:160) Level 1: "Created variable target_q/fully_connected_1/weights:0 with shape (128, 5) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f222c7d72f0>"
2018-04-20 09:28:53,099 (tf_logging.py:160) Level 1: "Created variable target_q/fully_connected_1/biases:0 with shape (5,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f222c7d35c0>"
2018-04-20 09:28:53,130 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/value'"
2018-04-20 09:28:53,130 (tf_logging.py:160) Level 1: "  in  --> gradients/Fill:0"
2018-04-20 09:28:53,130 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/value_grad/tuple/control_dependency:0, gradients/mean_squared_error/value_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,137 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/div'"
2018-04-20 09:28:53,137 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/value_grad/tuple/control_dependency:0"
2018-04-20 09:28:53,137 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/div_grad/tuple/control_dependency:0, gradients/mean_squared_error/div_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,140 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/Sum_1'"
2018-04-20 09:28:53,140 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/div_grad/tuple/control_dependency:0"
2018-04-20 09:28:53,140 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/Sum_1_grad/Tile:0"
2018-04-20 09:28:53,144 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/Select'"
2018-04-20 09:28:53,144 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/div_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,144 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/Select_grad/tuple/control_dependency:0, gradients/mean_squared_error/Select_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,146 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/Sum'"
2018-04-20 09:28:53,147 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/Sum_1_grad/Tile:0"
2018-04-20 09:28:53,147 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/Sum_grad/Tile:0"
2018-04-20 09:28:53,153 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/Mul'"
2018-04-20 09:28:53,153 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/Sum_grad/Tile:0"
2018-04-20 09:28:53,154 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/Mul_grad/tuple/control_dependency:0, gradients/mean_squared_error/Mul_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,156 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/num_present'"
2018-04-20 09:28:53,156 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/Select_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,157 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/num_present_grad/Tile:0"
2018-04-20 09:28:53,163 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/num_present/broadcast_weights'"
2018-04-20 09:28:53,163 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/num_present_grad/Tile:0"
2018-04-20 09:28:53,163 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/num_present/broadcast_weights_grad/tuple/control_dependency:0, gradients/mean_squared_error/num_present/broadcast_weights_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,164 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/num_present/broadcast_weights/ones_like'"
2018-04-20 09:28:53,165 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/num_present/broadcast_weights_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,165 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/num_present/broadcast_weights/ones_like_grad/Sum:0"
2018-04-20 09:28:53,172 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/SquaredDifference'"
2018-04-20 09:28:53,172 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/Mul_grad/tuple/control_dependency:0"
2018-04-20 09:28:53,172 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/SquaredDifference_grad/tuple/control_dependency:0, gradients/mean_squared_error/SquaredDifference_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,180 (tf_logging.py:160) Level 1: "Gradient for 'Sum'"
2018-04-20 09:28:53,180 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/SquaredDifference_grad/tuple/control_dependency:0"
2018-04-20 09:28:53,181 (tf_logging.py:160) Level 1: "  out --> gradients/Sum_grad/Tile:0"
2018-04-20 09:28:53,186 (tf_logging.py:160) Level 1: "Gradient for 'mul'"
2018-04-20 09:28:53,187 (tf_logging.py:160) Level 1: "  in  --> gradients/Sum_grad/Tile:0"
2018-04-20 09:28:53,187 (tf_logging.py:160) Level 1: "  out --> gradients/mul_grad/tuple/control_dependency:0, gradients/mul_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,189 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected_1/BiasAdd'"
2018-04-20 09:28:53,189 (tf_logging.py:160) Level 1: "  in  --> gradients/mul_grad/tuple/control_dependency:0"
2018-04-20 09:28:53,189 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency:0, gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,192 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected_1/MatMul'"
2018-04-20 09:28:53,192 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 09:28:53,192 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency:0, gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,193 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected_1/biases/read'"
2018-04-20 09:28:53,193 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,193 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,193 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/Relu'"
2018-04-20 09:28:53,194 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency:0"
2018-04-20 09:28:53,194 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/Relu_grad/ReluGrad:0"
2018-04-20 09:28:53,194 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected_1/weights/read'"
2018-04-20 09:28:53,194 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,194 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,196 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/BiasAdd'"
2018-04-20 09:28:53,196 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/Relu_grad/ReluGrad:0"
2018-04-20 09:28:53,196 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency:0, gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,198 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/MatMul'"
2018-04-20 09:28:53,199 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 09:28:53,199 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/MatMul_grad/tuple/control_dependency:0, gradients/q/fully_connected/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,199 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/biases/read'"
2018-04-20 09:28:53,199 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,199 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,200 (tf_logging.py:160) Level 1: "Gradient for 'q/Flatten/flatten/Reshape'"
2018-04-20 09:28:53,200 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/MatMul_grad/tuple/control_dependency:0"
2018-04-20 09:28:53,200 (tf_logging.py:160) Level 1: "  out --> gradients/q/Flatten/flatten/Reshape_grad/Reshape:0"
2018-04-20 09:28:53,201 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/weights/read'"
2018-04-20 09:28:53,201 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,201 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,202 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/Relu'"
2018-04-20 09:28:53,202 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Flatten/flatten/Reshape_grad/Reshape:0"
2018-04-20 09:28:53,202 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/Relu_grad/ReluGrad:0"
2018-04-20 09:28:53,203 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/BiasAdd'"
2018-04-20 09:28:53,204 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/Relu_grad/ReluGrad:0"
2018-04-20 09:28:53,204 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency:0, gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,208 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/Conv2D'"
2018-04-20 09:28:53,208 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 09:28:53,208 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency:0, gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,208 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/biases/read'"
2018-04-20 09:28:53,208 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,208 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,209 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/Relu'"
2018-04-20 09:28:53,209 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency:0"
2018-04-20 09:28:53,209 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/Relu_grad/ReluGrad:0"
2018-04-20 09:28:53,209 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/weights/read'"
2018-04-20 09:28:53,209 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,210 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,211 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/BiasAdd'"
2018-04-20 09:28:53,212 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/Relu_grad/ReluGrad:0"
2018-04-20 09:28:53,212 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency:0, gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,216 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/Conv2D'"
2018-04-20 09:28:53,217 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 09:28:53,217 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency:0, gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,217 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/biases/read'"
2018-04-20 09:28:53,217 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,217 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,218 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/Relu'"
2018-04-20 09:28:53,218 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency:0"
2018-04-20 09:28:53,218 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/Relu_grad/ReluGrad:0"
2018-04-20 09:28:53,218 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/weights/read'"
2018-04-20 09:28:53,218 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,218 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,220 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/BiasAdd'"
2018-04-20 09:28:53,220 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv/Relu_grad/ReluGrad:0"
2018-04-20 09:28:53,220 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/BiasAdd_grad/tuple/control_dependency:0, gradients/q/Conv/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,224 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/Conv2D'"
2018-04-20 09:28:53,225 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 09:28:53,225 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/Conv2D_grad/tuple/control_dependency:0, gradients/q/Conv/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,225 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/biases/read'"
2018-04-20 09:28:53,225 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,225 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,225 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/weights/read'"
2018-04-20 09:28:53,225 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,226 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:28:53,300 (tf_logging.py:126) WARNING: "From /home/syedeqbal/.local/lib/python3.5/site-packages/tensorflow/python/ops/clip_ops.py:113: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead"
2018-04-20 09:28:53,332 (tf_logging.py:160) Level 1: "Created variable q/Conv/weights/Adam:0 with shape (1, 1, 2, 8) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f21c20f3320>"
2018-04-20 09:28:53,334 (tf_logging.py:160) Level 1: "Created variable q/Conv/weights/Adam_1:0 with shape (1, 1, 2, 8) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f21c20f3320>"
2018-04-20 09:28:53,337 (tf_logging.py:160) Level 1: "Created variable q/Conv/biases/Adam:0 with shape (8,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f21c20f3320>"
2018-04-20 09:28:53,340 (tf_logging.py:160) Level 1: "Created variable q/Conv/biases/Adam_1:0 with shape (8,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f21c20f3320>"
2018-04-20 09:28:53,343 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/weights/Adam:0 with shape (3, 3, 8, 12) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f21c20f3320>"
2018-04-20 09:28:53,346 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/weights/Adam_1:0 with shape (3, 3, 8, 12) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f21c20f3320>"
2018-04-20 09:28:53,348 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/biases/Adam:0 with shape (12,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f21c20f3320>"
2018-04-20 09:28:53,351 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/biases/Adam_1:0 with shape (12,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f21c20f3320>"
2018-04-20 09:28:53,354 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/weights/Adam:0 with shape (3, 3, 12, 16) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f21c20f3320>"
2018-04-20 09:28:53,356 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/weights/Adam_1:0 with shape (3, 3, 12, 16) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f21c20b0f28>"
2018-04-20 09:28:53,359 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/biases/Adam:0 with shape (16,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f21c20b0f28>"
2018-04-20 09:28:53,362 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/biases/Adam_1:0 with shape (16,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f21c20b0f28>"
2018-04-20 09:28:53,364 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/weights/Adam:0 with shape (576, 128) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f21c20b0f28>"
2018-04-20 09:28:53,367 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/weights/Adam_1:0 with shape (576, 128) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f21c20b0f28>"
2018-04-20 09:28:53,369 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/biases/Adam:0 with shape (128,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f21c20b0f28>"
2018-04-20 09:28:53,372 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/biases/Adam_1:0 with shape (128,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f21c20b0f28>"
2018-04-20 09:28:53,375 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/weights/Adam:0 with shape (128, 5) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f21c20b0f28>"
2018-04-20 09:28:53,377 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/weights/Adam_1:0 with shape (128, 5) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f21c20b0f28>"
2018-04-20 09:28:53,379 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/biases/Adam:0 with shape (5,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f21c20b0f28>"
2018-04-20 09:28:53,382 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/biases/Adam_1:0 with shape (5,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f21c20b0f28>"
2018-04-20 09:28:53,533 (dqn_agent.py:161) DEBUG: "var_name: q/Conv/weights:0, var_value [[[[ 0.07914811  0.4790275   0.7519878   0.30090177 -0.7116133
    -0.38285536 -0.17304963 -0.67449665]
   [-0.32940283  0.5482898  -0.11913466 -0.7408853  -0.11541724
    -0.28320834  0.5569451  -0.07108968]]]]: "
2018-04-20 09:28:53,537 (dqn_agent.py:161) DEBUG: "var_name: q/Conv/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 09:28:53,545 (dqn_agent.py:161) DEBUG: "var_name: q/Conv_1/weights:0, var_value [[[[ 4.59266603e-02 -1.72088891e-01 -1.48474574e-02  1.39961183e-01
    -1.24499992e-01 -9.86169055e-02  5.83966076e-02 -3.10574323e-02
    -4.71849591e-02 -9.68626142e-03  1.11561358e-01  5.80064952e-02]
   [-1.74712315e-01  1.12578809e-01  1.70844316e-01 -7.22567439e-02
     5.09893447e-02 -6.62921742e-02 -1.35316670e-01  1.18894547e-01
    -7.61907697e-02 -1.11978814e-01 -9.48175192e-02 -8.32724571e-03]
   [ 6.27263188e-02  8.97668898e-02 -1.30530566e-01  1.23129964e-01
    -1.24589927e-01 -4.29591984e-02  1.31127506e-01  4.46048081e-02
     5.72550297e-03  6.66925460e-02  8.24193358e-02  1.53374523e-01]
   [ 1.19814336e-01  4.28056270e-02  1.66132718e-01  1.52832717e-02
    -2.76231617e-02 -3.99370193e-02 -6.52910024e-02  1.55058354e-01
     1.56291813e-01 -2.81294882e-02 -1.82388917e-01 -1.13509603e-01]
   [ 5.75251132e-02 -1.09999195e-01 -1.36744991e-01  4.72179502e-02
     3.64765525e-03 -1.31609604e-01  2.25259364e-03  2.50491053e-02
    -6.33881316e-02  1.50839180e-01  1.14190042e-01  1.42353624e-01]
   [ 8.74959826e-02  2.17679292e-02 -4.60047871e-02  4.37177718e-02
    -1.20182216e-01  1.66270137e-02 -1.66230053e-01 -6.18038923e-02
     7.97687173e-02 -1.23784333e-01  1.09827369e-02  1.38401866e-01]
   [-1.49266422e-02  4.34265733e-02  1.29332721e-01  8.45234096e-03
     6.72231764e-02 -3.86303514e-02  1.83291733e-03 -9.60594043e-02
    -1.55982077e-02  2.40914226e-02 -1.01943530e-01  8.47566724e-02]
   [-1.06488183e-01  1.33211851e-01  2.57079750e-02 -2.43195593e-02
    -1.14360161e-01  1.72666192e-01  2.91829854e-02 -5.00739366e-02
     1.61852151e-01 -1.46439001e-01  1.79510683e-01 -1.39846697e-01]]

  [[ 1.72673851e-01  2.51529217e-02  1.15051717e-02 -1.43374726e-01
    -1.36862695e-01 -3.57176065e-02 -9.79878679e-02  2.95825303e-02
    -7.06764236e-02  1.50512487e-01 -4.54729944e-02 -1.61682144e-01]
   [-1.48730189e-01  1.60694629e-01  1.68279529e-01  2.79130638e-02
    -1.72764510e-01  1.77673280e-01 -1.46749169e-02  1.78631872e-01
    -1.70602039e-01 -2.39093006e-02  1.52031660e-01  7.89385140e-02]
   [-1.02264136e-02  9.62170064e-02 -5.22153974e-02  9.72304344e-02
     1.53782755e-01 -9.59211513e-02 -1.42036110e-01  7.42993057e-02
     4.21266556e-02  8.14753771e-02 -6.23330325e-02  5.48714101e-02]
   [-4.26714271e-02  1.68763787e-01 -1.37789384e-01 -1.26971886e-01
    -7.12006018e-02 -1.24533772e-01 -1.26656294e-01  4.72326577e-02
    -1.53898358e-01 -1.29698232e-01 -1.65449083e-03  9.38509405e-03]
   [-5.22648394e-02  7.24693537e-02 -5.65063953e-03  1.69194818e-01
    -9.89471227e-02 -4.44261283e-02  1.20224714e-01 -1.61533177e-01
    -9.98510867e-02  6.56803250e-02 -1.49763092e-01 -3.69788259e-02]
   [ 1.23640776e-01  1.14785969e-01  8.30202699e-02 -1.17309093e-02
     1.75392538e-01 -4.08211350e-02 -1.15941830e-01  8.18128884e-02
     1.15362734e-01 -2.01758593e-02 -1.12635054e-01 -1.00648321e-01]
   [-1.64424479e-01 -6.04204908e-02 -1.01013444e-01 -1.57799035e-01
     7.98922181e-02  9.28924382e-02  1.45952523e-01 -1.47205502e-01
    -4.47390527e-02  8.18745792e-02  1.21312439e-01 -8.92264247e-02]
   [ 1.31564677e-01 -9.42128971e-02  1.74615413e-01 -8.29721242e-02
     1.68625563e-01 -6.82979822e-03  1.00587428e-01  9.79534686e-02
    -9.08489749e-02 -4.79797572e-02  6.88457489e-02 -1.24556452e-01]]

  [[ 2.09542811e-02 -1.76576704e-01 -1.75516590e-01  1.53792888e-01
     5.94764352e-02 -1.17908955e-01  4.38780934e-02 -1.16823249e-01
     1.59227967e-01 -4.43907380e-02 -1.03770643e-02 -1.01199009e-01]
   [ 1.58088326e-01  9.51612294e-02 -3.39910388e-03  1.78934425e-01
    -1.56330496e-01  9.69698131e-02  1.24928504e-01  5.12717664e-02
    -1.31829023e-01  7.67928660e-02  5.32713532e-03 -2.81759799e-02]
   [ 1.32242084e-01 -2.21901685e-02  1.53149754e-01  6.62189126e-02
    -1.33845508e-01  1.46808833e-01  1.34788275e-01 -3.07158530e-02
     1.57297105e-02 -1.61284938e-01  1.41481370e-01  8.88178945e-02]
   [ 1.37166053e-01  7.25163519e-03  1.82257146e-02  1.01106375e-01
    -1.46806121e-01  7.49268532e-02 -1.12262405e-01 -8.03965479e-02
     8.99758637e-02  1.68902785e-01  8.05737078e-02 -1.53716922e-01]
   [-3.87430191e-06  1.55886561e-01 -1.53968483e-01  4.74248379e-02
     1.48850322e-01  9.80639458e-02  2.69348770e-02  1.29187196e-01
    -1.04294844e-01  5.72997183e-02 -1.03384912e-01  1.04157507e-01]
   [-3.08575928e-02 -1.78174868e-01 -1.52732000e-01  9.38374996e-02
     1.23474330e-01  5.52441478e-02 -1.77889764e-01  1.00657642e-01
    -1.37531906e-01  9.26029384e-02  9.69907939e-02 -2.03150511e-03]
   [ 1.03919923e-01  4.18893993e-03  6.23003840e-02  1.20164841e-01
    -5.60711473e-02 -3.42509151e-03  2.82454491e-02  9.55198705e-02
    -1.80768549e-01 -5.15434295e-02 -8.48628059e-02 -1.43701017e-01]
   [ 1.09497100e-01 -1.76315621e-01 -8.78376290e-02 -1.06290691e-01
    -1.77713335e-01 -3.94454896e-02 -8.83867517e-02  8.48598778e-03
    -9.84680429e-02 -1.74542964e-02 -7.20858574e-03  1.28679574e-01]]]


 [[[ 1.28606260e-02 -1.11839347e-01  1.78446263e-01  1.60450101e-01
    -1.22931167e-01  4.03821021e-02 -8.86781290e-02  4.64679003e-02
     1.59533948e-01 -1.85661018e-02  4.76158410e-02  1.59816533e-01]
   [ 1.14592135e-01 -3.25613171e-02  1.02412939e-01  1.78614378e-01
     1.61424309e-01 -2.00513154e-02  3.79820317e-02  3.60320657e-02
    -3.44310254e-02  6.52043819e-02 -2.49615759e-02 -6.52617514e-02]
   [ 7.00071156e-02 -8.65188316e-02  6.12260848e-02  1.46166623e-01
     5.68872392e-02 -3.95068973e-02  1.19807422e-01 -5.52808344e-02
     1.14707381e-01  4.55020815e-02  1.22642010e-01 -1.17365927e-01]
   [-1.81644708e-01  1.43975854e-01 -1.42608792e-01 -6.97683170e-02
     1.74225003e-01 -1.23612136e-01  4.15722728e-02 -4.14943993e-02
     1.71231061e-01  1.79012775e-01  1.68393940e-01 -1.55556113e-01]
   [-1.29081085e-01 -5.31472266e-03 -9.76994485e-02 -1.48799866e-02
    -4.37819362e-02  1.06984407e-01 -8.46678019e-02  6.73810095e-02
    -8.88119861e-02 -1.43700629e-01 -1.66791588e-01  5.36713898e-02]
   [-1.75354496e-01  1.38470829e-01  5.61376214e-02 -4.80189323e-02
     6.90983534e-02 -1.49500221e-02  1.03393614e-01  2.00432688e-02
    -1.60512343e-01  8.45625103e-02 -9.86327529e-02 -8.51325989e-02]
   [ 3.47246677e-02 -1.27928957e-01  3.90052348e-02  9.58932042e-02
    -9.02312472e-02 -1.05098784e-02  1.45444274e-01  2.19392180e-02
    -9.71539840e-02 -1.72861278e-01  8.16225111e-02 -4.66572493e-02]
   [-1.37085468e-01 -7.39390105e-02 -7.37784803e-02 -9.79664996e-02
     1.69566035e-01 -1.68275714e-01 -1.73885524e-01  9.83146727e-02
    -5.77553809e-02  1.36770874e-01 -1.71338812e-01  1.14945710e-01]]

  [[-1.02200180e-01 -8.54808763e-02  2.09976882e-02  1.76483124e-01
    -2.46948749e-02  6.84345961e-02  1.45440042e-01 -1.15988143e-01
     4.61251885e-02  1.36736155e-01 -4.15718406e-02 -3.48895639e-02]
   [-7.83773214e-02 -4.37892973e-02 -1.72850400e-01  1.09205306e-01
    -7.62047470e-02  9.95500386e-02 -1.67300001e-01 -1.40161797e-01
     4.44115847e-02 -7.95173049e-02  9.77259576e-02  6.59237802e-02]
   [ 1.22180581e-01  4.58921790e-02 -8.81682336e-02  8.87607038e-02
     1.87306106e-03 -1.22860476e-01  8.13596249e-02  5.36538512e-02
    -1.21953189e-02  1.81094140e-01 -2.48734653e-02  2.73757875e-02]
   [-6.70417473e-02 -9.75400209e-03  6.90546036e-02 -6.57290220e-05
     3.89454663e-02 -3.19474638e-02 -4.86744791e-02  4.34660912e-02
    -1.78270772e-01  1.57679737e-01  1.47491872e-01  3.11343968e-02]
   [ 1.68085605e-01  3.50283235e-02  1.56668156e-01 -6.75793290e-02
    -6.54479265e-02 -1.66074708e-01  1.48709089e-01  1.63217157e-01
    -1.07698597e-01 -4.47358340e-02 -7.77370557e-02  5.51681370e-02]
   [ 1.08388275e-01  1.31204963e-01  7.76115060e-02  1.02005243e-01
    -3.76685858e-02  6.04691952e-02 -1.05460025e-01 -6.43647462e-02
    -1.98711604e-02 -1.54201686e-03 -7.20002279e-02  4.67528850e-02]
   [ 7.62280822e-02  6.35936260e-02 -6.29071742e-02  4.29544002e-02
     1.17542863e-01  9.46930349e-02 -5.15767783e-02  4.67247218e-02
     1.53215140e-01  1.70972854e-01  4.20156568e-02 -1.27667263e-01]
   [-1.00742653e-01  5.63824326e-02  7.62930512e-03  8.20686817e-02
    -6.75128624e-02  2.11458206e-02  5.47942668e-02 -1.78667665e-01
    -5.19984365e-02  1.43111467e-01  5.68439662e-02 -5.82566634e-02]]

  [[ 6.52910024e-02  3.88919264e-02  1.56293601e-01 -5.79654500e-02
    -5.25534004e-02 -1.51155949e-01  7.13013709e-02 -3.91205400e-02
     1.64552271e-01  4.98473644e-03  1.15655333e-01  1.76461577e-01]
   [-7.70413727e-02 -9.89104286e-02 -1.39436483e-01 -1.05452687e-02
     9.18515325e-02 -1.58981636e-01 -7.53689855e-02  1.25269741e-02
    -1.69140071e-01 -1.64931148e-01  9.61601734e-02 -7.61459395e-02]
   [ 3.81103605e-02  1.55175328e-01 -1.01402074e-01 -1.71500608e-01
     1.55800700e-01  1.45497173e-01 -2.21505910e-02  1.14997149e-01
     9.81632471e-02 -1.25671476e-02  2.27606595e-02  1.38822883e-01]
   [ 8.14593136e-02  1.23865992e-01 -8.12770575e-02 -9.59374309e-02
    -1.03909969e-02  1.38591886e-01 -9.04690474e-02 -1.76978916e-01
     6.39621466e-02  1.16951436e-01  1.33817613e-01 -4.85350490e-02]
   [-6.42985851e-02 -1.14503540e-01 -1.49273306e-01  6.70658201e-02
    -1.15240313e-01  1.05984628e-01 -1.68339431e-01  6.25888109e-02
     8.41828883e-02  1.18337244e-01 -6.16042241e-02 -5.10894656e-02]
   [-1.03813283e-01 -1.73969269e-01  1.42139852e-01 -7.57478178e-02
    -2.05801129e-02  4.91224378e-02 -6.06351346e-02 -5.70891649e-02
     3.74096781e-02 -7.16233999e-02 -8.07693377e-02  1.01306140e-02]
   [-1.70468539e-02  9.37549174e-02  2.21922547e-02  3.11460942e-02
     6.40661418e-02 -4.77975756e-02  4.64781225e-02 -5.60601354e-02
     1.77811980e-01 -1.71505868e-01 -1.51334792e-01 -7.61548206e-02]
   [ 1.52543306e-01 -1.58861890e-01 -7.21160620e-02  4.08331454e-02
    -3.71688753e-02 -1.30136758e-01  6.75946176e-02  1.19643956e-02
    -1.81868404e-01  1.05541915e-01  2.93406844e-02 -4.08212692e-02]]]


 [[[-1.26051843e-01 -1.70084387e-01 -9.52820629e-02  1.30769521e-01
    -1.04875259e-01 -3.49074900e-02  7.44546950e-02  1.76120907e-01
    -1.45677984e-01 -1.57409281e-01  7.59648979e-02  7.47658610e-02]
   [ 1.65956259e-01  4.41375226e-02  3.59243304e-02 -7.29618296e-02
    -1.42369032e-01  9.90335643e-02 -3.81329954e-02 -6.60448819e-02
    -5.02698570e-02  7.66457915e-02  3.91039103e-02  2.00575441e-02]
   [ 7.39718378e-02 -1.78248867e-01 -4.46717143e-02  1.50459915e-01
    -1.24331236e-01  1.54924780e-01  1.13002002e-01  1.11056924e-01
     3.68026644e-02  1.04091257e-01 -7.09437802e-02 -5.79119995e-02]
   [-1.10180579e-01  1.56654567e-01  3.64961773e-02 -4.38162386e-02
    -5.18400818e-02 -4.87378091e-02  1.57480896e-01  3.45415026e-02
    -6.92495853e-02  1.66018069e-01  5.02528399e-02 -1.57147631e-01]
   [-1.11175224e-01 -6.81748912e-02 -4.95221615e-02 -7.11339116e-02
    -1.62811160e-01  8.68570805e-02 -9.64322686e-02 -1.23721570e-01
     1.13224864e-01 -1.78154767e-01  2.28995532e-02  1.60965860e-01]
   [ 1.73273623e-01 -1.42604917e-01  9.60727334e-02  7.41100311e-02
    -1.10245645e-02  9.16182995e-02 -3.04630399e-02  4.74387705e-02
    -6.29801750e-02 -8.76510218e-02 -1.31499857e-01 -2.49503404e-02]
   [-9.36283022e-02  1.39113128e-01 -5.57173043e-02 -4.20599282e-02
    -1.49229646e-01  6.66291267e-02 -1.13109134e-01  1.00668132e-01
    -1.28383011e-01  1.62950575e-01 -1.02640823e-01 -1.04010336e-01]
   [ 5.51230013e-02  1.36328906e-01  8.22690129e-02 -8.52608830e-02
    -7.75496662e-02 -2.23609358e-02 -6.74213171e-02  1.71216428e-02
     1.47710085e-01  1.52977854e-01  4.76944447e-03  1.19491100e-01]]

  [[ 1.97386146e-02  1.41787380e-01  1.48842096e-01 -1.79836601e-01
     6.08225316e-02 -1.59452587e-01 -8.96047801e-02 -7.63107836e-02
    -1.11123033e-01  9.58444476e-02  1.51126266e-01 -1.11307204e-01]
   [-1.88637972e-02  1.46871716e-01  6.01410717e-02  2.86610723e-02
     1.23184323e-01 -1.35057673e-01 -1.49379343e-01 -5.34864366e-02
    -3.29534262e-02  3.02254111e-02 -1.36238098e-01 -8.39818642e-02]
   [-1.94984972e-02 -1.01037651e-01 -1.80198714e-01  6.18741959e-02
    -3.82479131e-02  1.00545645e-01  3.71569395e-02  1.80864781e-01
     8.67847800e-02  1.69556111e-01 -1.50802314e-01 -1.26330003e-01]
   [ 1.50527000e-01  5.19312769e-02  1.17203027e-01  7.27529228e-02
    -4.61325943e-02  1.22542679e-03 -1.64538175e-02 -1.26455456e-01
    -1.22738481e-02 -3.42369080e-03 -1.32781357e-01 -9.28237513e-02]
   [-1.29109412e-01  1.16934955e-01 -6.06799126e-03  3.48960012e-02
     1.12979501e-01  4.91897762e-02  5.11793196e-02  4.26351279e-02
     1.33226126e-01  1.48976833e-01 -9.27268192e-02 -6.90789521e-03]
   [-1.23111546e-01 -1.71052814e-01  8.02772939e-02 -1.01912886e-01
    -2.86003500e-02  1.14549160e-01  4.26118821e-02  8.39364231e-02
    -3.22494805e-02 -7.89153874e-02 -1.32538334e-01 -1.29463747e-01]
   [ 1.46687120e-01  1.52506828e-01  9.26443636e-02  6.21414185e-02
    -1.72423720e-01 -6.23126999e-02  2.05010623e-02 -1.00300699e-01
    -1.53363794e-02  1.37828499e-01 -8.18656608e-02  1.51547343e-01]
   [ 1.38815999e-01 -7.20064938e-02 -5.25365025e-02  2.56573856e-02
     6.23481721e-02  2.25929767e-02 -1.10020570e-01 -4.29743379e-02
     3.30728740e-02 -2.43608803e-02 -9.76782069e-02 -8.40325356e-02]]

  [[-1.63036332e-01  1.25057250e-02  7.12753832e-03 -1.06795110e-01
     6.51193708e-02  1.22607529e-01  1.57663882e-01 -4.83435243e-02
     1.39397770e-01 -2.29231119e-02  1.37293845e-01 -1.18514135e-01]
   [ 7.97202885e-02 -3.46474499e-02 -1.49823725e-01  6.80226386e-02
    -1.16630763e-01 -2.42122710e-02  4.53294814e-03 -3.08151096e-02
    -5.27321249e-02 -3.81362438e-03 -1.13759786e-02 -8.65967050e-02]
   [ 1.80331796e-01  6.82802200e-02 -8.55085179e-02  5.56591004e-02
    -3.77566814e-02 -8.91078115e-02 -1.47222176e-01  1.29493445e-01
     1.69769377e-01 -1.67796969e-01 -1.57929957e-02  7.98244476e-02]
   [ 1.39167458e-01 -1.52052820e-01 -4.07072157e-02  9.21656489e-02
     1.02456957e-02 -1.76625893e-01 -1.39610946e-01 -1.55866221e-01
     1.40045702e-01 -3.42336595e-02  5.93219548e-02 -1.42839015e-01]
   [-5.18756956e-02  1.35763884e-01  9.81894135e-02 -1.33831456e-01
    -1.48827434e-01  5.15295416e-02 -1.05127551e-01  8.44017863e-02
     1.17250323e-01  1.12633914e-01  1.10680908e-02 -1.19379058e-01]
   [-1.38842523e-01 -4.17533964e-02 -8.26727748e-02 -5.91531023e-02
     1.12382501e-01 -8.16313401e-02  7.49033093e-02  2.87096202e-03
     1.17437840e-01  1.01735413e-01  1.44566804e-01  1.13771379e-01]
   [-1.16637640e-01  5.05429655e-02  7.48217106e-03  7.32546151e-02
     9.94349122e-02 -7.83396289e-02 -1.66305840e-01 -1.37253538e-01
     1.25993550e-01 -1.71555489e-01  9.11465883e-02  7.38407373e-02]
   [ 1.10166609e-01 -3.80566865e-02 -9.39138532e-02 -1.52244821e-01
    -1.51174814e-02 -1.33969262e-01  1.64696008e-01  2.71832049e-02
     1.63365245e-01 -6.29455298e-02  1.39455616e-01  3.91784757e-02]]]]: "
2018-04-20 09:28:53,548 (dqn_agent.py:161) DEBUG: "var_name: q/Conv_1/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 09:28:53,554 (dqn_agent.py:161) DEBUG: "var_name: q/Conv_2/weights:0, var_value [[[[-0.02920526  0.03114332  0.07556178 ...  0.08078215  0.03317054
     0.08133997]
   [ 0.06541389 -0.0714056  -0.12045061 ... -0.01010297 -0.04065978
    -0.04366763]
   [-0.10315385  0.09700729 -0.03924992 ... -0.11348377  0.14366092
     0.14392848]
   ...
   [ 0.14039032  0.11492862 -0.13838169 ...  0.12618656 -0.14563419
     0.0656838 ]
   [-0.11907725  0.11028333 -0.08764619 ...  0.01702762  0.03354317
    -0.03116849]
   [ 0.00041163 -0.08662196 -0.10274317 ...  0.07911474  0.10078789
    -0.03744234]]

  [[ 0.12377752 -0.10194632  0.05374162 ... -0.01728672  0.07922804
    -0.12383551]
   [ 0.04989144 -0.03849512 -0.09851025 ...  0.01318242  0.01081064
     0.14884894]
   [ 0.05687344 -0.0954612   0.02583839 ... -0.00986621  0.01287015
    -0.12618616]
   ...
   [-0.09302413  0.06463918 -0.02820335 ...  0.13729946  0.04159676
     0.10923503]
   [-0.03035811 -0.07867058 -0.02609675 ... -0.0538284   0.11970116
     0.08582166]
   [-0.12506635 -0.1361765   0.03656243 ... -0.14304249 -0.02295403
    -0.14778678]]

  [[ 0.073322    0.00066382  0.01132812 ... -0.03657614  0.07289805
    -0.15138987]
   [-0.12140965  0.05063708  0.09882168 ... -0.01612529 -0.05614009
     0.05685283]
   [-0.14226279 -0.12296318  0.07010618 ... -0.09440058  0.11210941
    -0.03090063]
   ...
   [ 0.08294705 -0.03542627 -0.09705739 ... -0.06138823  0.02672639
     0.15292941]
   [ 0.06306201  0.00099602 -0.03438902 ...  0.14358433  0.01500393
    -0.10632665]
   [-0.00780861  0.06028855 -0.01955938 ...  0.06119812  0.13792737
     0.0712768 ]]]


 [[[ 0.00138822 -0.14444543  0.05700496 ... -0.1420688   0.05771205
    -0.06127967]
   [-0.142923   -0.15150027 -0.1405664  ...  0.07226712  0.14594705
     0.08877878]
   [ 0.01995686  0.08113527  0.1394745  ... -0.05097167 -0.05327528
     0.06352206]
   ...
   [-0.02183338 -0.02164148  0.14560981 ... -0.08714315  0.11033224
    -0.14970969]
   [ 0.11455075 -0.11459181  0.14244781 ...  0.14594416 -0.11412099
    -0.00499496]
   [-0.13352413 -0.13583553  0.15286417 ... -0.0552082   0.08746991
     0.15323408]]

  [[-0.1106329  -0.0358509   0.02746415 ... -0.06078894  0.04966255
     0.12742223]
   [ 0.09369339 -0.02016181  0.13986747 ... -0.07942931  0.03955626
    -0.08520231]
   [ 0.12014051 -0.1433076  -0.02773224 ... -0.04497212 -0.12718649
     0.07232293]
   ...
   [-0.11415031  0.04120016 -0.13765298 ... -0.03793531  0.09867357
     0.13389201]
   [-0.01294461 -0.13478827 -0.15234767 ... -0.08313898  0.0497714
     0.11732294]
   [-0.11552845 -0.03007513  0.1164618  ... -0.06640126 -0.14707418
     0.05282299]]

  [[-0.05480959  0.12044753 -0.01254866 ...  0.1409223  -0.10205963
    -0.08372974]
   [-0.14350599 -0.05941768 -0.11675452 ...  0.10383911 -0.00428914
    -0.09363412]
   [-0.02692752  0.10505442  0.12645723 ... -0.07301025  0.04839116
    -0.07205761]
   ...
   [ 0.06215242  0.01079732  0.00747621 ...  0.06894314  0.05767238
    -0.0177819 ]
   [-0.01610197 -0.07911693 -0.12925336 ...  0.06165558 -0.15149781
    -0.08739956]
   [ 0.00354733 -0.10406735  0.10553958 ...  0.05455711 -0.08983726
     0.11769201]]]


 [[[-0.1408274   0.05439532  0.07556535 ... -0.03507796  0.117148
    -0.11513217]
   [-0.03333833  0.05693002 -0.148012   ...  0.08571839 -0.11009482
    -0.03143985]
   [ 0.0369008   0.04954611  0.10708191 ... -0.09012675  0.00994809
    -0.14538626]
   ...
   [ 0.05741754  0.02945384  0.08636624 ...  0.14660443 -0.05157582
    -0.0426112 ]
   [ 0.125059    0.05557431 -0.04478034 ... -0.0117159   0.06688198
     0.04059625]
   [ 0.05203255  0.11688437 -0.11579502 ...  0.15246804 -0.15327331
    -0.02917311]]

  [[ 0.04812337  0.14541169 -0.02299583 ... -0.04381828  0.04496065
    -0.13958545]
   [ 0.0849608   0.02151982  0.13751878 ... -0.09880394 -0.05738863
    -0.11465292]
   [-0.04540027 -0.11332532 -0.14562838 ...  0.0929032   0.1173936
    -0.03032213]
   ...
   [-0.12221383  0.09325005  0.07185365 ...  0.09368923  0.03340632
     0.04187126]
   [-0.00506829 -0.10702516 -0.03905097 ...  0.10690762  0.14002176
     0.05246884]
   [ 0.07353538 -0.13594535 -0.03012741 ...  0.12792723 -0.04081091
    -0.1098295 ]]

  [[-0.06634346  0.02977486  0.08566067 ...  0.09430404  0.08419526
     0.08522362]
   [-0.08819869 -0.12208249  0.07034218 ...  0.0912735  -0.08815738
    -0.08286659]
   [-0.11275759 -0.05685685  0.10075052 ...  0.04972965 -0.05060253
    -0.09544295]
   ...
   [ 0.04746078  0.14117186 -0.00307433 ... -0.00714736  0.10469718
    -0.11343591]
   [-0.13416338 -0.12214646  0.0910908  ...  0.00146876 -0.04203351
     0.01481386]
   [-0.13841763  0.02974628  0.05971453 ...  0.08685987  0.01862156
    -0.02834779]]]]: "
2018-04-20 09:28:53,558 (dqn_agent.py:161) DEBUG: "var_name: q/Conv_2/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 09:28:53,562 (dqn_agent.py:161) DEBUG: "var_name: q/fully_connected/weights:0, var_value [[ 0.08157042  0.06623418  0.06776739 ...  0.05644212  0.07899103
   0.05643616]
 [ 0.02209343 -0.05179443 -0.02903633 ... -0.00462473  0.0866315
  -0.02627775]
 [-0.00445791  0.01925971  0.06567714 ... -0.03357385  0.07819278
   0.04664712]
 ...
 [ 0.03009177 -0.06488372  0.06634163 ... -0.03944565 -0.04472656
  -0.07609192]
 [-0.06219979  0.05804006 -0.01590803 ... -0.06922067 -0.0525541
   0.08135106]
 [-0.01098281 -0.08562314 -0.07261136 ... -0.08409451 -0.01397916
   0.02504937]]: "
2018-04-20 09:28:53,567 (dqn_agent.py:161) DEBUG: "var_name: q/fully_connected/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 09:28:53,575 (dqn_agent.py:161) DEBUG: "var_name: q/fully_connected_1/weights:0, var_value [[-1.33299828e-01  1.40574872e-02 -7.08519369e-02  6.46952689e-02
   9.59742069e-02]
 [-1.93864018e-01 -1.61325574e-01 -1.27446860e-01  2.11798012e-01
   1.96384192e-01]
 [-1.62822932e-01  1.54100925e-01 -2.03218877e-01  1.86855614e-01
   1.69897169e-01]
 [-1.34735703e-02  2.58669257e-04 -1.90357491e-01 -5.68246841e-03
   1.00014180e-01]
 [ 1.13576621e-01  3.52445692e-02  7.04729557e-02  9.39109623e-02
   1.04788691e-01]
 [ 4.65270877e-03 -4.56783473e-02  7.44275749e-02 -1.56244859e-01
   1.06541067e-01]
 [-3.39077413e-03 -5.53624034e-02  4.70186770e-02  2.04944879e-01
   3.21537405e-02]
 [-1.39143586e-01 -4.10440117e-02  1.65419012e-01  6.88962936e-02
   2.32711583e-02]
 [ 5.16156852e-02 -9.28531587e-03 -1.47460848e-02 -1.29877895e-01
  -2.08430141e-01]
 [-1.24819465e-01  1.29220456e-01 -1.76744461e-01 -1.65693939e-01
  -1.23002976e-01]
 [ 6.32750988e-02 -2.04019532e-01 -7.52302706e-02 -1.38983667e-01
   1.94035828e-01]
 [ 1.88507468e-01  1.17310137e-01 -9.67103615e-02 -1.20085582e-01
  -1.75580502e-01]
 [-1.36453196e-01  7.53062963e-02  1.86333507e-01  1.99722469e-01
   9.47043896e-02]
 [-8.57917666e-02  5.19664586e-02  1.13683581e-01  5.64240515e-02
  -8.79084468e-02]
 [ 4.06257510e-02  9.89227593e-02 -1.17120229e-01  1.42862946e-01
  -1.49873540e-01]
 [-2.06193388e-01  1.60203159e-01  2.06621438e-01 -5.88385612e-02
  -2.09971458e-01]
 [-1.63450658e-01 -5.57343662e-03  9.87532139e-02 -2.03066349e-01
   8.07760060e-02]
 [-1.60088852e-01 -1.01498790e-01  1.21336877e-02 -1.74619406e-02
   2.85941362e-03]
 [-9.28267837e-04  8.98760557e-02  1.31628960e-01 -2.18663663e-02
   5.96837699e-02]
 [ 1.03134096e-01 -1.22160636e-01 -8.58860016e-02  1.08571261e-01
  -1.11071490e-01]
 [-2.78026909e-02 -8.59253556e-02  1.14764988e-01  1.48713738e-01
   6.38012588e-03]
 [-1.55442983e-01 -1.29066616e-01 -1.29093245e-01 -5.37588000e-02
  -1.58720776e-01]
 [ 3.96580696e-02 -1.59128532e-01  1.77198738e-01 -1.03527457e-02
   1.32669419e-01]
 [ 2.05792040e-02 -1.53549463e-01  1.95737988e-01  1.42226875e-01
  -1.13157481e-01]
 [-1.14196606e-01  2.57390738e-03 -8.75675902e-02 -1.34542868e-01
  -1.19291604e-01]
 [ 7.68667459e-02  1.88262939e-01  9.44095552e-02 -8.99212211e-02
   9.73729193e-02]
 [ 2.07806557e-01  9.33260620e-02 -1.29229918e-01 -2.04818681e-01
   1.22991323e-01]
 [-1.07458860e-01  1.29220963e-01  7.39139616e-02 -1.23778522e-01
  -1.63169667e-01]
 [-2.27470398e-02  1.63773537e-01 -1.00449942e-01 -2.06083298e-01
  -1.72836930e-02]
 [ 5.94137609e-02 -8.15672129e-02 -1.27406180e-01 -1.91571876e-01
   1.71176940e-02]
 [-2.06798315e-02  1.38266891e-01  1.38171643e-01  1.91700399e-01
  -1.25953898e-01]
 [-5.31684905e-02 -3.75389010e-02  1.16632581e-02  3.84386182e-02
  -1.37449086e-01]
 [-4.07289416e-02 -5.69811463e-02  1.52470797e-01 -1.85510069e-01
   1.42048717e-01]
 [-4.06951606e-02  1.38778806e-01 -1.85947388e-01  1.43138587e-01
   1.28177285e-01]
 [ 8.99710357e-02 -1.61721781e-01 -3.68046761e-02 -4.57380563e-02
   4.95254993e-04]
 [-1.53600708e-01  4.52516675e-02  1.27036512e-01 -1.16491184e-01
   6.57955110e-02]
 [-6.16139024e-02 -5.18214703e-03 -1.30937845e-01 -1.14585012e-01
  -1.75196454e-01]
 [-1.94620371e-01 -2.03980654e-02 -1.58955842e-01  7.26519227e-02
  -1.73306316e-02]
 [-1.75178438e-01 -1.42431408e-02 -1.09862112e-01  2.25317180e-02
  -1.12451665e-01]
 [-1.53357133e-01 -1.09710343e-01 -1.37862548e-01  9.25220251e-02
  -1.44818902e-01]
 [ 5.81429601e-02 -1.29831821e-01 -1.75121158e-01 -4.49038148e-02
  -1.95001125e-01]
 [ 8.79958272e-03  1.03748083e-01  4.46168482e-02  1.19810611e-01
  -1.67408451e-01]
 [-1.94066912e-02 -4.55603004e-02 -1.62356049e-02 -1.00090802e-01
   6.25995994e-02]
 [ 2.04512358e-01 -5.51346838e-02  1.40624315e-01  1.60176247e-01
   1.87169224e-01]
 [ 2.11744457e-01 -3.81401479e-02  1.10687912e-02  7.24288821e-02
   8.87269974e-02]
 [ 9.30531323e-02 -9.58742499e-02  8.00922811e-02  8.39873254e-02
   8.94822776e-02]
 [ 1.53533459e-01  4.07693386e-02  1.16920471e-01  2.10090339e-01
  -4.98117507e-02]
 [ 9.24170315e-02 -8.13147277e-02  1.51871681e-01  1.61630422e-01
  -1.76149949e-01]
 [-9.98161361e-02 -1.97957620e-01  1.79989189e-02 -1.77015126e-01
   8.34802687e-02]
 [-1.34091109e-01 -2.21316665e-02 -1.89185783e-01  8.82847607e-02
   1.84389651e-01]
 [-1.12051971e-01 -1.52146801e-01  4.71714139e-02 -3.92214954e-02
  -1.32929534e-01]
 [ 1.91508263e-01  1.34995282e-01 -1.17333218e-01 -7.69265443e-02
  -3.91703099e-02]
 [-3.90403569e-02  7.71655142e-02  5.80673218e-02 -1.23770416e-01
   1.80938691e-02]
 [-1.99991658e-01 -1.30604208e-03  1.33748442e-01 -1.33045971e-01
   2.50199437e-03]
 [-1.20283075e-01 -4.17659432e-02  1.09589458e-01  6.80515766e-02
   1.12798393e-01]
 [ 9.99173522e-03  1.14754200e-01 -9.14048031e-02 -1.89841866e-01
   1.61151230e-01]
 [ 1.82970345e-01  2.11820155e-02  1.56734735e-01 -1.18818730e-01
  -4.47130501e-02]
 [-2.41348147e-02 -8.86413530e-02  1.89207852e-01 -1.25272632e-01
  -1.41281784e-01]
 [-1.16354607e-01  3.20801586e-02  1.47045374e-01 -3.08876932e-02
   2.02019781e-01]
 [ 6.14875555e-03  1.27297550e-01  7.21142292e-02 -2.00974122e-01
   2.68503129e-02]
 [ 1.92973077e-01 -7.58328438e-02  1.37268245e-01 -2.03969091e-01
  -5.90929687e-02]
 [-1.08924322e-01 -8.94440934e-02  1.97469890e-02 -1.35631725e-01
   1.10527873e-01]
 [-1.77012652e-01 -6.18345439e-02  1.03068411e-01 -1.19194679e-01
  -9.90418568e-02]
 [-4.15264666e-02  1.14324659e-01  4.54396307e-02 -2.01209292e-01
   1.91397458e-01]
 [ 2.10495889e-01  6.39667809e-02 -5.37462980e-02  1.83368206e-01
  -3.50108743e-02]
 [ 4.06920314e-02 -1.85996920e-01  4.13198769e-03 -3.35038453e-02
   1.44174308e-01]
 [ 1.62238747e-01  1.37864232e-01 -1.39489084e-01  1.02697134e-01
  -4.73292023e-02]
 [-6.67312741e-03 -1.80796742e-01  6.88863099e-02  1.51217908e-01
  -1.14925765e-01]
 [ 1.24556690e-01  1.96774036e-01  1.98205948e-01  9.99077559e-02
  -1.86149955e-01]
 [-6.42117113e-02  2.07862675e-01  8.95886123e-02 -1.92947894e-01
  -2.04674050e-01]
 [ 9.47193205e-02 -1.13070838e-01 -2.06116155e-01 -1.32610172e-01
   1.85954273e-01]
 [ 2.10419506e-01 -1.63228869e-01 -1.71216086e-01 -1.24598525e-01
  -1.54693916e-01]
 [ 1.45468861e-01 -3.27154249e-02  6.93160295e-02 -1.47741169e-01
  -1.58869356e-01]
 [-8.43391120e-02 -1.80306643e-01 -6.53254986e-03  1.79963320e-01
  -1.87741444e-01]
 [-1.16624981e-02 -2.42316425e-02 -1.79944515e-01  3.52976471e-02
  -4.84511703e-02]
 [ 1.06213987e-02  8.93397629e-03 -3.82776856e-02  1.05401129e-02
  -1.55844748e-01]
 [-1.01029508e-01  2.61832327e-02  1.35792792e-01 -1.03135407e-01
   3.71879637e-02]
 [ 9.54458416e-02 -1.16168968e-01  9.37369466e-02 -2.79847383e-02
  -1.37182206e-01]
 [-9.76120532e-02  2.05598891e-01 -1.06868811e-01  1.27204329e-01
   1.49802685e-01]
 [ 6.70772195e-02  3.02013308e-02 -7.55790323e-02 -1.99647725e-01
   7.73878396e-03]
 [ 1.14767253e-01  1.54064566e-01 -2.55355239e-03  1.31901413e-01
   1.53072029e-01]
 [-7.74801970e-02 -2.08543062e-01  6.48558140e-02  5.96918166e-03
   7.84949660e-02]
 [ 7.50566423e-02  1.12952858e-01 -1.34281576e-01  1.47529095e-01
   1.90393686e-01]
 [ 1.45587295e-01 -1.93827972e-01  2.03819215e-01  1.61185920e-01
  -1.70694143e-01]
 [ 1.84947193e-01 -9.87321138e-04  5.78837097e-02 -6.76939487e-02
   3.25574428e-02]
 [-1.23953968e-02  8.64458382e-02 -9.21477899e-02  8.11449289e-02
   2.07048833e-01]
 [ 1.52090222e-01  2.08526313e-01  9.52346325e-02  8.56096148e-02
   1.51132792e-01]
 [-1.38095587e-01  1.89284980e-01 -4.76497412e-02 -1.70217991e-01
  -6.45513535e-02]
 [ 1.62907451e-01  4.16189432e-05  5.21859229e-02 -4.28136736e-02
   2.83536464e-02]
 [ 2.49941200e-02  1.79801911e-01  2.23825872e-02  6.37984574e-02
   1.90637261e-01]
 [-1.11613177e-01  1.85310453e-01 -1.19038001e-01  1.50295615e-01
   1.55494332e-01]
 [ 2.11143196e-02 -8.70250165e-03  1.28290564e-01 -1.97300270e-01
   7.28970468e-02]
 [-2.51718163e-02  4.16837633e-02 -6.66119307e-02 -2.66940296e-02
   2.17834711e-02]
 [-5.59258163e-02  1.05253756e-01 -1.91947311e-01 -1.46291807e-01
   1.85605377e-01]
 [ 1.36108756e-01 -5.71402609e-02 -1.96304917e-03  1.74542964e-02
  -2.02672616e-01]
 [ 1.66650534e-01  9.12436843e-02  1.09799713e-01  1.00556284e-01
  -1.52703524e-01]
 [ 1.37518495e-01  1.06106132e-01 -1.89798936e-01 -1.85306042e-01
   2.87944674e-02]
 [ 2.33644396e-02 -3.53551209e-02 -1.29313275e-01  1.14356220e-01
   2.65521407e-02]
 [ 9.87855792e-02  2.04345733e-02  1.13541901e-01  1.27106309e-02
   1.28202289e-01]
 [-1.48128241e-01 -9.52904820e-02  1.90396339e-01 -2.11362988e-02
   2.09120154e-01]
 [ 1.60200477e-01 -2.08531618e-01 -4.95258421e-02 -1.57291830e-01
   1.95052624e-01]
 [ 1.00021899e-01 -3.89390886e-02 -2.34838873e-02 -3.31031829e-02
  -9.69290733e-04]
 [ 1.43746346e-01  1.96992368e-01 -5.24681509e-02 -3.16498727e-02
   1.64927810e-01]
 [-1.34221464e-01 -1.73774242e-01 -2.01056719e-01  1.65233731e-01
  -2.07562268e-01]
 [-1.62036598e-01 -1.27658367e-01  1.42982304e-01 -6.27174973e-04
  -8.96266475e-02]
 [-7.97394216e-02  5.48231006e-02 -1.03361160e-01 -4.32671010e-02
   1.03646606e-01]
 [-3.39051634e-02 -1.68837503e-01  1.50081098e-01 -9.88376290e-02
   1.41394466e-01]
 [-1.70523748e-01  7.36922920e-02 -4.59634960e-02 -1.47729874e-01
   1.26590282e-01]
 [ 3.94977927e-02 -4.23553735e-02 -1.07438959e-01  2.37901062e-02
  -1.30911961e-01]
 [ 5.04257977e-02  1.79057568e-01  2.02911735e-01  6.06529117e-02
   1.26227140e-02]
 [-9.79978219e-02  1.75997287e-01  4.79388535e-02  9.06721652e-02
  -1.76444769e-01]
 [-1.59125388e-01 -1.74650669e-01 -1.27384454e-01 -1.90612704e-01
  -4.08250093e-02]
 [ 1.83052123e-01 -5.32934219e-02  2.10260600e-01 -1.80872694e-01
  -7.23566860e-02]
 [ 7.72516429e-02  1.53194070e-01  1.58892840e-01 -2.86635011e-02
  -1.10854596e-01]
 [-1.37804210e-01 -1.53750509e-01  2.10951388e-01  3.84791195e-02
  -3.72670144e-02]
 [-2.05008924e-01  1.65603966e-01  1.37905627e-02 -1.31051019e-01
  -1.87281847e-01]
 [ 7.60070980e-02 -9.38904956e-02 -3.21145505e-02  2.05786556e-01
  -1.60290658e-01]
 [ 1.50911659e-01 -6.85408711e-04  7.17292130e-02 -1.12558112e-01
   8.05796683e-03]
 [ 1.79141074e-01  6.64601624e-02 -6.92120194e-02 -5.89349717e-02
   1.05314732e-01]
 [-5.36694676e-02  1.74739271e-01  1.08442426e-01 -6.52989000e-02
  -1.82026416e-01]
 [-1.94738805e-03 -3.06461006e-02 -1.07189305e-01  5.62258661e-02
   1.22701526e-01]
 [ 7.05108047e-04 -1.84519559e-01  8.60762596e-02 -6.98125511e-02
  -3.19413096e-02]
 [-2.30425596e-03 -1.85792834e-01 -2.10975885e-01  8.40231776e-03
  -1.17462605e-01]
 [ 7.62175024e-02  4.20083404e-02  1.55216455e-01 -9.79003385e-02
  -1.64052919e-01]
 [ 9.70424414e-02  1.73741877e-01 -3.36237103e-02  6.78210557e-02
   1.83016956e-02]
 [-1.61673069e-01 -8.19951296e-04 -1.96342975e-01  3.94056737e-03
  -2.08351642e-01]
 [-1.43294185e-01 -1.36637330e-01  1.64014935e-01 -6.10820353e-02
   1.85837388e-01]
 [ 1.45880431e-02  1.55484349e-01 -1.23854734e-01  9.29306746e-02
  -5.54155707e-02]]: "
2018-04-20 09:28:53,578 (dqn_agent.py:161) DEBUG: "var_name: q/fully_connected_1/biases:0, var_value [0. 0. 0. 0. 0.]: "
2018-04-20 09:28:53,582 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv/weights:0, var_value [[[[ 0.07914811  0.4790275   0.7519878   0.30090177 -0.7116133
    -0.38285536 -0.17304963 -0.67449665]
   [-0.32940283  0.5482898  -0.11913466 -0.7408853  -0.11541724
    -0.28320834  0.5569451  -0.07108968]]]]: "
2018-04-20 09:28:53,586 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 09:28:53,595 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv_1/weights:0, var_value [[[[ 4.59266603e-02 -1.72088891e-01 -1.48474574e-02  1.39961183e-01
    -1.24499992e-01 -9.86169055e-02  5.83966076e-02 -3.10574323e-02
    -4.71849591e-02 -9.68626142e-03  1.11561358e-01  5.80064952e-02]
   [-1.74712315e-01  1.12578809e-01  1.70844316e-01 -7.22567439e-02
     5.09893447e-02 -6.62921742e-02 -1.35316670e-01  1.18894547e-01
    -7.61907697e-02 -1.11978814e-01 -9.48175192e-02 -8.32724571e-03]
   [ 6.27263188e-02  8.97668898e-02 -1.30530566e-01  1.23129964e-01
    -1.24589927e-01 -4.29591984e-02  1.31127506e-01  4.46048081e-02
     5.72550297e-03  6.66925460e-02  8.24193358e-02  1.53374523e-01]
   [ 1.19814336e-01  4.28056270e-02  1.66132718e-01  1.52832717e-02
    -2.76231617e-02 -3.99370193e-02 -6.52910024e-02  1.55058354e-01
     1.56291813e-01 -2.81294882e-02 -1.82388917e-01 -1.13509603e-01]
   [ 5.75251132e-02 -1.09999195e-01 -1.36744991e-01  4.72179502e-02
     3.64765525e-03 -1.31609604e-01  2.25259364e-03  2.50491053e-02
    -6.33881316e-02  1.50839180e-01  1.14190042e-01  1.42353624e-01]
   [ 8.74959826e-02  2.17679292e-02 -4.60047871e-02  4.37177718e-02
    -1.20182216e-01  1.66270137e-02 -1.66230053e-01 -6.18038923e-02
     7.97687173e-02 -1.23784333e-01  1.09827369e-02  1.38401866e-01]
   [-1.49266422e-02  4.34265733e-02  1.29332721e-01  8.45234096e-03
     6.72231764e-02 -3.86303514e-02  1.83291733e-03 -9.60594043e-02
    -1.55982077e-02  2.40914226e-02 -1.01943530e-01  8.47566724e-02]
   [-1.06488183e-01  1.33211851e-01  2.57079750e-02 -2.43195593e-02
    -1.14360161e-01  1.72666192e-01  2.91829854e-02 -5.00739366e-02
     1.61852151e-01 -1.46439001e-01  1.79510683e-01 -1.39846697e-01]]

  [[ 1.72673851e-01  2.51529217e-02  1.15051717e-02 -1.43374726e-01
    -1.36862695e-01 -3.57176065e-02 -9.79878679e-02  2.95825303e-02
    -7.06764236e-02  1.50512487e-01 -4.54729944e-02 -1.61682144e-01]
   [-1.48730189e-01  1.60694629e-01  1.68279529e-01  2.79130638e-02
    -1.72764510e-01  1.77673280e-01 -1.46749169e-02  1.78631872e-01
    -1.70602039e-01 -2.39093006e-02  1.52031660e-01  7.89385140e-02]
   [-1.02264136e-02  9.62170064e-02 -5.22153974e-02  9.72304344e-02
     1.53782755e-01 -9.59211513e-02 -1.42036110e-01  7.42993057e-02
     4.21266556e-02  8.14753771e-02 -6.23330325e-02  5.48714101e-02]
   [-4.26714271e-02  1.68763787e-01 -1.37789384e-01 -1.26971886e-01
    -7.12006018e-02 -1.24533772e-01 -1.26656294e-01  4.72326577e-02
    -1.53898358e-01 -1.29698232e-01 -1.65449083e-03  9.38509405e-03]
   [-5.22648394e-02  7.24693537e-02 -5.65063953e-03  1.69194818e-01
    -9.89471227e-02 -4.44261283e-02  1.20224714e-01 -1.61533177e-01
    -9.98510867e-02  6.56803250e-02 -1.49763092e-01 -3.69788259e-02]
   [ 1.23640776e-01  1.14785969e-01  8.30202699e-02 -1.17309093e-02
     1.75392538e-01 -4.08211350e-02 -1.15941830e-01  8.18128884e-02
     1.15362734e-01 -2.01758593e-02 -1.12635054e-01 -1.00648321e-01]
   [-1.64424479e-01 -6.04204908e-02 -1.01013444e-01 -1.57799035e-01
     7.98922181e-02  9.28924382e-02  1.45952523e-01 -1.47205502e-01
    -4.47390527e-02  8.18745792e-02  1.21312439e-01 -8.92264247e-02]
   [ 1.31564677e-01 -9.42128971e-02  1.74615413e-01 -8.29721242e-02
     1.68625563e-01 -6.82979822e-03  1.00587428e-01  9.79534686e-02
    -9.08489749e-02 -4.79797572e-02  6.88457489e-02 -1.24556452e-01]]

  [[ 2.09542811e-02 -1.76576704e-01 -1.75516590e-01  1.53792888e-01
     5.94764352e-02 -1.17908955e-01  4.38780934e-02 -1.16823249e-01
     1.59227967e-01 -4.43907380e-02 -1.03770643e-02 -1.01199009e-01]
   [ 1.58088326e-01  9.51612294e-02 -3.39910388e-03  1.78934425e-01
    -1.56330496e-01  9.69698131e-02  1.24928504e-01  5.12717664e-02
    -1.31829023e-01  7.67928660e-02  5.32713532e-03 -2.81759799e-02]
   [ 1.32242084e-01 -2.21901685e-02  1.53149754e-01  6.62189126e-02
    -1.33845508e-01  1.46808833e-01  1.34788275e-01 -3.07158530e-02
     1.57297105e-02 -1.61284938e-01  1.41481370e-01  8.88178945e-02]
   [ 1.37166053e-01  7.25163519e-03  1.82257146e-02  1.01106375e-01
    -1.46806121e-01  7.49268532e-02 -1.12262405e-01 -8.03965479e-02
     8.99758637e-02  1.68902785e-01  8.05737078e-02 -1.53716922e-01]
   [-3.87430191e-06  1.55886561e-01 -1.53968483e-01  4.74248379e-02
     1.48850322e-01  9.80639458e-02  2.69348770e-02  1.29187196e-01
    -1.04294844e-01  5.72997183e-02 -1.03384912e-01  1.04157507e-01]
   [-3.08575928e-02 -1.78174868e-01 -1.52732000e-01  9.38374996e-02
     1.23474330e-01  5.52441478e-02 -1.77889764e-01  1.00657642e-01
    -1.37531906e-01  9.26029384e-02  9.69907939e-02 -2.03150511e-03]
   [ 1.03919923e-01  4.18893993e-03  6.23003840e-02  1.20164841e-01
    -5.60711473e-02 -3.42509151e-03  2.82454491e-02  9.55198705e-02
    -1.80768549e-01 -5.15434295e-02 -8.48628059e-02 -1.43701017e-01]
   [ 1.09497100e-01 -1.76315621e-01 -8.78376290e-02 -1.06290691e-01
    -1.77713335e-01 -3.94454896e-02 -8.83867517e-02  8.48598778e-03
    -9.84680429e-02 -1.74542964e-02 -7.20858574e-03  1.28679574e-01]]]


 [[[ 1.28606260e-02 -1.11839347e-01  1.78446263e-01  1.60450101e-01
    -1.22931167e-01  4.03821021e-02 -8.86781290e-02  4.64679003e-02
     1.59533948e-01 -1.85661018e-02  4.76158410e-02  1.59816533e-01]
   [ 1.14592135e-01 -3.25613171e-02  1.02412939e-01  1.78614378e-01
     1.61424309e-01 -2.00513154e-02  3.79820317e-02  3.60320657e-02
    -3.44310254e-02  6.52043819e-02 -2.49615759e-02 -6.52617514e-02]
   [ 7.00071156e-02 -8.65188316e-02  6.12260848e-02  1.46166623e-01
     5.68872392e-02 -3.95068973e-02  1.19807422e-01 -5.52808344e-02
     1.14707381e-01  4.55020815e-02  1.22642010e-01 -1.17365927e-01]
   [-1.81644708e-01  1.43975854e-01 -1.42608792e-01 -6.97683170e-02
     1.74225003e-01 -1.23612136e-01  4.15722728e-02 -4.14943993e-02
     1.71231061e-01  1.79012775e-01  1.68393940e-01 -1.55556113e-01]
   [-1.29081085e-01 -5.31472266e-03 -9.76994485e-02 -1.48799866e-02
    -4.37819362e-02  1.06984407e-01 -8.46678019e-02  6.73810095e-02
    -8.88119861e-02 -1.43700629e-01 -1.66791588e-01  5.36713898e-02]
   [-1.75354496e-01  1.38470829e-01  5.61376214e-02 -4.80189323e-02
     6.90983534e-02 -1.49500221e-02  1.03393614e-01  2.00432688e-02
    -1.60512343e-01  8.45625103e-02 -9.86327529e-02 -8.51325989e-02]
   [ 3.47246677e-02 -1.27928957e-01  3.90052348e-02  9.58932042e-02
    -9.02312472e-02 -1.05098784e-02  1.45444274e-01  2.19392180e-02
    -9.71539840e-02 -1.72861278e-01  8.16225111e-02 -4.66572493e-02]
   [-1.37085468e-01 -7.39390105e-02 -7.37784803e-02 -9.79664996e-02
     1.69566035e-01 -1.68275714e-01 -1.73885524e-01  9.83146727e-02
    -5.77553809e-02  1.36770874e-01 -1.71338812e-01  1.14945710e-01]]

  [[-1.02200180e-01 -8.54808763e-02  2.09976882e-02  1.76483124e-01
    -2.46948749e-02  6.84345961e-02  1.45440042e-01 -1.15988143e-01
     4.61251885e-02  1.36736155e-01 -4.15718406e-02 -3.48895639e-02]
   [-7.83773214e-02 -4.37892973e-02 -1.72850400e-01  1.09205306e-01
    -7.62047470e-02  9.95500386e-02 -1.67300001e-01 -1.40161797e-01
     4.44115847e-02 -7.95173049e-02  9.77259576e-02  6.59237802e-02]
   [ 1.22180581e-01  4.58921790e-02 -8.81682336e-02  8.87607038e-02
     1.87306106e-03 -1.22860476e-01  8.13596249e-02  5.36538512e-02
    -1.21953189e-02  1.81094140e-01 -2.48734653e-02  2.73757875e-02]
   [-6.70417473e-02 -9.75400209e-03  6.90546036e-02 -6.57290220e-05
     3.89454663e-02 -3.19474638e-02 -4.86744791e-02  4.34660912e-02
    -1.78270772e-01  1.57679737e-01  1.47491872e-01  3.11343968e-02]
   [ 1.68085605e-01  3.50283235e-02  1.56668156e-01 -6.75793290e-02
    -6.54479265e-02 -1.66074708e-01  1.48709089e-01  1.63217157e-01
    -1.07698597e-01 -4.47358340e-02 -7.77370557e-02  5.51681370e-02]
   [ 1.08388275e-01  1.31204963e-01  7.76115060e-02  1.02005243e-01
    -3.76685858e-02  6.04691952e-02 -1.05460025e-01 -6.43647462e-02
    -1.98711604e-02 -1.54201686e-03 -7.20002279e-02  4.67528850e-02]
   [ 7.62280822e-02  6.35936260e-02 -6.29071742e-02  4.29544002e-02
     1.17542863e-01  9.46930349e-02 -5.15767783e-02  4.67247218e-02
     1.53215140e-01  1.70972854e-01  4.20156568e-02 -1.27667263e-01]
   [-1.00742653e-01  5.63824326e-02  7.62930512e-03  8.20686817e-02
    -6.75128624e-02  2.11458206e-02  5.47942668e-02 -1.78667665e-01
    -5.19984365e-02  1.43111467e-01  5.68439662e-02 -5.82566634e-02]]

  [[ 6.52910024e-02  3.88919264e-02  1.56293601e-01 -5.79654500e-02
    -5.25534004e-02 -1.51155949e-01  7.13013709e-02 -3.91205400e-02
     1.64552271e-01  4.98473644e-03  1.15655333e-01  1.76461577e-01]
   [-7.70413727e-02 -9.89104286e-02 -1.39436483e-01 -1.05452687e-02
     9.18515325e-02 -1.58981636e-01 -7.53689855e-02  1.25269741e-02
    -1.69140071e-01 -1.64931148e-01  9.61601734e-02 -7.61459395e-02]
   [ 3.81103605e-02  1.55175328e-01 -1.01402074e-01 -1.71500608e-01
     1.55800700e-01  1.45497173e-01 -2.21505910e-02  1.14997149e-01
     9.81632471e-02 -1.25671476e-02  2.27606595e-02  1.38822883e-01]
   [ 8.14593136e-02  1.23865992e-01 -8.12770575e-02 -9.59374309e-02
    -1.03909969e-02  1.38591886e-01 -9.04690474e-02 -1.76978916e-01
     6.39621466e-02  1.16951436e-01  1.33817613e-01 -4.85350490e-02]
   [-6.42985851e-02 -1.14503540e-01 -1.49273306e-01  6.70658201e-02
    -1.15240313e-01  1.05984628e-01 -1.68339431e-01  6.25888109e-02
     8.41828883e-02  1.18337244e-01 -6.16042241e-02 -5.10894656e-02]
   [-1.03813283e-01 -1.73969269e-01  1.42139852e-01 -7.57478178e-02
    -2.05801129e-02  4.91224378e-02 -6.06351346e-02 -5.70891649e-02
     3.74096781e-02 -7.16233999e-02 -8.07693377e-02  1.01306140e-02]
   [-1.70468539e-02  9.37549174e-02  2.21922547e-02  3.11460942e-02
     6.40661418e-02 -4.77975756e-02  4.64781225e-02 -5.60601354e-02
     1.77811980e-01 -1.71505868e-01 -1.51334792e-01 -7.61548206e-02]
   [ 1.52543306e-01 -1.58861890e-01 -7.21160620e-02  4.08331454e-02
    -3.71688753e-02 -1.30136758e-01  6.75946176e-02  1.19643956e-02
    -1.81868404e-01  1.05541915e-01  2.93406844e-02 -4.08212692e-02]]]


 [[[-1.26051843e-01 -1.70084387e-01 -9.52820629e-02  1.30769521e-01
    -1.04875259e-01 -3.49074900e-02  7.44546950e-02  1.76120907e-01
    -1.45677984e-01 -1.57409281e-01  7.59648979e-02  7.47658610e-02]
   [ 1.65956259e-01  4.41375226e-02  3.59243304e-02 -7.29618296e-02
    -1.42369032e-01  9.90335643e-02 -3.81329954e-02 -6.60448819e-02
    -5.02698570e-02  7.66457915e-02  3.91039103e-02  2.00575441e-02]
   [ 7.39718378e-02 -1.78248867e-01 -4.46717143e-02  1.50459915e-01
    -1.24331236e-01  1.54924780e-01  1.13002002e-01  1.11056924e-01
     3.68026644e-02  1.04091257e-01 -7.09437802e-02 -5.79119995e-02]
   [-1.10180579e-01  1.56654567e-01  3.64961773e-02 -4.38162386e-02
    -5.18400818e-02 -4.87378091e-02  1.57480896e-01  3.45415026e-02
    -6.92495853e-02  1.66018069e-01  5.02528399e-02 -1.57147631e-01]
   [-1.11175224e-01 -6.81748912e-02 -4.95221615e-02 -7.11339116e-02
    -1.62811160e-01  8.68570805e-02 -9.64322686e-02 -1.23721570e-01
     1.13224864e-01 -1.78154767e-01  2.28995532e-02  1.60965860e-01]
   [ 1.73273623e-01 -1.42604917e-01  9.60727334e-02  7.41100311e-02
    -1.10245645e-02  9.16182995e-02 -3.04630399e-02  4.74387705e-02
    -6.29801750e-02 -8.76510218e-02 -1.31499857e-01 -2.49503404e-02]
   [-9.36283022e-02  1.39113128e-01 -5.57173043e-02 -4.20599282e-02
    -1.49229646e-01  6.66291267e-02 -1.13109134e-01  1.00668132e-01
    -1.28383011e-01  1.62950575e-01 -1.02640823e-01 -1.04010336e-01]
   [ 5.51230013e-02  1.36328906e-01  8.22690129e-02 -8.52608830e-02
    -7.75496662e-02 -2.23609358e-02 -6.74213171e-02  1.71216428e-02
     1.47710085e-01  1.52977854e-01  4.76944447e-03  1.19491100e-01]]

  [[ 1.97386146e-02  1.41787380e-01  1.48842096e-01 -1.79836601e-01
     6.08225316e-02 -1.59452587e-01 -8.96047801e-02 -7.63107836e-02
    -1.11123033e-01  9.58444476e-02  1.51126266e-01 -1.11307204e-01]
   [-1.88637972e-02  1.46871716e-01  6.01410717e-02  2.86610723e-02
     1.23184323e-01 -1.35057673e-01 -1.49379343e-01 -5.34864366e-02
    -3.29534262e-02  3.02254111e-02 -1.36238098e-01 -8.39818642e-02]
   [-1.94984972e-02 -1.01037651e-01 -1.80198714e-01  6.18741959e-02
    -3.82479131e-02  1.00545645e-01  3.71569395e-02  1.80864781e-01
     8.67847800e-02  1.69556111e-01 -1.50802314e-01 -1.26330003e-01]
   [ 1.50527000e-01  5.19312769e-02  1.17203027e-01  7.27529228e-02
    -4.61325943e-02  1.22542679e-03 -1.64538175e-02 -1.26455456e-01
    -1.22738481e-02 -3.42369080e-03 -1.32781357e-01 -9.28237513e-02]
   [-1.29109412e-01  1.16934955e-01 -6.06799126e-03  3.48960012e-02
     1.12979501e-01  4.91897762e-02  5.11793196e-02  4.26351279e-02
     1.33226126e-01  1.48976833e-01 -9.27268192e-02 -6.90789521e-03]
   [-1.23111546e-01 -1.71052814e-01  8.02772939e-02 -1.01912886e-01
    -2.86003500e-02  1.14549160e-01  4.26118821e-02  8.39364231e-02
    -3.22494805e-02 -7.89153874e-02 -1.32538334e-01 -1.29463747e-01]
   [ 1.46687120e-01  1.52506828e-01  9.26443636e-02  6.21414185e-02
    -1.72423720e-01 -6.23126999e-02  2.05010623e-02 -1.00300699e-01
    -1.53363794e-02  1.37828499e-01 -8.18656608e-02  1.51547343e-01]
   [ 1.38815999e-01 -7.20064938e-02 -5.25365025e-02  2.56573856e-02
     6.23481721e-02  2.25929767e-02 -1.10020570e-01 -4.29743379e-02
     3.30728740e-02 -2.43608803e-02 -9.76782069e-02 -8.40325356e-02]]

  [[-1.63036332e-01  1.25057250e-02  7.12753832e-03 -1.06795110e-01
     6.51193708e-02  1.22607529e-01  1.57663882e-01 -4.83435243e-02
     1.39397770e-01 -2.29231119e-02  1.37293845e-01 -1.18514135e-01]
   [ 7.97202885e-02 -3.46474499e-02 -1.49823725e-01  6.80226386e-02
    -1.16630763e-01 -2.42122710e-02  4.53294814e-03 -3.08151096e-02
    -5.27321249e-02 -3.81362438e-03 -1.13759786e-02 -8.65967050e-02]
   [ 1.80331796e-01  6.82802200e-02 -8.55085179e-02  5.56591004e-02
    -3.77566814e-02 -8.91078115e-02 -1.47222176e-01  1.29493445e-01
     1.69769377e-01 -1.67796969e-01 -1.57929957e-02  7.98244476e-02]
   [ 1.39167458e-01 -1.52052820e-01 -4.07072157e-02  9.21656489e-02
     1.02456957e-02 -1.76625893e-01 -1.39610946e-01 -1.55866221e-01
     1.40045702e-01 -3.42336595e-02  5.93219548e-02 -1.42839015e-01]
   [-5.18756956e-02  1.35763884e-01  9.81894135e-02 -1.33831456e-01
    -1.48827434e-01  5.15295416e-02 -1.05127551e-01  8.44017863e-02
     1.17250323e-01  1.12633914e-01  1.10680908e-02 -1.19379058e-01]
   [-1.38842523e-01 -4.17533964e-02 -8.26727748e-02 -5.91531023e-02
     1.12382501e-01 -8.16313401e-02  7.49033093e-02  2.87096202e-03
     1.17437840e-01  1.01735413e-01  1.44566804e-01  1.13771379e-01]
   [-1.16637640e-01  5.05429655e-02  7.48217106e-03  7.32546151e-02
     9.94349122e-02 -7.83396289e-02 -1.66305840e-01 -1.37253538e-01
     1.25993550e-01 -1.71555489e-01  9.11465883e-02  7.38407373e-02]
   [ 1.10166609e-01 -3.80566865e-02 -9.39138532e-02 -1.52244821e-01
    -1.51174814e-02 -1.33969262e-01  1.64696008e-01  2.71832049e-02
     1.63365245e-01 -6.29455298e-02  1.39455616e-01  3.91784757e-02]]]]: "
2018-04-20 09:28:53,599 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv_1/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 09:28:53,606 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv_2/weights:0, var_value [[[[-0.02920526  0.03114332  0.07556178 ...  0.08078215  0.03317054
     0.08133997]
   [ 0.06541389 -0.0714056  -0.12045061 ... -0.01010297 -0.04065978
    -0.04366763]
   [-0.10315385  0.09700729 -0.03924992 ... -0.11348377  0.14366092
     0.14392848]
   ...
   [ 0.14039032  0.11492862 -0.13838169 ...  0.12618656 -0.14563419
     0.0656838 ]
   [-0.11907725  0.11028333 -0.08764619 ...  0.01702762  0.03354317
    -0.03116849]
   [ 0.00041163 -0.08662196 -0.10274317 ...  0.07911474  0.10078789
    -0.03744234]]

  [[ 0.12377752 -0.10194632  0.05374162 ... -0.01728672  0.07922804
    -0.12383551]
   [ 0.04989144 -0.03849512 -0.09851025 ...  0.01318242  0.01081064
     0.14884894]
   [ 0.05687344 -0.0954612   0.02583839 ... -0.00986621  0.01287015
    -0.12618616]
   ...
   [-0.09302413  0.06463918 -0.02820335 ...  0.13729946  0.04159676
     0.10923503]
   [-0.03035811 -0.07867058 -0.02609675 ... -0.0538284   0.11970116
     0.08582166]
   [-0.12506635 -0.1361765   0.03656243 ... -0.14304249 -0.02295403
    -0.14778678]]

  [[ 0.073322    0.00066382  0.01132812 ... -0.03657614  0.07289805
    -0.15138987]
   [-0.12140965  0.05063708  0.09882168 ... -0.01612529 -0.05614009
     0.05685283]
   [-0.14226279 -0.12296318  0.07010618 ... -0.09440058  0.11210941
    -0.03090063]
   ...
   [ 0.08294705 -0.03542627 -0.09705739 ... -0.06138823  0.02672639
     0.15292941]
   [ 0.06306201  0.00099602 -0.03438902 ...  0.14358433  0.01500393
    -0.10632665]
   [-0.00780861  0.06028855 -0.01955938 ...  0.06119812  0.13792737
     0.0712768 ]]]


 [[[ 0.00138822 -0.14444543  0.05700496 ... -0.1420688   0.05771205
    -0.06127967]
   [-0.142923   -0.15150027 -0.1405664  ...  0.07226712  0.14594705
     0.08877878]
   [ 0.01995686  0.08113527  0.1394745  ... -0.05097167 -0.05327528
     0.06352206]
   ...
   [-0.02183338 -0.02164148  0.14560981 ... -0.08714315  0.11033224
    -0.14970969]
   [ 0.11455075 -0.11459181  0.14244781 ...  0.14594416 -0.11412099
    -0.00499496]
   [-0.13352413 -0.13583553  0.15286417 ... -0.0552082   0.08746991
     0.15323408]]

  [[-0.1106329  -0.0358509   0.02746415 ... -0.06078894  0.04966255
     0.12742223]
   [ 0.09369339 -0.02016181  0.13986747 ... -0.07942931  0.03955626
    -0.08520231]
   [ 0.12014051 -0.1433076  -0.02773224 ... -0.04497212 -0.12718649
     0.07232293]
   ...
   [-0.11415031  0.04120016 -0.13765298 ... -0.03793531  0.09867357
     0.13389201]
   [-0.01294461 -0.13478827 -0.15234767 ... -0.08313898  0.0497714
     0.11732294]
   [-0.11552845 -0.03007513  0.1164618  ... -0.06640126 -0.14707418
     0.05282299]]

  [[-0.05480959  0.12044753 -0.01254866 ...  0.1409223  -0.10205963
    -0.08372974]
   [-0.14350599 -0.05941768 -0.11675452 ...  0.10383911 -0.00428914
    -0.09363412]
   [-0.02692752  0.10505442  0.12645723 ... -0.07301025  0.04839116
    -0.07205761]
   ...
   [ 0.06215242  0.01079732  0.00747621 ...  0.06894314  0.05767238
    -0.0177819 ]
   [-0.01610197 -0.07911693 -0.12925336 ...  0.06165558 -0.15149781
    -0.08739956]
   [ 0.00354733 -0.10406735  0.10553958 ...  0.05455711 -0.08983726
     0.11769201]]]


 [[[-0.1408274   0.05439532  0.07556535 ... -0.03507796  0.117148
    -0.11513217]
   [-0.03333833  0.05693002 -0.148012   ...  0.08571839 -0.11009482
    -0.03143985]
   [ 0.0369008   0.04954611  0.10708191 ... -0.09012675  0.00994809
    -0.14538626]
   ...
   [ 0.05741754  0.02945384  0.08636624 ...  0.14660443 -0.05157582
    -0.0426112 ]
   [ 0.125059    0.05557431 -0.04478034 ... -0.0117159   0.06688198
     0.04059625]
   [ 0.05203255  0.11688437 -0.11579502 ...  0.15246804 -0.15327331
    -0.02917311]]

  [[ 0.04812337  0.14541169 -0.02299583 ... -0.04381828  0.04496065
    -0.13958545]
   [ 0.0849608   0.02151982  0.13751878 ... -0.09880394 -0.05738863
    -0.11465292]
   [-0.04540027 -0.11332532 -0.14562838 ...  0.0929032   0.1173936
    -0.03032213]
   ...
   [-0.12221383  0.09325005  0.07185365 ...  0.09368923  0.03340632
     0.04187126]
   [-0.00506829 -0.10702516 -0.03905097 ...  0.10690762  0.14002176
     0.05246884]
   [ 0.07353538 -0.13594535 -0.03012741 ...  0.12792723 -0.04081091
    -0.1098295 ]]

  [[-0.06634346  0.02977486  0.08566067 ...  0.09430404  0.08419526
     0.08522362]
   [-0.08819869 -0.12208249  0.07034218 ...  0.0912735  -0.08815738
    -0.08286659]
   [-0.11275759 -0.05685685  0.10075052 ...  0.04972965 -0.05060253
    -0.09544295]
   ...
   [ 0.04746078  0.14117186 -0.00307433 ... -0.00714736  0.10469718
    -0.11343591]
   [-0.13416338 -0.12214646  0.0910908  ...  0.00146876 -0.04203351
     0.01481386]
   [-0.13841763  0.02974628  0.05971453 ...  0.08685987  0.01862156
    -0.02834779]]]]: "
2018-04-20 09:28:53,610 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv_2/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 09:28:53,614 (dqn_agent.py:161) DEBUG: "var_name: target_q/fully_connected/weights:0, var_value [[ 0.08157042  0.06623418  0.06776739 ...  0.05644212  0.07899103
   0.05643616]
 [ 0.02209343 -0.05179443 -0.02903633 ... -0.00462473  0.0866315
  -0.02627775]
 [-0.00445791  0.01925971  0.06567714 ... -0.03357385  0.07819278
   0.04664712]
 ...
 [ 0.03009177 -0.06488372  0.06634163 ... -0.03944565 -0.04472656
  -0.07609192]
 [-0.06219979  0.05804006 -0.01590803 ... -0.06922067 -0.0525541
   0.08135106]
 [-0.01098281 -0.08562314 -0.07261136 ... -0.08409451 -0.01397916
   0.02504937]]: "
2018-04-20 09:28:53,619 (dqn_agent.py:161) DEBUG: "var_name: target_q/fully_connected/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 09:28:53,626 (dqn_agent.py:161) DEBUG: "var_name: target_q/fully_connected_1/weights:0, var_value [[-1.33299828e-01  1.40574872e-02 -7.08519369e-02  6.46952689e-02
   9.59742069e-02]
 [-1.93864018e-01 -1.61325574e-01 -1.27446860e-01  2.11798012e-01
   1.96384192e-01]
 [-1.62822932e-01  1.54100925e-01 -2.03218877e-01  1.86855614e-01
   1.69897169e-01]
 [-1.34735703e-02  2.58669257e-04 -1.90357491e-01 -5.68246841e-03
   1.00014180e-01]
 [ 1.13576621e-01  3.52445692e-02  7.04729557e-02  9.39109623e-02
   1.04788691e-01]
 [ 4.65270877e-03 -4.56783473e-02  7.44275749e-02 -1.56244859e-01
   1.06541067e-01]
 [-3.39077413e-03 -5.53624034e-02  4.70186770e-02  2.04944879e-01
   3.21537405e-02]
 [-1.39143586e-01 -4.10440117e-02  1.65419012e-01  6.88962936e-02
   2.32711583e-02]
 [ 5.16156852e-02 -9.28531587e-03 -1.47460848e-02 -1.29877895e-01
  -2.08430141e-01]
 [-1.24819465e-01  1.29220456e-01 -1.76744461e-01 -1.65693939e-01
  -1.23002976e-01]
 [ 6.32750988e-02 -2.04019532e-01 -7.52302706e-02 -1.38983667e-01
   1.94035828e-01]
 [ 1.88507468e-01  1.17310137e-01 -9.67103615e-02 -1.20085582e-01
  -1.75580502e-01]
 [-1.36453196e-01  7.53062963e-02  1.86333507e-01  1.99722469e-01
   9.47043896e-02]
 [-8.57917666e-02  5.19664586e-02  1.13683581e-01  5.64240515e-02
  -8.79084468e-02]
 [ 4.06257510e-02  9.89227593e-02 -1.17120229e-01  1.42862946e-01
  -1.49873540e-01]
 [-2.06193388e-01  1.60203159e-01  2.06621438e-01 -5.88385612e-02
  -2.09971458e-01]
 [-1.63450658e-01 -5.57343662e-03  9.87532139e-02 -2.03066349e-01
   8.07760060e-02]
 [-1.60088852e-01 -1.01498790e-01  1.21336877e-02 -1.74619406e-02
   2.85941362e-03]
 [-9.28267837e-04  8.98760557e-02  1.31628960e-01 -2.18663663e-02
   5.96837699e-02]
 [ 1.03134096e-01 -1.22160636e-01 -8.58860016e-02  1.08571261e-01
  -1.11071490e-01]
 [-2.78026909e-02 -8.59253556e-02  1.14764988e-01  1.48713738e-01
   6.38012588e-03]
 [-1.55442983e-01 -1.29066616e-01 -1.29093245e-01 -5.37588000e-02
  -1.58720776e-01]
 [ 3.96580696e-02 -1.59128532e-01  1.77198738e-01 -1.03527457e-02
   1.32669419e-01]
 [ 2.05792040e-02 -1.53549463e-01  1.95737988e-01  1.42226875e-01
  -1.13157481e-01]
 [-1.14196606e-01  2.57390738e-03 -8.75675902e-02 -1.34542868e-01
  -1.19291604e-01]
 [ 7.68667459e-02  1.88262939e-01  9.44095552e-02 -8.99212211e-02
   9.73729193e-02]
 [ 2.07806557e-01  9.33260620e-02 -1.29229918e-01 -2.04818681e-01
   1.22991323e-01]
 [-1.07458860e-01  1.29220963e-01  7.39139616e-02 -1.23778522e-01
  -1.63169667e-01]
 [-2.27470398e-02  1.63773537e-01 -1.00449942e-01 -2.06083298e-01
  -1.72836930e-02]
 [ 5.94137609e-02 -8.15672129e-02 -1.27406180e-01 -1.91571876e-01
   1.71176940e-02]
 [-2.06798315e-02  1.38266891e-01  1.38171643e-01  1.91700399e-01
  -1.25953898e-01]
 [-5.31684905e-02 -3.75389010e-02  1.16632581e-02  3.84386182e-02
  -1.37449086e-01]
 [-4.07289416e-02 -5.69811463e-02  1.52470797e-01 -1.85510069e-01
   1.42048717e-01]
 [-4.06951606e-02  1.38778806e-01 -1.85947388e-01  1.43138587e-01
   1.28177285e-01]
 [ 8.99710357e-02 -1.61721781e-01 -3.68046761e-02 -4.57380563e-02
   4.95254993e-04]
 [-1.53600708e-01  4.52516675e-02  1.27036512e-01 -1.16491184e-01
   6.57955110e-02]
 [-6.16139024e-02 -5.18214703e-03 -1.30937845e-01 -1.14585012e-01
  -1.75196454e-01]
 [-1.94620371e-01 -2.03980654e-02 -1.58955842e-01  7.26519227e-02
  -1.73306316e-02]
 [-1.75178438e-01 -1.42431408e-02 -1.09862112e-01  2.25317180e-02
  -1.12451665e-01]
 [-1.53357133e-01 -1.09710343e-01 -1.37862548e-01  9.25220251e-02
  -1.44818902e-01]
 [ 5.81429601e-02 -1.29831821e-01 -1.75121158e-01 -4.49038148e-02
  -1.95001125e-01]
 [ 8.79958272e-03  1.03748083e-01  4.46168482e-02  1.19810611e-01
  -1.67408451e-01]
 [-1.94066912e-02 -4.55603004e-02 -1.62356049e-02 -1.00090802e-01
   6.25995994e-02]
 [ 2.04512358e-01 -5.51346838e-02  1.40624315e-01  1.60176247e-01
   1.87169224e-01]
 [ 2.11744457e-01 -3.81401479e-02  1.10687912e-02  7.24288821e-02
   8.87269974e-02]
 [ 9.30531323e-02 -9.58742499e-02  8.00922811e-02  8.39873254e-02
   8.94822776e-02]
 [ 1.53533459e-01  4.07693386e-02  1.16920471e-01  2.10090339e-01
  -4.98117507e-02]
 [ 9.24170315e-02 -8.13147277e-02  1.51871681e-01  1.61630422e-01
  -1.76149949e-01]
 [-9.98161361e-02 -1.97957620e-01  1.79989189e-02 -1.77015126e-01
   8.34802687e-02]
 [-1.34091109e-01 -2.21316665e-02 -1.89185783e-01  8.82847607e-02
   1.84389651e-01]
 [-1.12051971e-01 -1.52146801e-01  4.71714139e-02 -3.92214954e-02
  -1.32929534e-01]
 [ 1.91508263e-01  1.34995282e-01 -1.17333218e-01 -7.69265443e-02
  -3.91703099e-02]
 [-3.90403569e-02  7.71655142e-02  5.80673218e-02 -1.23770416e-01
   1.80938691e-02]
 [-1.99991658e-01 -1.30604208e-03  1.33748442e-01 -1.33045971e-01
   2.50199437e-03]
 [-1.20283075e-01 -4.17659432e-02  1.09589458e-01  6.80515766e-02
   1.12798393e-01]
 [ 9.99173522e-03  1.14754200e-01 -9.14048031e-02 -1.89841866e-01
   1.61151230e-01]
 [ 1.82970345e-01  2.11820155e-02  1.56734735e-01 -1.18818730e-01
  -4.47130501e-02]
 [-2.41348147e-02 -8.86413530e-02  1.89207852e-01 -1.25272632e-01
  -1.41281784e-01]
 [-1.16354607e-01  3.20801586e-02  1.47045374e-01 -3.08876932e-02
   2.02019781e-01]
 [ 6.14875555e-03  1.27297550e-01  7.21142292e-02 -2.00974122e-01
   2.68503129e-02]
 [ 1.92973077e-01 -7.58328438e-02  1.37268245e-01 -2.03969091e-01
  -5.90929687e-02]
 [-1.08924322e-01 -8.94440934e-02  1.97469890e-02 -1.35631725e-01
   1.10527873e-01]
 [-1.77012652e-01 -6.18345439e-02  1.03068411e-01 -1.19194679e-01
  -9.90418568e-02]
 [-4.15264666e-02  1.14324659e-01  4.54396307e-02 -2.01209292e-01
   1.91397458e-01]
 [ 2.10495889e-01  6.39667809e-02 -5.37462980e-02  1.83368206e-01
  -3.50108743e-02]
 [ 4.06920314e-02 -1.85996920e-01  4.13198769e-03 -3.35038453e-02
   1.44174308e-01]
 [ 1.62238747e-01  1.37864232e-01 -1.39489084e-01  1.02697134e-01
  -4.73292023e-02]
 [-6.67312741e-03 -1.80796742e-01  6.88863099e-02  1.51217908e-01
  -1.14925765e-01]
 [ 1.24556690e-01  1.96774036e-01  1.98205948e-01  9.99077559e-02
  -1.86149955e-01]
 [-6.42117113e-02  2.07862675e-01  8.95886123e-02 -1.92947894e-01
  -2.04674050e-01]
 [ 9.47193205e-02 -1.13070838e-01 -2.06116155e-01 -1.32610172e-01
   1.85954273e-01]
 [ 2.10419506e-01 -1.63228869e-01 -1.71216086e-01 -1.24598525e-01
  -1.54693916e-01]
 [ 1.45468861e-01 -3.27154249e-02  6.93160295e-02 -1.47741169e-01
  -1.58869356e-01]
 [-8.43391120e-02 -1.80306643e-01 -6.53254986e-03  1.79963320e-01
  -1.87741444e-01]
 [-1.16624981e-02 -2.42316425e-02 -1.79944515e-01  3.52976471e-02
  -4.84511703e-02]
 [ 1.06213987e-02  8.93397629e-03 -3.82776856e-02  1.05401129e-02
  -1.55844748e-01]
 [-1.01029508e-01  2.61832327e-02  1.35792792e-01 -1.03135407e-01
   3.71879637e-02]
 [ 9.54458416e-02 -1.16168968e-01  9.37369466e-02 -2.79847383e-02
  -1.37182206e-01]
 [-9.76120532e-02  2.05598891e-01 -1.06868811e-01  1.27204329e-01
   1.49802685e-01]
 [ 6.70772195e-02  3.02013308e-02 -7.55790323e-02 -1.99647725e-01
   7.73878396e-03]
 [ 1.14767253e-01  1.54064566e-01 -2.55355239e-03  1.31901413e-01
   1.53072029e-01]
 [-7.74801970e-02 -2.08543062e-01  6.48558140e-02  5.96918166e-03
   7.84949660e-02]
 [ 7.50566423e-02  1.12952858e-01 -1.34281576e-01  1.47529095e-01
   1.90393686e-01]
 [ 1.45587295e-01 -1.93827972e-01  2.03819215e-01  1.61185920e-01
  -1.70694143e-01]
 [ 1.84947193e-01 -9.87321138e-04  5.78837097e-02 -6.76939487e-02
   3.25574428e-02]
 [-1.23953968e-02  8.64458382e-02 -9.21477899e-02  8.11449289e-02
   2.07048833e-01]
 [ 1.52090222e-01  2.08526313e-01  9.52346325e-02  8.56096148e-02
   1.51132792e-01]
 [-1.38095587e-01  1.89284980e-01 -4.76497412e-02 -1.70217991e-01
  -6.45513535e-02]
 [ 1.62907451e-01  4.16189432e-05  5.21859229e-02 -4.28136736e-02
   2.83536464e-02]
 [ 2.49941200e-02  1.79801911e-01  2.23825872e-02  6.37984574e-02
   1.90637261e-01]
 [-1.11613177e-01  1.85310453e-01 -1.19038001e-01  1.50295615e-01
   1.55494332e-01]
 [ 2.11143196e-02 -8.70250165e-03  1.28290564e-01 -1.97300270e-01
   7.28970468e-02]
 [-2.51718163e-02  4.16837633e-02 -6.66119307e-02 -2.66940296e-02
   2.17834711e-02]
 [-5.59258163e-02  1.05253756e-01 -1.91947311e-01 -1.46291807e-01
   1.85605377e-01]
 [ 1.36108756e-01 -5.71402609e-02 -1.96304917e-03  1.74542964e-02
  -2.02672616e-01]
 [ 1.66650534e-01  9.12436843e-02  1.09799713e-01  1.00556284e-01
  -1.52703524e-01]
 [ 1.37518495e-01  1.06106132e-01 -1.89798936e-01 -1.85306042e-01
   2.87944674e-02]
 [ 2.33644396e-02 -3.53551209e-02 -1.29313275e-01  1.14356220e-01
   2.65521407e-02]
 [ 9.87855792e-02  2.04345733e-02  1.13541901e-01  1.27106309e-02
   1.28202289e-01]
 [-1.48128241e-01 -9.52904820e-02  1.90396339e-01 -2.11362988e-02
   2.09120154e-01]
 [ 1.60200477e-01 -2.08531618e-01 -4.95258421e-02 -1.57291830e-01
   1.95052624e-01]
 [ 1.00021899e-01 -3.89390886e-02 -2.34838873e-02 -3.31031829e-02
  -9.69290733e-04]
 [ 1.43746346e-01  1.96992368e-01 -5.24681509e-02 -3.16498727e-02
   1.64927810e-01]
 [-1.34221464e-01 -1.73774242e-01 -2.01056719e-01  1.65233731e-01
  -2.07562268e-01]
 [-1.62036598e-01 -1.27658367e-01  1.42982304e-01 -6.27174973e-04
  -8.96266475e-02]
 [-7.97394216e-02  5.48231006e-02 -1.03361160e-01 -4.32671010e-02
   1.03646606e-01]
 [-3.39051634e-02 -1.68837503e-01  1.50081098e-01 -9.88376290e-02
   1.41394466e-01]
 [-1.70523748e-01  7.36922920e-02 -4.59634960e-02 -1.47729874e-01
   1.26590282e-01]
 [ 3.94977927e-02 -4.23553735e-02 -1.07438959e-01  2.37901062e-02
  -1.30911961e-01]
 [ 5.04257977e-02  1.79057568e-01  2.02911735e-01  6.06529117e-02
   1.26227140e-02]
 [-9.79978219e-02  1.75997287e-01  4.79388535e-02  9.06721652e-02
  -1.76444769e-01]
 [-1.59125388e-01 -1.74650669e-01 -1.27384454e-01 -1.90612704e-01
  -4.08250093e-02]
 [ 1.83052123e-01 -5.32934219e-02  2.10260600e-01 -1.80872694e-01
  -7.23566860e-02]
 [ 7.72516429e-02  1.53194070e-01  1.58892840e-01 -2.86635011e-02
  -1.10854596e-01]
 [-1.37804210e-01 -1.53750509e-01  2.10951388e-01  3.84791195e-02
  -3.72670144e-02]
 [-2.05008924e-01  1.65603966e-01  1.37905627e-02 -1.31051019e-01
  -1.87281847e-01]
 [ 7.60070980e-02 -9.38904956e-02 -3.21145505e-02  2.05786556e-01
  -1.60290658e-01]
 [ 1.50911659e-01 -6.85408711e-04  7.17292130e-02 -1.12558112e-01
   8.05796683e-03]
 [ 1.79141074e-01  6.64601624e-02 -6.92120194e-02 -5.89349717e-02
   1.05314732e-01]
 [-5.36694676e-02  1.74739271e-01  1.08442426e-01 -6.52989000e-02
  -1.82026416e-01]
 [-1.94738805e-03 -3.06461006e-02 -1.07189305e-01  5.62258661e-02
   1.22701526e-01]
 [ 7.05108047e-04 -1.84519559e-01  8.60762596e-02 -6.98125511e-02
  -3.19413096e-02]
 [-2.30425596e-03 -1.85792834e-01 -2.10975885e-01  8.40231776e-03
  -1.17462605e-01]
 [ 7.62175024e-02  4.20083404e-02  1.55216455e-01 -9.79003385e-02
  -1.64052919e-01]
 [ 9.70424414e-02  1.73741877e-01 -3.36237103e-02  6.78210557e-02
   1.83016956e-02]
 [-1.61673069e-01 -8.19951296e-04 -1.96342975e-01  3.94056737e-03
  -2.08351642e-01]
 [-1.43294185e-01 -1.36637330e-01  1.64014935e-01 -6.10820353e-02
   1.85837388e-01]
 [ 1.45880431e-02  1.55484349e-01 -1.23854734e-01  9.29306746e-02
  -5.54155707e-02]]: "
2018-04-20 09:28:53,630 (dqn_agent.py:161) DEBUG: "var_name: target_q/fully_connected_1/biases:0, var_value [0. 0. 0. 0. 0.]: "
2018-04-20 09:28:54,502 (dqn_main.py:212) DEBUG: "Episode 1, mean reward over last 10000 episodes: 0"
2018-04-20 09:28:54,502 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:28:54,502 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -1.0, done: True"
2018-04-20 09:28:54,502 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:29,070 (dqn_main.py:61) DEBUG: ">>>> RUNNING data_file=7_17.npy,reuse_weights=None,test=True<<<<"
2018-04-20 09:30:29,491 (tf_logging.py:160) Level 1: "Registering Batch (<function _BatchGrad at 0x7fa912df4378>) in gradient."
2018-04-20 09:30:29,492 (tf_logging.py:160) Level 1: "Registering Unbatch (<function _UnbatchGrad at 0x7fa912df4e18>) in gradient."
2018-04-20 09:30:29,499 (tf_logging.py:160) Level 1: "Registering ZeroInitializer (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,524 (tf_logging.py:160) Level 1: "Registering SparseFeatureCross (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,527 (tf_logging.py:160) Level 1: "Registering SparseFeatureCrossV2 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,533 (tf_logging.py:160) Level 1: "Registering SparseFeatureCross (None) in gradient."
2018-04-20 09:30:29,534 (tf_logging.py:160) Level 1: "Registering SparseFeatureCrossV2 (None) in gradient."
2018-04-20 09:30:29,540 (tf_logging.py:160) Level 1: "Registering GDNLowerBound (<function GDN._lower_bound_grad at 0x7fa9104d76a8>) in gradient."
2018-04-20 09:30:29,568 (tf_logging.py:160) Level 1: "Registering ObtainNext (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,581 (tf_logging.py:160) Level 1: "Registering hparams ((<class 'tensorflow.contrib.training.python.training.hparam_pb2.HParamDef'>, <function HParams.to_proto at 0x7fa910093620>, <function HParams.from_proto at 0x7fa9100936a8>)) in proto functions."
2018-04-20 09:30:29,591 (tf_logging.py:160) Level 1: "Registering GRUBlockCell (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,593 (tf_logging.py:160) Level 1: "Registering GRUBlockCellGrad (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,595 (tf_logging.py:160) Level 1: "Registering GRUBlockCell (<function _GRUBlockCellGrad at 0x7fa91002cb70>) in gradient."
2018-04-20 09:30:29,597 (tf_logging.py:160) Level 1: "Registering BlockLSTM (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,599 (tf_logging.py:160) Level 1: "Registering BlockLSTMGrad (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,600 (tf_logging.py:160) Level 1: "Registering LSTMBlockCell (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,602 (tf_logging.py:160) Level 1: "Registering LSTMBlockCellGrad (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,605 (tf_logging.py:160) Level 1: "Registering LSTMBlockCell (<function _LSTMBlockCellGrad at 0x7fa9082e0d90>) in gradient."
2018-04-20 09:30:29,605 (tf_logging.py:160) Level 1: "Registering BlockLSTM (<function _BlockLSTMGrad at 0x7fa9082e0e18>) in gradient."
2018-04-20 09:30:29,610 (tf_logging.py:160) Level 1: "Registering KMC2ChainInitialization (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,611 (tf_logging.py:160) Level 1: "Registering KmeansPlusPlusInitialization (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,613 (tf_logging.py:160) Level 1: "Registering NearestNeighbors (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,616 (tf_logging.py:160) Level 1: "Registering MaskedMatmul (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,618 (tf_logging.py:160) Level 1: "Registering WALSComputePartialLhsAndRhs (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,633 (tf_logging.py:160) Level 1: "Registering ConfigureDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,634 (tf_logging.py:160) Level 1: "Registering CrossReplicaSum (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,635 (tf_logging.py:160) Level 1: "Registering InfeedDequeue (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,636 (tf_logging.py:160) Level 1: "Registering InfeedDequeueTuple (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,636 (tf_logging.py:160) Level 1: "Registering InfeedEnqueue (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,637 (tf_logging.py:160) Level 1: "Registering InfeedEnqueueTuple (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,638 (tf_logging.py:160) Level 1: "Registering OutfeedDequeue (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,638 (tf_logging.py:160) Level 1: "Registering OutfeedDequeueTuple (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,639 (tf_logging.py:160) Level 1: "Registering OutfeedEnqueue (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,639 (tf_logging.py:160) Level 1: "Registering OutfeedEnqueueTuple (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,640 (tf_logging.py:160) Level 1: "Registering ShutdownDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,641 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingActivations (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,641 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingEnqueueSparseBatch (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,642 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingLoadAdagradParameters (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,643 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingLoadGradientDescentParameters (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,643 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingReceiveActivations (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,653 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingRetrieveAdagradParameters (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,653 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingRetrieveGradientDescentParameters (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,654 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingSendGradients (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,655 (tf_logging.py:160) Level 1: "Registering TPUReplicate (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,655 (tf_logging.py:160) Level 1: "Registering TPUReplicateMetadata (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,656 (tf_logging.py:160) Level 1: "Registering TPUReplicatedInput (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,657 (tf_logging.py:160) Level 1: "Registering TPUReplicatedOutput (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,673 (tf_logging.py:160) Level 1: "Registering _ConfigureDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,674 (tf_logging.py:160) Level 1: "Registering _WaitForDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,675 (tf_logging.py:160) Level 1: "Registering _SetGlobalTPUArray (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,676 (tf_logging.py:160) Level 1: "Registering _ShutdownDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,676 (tf_logging.py:160) Level 1: "Registering _InitializeHostForDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,677 (tf_logging.py:160) Level 1: "Registering _DisconnectHostFromDistributedTPUSystem (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,679 (tf_logging.py:160) Level 1: "Registering CrossReplicaSum (<function _cross_replica_sum_grad at 0x7fa908198400>) in gradient."
2018-04-20 09:30:29,692 (tf_logging.py:160) Level 1: "Registering CloseSummaryWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,694 (tf_logging.py:160) Level 1: "Registering CreateSummaryDbWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,695 (tf_logging.py:160) Level 1: "Registering CreateSummaryFileWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,695 (tf_logging.py:160) Level 1: "Registering FlushSummaryWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,696 (tf_logging.py:160) Level 1: "Registering ImportEvent (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,697 (tf_logging.py:160) Level 1: "Registering SummaryWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,697 (tf_logging.py:160) Level 1: "Registering WriteAudioSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,723 (tf_logging.py:160) Level 1: "Registering WriteGraphSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,724 (tf_logging.py:160) Level 1: "Registering WriteHistogramSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,724 (tf_logging.py:160) Level 1: "Registering WriteImageSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,725 (tf_logging.py:160) Level 1: "Registering WriteScalarSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,725 (tf_logging.py:160) Level 1: "Registering WriteSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,763 (tf_logging.py:160) Level 1: "Registering BigQueryReader (None) in gradient."
2018-04-20 09:30:29,766 (tf_logging.py:160) Level 1: "Registering RangeDecode (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,767 (tf_logging.py:160) Level 1: "Registering RangeEncode (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,802 (tf_logging.py:160) Level 1: "Registering CudnnRNN (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,806 (tf_logging.py:160) Level 1: "Registering CudnnRNNBackprop (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,807 (tf_logging.py:160) Level 1: "Registering CudnnRNNCanonicalToParams (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,808 (tf_logging.py:160) Level 1: "Registering CudnnRNNParamsSize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,810 (tf_logging.py:160) Level 1: "Registering CudnnRNNParamsToCanonical (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,819 (tf_logging.py:160) Level 1: "Registering CudnnRNN (<function _cudnn_rnn_backward at 0x7fa8d5d546a8>) in gradient."
2018-04-20 09:30:29,821 (tf_logging.py:160) Level 1: "Registering CudnnRNNParamsSize (<function call_cpp_shape_fn at 0x7fa97e53d840>) in shape functions."
2018-04-20 09:30:29,822 (tf_logging.py:160) Level 1: "Registering CudnnRNNParamsToCanonical (<function call_cpp_shape_fn at 0x7fa97e53d840>) in shape functions."
2018-04-20 09:30:29,822 (tf_logging.py:160) Level 1: "Registering CudnnRNNCanonicalToParams (<function call_cpp_shape_fn at 0x7fa97e53d840>) in shape functions."
2018-04-20 09:30:29,823 (tf_logging.py:160) Level 1: "Registering CudnnRNN (<function call_cpp_shape_fn at 0x7fa97e53d840>) in shape functions."
2018-04-20 09:30:29,824 (tf_logging.py:160) Level 1: "Registering CudnnRNNBackprop (<function call_cpp_shape_fn at 0x7fa97e53d840>) in shape functions."
2018-04-20 09:30:29,856 (tf_logging.py:160) Level 1: "Registering AdjustHsvInYiq (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,860 (tf_logging.py:160) Level 1: "Registering BipartiteMatch (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,861 (tf_logging.py:160) Level 1: "Registering ImageConnectedComponents (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,862 (tf_logging.py:160) Level 1: "Registering ImageProjectiveTransform (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,865 (tf_logging.py:160) Level 1: "Registering ImageConnectedComponents (<function call_cpp_shape_fn at 0x7fa97e53d840>) in shape functions."
2018-04-20 09:30:29,866 (tf_logging.py:160) Level 1: "Registering ImageProjectiveTransform (<function call_cpp_shape_fn at 0x7fa97e53d840>) in shape functions."
2018-04-20 09:30:29,867 (tf_logging.py:160) Level 1: "Registering ImageProjectiveTransform (<function _image_projective_transform_grad at 0x7fa8d5674b70>) in gradient."
2018-04-20 09:30:29,867 (tf_logging.py:160) Level 1: "Registering BipartiteMatch (None) in gradient."
2018-04-20 09:30:29,868 (tf_logging.py:160) Level 1: "Registering ImageConnectedComponents (None) in gradient."
2018-04-20 09:30:29,869 (tf_logging.py:160) Level 1: "Registering SingleImageRandomDotStereograms (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,874 (tf_logging.py:160) Level 1: "Registering SingleImageRandomDotStereograms (None) in gradient."
2018-04-20 09:30:29,904 (tf_logging.py:160) Level 1: "Registering BytesInUse (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,904 (tf_logging.py:160) Level 1: "Registering BytesLimit (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,905 (tf_logging.py:160) Level 1: "Registering MaxBytesInUse (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,910 (tf_logging.py:160) Level 1: "Registering NcclAllReduce (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,910 (tf_logging.py:160) Level 1: "Registering NcclBroadcast (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,911 (tf_logging.py:160) Level 1: "Registering NcclReduce (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,913 (tf_logging.py:160) Level 1: "Registering _NcclReduceSend (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,914 (tf_logging.py:160) Level 1: "Registering _NcclReduceRecv (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,914 (tf_logging.py:160) Level 1: "Registering _NcclBroadcastSend (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,914 (tf_logging.py:160) Level 1: "Registering _NcclBroadcastRecv (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,915 (tf_logging.py:160) Level 1: "Registering NcclAllReduce (<function _all_sum_grad at 0x7fa8d4d26950>) in gradient."
2018-04-20 09:30:29,915 (tf_logging.py:160) Level 1: "Registering NcclReduce (<function _reduce_sum_grad at 0x7fa8d4d26bf8>) in gradient."
2018-04-20 09:30:29,915 (tf_logging.py:160) Level 1: "Registering NcclBroadcast (<function _broadcast_grad at 0x7fa8d4d26d90>) in gradient."
2018-04-20 09:30:29,916 (tf_logging.py:160) Level 1: "Registering PeriodicResample (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,921 (tf_logging.py:160) Level 1: "Registering FoldFusedBatchNormGrad (<function _FoldFusedBatchNormGrad at 0x7fa8d4a6c048>) in gradient."
2018-04-20 09:30:29,924 (tf_logging.py:160) Level 1: "Registering Resampler (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,925 (tf_logging.py:160) Level 1: "Registering ResamplerGrad (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,926 (tf_logging.py:160) Level 1: "Registering Resampler (<function _resampler_grad at 0x7fa8d479ac80>) in gradient."
2018-04-20 09:30:29,927 (tf_logging.py:160) Level 1: "Registering ResamplerGrad (None) in gradient."
2018-04-20 09:30:29,930 (tf_logging.py:160) Level 1: "Registering GatherTree (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,940 (tf_logging.py:160) Level 1: "Registering StatelessRandomNormal (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,941 (tf_logging.py:160) Level 1: "Registering StatelessRandomUniform (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,941 (tf_logging.py:160) Level 1: "Registering StatelessTruncatedNormal (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,942 (tf_logging.py:160) Level 1: "Registering StatelessRandomNormal (None) in gradient."
2018-04-20 09:30:29,942 (tf_logging.py:160) Level 1: "Registering StatelessRandomUniform (None) in gradient."
2018-04-20 09:30:29,942 (tf_logging.py:160) Level 1: "Registering StatelessTruncatedNormal (None) in gradient."
2018-04-20 09:30:29,949 (tf_logging.py:160) Level 1: "Registering ReinterpretStringToFloat (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,951 (tf_logging.py:160) Level 1: "Registering ScatterAddNdim (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,958 (tf_logging.py:160) Level 1: "Registering CreateTreeVariable (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,958 (tf_logging.py:160) Level 1: "Registering DecisionTreeResourceHandleOp (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,959 (tf_logging.py:160) Level 1: "Registering FeatureUsageCounts (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,959 (tf_logging.py:160) Level 1: "Registering TraverseTreeV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,959 (tf_logging.py:160) Level 1: "Registering TreeDeserialize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,959 (tf_logging.py:160) Level 1: "Registering TreeIsInitializedOp (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,960 (tf_logging.py:160) Level 1: "Registering TreePredictionsV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,961 (tf_logging.py:160) Level 1: "Registering TreeSerialize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,961 (tf_logging.py:160) Level 1: "Registering TreeSize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,961 (tf_logging.py:160) Level 1: "Registering UpdateModelV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,964 (tf_logging.py:160) Level 1: "Registering TreeVariable (None) in gradient."
2018-04-20 09:30:29,965 (tf_logging.py:160) Level 1: "Registering TreeSerialize (None) in gradient."
2018-04-20 09:30:29,965 (tf_logging.py:160) Level 1: "Registering TreeDeserialize (None) in gradient."
2018-04-20 09:30:29,965 (tf_logging.py:160) Level 1: "Registering TreeSize (None) in gradient."
2018-04-20 09:30:29,965 (tf_logging.py:160) Level 1: "Registering TreePredictionsV4 (None) in gradient."
2018-04-20 09:30:29,966 (tf_logging.py:160) Level 1: "Registering FeatureUsageCounts (None) in gradient."
2018-04-20 09:30:29,966 (tf_logging.py:160) Level 1: "Registering CreateFertileStatsVariable (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,967 (tf_logging.py:160) Level 1: "Registering FertileStatsDeserialize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,967 (tf_logging.py:160) Level 1: "Registering FertileStatsIsInitializedOp (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,967 (tf_logging.py:160) Level 1: "Registering FertileStatsResourceHandleOp (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,967 (tf_logging.py:160) Level 1: "Registering FertileStatsSerialize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,968 (tf_logging.py:160) Level 1: "Registering FinalizeTree (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,968 (tf_logging.py:160) Level 1: "Registering GrowTreeV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,968 (tf_logging.py:160) Level 1: "Registering ProcessInputV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,971 (tf_logging.py:160) Level 1: "Registering FertileStatsVariable (None) in gradient."
2018-04-20 09:30:29,971 (tf_logging.py:160) Level 1: "Registering FertileStatsSerialize (None) in gradient."
2018-04-20 09:30:29,971 (tf_logging.py:160) Level 1: "Registering FertileStatsDeserialize (None) in gradient."
2018-04-20 09:30:29,972 (tf_logging.py:160) Level 1: "Registering GrowTreeV4 (None) in gradient."
2018-04-20 09:30:29,972 (tf_logging.py:160) Level 1: "Registering ProcessInputV4 (None) in gradient."
2018-04-20 09:30:29,972 (tf_logging.py:160) Level 1: "Registering FinalizeTree (None) in gradient."
2018-04-20 09:30:29,986 (tf_logging.py:160) Level 1: "Registering FunctionBufferingResource (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,987 (tf_logging.py:160) Level 1: "Registering FunctionBufferingResourceGetNext (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,994 (tf_logging.py:160) Level 1: "Registering RemoteFusedGraphExecute (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7fa97e53d950>) in default shape functions."
2018-04-20 09:30:29,995 (tf_logging.py:160) Level 1: "Registering RemoteFusedGraphExecute (None) in gradient."
2018-04-20 09:30:30,019 (tf_logging.py:160) Level 1: "Created variable q/Conv/weights:0 with shape (1, 1, 2, 8) and init <function variance_scaling_initializer.<locals>._initializer at 0x7fa9104ce510>"
2018-04-20 09:30:30,023 (tf_logging.py:160) Level 1: "Created variable q/Conv/biases:0 with shape (8,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa9104d3208>"
2018-04-20 09:30:30,044 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/weights:0 with shape (3, 3, 8, 12) and init <function variance_scaling_initializer.<locals>._initializer at 0x7fa9104ce510>"
2018-04-20 09:30:30,048 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/biases:0 with shape (12,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa9104d3208>"
2018-04-20 09:30:30,070 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/weights:0 with shape (3, 3, 12, 16) and init <function variance_scaling_initializer.<locals>._initializer at 0x7fa9104ce510>"
2018-04-20 09:30:30,086 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/biases:0 with shape (16,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa9104d3208>"
2018-04-20 09:30:30,107 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/weights:0 with shape (576, 128) and init <function variance_scaling_initializer.<locals>._initializer at 0x7fa9104d72f0>"
2018-04-20 09:30:30,111 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/biases:0 with shape (128,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa9104d35f8>"
2018-04-20 09:30:30,117 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/weights:0 with shape (128, 5) and init <function variance_scaling_initializer.<locals>._initializer at 0x7fa9104d72f0>"
2018-04-20 09:30:30,121 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/biases:0 with shape (5,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa9104d35f8>"
2018-04-20 09:30:30,128 (tf_logging.py:160) Level 1: "Created variable target_q/Conv/weights:0 with shape (1, 1, 2, 8) and init <function variance_scaling_initializer.<locals>._initializer at 0x7fa9104ce510>"
2018-04-20 09:30:30,132 (tf_logging.py:160) Level 1: "Created variable target_q/Conv/biases:0 with shape (8,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa9104d3208>"
2018-04-20 09:30:30,139 (tf_logging.py:160) Level 1: "Created variable target_q/Conv_1/weights:0 with shape (3, 3, 8, 12) and init <function variance_scaling_initializer.<locals>._initializer at 0x7fa9104ce510>"
2018-04-20 09:30:30,142 (tf_logging.py:160) Level 1: "Created variable target_q/Conv_1/biases:0 with shape (12,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa9104d3208>"
2018-04-20 09:30:30,150 (tf_logging.py:160) Level 1: "Created variable target_q/Conv_2/weights:0 with shape (3, 3, 12, 16) and init <function variance_scaling_initializer.<locals>._initializer at 0x7fa9104ce510>"
2018-04-20 09:30:30,153 (tf_logging.py:160) Level 1: "Created variable target_q/Conv_2/biases:0 with shape (16,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa9104d3208>"
2018-04-20 09:30:30,165 (tf_logging.py:160) Level 1: "Created variable target_q/fully_connected/weights:0 with shape (576, 128) and init <function variance_scaling_initializer.<locals>._initializer at 0x7fa9104d72f0>"
2018-04-20 09:30:30,168 (tf_logging.py:160) Level 1: "Created variable target_q/fully_connected/biases:0 with shape (128,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa9104d35f8>"
2018-04-20 09:30:30,175 (tf_logging.py:160) Level 1: "Created variable target_q/fully_connected_1/weights:0 with shape (128, 5) and init <function variance_scaling_initializer.<locals>._initializer at 0x7fa9104d72f0>"
2018-04-20 09:30:30,193 (tf_logging.py:160) Level 1: "Created variable target_q/fully_connected_1/biases:0 with shape (5,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa9104d35f8>"
2018-04-20 09:30:30,267 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/value'"
2018-04-20 09:30:30,274 (tf_logging.py:160) Level 1: "  in  --> gradients/Fill:0"
2018-04-20 09:30:30,274 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/value_grad/tuple/control_dependency:0, gradients/mean_squared_error/value_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,284 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/div'"
2018-04-20 09:30:30,293 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/value_grad/tuple/control_dependency:0"
2018-04-20 09:30:30,294 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/div_grad/tuple/control_dependency:0, gradients/mean_squared_error/div_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,297 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/Sum_1'"
2018-04-20 09:30:30,297 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/div_grad/tuple/control_dependency:0"
2018-04-20 09:30:30,297 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/Sum_1_grad/Tile:0"
2018-04-20 09:30:30,301 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/Select'"
2018-04-20 09:30:30,302 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/div_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,302 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/Select_grad/tuple/control_dependency:0, gradients/mean_squared_error/Select_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,304 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/Sum'"
2018-04-20 09:30:30,304 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/Sum_1_grad/Tile:0"
2018-04-20 09:30:30,304 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/Sum_grad/Tile:0"
2018-04-20 09:30:30,310 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/Mul'"
2018-04-20 09:30:30,311 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/Sum_grad/Tile:0"
2018-04-20 09:30:30,311 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/Mul_grad/tuple/control_dependency:0, gradients/mean_squared_error/Mul_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,313 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/num_present'"
2018-04-20 09:30:30,313 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/Select_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,313 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/num_present_grad/Tile:0"
2018-04-20 09:30:30,319 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/num_present/broadcast_weights'"
2018-04-20 09:30:30,319 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/num_present_grad/Tile:0"
2018-04-20 09:30:30,319 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/num_present/broadcast_weights_grad/tuple/control_dependency:0, gradients/mean_squared_error/num_present/broadcast_weights_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,320 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/num_present/broadcast_weights/ones_like'"
2018-04-20 09:30:30,320 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/num_present/broadcast_weights_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,320 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/num_present/broadcast_weights/ones_like_grad/Sum:0"
2018-04-20 09:30:30,326 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/SquaredDifference'"
2018-04-20 09:30:30,327 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/Mul_grad/tuple/control_dependency:0"
2018-04-20 09:30:30,327 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/SquaredDifference_grad/tuple/control_dependency:0, gradients/mean_squared_error/SquaredDifference_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,334 (tf_logging.py:160) Level 1: "Gradient for 'Sum'"
2018-04-20 09:30:30,334 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/SquaredDifference_grad/tuple/control_dependency:0"
2018-04-20 09:30:30,334 (tf_logging.py:160) Level 1: "  out --> gradients/Sum_grad/Tile:0"
2018-04-20 09:30:30,339 (tf_logging.py:160) Level 1: "Gradient for 'mul'"
2018-04-20 09:30:30,339 (tf_logging.py:160) Level 1: "  in  --> gradients/Sum_grad/Tile:0"
2018-04-20 09:30:30,339 (tf_logging.py:160) Level 1: "  out --> gradients/mul_grad/tuple/control_dependency:0, gradients/mul_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,341 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected_1/BiasAdd'"
2018-04-20 09:30:30,341 (tf_logging.py:160) Level 1: "  in  --> gradients/mul_grad/tuple/control_dependency:0"
2018-04-20 09:30:30,341 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency:0, gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,344 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected_1/MatMul'"
2018-04-20 09:30:30,344 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 09:30:30,344 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency:0, gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,344 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected_1/biases/read'"
2018-04-20 09:30:30,344 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,344 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,345 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/Relu'"
2018-04-20 09:30:30,345 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency:0"
2018-04-20 09:30:30,345 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/Relu_grad/ReluGrad:0"
2018-04-20 09:30:30,345 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected_1/weights/read'"
2018-04-20 09:30:30,346 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,346 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,347 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/BiasAdd'"
2018-04-20 09:30:30,348 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/Relu_grad/ReluGrad:0"
2018-04-20 09:30:30,348 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency:0, gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,350 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/MatMul'"
2018-04-20 09:30:30,350 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 09:30:30,350 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/MatMul_grad/tuple/control_dependency:0, gradients/q/fully_connected/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,351 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/biases/read'"
2018-04-20 09:30:30,351 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,351 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,352 (tf_logging.py:160) Level 1: "Gradient for 'q/Flatten/flatten/Reshape'"
2018-04-20 09:30:30,352 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/MatMul_grad/tuple/control_dependency:0"
2018-04-20 09:30:30,352 (tf_logging.py:160) Level 1: "  out --> gradients/q/Flatten/flatten/Reshape_grad/Reshape:0"
2018-04-20 09:30:30,352 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/weights/read'"
2018-04-20 09:30:30,352 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,352 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,353 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/Relu'"
2018-04-20 09:30:30,353 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Flatten/flatten/Reshape_grad/Reshape:0"
2018-04-20 09:30:30,353 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/Relu_grad/ReluGrad:0"
2018-04-20 09:30:30,355 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/BiasAdd'"
2018-04-20 09:30:30,355 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/Relu_grad/ReluGrad:0"
2018-04-20 09:30:30,355 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency:0, gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,359 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/Conv2D'"
2018-04-20 09:30:30,360 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 09:30:30,360 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency:0, gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,360 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/biases/read'"
2018-04-20 09:30:30,360 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,360 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,361 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/Relu'"
2018-04-20 09:30:30,361 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency:0"
2018-04-20 09:30:30,361 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/Relu_grad/ReluGrad:0"
2018-04-20 09:30:30,361 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/weights/read'"
2018-04-20 09:30:30,361 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,361 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,363 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/BiasAdd'"
2018-04-20 09:30:30,363 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/Relu_grad/ReluGrad:0"
2018-04-20 09:30:30,363 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency:0, gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,367 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/Conv2D'"
2018-04-20 09:30:30,367 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 09:30:30,367 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency:0, gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,368 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/biases/read'"
2018-04-20 09:30:30,368 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,368 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,368 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/Relu'"
2018-04-20 09:30:30,369 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency:0"
2018-04-20 09:30:30,369 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/Relu_grad/ReluGrad:0"
2018-04-20 09:30:30,369 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/weights/read'"
2018-04-20 09:30:30,369 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,369 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,371 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/BiasAdd'"
2018-04-20 09:30:30,371 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv/Relu_grad/ReluGrad:0"
2018-04-20 09:30:30,371 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/BiasAdd_grad/tuple/control_dependency:0, gradients/q/Conv/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,375 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/Conv2D'"
2018-04-20 09:30:30,375 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 09:30:30,375 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/Conv2D_grad/tuple/control_dependency:0, gradients/q/Conv/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,376 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/biases/read'"
2018-04-20 09:30:30,376 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,376 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,376 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/weights/read'"
2018-04-20 09:30:30,376 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,376 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:30,477 (tf_logging.py:126) WARNING: "From /home/syedeqbal/.local/lib/python3.5/site-packages/tensorflow/python/ops/clip_ops.py:113: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead"
2018-04-20 09:30:30,584 (tf_logging.py:160) Level 1: "Created variable q/Conv/weights/Adam:0 with shape (1, 1, 2, 8) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa8b8ddf358>"
2018-04-20 09:30:30,597 (tf_logging.py:160) Level 1: "Created variable q/Conv/weights/Adam_1:0 with shape (1, 1, 2, 8) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa8b8ddf358>"
2018-04-20 09:30:30,607 (tf_logging.py:160) Level 1: "Created variable q/Conv/biases/Adam:0 with shape (8,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa8b8ddf358>"
2018-04-20 09:30:30,617 (tf_logging.py:160) Level 1: "Created variable q/Conv/biases/Adam_1:0 with shape (8,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa8b8ddf358>"
2018-04-20 09:30:30,627 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/weights/Adam:0 with shape (3, 3, 8, 12) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa8b8ddf358>"
2018-04-20 09:30:30,640 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/weights/Adam_1:0 with shape (3, 3, 8, 12) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa8b8ddf358>"
2018-04-20 09:30:30,649 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/biases/Adam:0 with shape (12,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa8b8ddf358>"
2018-04-20 09:30:30,658 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/biases/Adam_1:0 with shape (12,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa8b8ddf358>"
2018-04-20 09:30:30,661 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/weights/Adam:0 with shape (3, 3, 12, 16) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa8b8ddf358>"
2018-04-20 09:30:30,665 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/weights/Adam_1:0 with shape (3, 3, 12, 16) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa8b8e0cf28>"
2018-04-20 09:30:30,668 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/biases/Adam:0 with shape (16,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa8b8e0cf28>"
2018-04-20 09:30:30,670 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/biases/Adam_1:0 with shape (16,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa8b8e0cf28>"
2018-04-20 09:30:30,673 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/weights/Adam:0 with shape (576, 128) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa8b8e0cf28>"
2018-04-20 09:30:30,675 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/weights/Adam_1:0 with shape (576, 128) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa8b8e0cf28>"
2018-04-20 09:30:30,678 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/biases/Adam:0 with shape (128,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa8b8e0cf28>"
2018-04-20 09:30:30,680 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/biases/Adam_1:0 with shape (128,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa8b8e0cf28>"
2018-04-20 09:30:30,683 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/weights/Adam:0 with shape (128, 5) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa8b8e0cf28>"
2018-04-20 09:30:30,685 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/weights/Adam_1:0 with shape (128, 5) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa8b8e0cf28>"
2018-04-20 09:30:30,688 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/biases/Adam:0 with shape (5,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa8b8e0cf28>"
2018-04-20 09:30:30,691 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/biases/Adam_1:0 with shape (5,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7fa8b8e0cf28>"
2018-04-20 09:30:30,819 (dqn_agent.py:161) DEBUG: "var_name: q/Conv/weights:0, var_value [[[[ 0.16578859 -0.16878021  0.7039348  -0.5990083  -0.5231885
     0.12528002  0.3845706   0.58010113]
   [-0.1548481  -0.41433412 -0.21852148 -0.35893342  0.6082158
     0.3999889   0.58211505 -0.26015198]]]]: "
2018-04-20 09:30:30,825 (dqn_agent.py:161) DEBUG: "var_name: q/Conv/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 09:30:30,837 (dqn_agent.py:161) DEBUG: "var_name: q/Conv_1/weights:0, var_value [[[[ 1.50372803e-01 -4.65755910e-02  6.63120598e-02 -1.35417745e-01
    -8.24370235e-02 -1.52714670e-01 -1.77968279e-01 -1.38832420e-01
    -1.16875656e-01  1.51195586e-01  1.10575348e-01  9.78565514e-02]
   [ 9.89191234e-02  7.67598152e-02 -1.66469067e-02  7.34809935e-02
     8.29356015e-02  1.19481683e-02 -1.79388598e-01 -1.44438356e-01
     7.07273185e-03 -1.77472010e-01  8.87598395e-02  1.48418576e-01]
   [-1.66158974e-01 -1.18967593e-02 -4.12107557e-02 -1.54847249e-01
     1.17666066e-01 -1.38515577e-01  1.65102780e-02 -1.09486468e-01
    -1.41777694e-01  9.60279405e-02  2.53623426e-02 -1.03353307e-01]
   [ 5.52144647e-03  9.48200822e-02  3.09036374e-02  1.07741743e-01
    -1.58003852e-01  1.00059152e-01 -3.98937464e-02 -1.39132082e-01
     1.46161884e-01 -9.86199975e-02  5.65466583e-02 -1.79113835e-01]
   [-1.25564590e-01  1.41239941e-01 -5.20381778e-02 -6.02059364e-02
     3.34170163e-02  7.30284750e-02 -8.97882581e-02 -4.29988056e-02
    -1.51726469e-01  3.51880342e-02 -7.81367794e-02 -3.25431228e-02]
   [ 1.82122052e-01 -9.67563912e-02  1.00072682e-01 -1.05278946e-01
    -3.69303375e-02  4.92800772e-03 -2.31504589e-02 -5.03832102e-03
     1.81149483e-01  1.81027949e-01  1.24728292e-01 -1.31427914e-01]
   [-1.80586249e-01 -1.36025965e-01  4.48914468e-02 -5.97371310e-02
    -6.78593963e-02 -6.46777675e-02  1.34997427e-01  1.21811777e-02
     9.64576602e-02  1.58229679e-01  1.37813747e-01 -2.31378824e-02]
   [-9.52447131e-02  1.47893041e-01 -3.06760669e-02 -2.78017670e-02
    -2.98631638e-02 -1.24209307e-01  9.12289321e-02 -9.49710608e-04
     1.14439696e-01  1.43336982e-01 -1.32964581e-01 -9.92896929e-02]]

  [[-6.49723262e-02  1.58546180e-01  5.85785955e-02 -1.50315136e-01
    -6.15584701e-02 -1.41734332e-01  6.16731346e-02 -1.22978218e-01
     1.81306928e-01 -2.63602883e-02  1.26414150e-02 -1.50923759e-01]
   [-1.40209600e-01 -9.67322737e-02  1.24145299e-02  6.59394115e-02
     1.41328335e-01  8.43215585e-02  1.14990234e-01 -1.16814151e-01
     3.76809388e-02  2.42543519e-02  5.33993393e-02 -7.67892525e-02]
   [-9.87472758e-02  1.74100071e-01  4.51567620e-02  1.41774416e-01
     1.41309172e-01  2.58868784e-02 -1.43943951e-01 -1.37666881e-01
     1.47413224e-01  1.99114233e-02  1.03365660e-01 -9.21891481e-02]
   [-1.67833194e-01  1.96955949e-02 -1.77946121e-01 -1.34419441e-01
     1.75737649e-01  8.71360302e-03  3.25536728e-03 -1.43141359e-01
     1.20177001e-01 -1.45054042e-01  1.27553076e-01  1.53062642e-02]
   [-1.55145079e-02  1.71647877e-01  4.45766449e-02  8.31186771e-02
    -7.10270032e-02 -1.09896958e-02 -2.90575325e-02 -6.20858297e-02
    -4.92762625e-02  2.22920179e-02 -5.88739440e-02  1.71498477e-01]
   [-8.99066553e-02 -1.71779886e-01 -1.65016860e-01  1.04004711e-01
     9.67311859e-03 -1.54113770e-02 -1.70659572e-01 -8.31511989e-02
     3.37359458e-02  1.55402720e-03  9.14124548e-02  7.11061060e-03]
   [-1.43738240e-01 -1.68416440e-01 -1.72697783e-01 -1.13055982e-01
     1.71616912e-01  1.39764518e-01 -1.03619576e-01  1.14000082e-01
    -9.52616334e-03  1.18024051e-01 -4.03728336e-02  1.08210146e-01]
   [ 1.73561484e-01  9.88033414e-02 -1.72187835e-01  1.25137299e-01
    -1.23160735e-01  7.95265436e-02  8.18993449e-02  2.86989361e-02
     2.07359940e-02 -7.31796026e-05  1.80210263e-01  6.27235323e-02]]

  [[ 6.60870969e-03 -1.21559039e-01 -6.81037679e-02  4.53340560e-02
     7.55124092e-02  1.80749804e-01 -7.44268298e-03 -5.38325906e-02
    -1.13388635e-01 -3.08124125e-02 -1.79469511e-01  1.35015100e-01]
   [ 1.67978674e-01  1.71190590e-01 -1.61744744e-01  6.67512417e-04
     1.17815793e-01  2.60507613e-02  3.34459543e-02  1.59345895e-01
    -1.78536028e-01  1.41344666e-01  1.04296505e-02 -7.02945814e-02]
   [ 4.77891862e-02 -1.02742903e-01  1.56789571e-02 -1.36362284e-01
     1.65883392e-01 -1.68079048e-01  1.21308386e-01 -1.42047554e-02
     8.56704414e-02 -7.17130676e-02  1.17512047e-01 -8.82266909e-02]
   [-3.50956172e-02 -8.91575217e-02  3.36481035e-02 -1.23550743e-02
    -7.22268820e-02  1.74243808e-01 -1.39517486e-01  1.28090173e-01
    -1.26272231e-01  1.55808061e-01  2.08957046e-02 -1.18645594e-01]
   [ 7.13585317e-02 -3.16085517e-02 -1.65610015e-03 -8.18596482e-02
     7.13812411e-02  1.46497369e-01 -1.18483707e-01 -4.29078937e-03
     5.63763082e-03 -4.74429578e-02 -9.13266167e-02  6.01610541e-02]
   [-3.59444022e-02  2.49007642e-02  8.52181911e-02  1.11225158e-01
    -1.68843284e-01  1.38022453e-02 -1.29408032e-01 -1.27537102e-01
    -1.64736927e-01 -1.63101792e-01 -5.62077910e-02  4.17557508e-02]
   [-4.67253774e-02 -1.25943989e-01  1.78297579e-01  7.24245906e-02
     1.71259105e-01 -1.48414478e-01  8.97851586e-02  1.71935797e-01
    -1.20076180e-01  6.27714545e-02 -1.31946474e-01  5.90580702e-03]
   [-1.11516714e-02 -4.76029217e-02 -8.17512199e-02 -6.77612349e-02
    -6.90109134e-02 -1.18763387e-01  1.14549041e-01  1.24193341e-01
    -4.94612157e-02  1.08101368e-01 -4.13815677e-02  1.03034586e-01]]]


 [[[ 1.03024930e-01 -7.02546537e-03 -2.97795087e-02  9.59316492e-02
    -1.21294126e-01 -8.22076201e-02 -8.04460421e-02  1.67265356e-01
    -7.78349936e-02  1.49735332e-01  4.41252887e-02  1.56957269e-01]
   [ 5.70124686e-02  2.57944614e-02 -1.11137785e-01 -7.57582635e-02
     1.59029961e-02 -1.73812002e-01  4.12420630e-02  1.76606685e-01
    -1.10035628e-01 -1.08016923e-01 -7.28153959e-02 -4.51277643e-02]
   [ 1.05051905e-01 -3.10264379e-02  8.81486833e-02  1.43133968e-01
     3.28181833e-02  1.27911597e-01 -3.45832855e-02  1.39498591e-01
     1.14050001e-01 -4.24026698e-02 -8.59723687e-02 -1.65779963e-01]
   [-6.03268147e-02 -1.46665573e-02 -1.37881398e-01  3.95148993e-03
    -5.62563688e-02  8.25574100e-02 -6.08313605e-02 -1.90340877e-02
    -7.64632225e-03 -1.05154760e-01  1.13561392e-01 -5.71756214e-02]
   [ 1.35875374e-01 -1.67817473e-01  1.01750970e-01 -8.54162350e-02
    -1.76406413e-01  1.36459082e-01 -4.39292789e-02 -2.14182138e-02
     1.56653315e-01 -1.64324746e-01 -1.60880029e-01 -8.23006034e-04]
   [ 9.53239202e-02 -1.11630887e-01  7.12765157e-02  6.14777207e-02
    -1.69305697e-01  2.91113704e-02 -3.56722027e-02  4.45723385e-02
    -4.42971438e-02  9.62186754e-02  1.60977006e-01  6.78107142e-02]
   [-1.72911420e-01 -1.43857628e-01  8.68752599e-04  9.54736769e-03
    -9.24694315e-02 -1.78487062e-01 -5.61368465e-03  6.78707063e-02
    -2.06757486e-02 -3.45145464e-02 -1.74988851e-01 -7.25035146e-02]
   [ 7.36595690e-02  1.87935531e-02 -1.59472674e-02 -5.99457622e-02
    -7.34177977e-02  5.31561375e-02 -6.85833693e-02  8.55869055e-03
     1.18327230e-01  8.56759846e-02 -1.35336205e-01  1.29384041e-01]]

  [[-9.49209407e-02 -1.43931061e-01  1.39986843e-01  1.04966283e-01
    -1.22518159e-01  1.38866931e-01  1.80403054e-01 -1.03378445e-02
     1.81240708e-01 -9.13791135e-02 -1.13647759e-01 -1.33086234e-01]
   [ 1.48116529e-01 -1.08002000e-01 -5.76655343e-02  1.56000018e-01
     1.43986583e-01  9.11345780e-02 -2.25448012e-02 -5.31424284e-02
    -2.57670432e-02 -1.24103621e-01 -1.23525642e-01  7.62276053e-02]
   [-7.34393895e-02 -1.79097041e-01  1.46193624e-01  4.55062091e-02
    -7.12102205e-02 -9.33868438e-02  1.12774521e-01  1.34814084e-01
     1.39555365e-01 -1.31254926e-01  1.81404173e-01  1.51048422e-01]
   [ 7.08374381e-02 -1.38815701e-01 -4.12131548e-02  1.45837814e-01
     4.25314754e-02 -1.42138585e-01 -4.18532938e-02 -1.43844575e-01
    -1.28269911e-01 -1.44390166e-01  5.82012087e-02  6.23516589e-02]
   [ 1.66853756e-01  1.08520240e-01 -5.43589443e-02 -1.01308919e-01
    -7.73917362e-02 -1.01675436e-01 -2.85132229e-03 -7.55310878e-02
     9.21154916e-02 -1.01184249e-02  1.36583239e-01  1.27481431e-01]
   [ 1.51185572e-01 -7.94477016e-02  6.14285767e-02 -1.09383434e-01
    -1.11160576e-02  6.78442419e-02 -1.52483404e-01 -1.91215426e-02
    -1.80681631e-01  6.66188151e-02  5.03838211e-02  6.95326626e-02]
   [ 3.85258496e-02 -5.02071828e-02  3.06560546e-02 -1.79994345e-01
     9.67103839e-02  1.20052457e-01  1.13115132e-01 -1.55062199e-01
     1.63078249e-01 -6.48751706e-02  1.65045142e-01 -1.62858605e-01]
   [ 6.52627647e-03 -3.22298855e-02  1.31609440e-01  1.30915135e-01
    -1.60923213e-01  5.48911244e-02  1.80156499e-01 -1.70418173e-01
    -1.52948812e-01 -8.17985386e-02  9.87262428e-02  1.77291811e-01]]

  [[-1.21646821e-02  1.11088246e-01  4.17499542e-02  1.78560048e-01
     1.13445967e-01  3.90263498e-02  1.50789201e-01 -1.12456851e-01
    -3.18788737e-02  1.05727613e-01 -1.43852800e-01  3.73693258e-02]
   [ 1.51212364e-01 -8.62382874e-02  1.55266970e-02  9.51764584e-02
    -1.38199165e-01  1.18672848e-02 -1.41300172e-01 -1.69071898e-01
     1.52420819e-01 -1.76010519e-01  8.78888667e-02  7.76669681e-02]
   [-5.28266728e-02 -7.85517693e-03 -9.20811519e-02  1.63302064e-01
     1.41457707e-01 -8.70479271e-02 -1.75527871e-01 -1.49765193e-01
     1.02608055e-02 -1.22574881e-01 -7.00742826e-02 -1.72640368e-01]
   [-6.49261028e-02  3.76553088e-02  1.51447207e-02 -1.18315905e-01
    -8.06945935e-02  1.49511456e-01  4.14071679e-02 -1.27147347e-01
     1.80286735e-01  7.19477832e-02  1.55820101e-02 -1.03261203e-01]
   [ 1.41694337e-01 -6.24322295e-02  1.15811795e-01 -9.51586142e-02
     1.49993539e-01  1.17649287e-01  3.02957594e-02  2.66269594e-02
    -1.63218677e-01  1.16232336e-01 -6.88857660e-02 -3.34617198e-02]
   [ 1.85265839e-02 -1.72780707e-01  1.06177509e-01 -8.92564133e-02
     1.17356837e-01  1.70722187e-01  8.87984335e-02 -1.47996560e-01
     1.34868056e-01  1.92952156e-02 -1.66095763e-01  2.49674916e-02]
   [ 2.87357569e-02  1.41703129e-01  7.52265155e-02 -8.48462209e-02
     2.94032395e-02  1.42702430e-01  1.53979063e-01 -1.11719072e-02
     1.29699051e-01 -5.90743572e-02  1.40473545e-02  1.56315535e-01]
   [ 6.19040430e-02 -2.06189901e-02 -5.67361414e-02  1.76428229e-01
    -1.10530704e-02  8.85301828e-02 -8.84541869e-03 -1.52084410e-01
    -3.88459563e-02  1.40014976e-01  1.55961126e-01 -1.64046645e-01]]]


 [[[ 4.25648689e-03  8.98439586e-02 -4.35977727e-02  1.06983155e-01
     2.51899362e-02  8.77319276e-03 -1.19932838e-01 -1.42490342e-01
    -6.24369755e-02  1.74831808e-01 -1.11000672e-01 -1.73406303e-03]
   [-4.36147004e-02 -7.79993609e-02  1.46764934e-01  1.20519042e-01
     3.80317420e-02  1.32458508e-01 -2.51937658e-02  9.32906568e-02
     9.58300531e-02  6.76800609e-02  6.37915134e-02 -2.08935142e-03]
   [ 9.21428204e-02 -1.26626223e-01 -1.05295703e-01  1.64834261e-01
     1.80658787e-01 -9.24042687e-02 -1.29927993e-01 -6.22721314e-02
    -1.05359912e-01  5.23713529e-02  2.36761123e-02 -1.63138628e-01]
   [-9.54960063e-02 -2.14881748e-02  1.12646163e-01  1.74191535e-01
     3.44628096e-03  1.61926299e-01  1.58273250e-01  1.56867951e-02
     2.06706077e-02  1.25562221e-01 -1.65372059e-01  4.79232520e-02]
   [ 1.19962305e-01 -4.58623618e-02 -1.49416864e-01  1.55377656e-01
    -3.89145166e-02 -5.39887697e-02  1.60350204e-01 -9.65190232e-02
     3.29748392e-02 -1.64857507e-01  1.05096161e-01  7.07103014e-02]
   [-1.20915376e-01  1.08093202e-01 -1.31271765e-01 -1.79597750e-01
    -2.57807970e-02 -9.47172716e-02  1.47617459e-01 -1.55910969e-01
     1.50786340e-01  1.54214382e-01  5.77574670e-02  1.12168819e-01]
   [-1.90540254e-02  1.39549166e-01 -9.14754868e-02 -9.72161889e-02
     1.55543745e-01 -1.36237085e-01 -1.10009469e-01  1.20209605e-01
     6.74618781e-02  8.37951601e-02  1.76556736e-01 -7.34775141e-02]
   [-1.59330264e-01  1.18923366e-01  6.27512187e-02 -3.31075639e-02
    -1.00204982e-01  1.22297585e-01 -5.15450388e-02 -8.07907060e-02
    -1.34177387e-01 -1.10616878e-01  1.72897637e-01 -1.29213497e-01]]

  [[ 1.11783534e-01 -5.45459390e-02 -1.35401487e-02  1.18027538e-01
     6.95149004e-02 -6.89958036e-03 -5.83146513e-03  1.51529521e-01
     8.57773423e-02 -8.92933309e-02  1.61266744e-01  1.33006960e-01]
   [ 1.64932668e-01 -9.97894555e-02  3.20096761e-02  1.32233053e-01
    -1.15717351e-01  9.46811736e-02 -8.10090527e-02  1.63969189e-01
     1.59583390e-01 -1.23477802e-01  1.80558830e-01 -1.50979385e-01]
   [-1.52807906e-01 -6.37370348e-03  1.46654993e-01 -1.25455454e-01
    -1.45555139e-02  6.47767484e-02 -1.07124448e-01 -9.12621915e-02
    -1.72373012e-01  1.76593721e-01  1.15190953e-01  1.16567612e-01]
   [ 1.20363206e-01  1.19858354e-01 -3.20471972e-02  1.29741937e-01
    -4.45766896e-02  1.33567452e-01  1.54925525e-01 -1.41365811e-01
     6.83134794e-02 -1.05220228e-01 -1.36043519e-01  1.47954345e-01]
   [-9.96115506e-02 -1.23997279e-01  1.29717439e-01  1.12763107e-01
    -6.63868934e-02 -1.78603247e-01  1.59075797e-01 -5.31462580e-02
    -1.72569335e-01 -8.85271728e-02  6.40488118e-02  5.85163087e-02]
   [-1.77035809e-01 -5.47862202e-02 -9.55599472e-02 -1.43166661e-01
     8.62739384e-02  2.65710652e-02  5.07326573e-02 -1.33114621e-01
    -1.68177992e-01 -1.21893562e-01  8.01801682e-04 -1.74880162e-01]
   [ 1.62263334e-01  1.25606716e-01 -1.22779377e-01  4.77101356e-02
     1.39659226e-01 -6.95866719e-02  1.48140907e-01 -5.99611700e-02
     8.73327255e-02  1.65933937e-01 -7.29069784e-02 -2.85871178e-02]
   [ 8.90282691e-02 -7.42706582e-02 -1.20910458e-01  1.25831723e-01
     1.14927262e-01 -1.81317806e-01 -1.38245776e-01 -1.76458612e-01
     9.16392505e-02 -6.08193949e-02  1.08285099e-02 -1.50721297e-01]]

  [[ 6.03461862e-02  1.24547660e-01 -8.12763646e-02 -1.74457580e-01
     9.16769803e-02 -6.66351616e-03  1.56731755e-01  3.42933834e-02
    -3.50841731e-02  1.58686489e-02 -6.58075660e-02  1.26392215e-01]
   [ 1.39954239e-02  5.04558980e-02  5.04422784e-02 -1.74083263e-02
    -1.06142305e-01  6.49550408e-02  8.85375440e-02  3.10065448e-02
    -1.31664664e-01  1.75815821e-01  2.67497450e-02  2.62670070e-02]
   [ 6.33399040e-02 -1.31615520e-01 -1.40392184e-02 -3.05083990e-02
     7.33584166e-02 -1.15155280e-02 -4.37519848e-02  9.74804163e-02
    -5.79845607e-02 -1.43975466e-02 -1.52669489e-01  1.07540905e-01]
   [ 1.42249972e-01 -1.79174826e-01  1.14173412e-01 -1.15154043e-01
     1.23451293e-01  8.14085901e-02  3.12688947e-02 -5.90064973e-02
    -9.61571261e-02 -2.31606066e-02 -1.56199604e-01  1.80257291e-01]
   [-1.03674076e-01 -4.80517745e-04 -1.49942353e-01 -1.45888090e-01
     3.76347601e-02 -6.96528330e-02  8.85638595e-02 -7.45727122e-03
     1.21188790e-01  3.01212966e-02 -1.78860933e-01 -4.83771712e-02]
   [-1.33370608e-01  7.48704374e-02 -6.24780655e-02  4.20927107e-02
     6.18667901e-02  1.31099313e-01 -3.75017822e-02 -7.03971386e-02
     1.62500918e-01 -1.47199631e-02 -8.18408430e-02 -2.02136785e-02]
   [ 4.42216694e-02 -8.60013142e-02  1.57468051e-01  1.37674659e-02
     6.86165392e-02  2.51895785e-02  5.50284088e-02 -1.44589245e-02
     9.32712853e-02 -1.61228791e-01  1.78502589e-01  1.29311472e-01]
   [-5.49125373e-02 -1.51102275e-01  1.31593674e-01  9.53472257e-02
     1.79685354e-02 -8.44948590e-02  4.86635119e-02  2.34054476e-02
    -1.06498890e-01  7.17085004e-02 -1.80102378e-01  1.50361359e-01]]]]: "
2018-04-20 09:30:30,843 (dqn_agent.py:161) DEBUG: "var_name: q/Conv_1/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 09:30:30,851 (dqn_agent.py:161) DEBUG: "var_name: q/Conv_2/weights:0, var_value [[[[-0.12522422 -0.1354345   0.09417535 ... -0.11621692  0.029524
    -0.07588997]
   [-0.08668954 -0.00297628 -0.0280368  ...  0.13890739  0.04549155
     0.02974808]
   [ 0.00260571  0.00451906  0.09286064 ... -0.13508692  0.05490991
     0.00800513]
   ...
   [ 0.04271789 -0.11691079 -0.14807814 ...  0.05746791 -0.02532297
    -0.06981846]
   [-0.04235376  0.00743799  0.12039594 ...  0.13588114 -0.03065713
     0.03426272]
   [-0.08544461  0.06057513 -0.14685057 ...  0.12645708 -0.10506473
    -0.05202372]]

  [[-0.0017053  -0.06590755 -0.12074768 ... -0.03506527  0.0471594
    -0.12902296]
   [ 0.06385727  0.02352367 -0.10391571 ... -0.06317076  0.10501872
     0.13921537]
   [-0.08738466  0.07329221 -0.1053246  ...  0.08514492  0.09068289
     0.05181745]
   ...
   [-0.11489826 -0.08441728 -0.05160032 ... -0.11444561 -0.02635787
     0.09266385]
   [-0.08226252 -0.05534509  0.03708895 ...  0.09940009  0.09619759
    -0.08005884]
   [ 0.14432804 -0.1319058  -0.0333412  ... -0.07117078 -0.03679721
    -0.08127585]]

  [[-0.14999907  0.00182149 -0.1291438  ...  0.1006272  -0.08041786
     0.10595734]
   [-0.15308557  0.04255168 -0.07102057 ... -0.0605379   0.09419173
    -0.11082023]
   [ 0.00714652  0.07216077 -0.07786005 ... -0.00067776  0.03274879
     0.05973859]
   ...
   [ 0.05690575 -0.13456014  0.09023222 ...  0.06514753  0.00051269
     0.15151139]
   [ 0.10813822 -0.05123677 -0.06322377 ... -0.07094847  0.03822237
     0.10246955]
   [ 0.1189784  -0.08899488  0.05898589 ... -0.11835147 -0.11053056
     0.1398172 ]]]


 [[[-0.13088883 -0.09102157 -0.01774706 ... -0.1386186  -0.03951944
     0.04540797]
   [ 0.0129533   0.01806973  0.11763816 ... -0.11220305 -0.11066774
    -0.09547827]
   [-0.10805482 -0.00213471 -0.04634861 ... -0.0838397   0.04927443
    -0.139608  ]
   ...
   [-0.08670194  0.12110518 -0.04537459 ...  0.03149109 -0.14170036
    -0.0120991 ]
   [-0.07291777  0.0526129  -0.06326388 ...  0.10662468 -0.08225171
     0.07743359]
   [-0.0266626   0.02086495  0.0366534  ...  0.11856143  0.11629193
     0.03119802]]

  [[-0.12298562  0.11590634 -0.00844648 ... -0.08813802 -0.04071294
    -0.05604029]
   [-0.1068588   0.03327785 -0.09436019 ...  0.04751584  0.01258445
     0.05925806]
   [ 0.07963617  0.03043199  0.01705211 ... -0.00663181 -0.1299533
     0.01570322]
   ...
   [-0.03363621  0.06438722  0.05083276 ... -0.03031117  0.12927397
     0.06691447]
   [-0.13986729  0.07173596  0.04670653 ... -0.115233    0.06701972
     0.14322536]
   [ 0.08088674 -0.08694081 -0.11239843 ... -0.1351938   0.11261041
     0.02717426]]

  [[ 0.13991122 -0.13064092  0.09233956 ...  0.0161047  -0.14876941
    -0.02430941]
   [ 0.01682532  0.13362668 -0.01136413 ... -0.05301271 -0.13972676
    -0.10186359]
   [ 0.02111846 -0.07457238  0.03911866 ... -0.06220826  0.10248439
     0.06369692]
   ...
   [ 0.15007146 -0.09400775 -0.05343858 ... -0.14926487 -0.09633681
     0.09016615]
   [-0.08707546 -0.03527912 -0.08245905 ...  0.09516852 -0.0007882
     0.05023497]
   [ 0.09024264 -0.09672493  0.02637583 ... -0.07301643 -0.01900829
    -0.12638085]]]


 [[[ 0.03938733  0.03906973  0.11211483 ... -0.04197498  0.0372963
     0.04559989]
   [-0.04688451 -0.01231976  0.06546494 ... -0.02586299 -0.04173272
    -0.10286638]
   [-0.09964574  0.1187769  -0.11503078 ...  0.02263713 -0.06730957
    -0.00470072]
   ...
   [ 0.1311542   0.11009382  0.11269118 ... -0.04250956  0.03042756
    -0.09522898]
   [-0.02665584  0.01291297  0.12490769 ... -0.0878212   0.14664848
     0.04764427]
   [ 0.07134758  0.08039707 -0.06811168 ...  0.02068302  0.03081958
     0.01278549]]

  [[ 0.14920895  0.07616501  0.02586679 ...  0.14995386  0.12782706
    -0.04017604]
   [ 0.03853169 -0.15360948  0.05542544 ... -0.07664546 -0.0714123
    -0.03333351]
   [-0.01313841  0.05898832  0.12622394 ... -0.020441    0.15000705
     0.0939586 ]
   ...
   [-0.04966236 -0.09621243  0.0729572  ... -0.05230574  0.08345963
    -0.11977363]
   [ 0.0275363  -0.02793138  0.10183831 ...  0.12256519 -0.10003938
     0.01554742]
   [ 0.08111656  0.0452089   0.13995512 ... -0.10029098  0.03191343
    -0.11672935]]

  [[ 0.1199619  -0.08640862  0.06365936 ... -0.12824656  0.09125014
     0.10840641]
   [ 0.02333318  0.10390221  0.09637664 ... -0.1134121  -0.12880318
    -0.11095425]
   [ 0.02464764  0.04679088 -0.1422983  ... -0.07373875 -0.05465475
     0.13453986]
   ...
   [ 0.02748016 -0.13626346  0.08940756 ...  0.02961722  0.07047635
     0.09916653]
   [ 0.0960225  -0.02609561  0.09388299 ... -0.01542278  0.02156408
     0.08577876]
   [ 0.06079799  0.12907632 -0.08451672 ... -0.05292048  0.0811267
     0.13957442]]]]: "
2018-04-20 09:30:30,855 (dqn_agent.py:161) DEBUG: "var_name: q/Conv_2/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 09:30:30,861 (dqn_agent.py:161) DEBUG: "var_name: q/fully_connected/weights:0, var_value [[-0.01165338  0.06772149 -0.07559088 ... -0.04275567 -0.07500613
  -0.07135338]
 [-0.06975953 -0.01027971  0.02858579 ... -0.04060309 -0.02329833
   0.02616174]
 [ 0.02934137  0.06960989 -0.01913106 ...  0.09125461  0.02750253
   0.07366175]
 ...
 [ 0.05613547  0.06916746 -0.07303284 ...  0.03601373 -0.00402633
   0.07013955]
 [-0.08416068 -0.07750266 -0.03354026 ... -0.02956528 -0.07028671
  -0.04191624]
 [-0.06461404 -0.01216286 -0.03355556 ... -0.05218419 -0.08294372
   0.08601653]]: "
2018-04-20 09:30:30,867 (dqn_agent.py:161) DEBUG: "var_name: q/fully_connected/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 09:30:30,876 (dqn_agent.py:161) DEBUG: "var_name: q/fully_connected_1/weights:0, var_value [[ 0.11870596 -0.15481125 -0.08325458 -0.08356291  0.08852899]
 [-0.01849052  0.06371495  0.0184916  -0.05823043  0.0574483 ]
 [ 0.19474357  0.0282993   0.14010581  0.16359675  0.00182505]
 [-0.08241451  0.00947648  0.10794613  0.05049366 -0.01001088]
 [-0.14022098  0.1514669   0.0678007   0.01713617  0.15390167]
 [-0.05876082 -0.07358465 -0.13201798 -0.12570804  0.01221827]
 [-0.07425344  0.12143624  0.07878765  0.02007711  0.09286267]
 [-0.13791743  0.07838187 -0.05613495  0.09285158  0.19956061]
 [ 0.10805166 -0.05447119  0.13778886 -0.07942197  0.20851532]
 [-0.19574533 -0.06973067 -0.04073122  0.05821517 -0.1321418 ]
 [ 0.16401622  0.15225562 -0.03095718 -0.04711439  0.0270002 ]
 [ 0.11706933  0.0592455   0.09083107  0.11641932  0.03405657]
 [ 0.03040607  0.04500788  0.05787361 -0.14870766 -0.1327883 ]
 [ 0.03028473  0.03329678  0.12971964 -0.17246987 -0.07720664]
 [ 0.07415843  0.04051423  0.18194291 -0.06031424  0.06225461]
 [-0.06854317  0.13581443  0.2008906   0.01990129  0.11714604]
 [-0.05915804  0.01314983 -0.07446997  0.07476658  0.15690085]
 [-0.05559535 -0.18741989  0.2027219   0.2009961   0.05214098]
 [-0.05809887  0.11117184  0.15488884  0.16936141  0.19524512]
 [-0.14364335 -0.02939688  0.08226016 -0.19049396 -0.08981791]
 [-0.07796057  0.09598601 -0.1731134   0.08341271 -0.04922266]
 [-0.01838033  0.16872826  0.10187683  0.15695244  0.00467034]
 [ 0.12725466  0.09740776 -0.11939754  0.17046866  0.16501188]
 [-0.058165   -0.09144739 -0.1762802   0.00307301 -0.07133847]
 [ 0.12365672 -0.18159056 -0.12886395 -0.04562421 -0.14570783]
 [-0.14515418 -0.1258271   0.12732568 -0.06867458 -0.1598238 ]
 [ 0.12676376 -0.20967916 -0.01580501  0.12767547 -0.14316487]
 [ 0.07466397  0.19889629 -0.06243522 -0.08853775 -0.00535955]
 [-0.13031472 -0.02444483 -0.08873296  0.00349337  0.10584959]
 [ 0.11085191 -0.08651499  0.05576751  0.10258698  0.06979695]
 [ 0.0460459   0.1971511   0.01044288  0.14720884 -0.20767003]
 [-0.03380635 -0.03087747  0.20766097  0.15110832  0.17644873]
 [ 0.17145759 -0.06252871  0.03008197  0.01492693 -0.00988074]
 [-0.03732611  0.18120414 -0.12720662  0.01327081  0.06358033]
 [ 0.06066501 -0.05360521 -0.18311344 -0.00502719  0.07951105]
 [-0.04452883 -0.19004758 -0.08509952 -0.03402294  0.01059683]
 [ 0.02818963  0.20387697  0.15909317  0.19612503 -0.18932626]
 [ 0.16145715  0.07530695 -0.0775439  -0.01408909  0.10275957]
 [-0.13024464  0.03376448  0.13551894  0.11391729 -0.11753183]
 [-0.09155996 -0.09994835 -0.14183679  0.12092179  0.2008149 ]
 [ 0.08213508  0.03913659 -0.19157365 -0.14531796  0.10953736]
 [ 0.01025492  0.15585119 -0.0205951   0.1926255   0.03500374]
 [-0.17024046 -0.02630918  0.02272911  0.00827192  0.21206793]
 [ 0.04478785 -0.06176957 -0.16253135 -0.08820727 -0.19107611]
 [ 0.03661002  0.02499609 -0.13273752 -0.14817317 -0.20688543]
 [-0.136457   -0.16357595  0.06342134 -0.08944865  0.088478  ]
 [ 0.13113368 -0.05381112 -0.21110208  0.08085087 -0.07331403]
 [-0.02425291 -0.12829804 -0.096749   -0.12726212  0.10596576]
 [ 0.18752867  0.05446807 -0.11938838  0.18519834  0.02568363]
 [ 0.05107617 -0.13383083  0.12638038  0.06299251 -0.19418857]
 [ 0.21073759 -0.08026709  0.02570985  0.06507269 -0.17872274]
 [-0.08997803 -0.09236554  0.2098794   0.1007517  -0.18008167]
 [-0.05088186  0.01850961 -0.1553129  -0.11694446 -0.02926728]
 [ 0.12238765 -0.1467902   0.17086092  0.03407668 -0.1571192 ]
 [ 0.2001664   0.06628212 -0.18702677 -0.08881039 -0.05014227]
 [-0.16131322 -0.01338322 -0.11745212  0.10844958  0.03619209]
 [ 0.16515875  0.20122135 -0.00852163 -0.15165995  0.05736285]
 [-0.0056102   0.01120335 -0.039601   -0.0784713   0.1706138 ]
 [-0.18446264 -0.13866833  0.12121865 -0.13670716 -0.06040463]
 [-0.06053007  0.06257394 -0.19829705  0.0083417   0.11260951]
 [-0.09664686 -0.01276755  0.09975061  0.11941856  0.16222301]
 [ 0.19435817 -0.20760411  0.14799121  0.0387938   0.15001747]
 [ 0.18698838  0.1820336   0.08803049  0.06564122  0.19509685]
 [-0.00950119  0.05600187 -0.01585135  0.0136506   0.07987544]
 [ 0.01071411  0.13388419  0.20310634 -0.12489062  0.18849719]
 [ 0.17595473 -0.03391731  0.00028606  0.01688054  0.11814392]
 [ 0.14996955  0.16897684  0.08489561 -0.16387957 -0.09658629]
 [-0.00572459 -0.03371689 -0.00589196 -0.12346446  0.17268154]
 [ 0.14934197 -0.13974467 -0.20037621  0.0794566  -0.20891617]
 [ 0.08974302 -0.0734383  -0.03546232 -0.05977382  0.13392445]
 [-0.06005476 -0.17769825  0.05928564 -0.06719276  0.0247198 ]
 [-0.15733245  0.16773114  0.05051798  0.10795903 -0.19855264]
 [-0.19375646 -0.14612946  0.02872367 -0.01842095 -0.18731324]
 [ 0.04998356 -0.06341602 -0.12803528 -0.18418524 -0.09847698]
 [-0.10515785 -0.13462126 -0.08387348 -0.01258479  0.04680407]
 [-0.16451901  0.10233438  0.07279852 -0.0383343   0.04631194]
 [-0.05804706  0.06967178  0.0796783  -0.11187002  0.04453248]
 [-0.16981372 -0.03683335 -0.05120616  0.05916715 -0.12504143]
 [-0.1842099  -0.12976742  0.06102619  0.053002    0.11583146]
 [ 0.06445989  0.00352162 -0.02236424  0.05631351 -0.18259268]
 [-0.186566   -0.1534721  -0.00459099  0.06794512  0.15025187]
 [ 0.16575283 -0.08664975 -0.11617312  0.05678836 -0.12248691]
 [-0.19396895  0.03695837 -0.00519243 -0.05851391 -0.18112351]
 [-0.1592849  -0.1529779   0.1379495  -0.16804002  0.10364354]
 [-0.08048671 -0.10631137  0.14507023  0.10860464 -0.15571897]
 [ 0.05767405  0.15034914  0.03106216  0.03045295 -0.06186159]
 [-0.129422   -0.21169983 -0.1626545   0.14628795 -0.0628999 ]
 [ 0.01872949 -0.07295378  0.06444728  0.04372817 -0.18703948]
 [ 0.16834888 -0.12346137 -0.20794638 -0.11178424  0.1723615 ]
 [-0.05670936  0.06118587 -0.03188844 -0.14303224  0.20373943]
 [ 0.11243004  0.11467034  0.15567076 -0.08211325 -0.11773717]
 [-0.10844365  0.12770891 -0.20028517 -0.07567084 -0.04560679]
 [ 0.124928   -0.21079926  0.08473417 -0.15557262  0.02163063]
 [ 0.02932152  0.12775981  0.13599658 -0.17701118 -0.16031364]
 [-0.01065761 -0.11042659 -0.09209082 -0.18266428 -0.0700178 ]
 [-0.04550071 -0.11339108  0.19916847  0.06390637 -0.08612877]
 [ 0.14215967  0.00669667  0.16665241  0.00307089  0.09122986]
 [ 0.1852211   0.05512637 -0.12161277  0.2123535   0.01983683]
 [-0.07329944 -0.14195108 -0.15203196 -0.08365381  0.09283501]
 [ 0.10755169 -0.02434866  0.11233383  0.05180568 -0.01607811]
 [-0.13685755  0.19209418 -0.13852623  0.13343418  0.16740105]
 [ 0.09855086 -0.16175449 -0.15750082 -0.11597005  0.19820035]
 [-0.02913056 -0.04245529  0.08314037 -0.01706158  0.19339389]
 [-0.21121754  0.06868714  0.13475317 -0.05326384 -0.00214358]
 [ 0.05587006  0.11235818  0.02798373 -0.15585741 -0.12964344]
 [ 0.16723248  0.16166076 -0.13607234 -0.11485618 -0.13980564]
 [ 0.15420306  0.04603398  0.20680773 -0.18654817 -0.01594858]
 [-0.04814774  0.13367876  0.16997239 -0.01469879 -0.03121002]
 [ 0.03704789 -0.12046593 -0.17657067  0.03373668 -0.05611451]
 [ 0.13235953 -0.01615311  0.00642343 -0.05527449  0.06542054]
 [ 0.01838723 -0.11417508 -0.14777616  0.1668779   0.13927963]
 [ 0.14299482 -0.16021495 -0.00349504 -0.00945121 -0.03680909]
 [ 0.15246865  0.16281214  0.16994256  0.09518212  0.12469292]
 [-0.00890876  0.14164087  0.09123138  0.21208566 -0.11661971]
 [ 0.17379218  0.1704965  -0.02545093 -0.2097229   0.1095877 ]
 [ 0.15858415  0.03697285 -0.14251359 -0.08646128 -0.09676763]
 [ 0.08376098 -0.19605236 -0.03285114  0.16838276 -0.09117926]
 [-0.08535226 -0.14517277  0.1861194  -0.16224594  0.08802232]
 [ 0.06046149  0.02778006  0.20381129 -0.00219168 -0.19863513]
 [ 0.03249429  0.11393541  0.03708826 -0.13691509 -0.12910494]
 [ 0.13910034  0.16108185  0.02288209 -0.05193147 -0.05181526]
 [-0.02375491 -0.01449531 -0.06506823  0.15824932  0.05737817]
 [-0.15993921 -0.15391265 -0.00290221 -0.16329236 -0.11534227]
 [-0.152004    0.02057642  0.04729456 -0.15693027 -0.00726774]
 [ 0.03124861 -0.19861938  0.17666292  0.08555436  0.04093698]
 [-0.14260468 -0.2113337   0.1300441   0.04472855  0.20611334]
 [ 0.09716618 -0.20655754  0.16672412 -0.18893832 -0.00610258]
 [-0.01092255 -0.14002511 -0.00033168 -0.17544875 -0.08068506]]: "
2018-04-20 09:30:30,881 (dqn_agent.py:161) DEBUG: "var_name: q/fully_connected_1/biases:0, var_value [0. 0. 0. 0. 0.]: "
2018-04-20 09:30:30,886 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv/weights:0, var_value [[[[ 0.16578859 -0.16878021  0.7039348  -0.5990083  -0.5231885
     0.12528002  0.3845706   0.58010113]
   [-0.1548481  -0.41433412 -0.21852148 -0.35893342  0.6082158
     0.3999889   0.58211505 -0.26015198]]]]: "
2018-04-20 09:30:30,891 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 09:30:30,902 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv_1/weights:0, var_value [[[[ 1.50372803e-01 -4.65755910e-02  6.63120598e-02 -1.35417745e-01
    -8.24370235e-02 -1.52714670e-01 -1.77968279e-01 -1.38832420e-01
    -1.16875656e-01  1.51195586e-01  1.10575348e-01  9.78565514e-02]
   [ 9.89191234e-02  7.67598152e-02 -1.66469067e-02  7.34809935e-02
     8.29356015e-02  1.19481683e-02 -1.79388598e-01 -1.44438356e-01
     7.07273185e-03 -1.77472010e-01  8.87598395e-02  1.48418576e-01]
   [-1.66158974e-01 -1.18967593e-02 -4.12107557e-02 -1.54847249e-01
     1.17666066e-01 -1.38515577e-01  1.65102780e-02 -1.09486468e-01
    -1.41777694e-01  9.60279405e-02  2.53623426e-02 -1.03353307e-01]
   [ 5.52144647e-03  9.48200822e-02  3.09036374e-02  1.07741743e-01
    -1.58003852e-01  1.00059152e-01 -3.98937464e-02 -1.39132082e-01
     1.46161884e-01 -9.86199975e-02  5.65466583e-02 -1.79113835e-01]
   [-1.25564590e-01  1.41239941e-01 -5.20381778e-02 -6.02059364e-02
     3.34170163e-02  7.30284750e-02 -8.97882581e-02 -4.29988056e-02
    -1.51726469e-01  3.51880342e-02 -7.81367794e-02 -3.25431228e-02]
   [ 1.82122052e-01 -9.67563912e-02  1.00072682e-01 -1.05278946e-01
    -3.69303375e-02  4.92800772e-03 -2.31504589e-02 -5.03832102e-03
     1.81149483e-01  1.81027949e-01  1.24728292e-01 -1.31427914e-01]
   [-1.80586249e-01 -1.36025965e-01  4.48914468e-02 -5.97371310e-02
    -6.78593963e-02 -6.46777675e-02  1.34997427e-01  1.21811777e-02
     9.64576602e-02  1.58229679e-01  1.37813747e-01 -2.31378824e-02]
   [-9.52447131e-02  1.47893041e-01 -3.06760669e-02 -2.78017670e-02
    -2.98631638e-02 -1.24209307e-01  9.12289321e-02 -9.49710608e-04
     1.14439696e-01  1.43336982e-01 -1.32964581e-01 -9.92896929e-02]]

  [[-6.49723262e-02  1.58546180e-01  5.85785955e-02 -1.50315136e-01
    -6.15584701e-02 -1.41734332e-01  6.16731346e-02 -1.22978218e-01
     1.81306928e-01 -2.63602883e-02  1.26414150e-02 -1.50923759e-01]
   [-1.40209600e-01 -9.67322737e-02  1.24145299e-02  6.59394115e-02
     1.41328335e-01  8.43215585e-02  1.14990234e-01 -1.16814151e-01
     3.76809388e-02  2.42543519e-02  5.33993393e-02 -7.67892525e-02]
   [-9.87472758e-02  1.74100071e-01  4.51567620e-02  1.41774416e-01
     1.41309172e-01  2.58868784e-02 -1.43943951e-01 -1.37666881e-01
     1.47413224e-01  1.99114233e-02  1.03365660e-01 -9.21891481e-02]
   [-1.67833194e-01  1.96955949e-02 -1.77946121e-01 -1.34419441e-01
     1.75737649e-01  8.71360302e-03  3.25536728e-03 -1.43141359e-01
     1.20177001e-01 -1.45054042e-01  1.27553076e-01  1.53062642e-02]
   [-1.55145079e-02  1.71647877e-01  4.45766449e-02  8.31186771e-02
    -7.10270032e-02 -1.09896958e-02 -2.90575325e-02 -6.20858297e-02
    -4.92762625e-02  2.22920179e-02 -5.88739440e-02  1.71498477e-01]
   [-8.99066553e-02 -1.71779886e-01 -1.65016860e-01  1.04004711e-01
     9.67311859e-03 -1.54113770e-02 -1.70659572e-01 -8.31511989e-02
     3.37359458e-02  1.55402720e-03  9.14124548e-02  7.11061060e-03]
   [-1.43738240e-01 -1.68416440e-01 -1.72697783e-01 -1.13055982e-01
     1.71616912e-01  1.39764518e-01 -1.03619576e-01  1.14000082e-01
    -9.52616334e-03  1.18024051e-01 -4.03728336e-02  1.08210146e-01]
   [ 1.73561484e-01  9.88033414e-02 -1.72187835e-01  1.25137299e-01
    -1.23160735e-01  7.95265436e-02  8.18993449e-02  2.86989361e-02
     2.07359940e-02 -7.31796026e-05  1.80210263e-01  6.27235323e-02]]

  [[ 6.60870969e-03 -1.21559039e-01 -6.81037679e-02  4.53340560e-02
     7.55124092e-02  1.80749804e-01 -7.44268298e-03 -5.38325906e-02
    -1.13388635e-01 -3.08124125e-02 -1.79469511e-01  1.35015100e-01]
   [ 1.67978674e-01  1.71190590e-01 -1.61744744e-01  6.67512417e-04
     1.17815793e-01  2.60507613e-02  3.34459543e-02  1.59345895e-01
    -1.78536028e-01  1.41344666e-01  1.04296505e-02 -7.02945814e-02]
   [ 4.77891862e-02 -1.02742903e-01  1.56789571e-02 -1.36362284e-01
     1.65883392e-01 -1.68079048e-01  1.21308386e-01 -1.42047554e-02
     8.56704414e-02 -7.17130676e-02  1.17512047e-01 -8.82266909e-02]
   [-3.50956172e-02 -8.91575217e-02  3.36481035e-02 -1.23550743e-02
    -7.22268820e-02  1.74243808e-01 -1.39517486e-01  1.28090173e-01
    -1.26272231e-01  1.55808061e-01  2.08957046e-02 -1.18645594e-01]
   [ 7.13585317e-02 -3.16085517e-02 -1.65610015e-03 -8.18596482e-02
     7.13812411e-02  1.46497369e-01 -1.18483707e-01 -4.29078937e-03
     5.63763082e-03 -4.74429578e-02 -9.13266167e-02  6.01610541e-02]
   [-3.59444022e-02  2.49007642e-02  8.52181911e-02  1.11225158e-01
    -1.68843284e-01  1.38022453e-02 -1.29408032e-01 -1.27537102e-01
    -1.64736927e-01 -1.63101792e-01 -5.62077910e-02  4.17557508e-02]
   [-4.67253774e-02 -1.25943989e-01  1.78297579e-01  7.24245906e-02
     1.71259105e-01 -1.48414478e-01  8.97851586e-02  1.71935797e-01
    -1.20076180e-01  6.27714545e-02 -1.31946474e-01  5.90580702e-03]
   [-1.11516714e-02 -4.76029217e-02 -8.17512199e-02 -6.77612349e-02
    -6.90109134e-02 -1.18763387e-01  1.14549041e-01  1.24193341e-01
    -4.94612157e-02  1.08101368e-01 -4.13815677e-02  1.03034586e-01]]]


 [[[ 1.03024930e-01 -7.02546537e-03 -2.97795087e-02  9.59316492e-02
    -1.21294126e-01 -8.22076201e-02 -8.04460421e-02  1.67265356e-01
    -7.78349936e-02  1.49735332e-01  4.41252887e-02  1.56957269e-01]
   [ 5.70124686e-02  2.57944614e-02 -1.11137785e-01 -7.57582635e-02
     1.59029961e-02 -1.73812002e-01  4.12420630e-02  1.76606685e-01
    -1.10035628e-01 -1.08016923e-01 -7.28153959e-02 -4.51277643e-02]
   [ 1.05051905e-01 -3.10264379e-02  8.81486833e-02  1.43133968e-01
     3.28181833e-02  1.27911597e-01 -3.45832855e-02  1.39498591e-01
     1.14050001e-01 -4.24026698e-02 -8.59723687e-02 -1.65779963e-01]
   [-6.03268147e-02 -1.46665573e-02 -1.37881398e-01  3.95148993e-03
    -5.62563688e-02  8.25574100e-02 -6.08313605e-02 -1.90340877e-02
    -7.64632225e-03 -1.05154760e-01  1.13561392e-01 -5.71756214e-02]
   [ 1.35875374e-01 -1.67817473e-01  1.01750970e-01 -8.54162350e-02
    -1.76406413e-01  1.36459082e-01 -4.39292789e-02 -2.14182138e-02
     1.56653315e-01 -1.64324746e-01 -1.60880029e-01 -8.23006034e-04]
   [ 9.53239202e-02 -1.11630887e-01  7.12765157e-02  6.14777207e-02
    -1.69305697e-01  2.91113704e-02 -3.56722027e-02  4.45723385e-02
    -4.42971438e-02  9.62186754e-02  1.60977006e-01  6.78107142e-02]
   [-1.72911420e-01 -1.43857628e-01  8.68752599e-04  9.54736769e-03
    -9.24694315e-02 -1.78487062e-01 -5.61368465e-03  6.78707063e-02
    -2.06757486e-02 -3.45145464e-02 -1.74988851e-01 -7.25035146e-02]
   [ 7.36595690e-02  1.87935531e-02 -1.59472674e-02 -5.99457622e-02
    -7.34177977e-02  5.31561375e-02 -6.85833693e-02  8.55869055e-03
     1.18327230e-01  8.56759846e-02 -1.35336205e-01  1.29384041e-01]]

  [[-9.49209407e-02 -1.43931061e-01  1.39986843e-01  1.04966283e-01
    -1.22518159e-01  1.38866931e-01  1.80403054e-01 -1.03378445e-02
     1.81240708e-01 -9.13791135e-02 -1.13647759e-01 -1.33086234e-01]
   [ 1.48116529e-01 -1.08002000e-01 -5.76655343e-02  1.56000018e-01
     1.43986583e-01  9.11345780e-02 -2.25448012e-02 -5.31424284e-02
    -2.57670432e-02 -1.24103621e-01 -1.23525642e-01  7.62276053e-02]
   [-7.34393895e-02 -1.79097041e-01  1.46193624e-01  4.55062091e-02
    -7.12102205e-02 -9.33868438e-02  1.12774521e-01  1.34814084e-01
     1.39555365e-01 -1.31254926e-01  1.81404173e-01  1.51048422e-01]
   [ 7.08374381e-02 -1.38815701e-01 -4.12131548e-02  1.45837814e-01
     4.25314754e-02 -1.42138585e-01 -4.18532938e-02 -1.43844575e-01
    -1.28269911e-01 -1.44390166e-01  5.82012087e-02  6.23516589e-02]
   [ 1.66853756e-01  1.08520240e-01 -5.43589443e-02 -1.01308919e-01
    -7.73917362e-02 -1.01675436e-01 -2.85132229e-03 -7.55310878e-02
     9.21154916e-02 -1.01184249e-02  1.36583239e-01  1.27481431e-01]
   [ 1.51185572e-01 -7.94477016e-02  6.14285767e-02 -1.09383434e-01
    -1.11160576e-02  6.78442419e-02 -1.52483404e-01 -1.91215426e-02
    -1.80681631e-01  6.66188151e-02  5.03838211e-02  6.95326626e-02]
   [ 3.85258496e-02 -5.02071828e-02  3.06560546e-02 -1.79994345e-01
     9.67103839e-02  1.20052457e-01  1.13115132e-01 -1.55062199e-01
     1.63078249e-01 -6.48751706e-02  1.65045142e-01 -1.62858605e-01]
   [ 6.52627647e-03 -3.22298855e-02  1.31609440e-01  1.30915135e-01
    -1.60923213e-01  5.48911244e-02  1.80156499e-01 -1.70418173e-01
    -1.52948812e-01 -8.17985386e-02  9.87262428e-02  1.77291811e-01]]

  [[-1.21646821e-02  1.11088246e-01  4.17499542e-02  1.78560048e-01
     1.13445967e-01  3.90263498e-02  1.50789201e-01 -1.12456851e-01
    -3.18788737e-02  1.05727613e-01 -1.43852800e-01  3.73693258e-02]
   [ 1.51212364e-01 -8.62382874e-02  1.55266970e-02  9.51764584e-02
    -1.38199165e-01  1.18672848e-02 -1.41300172e-01 -1.69071898e-01
     1.52420819e-01 -1.76010519e-01  8.78888667e-02  7.76669681e-02]
   [-5.28266728e-02 -7.85517693e-03 -9.20811519e-02  1.63302064e-01
     1.41457707e-01 -8.70479271e-02 -1.75527871e-01 -1.49765193e-01
     1.02608055e-02 -1.22574881e-01 -7.00742826e-02 -1.72640368e-01]
   [-6.49261028e-02  3.76553088e-02  1.51447207e-02 -1.18315905e-01
    -8.06945935e-02  1.49511456e-01  4.14071679e-02 -1.27147347e-01
     1.80286735e-01  7.19477832e-02  1.55820101e-02 -1.03261203e-01]
   [ 1.41694337e-01 -6.24322295e-02  1.15811795e-01 -9.51586142e-02
     1.49993539e-01  1.17649287e-01  3.02957594e-02  2.66269594e-02
    -1.63218677e-01  1.16232336e-01 -6.88857660e-02 -3.34617198e-02]
   [ 1.85265839e-02 -1.72780707e-01  1.06177509e-01 -8.92564133e-02
     1.17356837e-01  1.70722187e-01  8.87984335e-02 -1.47996560e-01
     1.34868056e-01  1.92952156e-02 -1.66095763e-01  2.49674916e-02]
   [ 2.87357569e-02  1.41703129e-01  7.52265155e-02 -8.48462209e-02
     2.94032395e-02  1.42702430e-01  1.53979063e-01 -1.11719072e-02
     1.29699051e-01 -5.90743572e-02  1.40473545e-02  1.56315535e-01]
   [ 6.19040430e-02 -2.06189901e-02 -5.67361414e-02  1.76428229e-01
    -1.10530704e-02  8.85301828e-02 -8.84541869e-03 -1.52084410e-01
    -3.88459563e-02  1.40014976e-01  1.55961126e-01 -1.64046645e-01]]]


 [[[ 4.25648689e-03  8.98439586e-02 -4.35977727e-02  1.06983155e-01
     2.51899362e-02  8.77319276e-03 -1.19932838e-01 -1.42490342e-01
    -6.24369755e-02  1.74831808e-01 -1.11000672e-01 -1.73406303e-03]
   [-4.36147004e-02 -7.79993609e-02  1.46764934e-01  1.20519042e-01
     3.80317420e-02  1.32458508e-01 -2.51937658e-02  9.32906568e-02
     9.58300531e-02  6.76800609e-02  6.37915134e-02 -2.08935142e-03]
   [ 9.21428204e-02 -1.26626223e-01 -1.05295703e-01  1.64834261e-01
     1.80658787e-01 -9.24042687e-02 -1.29927993e-01 -6.22721314e-02
    -1.05359912e-01  5.23713529e-02  2.36761123e-02 -1.63138628e-01]
   [-9.54960063e-02 -2.14881748e-02  1.12646163e-01  1.74191535e-01
     3.44628096e-03  1.61926299e-01  1.58273250e-01  1.56867951e-02
     2.06706077e-02  1.25562221e-01 -1.65372059e-01  4.79232520e-02]
   [ 1.19962305e-01 -4.58623618e-02 -1.49416864e-01  1.55377656e-01
    -3.89145166e-02 -5.39887697e-02  1.60350204e-01 -9.65190232e-02
     3.29748392e-02 -1.64857507e-01  1.05096161e-01  7.07103014e-02]
   [-1.20915376e-01  1.08093202e-01 -1.31271765e-01 -1.79597750e-01
    -2.57807970e-02 -9.47172716e-02  1.47617459e-01 -1.55910969e-01
     1.50786340e-01  1.54214382e-01  5.77574670e-02  1.12168819e-01]
   [-1.90540254e-02  1.39549166e-01 -9.14754868e-02 -9.72161889e-02
     1.55543745e-01 -1.36237085e-01 -1.10009469e-01  1.20209605e-01
     6.74618781e-02  8.37951601e-02  1.76556736e-01 -7.34775141e-02]
   [-1.59330264e-01  1.18923366e-01  6.27512187e-02 -3.31075639e-02
    -1.00204982e-01  1.22297585e-01 -5.15450388e-02 -8.07907060e-02
    -1.34177387e-01 -1.10616878e-01  1.72897637e-01 -1.29213497e-01]]

  [[ 1.11783534e-01 -5.45459390e-02 -1.35401487e-02  1.18027538e-01
     6.95149004e-02 -6.89958036e-03 -5.83146513e-03  1.51529521e-01
     8.57773423e-02 -8.92933309e-02  1.61266744e-01  1.33006960e-01]
   [ 1.64932668e-01 -9.97894555e-02  3.20096761e-02  1.32233053e-01
    -1.15717351e-01  9.46811736e-02 -8.10090527e-02  1.63969189e-01
     1.59583390e-01 -1.23477802e-01  1.80558830e-01 -1.50979385e-01]
   [-1.52807906e-01 -6.37370348e-03  1.46654993e-01 -1.25455454e-01
    -1.45555139e-02  6.47767484e-02 -1.07124448e-01 -9.12621915e-02
    -1.72373012e-01  1.76593721e-01  1.15190953e-01  1.16567612e-01]
   [ 1.20363206e-01  1.19858354e-01 -3.20471972e-02  1.29741937e-01
    -4.45766896e-02  1.33567452e-01  1.54925525e-01 -1.41365811e-01
     6.83134794e-02 -1.05220228e-01 -1.36043519e-01  1.47954345e-01]
   [-9.96115506e-02 -1.23997279e-01  1.29717439e-01  1.12763107e-01
    -6.63868934e-02 -1.78603247e-01  1.59075797e-01 -5.31462580e-02
    -1.72569335e-01 -8.85271728e-02  6.40488118e-02  5.85163087e-02]
   [-1.77035809e-01 -5.47862202e-02 -9.55599472e-02 -1.43166661e-01
     8.62739384e-02  2.65710652e-02  5.07326573e-02 -1.33114621e-01
    -1.68177992e-01 -1.21893562e-01  8.01801682e-04 -1.74880162e-01]
   [ 1.62263334e-01  1.25606716e-01 -1.22779377e-01  4.77101356e-02
     1.39659226e-01 -6.95866719e-02  1.48140907e-01 -5.99611700e-02
     8.73327255e-02  1.65933937e-01 -7.29069784e-02 -2.85871178e-02]
   [ 8.90282691e-02 -7.42706582e-02 -1.20910458e-01  1.25831723e-01
     1.14927262e-01 -1.81317806e-01 -1.38245776e-01 -1.76458612e-01
     9.16392505e-02 -6.08193949e-02  1.08285099e-02 -1.50721297e-01]]

  [[ 6.03461862e-02  1.24547660e-01 -8.12763646e-02 -1.74457580e-01
     9.16769803e-02 -6.66351616e-03  1.56731755e-01  3.42933834e-02
    -3.50841731e-02  1.58686489e-02 -6.58075660e-02  1.26392215e-01]
   [ 1.39954239e-02  5.04558980e-02  5.04422784e-02 -1.74083263e-02
    -1.06142305e-01  6.49550408e-02  8.85375440e-02  3.10065448e-02
    -1.31664664e-01  1.75815821e-01  2.67497450e-02  2.62670070e-02]
   [ 6.33399040e-02 -1.31615520e-01 -1.40392184e-02 -3.05083990e-02
     7.33584166e-02 -1.15155280e-02 -4.37519848e-02  9.74804163e-02
    -5.79845607e-02 -1.43975466e-02 -1.52669489e-01  1.07540905e-01]
   [ 1.42249972e-01 -1.79174826e-01  1.14173412e-01 -1.15154043e-01
     1.23451293e-01  8.14085901e-02  3.12688947e-02 -5.90064973e-02
    -9.61571261e-02 -2.31606066e-02 -1.56199604e-01  1.80257291e-01]
   [-1.03674076e-01 -4.80517745e-04 -1.49942353e-01 -1.45888090e-01
     3.76347601e-02 -6.96528330e-02  8.85638595e-02 -7.45727122e-03
     1.21188790e-01  3.01212966e-02 -1.78860933e-01 -4.83771712e-02]
   [-1.33370608e-01  7.48704374e-02 -6.24780655e-02  4.20927107e-02
     6.18667901e-02  1.31099313e-01 -3.75017822e-02 -7.03971386e-02
     1.62500918e-01 -1.47199631e-02 -8.18408430e-02 -2.02136785e-02]
   [ 4.42216694e-02 -8.60013142e-02  1.57468051e-01  1.37674659e-02
     6.86165392e-02  2.51895785e-02  5.50284088e-02 -1.44589245e-02
     9.32712853e-02 -1.61228791e-01  1.78502589e-01  1.29311472e-01]
   [-5.49125373e-02 -1.51102275e-01  1.31593674e-01  9.53472257e-02
     1.79685354e-02 -8.44948590e-02  4.86635119e-02  2.34054476e-02
    -1.06498890e-01  7.17085004e-02 -1.80102378e-01  1.50361359e-01]]]]: "
2018-04-20 09:30:30,908 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv_1/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 09:30:30,918 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv_2/weights:0, var_value [[[[-0.12522422 -0.1354345   0.09417535 ... -0.11621692  0.029524
    -0.07588997]
   [-0.08668954 -0.00297628 -0.0280368  ...  0.13890739  0.04549155
     0.02974808]
   [ 0.00260571  0.00451906  0.09286064 ... -0.13508692  0.05490991
     0.00800513]
   ...
   [ 0.04271789 -0.11691079 -0.14807814 ...  0.05746791 -0.02532297
    -0.06981846]
   [-0.04235376  0.00743799  0.12039594 ...  0.13588114 -0.03065713
     0.03426272]
   [-0.08544461  0.06057513 -0.14685057 ...  0.12645708 -0.10506473
    -0.05202372]]

  [[-0.0017053  -0.06590755 -0.12074768 ... -0.03506527  0.0471594
    -0.12902296]
   [ 0.06385727  0.02352367 -0.10391571 ... -0.06317076  0.10501872
     0.13921537]
   [-0.08738466  0.07329221 -0.1053246  ...  0.08514492  0.09068289
     0.05181745]
   ...
   [-0.11489826 -0.08441728 -0.05160032 ... -0.11444561 -0.02635787
     0.09266385]
   [-0.08226252 -0.05534509  0.03708895 ...  0.09940009  0.09619759
    -0.08005884]
   [ 0.14432804 -0.1319058  -0.0333412  ... -0.07117078 -0.03679721
    -0.08127585]]

  [[-0.14999907  0.00182149 -0.1291438  ...  0.1006272  -0.08041786
     0.10595734]
   [-0.15308557  0.04255168 -0.07102057 ... -0.0605379   0.09419173
    -0.11082023]
   [ 0.00714652  0.07216077 -0.07786005 ... -0.00067776  0.03274879
     0.05973859]
   ...
   [ 0.05690575 -0.13456014  0.09023222 ...  0.06514753  0.00051269
     0.15151139]
   [ 0.10813822 -0.05123677 -0.06322377 ... -0.07094847  0.03822237
     0.10246955]
   [ 0.1189784  -0.08899488  0.05898589 ... -0.11835147 -0.11053056
     0.1398172 ]]]


 [[[-0.13088883 -0.09102157 -0.01774706 ... -0.1386186  -0.03951944
     0.04540797]
   [ 0.0129533   0.01806973  0.11763816 ... -0.11220305 -0.11066774
    -0.09547827]
   [-0.10805482 -0.00213471 -0.04634861 ... -0.0838397   0.04927443
    -0.139608  ]
   ...
   [-0.08670194  0.12110518 -0.04537459 ...  0.03149109 -0.14170036
    -0.0120991 ]
   [-0.07291777  0.0526129  -0.06326388 ...  0.10662468 -0.08225171
     0.07743359]
   [-0.0266626   0.02086495  0.0366534  ...  0.11856143  0.11629193
     0.03119802]]

  [[-0.12298562  0.11590634 -0.00844648 ... -0.08813802 -0.04071294
    -0.05604029]
   [-0.1068588   0.03327785 -0.09436019 ...  0.04751584  0.01258445
     0.05925806]
   [ 0.07963617  0.03043199  0.01705211 ... -0.00663181 -0.1299533
     0.01570322]
   ...
   [-0.03363621  0.06438722  0.05083276 ... -0.03031117  0.12927397
     0.06691447]
   [-0.13986729  0.07173596  0.04670653 ... -0.115233    0.06701972
     0.14322536]
   [ 0.08088674 -0.08694081 -0.11239843 ... -0.1351938   0.11261041
     0.02717426]]

  [[ 0.13991122 -0.13064092  0.09233956 ...  0.0161047  -0.14876941
    -0.02430941]
   [ 0.01682532  0.13362668 -0.01136413 ... -0.05301271 -0.13972676
    -0.10186359]
   [ 0.02111846 -0.07457238  0.03911866 ... -0.06220826  0.10248439
     0.06369692]
   ...
   [ 0.15007146 -0.09400775 -0.05343858 ... -0.14926487 -0.09633681
     0.09016615]
   [-0.08707546 -0.03527912 -0.08245905 ...  0.09516852 -0.0007882
     0.05023497]
   [ 0.09024264 -0.09672493  0.02637583 ... -0.07301643 -0.01900829
    -0.12638085]]]


 [[[ 0.03938733  0.03906973  0.11211483 ... -0.04197498  0.0372963
     0.04559989]
   [-0.04688451 -0.01231976  0.06546494 ... -0.02586299 -0.04173272
    -0.10286638]
   [-0.09964574  0.1187769  -0.11503078 ...  0.02263713 -0.06730957
    -0.00470072]
   ...
   [ 0.1311542   0.11009382  0.11269118 ... -0.04250956  0.03042756
    -0.09522898]
   [-0.02665584  0.01291297  0.12490769 ... -0.0878212   0.14664848
     0.04764427]
   [ 0.07134758  0.08039707 -0.06811168 ...  0.02068302  0.03081958
     0.01278549]]

  [[ 0.14920895  0.07616501  0.02586679 ...  0.14995386  0.12782706
    -0.04017604]
   [ 0.03853169 -0.15360948  0.05542544 ... -0.07664546 -0.0714123
    -0.03333351]
   [-0.01313841  0.05898832  0.12622394 ... -0.020441    0.15000705
     0.0939586 ]
   ...
   [-0.04966236 -0.09621243  0.0729572  ... -0.05230574  0.08345963
    -0.11977363]
   [ 0.0275363  -0.02793138  0.10183831 ...  0.12256519 -0.10003938
     0.01554742]
   [ 0.08111656  0.0452089   0.13995512 ... -0.10029098  0.03191343
    -0.11672935]]

  [[ 0.1199619  -0.08640862  0.06365936 ... -0.12824656  0.09125014
     0.10840641]
   [ 0.02333318  0.10390221  0.09637664 ... -0.1134121  -0.12880318
    -0.11095425]
   [ 0.02464764  0.04679088 -0.1422983  ... -0.07373875 -0.05465475
     0.13453986]
   ...
   [ 0.02748016 -0.13626346  0.08940756 ...  0.02961722  0.07047635
     0.09916653]
   [ 0.0960225  -0.02609561  0.09388299 ... -0.01542278  0.02156408
     0.08577876]
   [ 0.06079799  0.12907632 -0.08451672 ... -0.05292048  0.0811267
     0.13957442]]]]: "
2018-04-20 09:30:30,923 (dqn_agent.py:161) DEBUG: "var_name: target_q/Conv_2/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 09:30:30,929 (dqn_agent.py:161) DEBUG: "var_name: target_q/fully_connected/weights:0, var_value [[-0.01165338  0.06772149 -0.07559088 ... -0.04275567 -0.07500613
  -0.07135338]
 [-0.06975953 -0.01027971  0.02858579 ... -0.04060309 -0.02329833
   0.02616174]
 [ 0.02934137  0.06960989 -0.01913106 ...  0.09125461  0.02750253
   0.07366175]
 ...
 [ 0.05613547  0.06916746 -0.07303284 ...  0.03601373 -0.00402633
   0.07013955]
 [-0.08416068 -0.07750266 -0.03354026 ... -0.02956528 -0.07028671
  -0.04191624]
 [-0.06461404 -0.01216286 -0.03355556 ... -0.05218419 -0.08294372
   0.08601653]]: "
2018-04-20 09:30:30,935 (dqn_agent.py:161) DEBUG: "var_name: target_q/fully_connected/biases:0, var_value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0.]: "
2018-04-20 09:30:30,945 (dqn_agent.py:161) DEBUG: "var_name: target_q/fully_connected_1/weights:0, var_value [[ 0.11870596 -0.15481125 -0.08325458 -0.08356291  0.08852899]
 [-0.01849052  0.06371495  0.0184916  -0.05823043  0.0574483 ]
 [ 0.19474357  0.0282993   0.14010581  0.16359675  0.00182505]
 [-0.08241451  0.00947648  0.10794613  0.05049366 -0.01001088]
 [-0.14022098  0.1514669   0.0678007   0.01713617  0.15390167]
 [-0.05876082 -0.07358465 -0.13201798 -0.12570804  0.01221827]
 [-0.07425344  0.12143624  0.07878765  0.02007711  0.09286267]
 [-0.13791743  0.07838187 -0.05613495  0.09285158  0.19956061]
 [ 0.10805166 -0.05447119  0.13778886 -0.07942197  0.20851532]
 [-0.19574533 -0.06973067 -0.04073122  0.05821517 -0.1321418 ]
 [ 0.16401622  0.15225562 -0.03095718 -0.04711439  0.0270002 ]
 [ 0.11706933  0.0592455   0.09083107  0.11641932  0.03405657]
 [ 0.03040607  0.04500788  0.05787361 -0.14870766 -0.1327883 ]
 [ 0.03028473  0.03329678  0.12971964 -0.17246987 -0.07720664]
 [ 0.07415843  0.04051423  0.18194291 -0.06031424  0.06225461]
 [-0.06854317  0.13581443  0.2008906   0.01990129  0.11714604]
 [-0.05915804  0.01314983 -0.07446997  0.07476658  0.15690085]
 [-0.05559535 -0.18741989  0.2027219   0.2009961   0.05214098]
 [-0.05809887  0.11117184  0.15488884  0.16936141  0.19524512]
 [-0.14364335 -0.02939688  0.08226016 -0.19049396 -0.08981791]
 [-0.07796057  0.09598601 -0.1731134   0.08341271 -0.04922266]
 [-0.01838033  0.16872826  0.10187683  0.15695244  0.00467034]
 [ 0.12725466  0.09740776 -0.11939754  0.17046866  0.16501188]
 [-0.058165   -0.09144739 -0.1762802   0.00307301 -0.07133847]
 [ 0.12365672 -0.18159056 -0.12886395 -0.04562421 -0.14570783]
 [-0.14515418 -0.1258271   0.12732568 -0.06867458 -0.1598238 ]
 [ 0.12676376 -0.20967916 -0.01580501  0.12767547 -0.14316487]
 [ 0.07466397  0.19889629 -0.06243522 -0.08853775 -0.00535955]
 [-0.13031472 -0.02444483 -0.08873296  0.00349337  0.10584959]
 [ 0.11085191 -0.08651499  0.05576751  0.10258698  0.06979695]
 [ 0.0460459   0.1971511   0.01044288  0.14720884 -0.20767003]
 [-0.03380635 -0.03087747  0.20766097  0.15110832  0.17644873]
 [ 0.17145759 -0.06252871  0.03008197  0.01492693 -0.00988074]
 [-0.03732611  0.18120414 -0.12720662  0.01327081  0.06358033]
 [ 0.06066501 -0.05360521 -0.18311344 -0.00502719  0.07951105]
 [-0.04452883 -0.19004758 -0.08509952 -0.03402294  0.01059683]
 [ 0.02818963  0.20387697  0.15909317  0.19612503 -0.18932626]
 [ 0.16145715  0.07530695 -0.0775439  -0.01408909  0.10275957]
 [-0.13024464  0.03376448  0.13551894  0.11391729 -0.11753183]
 [-0.09155996 -0.09994835 -0.14183679  0.12092179  0.2008149 ]
 [ 0.08213508  0.03913659 -0.19157365 -0.14531796  0.10953736]
 [ 0.01025492  0.15585119 -0.0205951   0.1926255   0.03500374]
 [-0.17024046 -0.02630918  0.02272911  0.00827192  0.21206793]
 [ 0.04478785 -0.06176957 -0.16253135 -0.08820727 -0.19107611]
 [ 0.03661002  0.02499609 -0.13273752 -0.14817317 -0.20688543]
 [-0.136457   -0.16357595  0.06342134 -0.08944865  0.088478  ]
 [ 0.13113368 -0.05381112 -0.21110208  0.08085087 -0.07331403]
 [-0.02425291 -0.12829804 -0.096749   -0.12726212  0.10596576]
 [ 0.18752867  0.05446807 -0.11938838  0.18519834  0.02568363]
 [ 0.05107617 -0.13383083  0.12638038  0.06299251 -0.19418857]
 [ 0.21073759 -0.08026709  0.02570985  0.06507269 -0.17872274]
 [-0.08997803 -0.09236554  0.2098794   0.1007517  -0.18008167]
 [-0.05088186  0.01850961 -0.1553129  -0.11694446 -0.02926728]
 [ 0.12238765 -0.1467902   0.17086092  0.03407668 -0.1571192 ]
 [ 0.2001664   0.06628212 -0.18702677 -0.08881039 -0.05014227]
 [-0.16131322 -0.01338322 -0.11745212  0.10844958  0.03619209]
 [ 0.16515875  0.20122135 -0.00852163 -0.15165995  0.05736285]
 [-0.0056102   0.01120335 -0.039601   -0.0784713   0.1706138 ]
 [-0.18446264 -0.13866833  0.12121865 -0.13670716 -0.06040463]
 [-0.06053007  0.06257394 -0.19829705  0.0083417   0.11260951]
 [-0.09664686 -0.01276755  0.09975061  0.11941856  0.16222301]
 [ 0.19435817 -0.20760411  0.14799121  0.0387938   0.15001747]
 [ 0.18698838  0.1820336   0.08803049  0.06564122  0.19509685]
 [-0.00950119  0.05600187 -0.01585135  0.0136506   0.07987544]
 [ 0.01071411  0.13388419  0.20310634 -0.12489062  0.18849719]
 [ 0.17595473 -0.03391731  0.00028606  0.01688054  0.11814392]
 [ 0.14996955  0.16897684  0.08489561 -0.16387957 -0.09658629]
 [-0.00572459 -0.03371689 -0.00589196 -0.12346446  0.17268154]
 [ 0.14934197 -0.13974467 -0.20037621  0.0794566  -0.20891617]
 [ 0.08974302 -0.0734383  -0.03546232 -0.05977382  0.13392445]
 [-0.06005476 -0.17769825  0.05928564 -0.06719276  0.0247198 ]
 [-0.15733245  0.16773114  0.05051798  0.10795903 -0.19855264]
 [-0.19375646 -0.14612946  0.02872367 -0.01842095 -0.18731324]
 [ 0.04998356 -0.06341602 -0.12803528 -0.18418524 -0.09847698]
 [-0.10515785 -0.13462126 -0.08387348 -0.01258479  0.04680407]
 [-0.16451901  0.10233438  0.07279852 -0.0383343   0.04631194]
 [-0.05804706  0.06967178  0.0796783  -0.11187002  0.04453248]
 [-0.16981372 -0.03683335 -0.05120616  0.05916715 -0.12504143]
 [-0.1842099  -0.12976742  0.06102619  0.053002    0.11583146]
 [ 0.06445989  0.00352162 -0.02236424  0.05631351 -0.18259268]
 [-0.186566   -0.1534721  -0.00459099  0.06794512  0.15025187]
 [ 0.16575283 -0.08664975 -0.11617312  0.05678836 -0.12248691]
 [-0.19396895  0.03695837 -0.00519243 -0.05851391 -0.18112351]
 [-0.1592849  -0.1529779   0.1379495  -0.16804002  0.10364354]
 [-0.08048671 -0.10631137  0.14507023  0.10860464 -0.15571897]
 [ 0.05767405  0.15034914  0.03106216  0.03045295 -0.06186159]
 [-0.129422   -0.21169983 -0.1626545   0.14628795 -0.0628999 ]
 [ 0.01872949 -0.07295378  0.06444728  0.04372817 -0.18703948]
 [ 0.16834888 -0.12346137 -0.20794638 -0.11178424  0.1723615 ]
 [-0.05670936  0.06118587 -0.03188844 -0.14303224  0.20373943]
 [ 0.11243004  0.11467034  0.15567076 -0.08211325 -0.11773717]
 [-0.10844365  0.12770891 -0.20028517 -0.07567084 -0.04560679]
 [ 0.124928   -0.21079926  0.08473417 -0.15557262  0.02163063]
 [ 0.02932152  0.12775981  0.13599658 -0.17701118 -0.16031364]
 [-0.01065761 -0.11042659 -0.09209082 -0.18266428 -0.0700178 ]
 [-0.04550071 -0.11339108  0.19916847  0.06390637 -0.08612877]
 [ 0.14215967  0.00669667  0.16665241  0.00307089  0.09122986]
 [ 0.1852211   0.05512637 -0.12161277  0.2123535   0.01983683]
 [-0.07329944 -0.14195108 -0.15203196 -0.08365381  0.09283501]
 [ 0.10755169 -0.02434866  0.11233383  0.05180568 -0.01607811]
 [-0.13685755  0.19209418 -0.13852623  0.13343418  0.16740105]
 [ 0.09855086 -0.16175449 -0.15750082 -0.11597005  0.19820035]
 [-0.02913056 -0.04245529  0.08314037 -0.01706158  0.19339389]
 [-0.21121754  0.06868714  0.13475317 -0.05326384 -0.00214358]
 [ 0.05587006  0.11235818  0.02798373 -0.15585741 -0.12964344]
 [ 0.16723248  0.16166076 -0.13607234 -0.11485618 -0.13980564]
 [ 0.15420306  0.04603398  0.20680773 -0.18654817 -0.01594858]
 [-0.04814774  0.13367876  0.16997239 -0.01469879 -0.03121002]
 [ 0.03704789 -0.12046593 -0.17657067  0.03373668 -0.05611451]
 [ 0.13235953 -0.01615311  0.00642343 -0.05527449  0.06542054]
 [ 0.01838723 -0.11417508 -0.14777616  0.1668779   0.13927963]
 [ 0.14299482 -0.16021495 -0.00349504 -0.00945121 -0.03680909]
 [ 0.15246865  0.16281214  0.16994256  0.09518212  0.12469292]
 [-0.00890876  0.14164087  0.09123138  0.21208566 -0.11661971]
 [ 0.17379218  0.1704965  -0.02545093 -0.2097229   0.1095877 ]
 [ 0.15858415  0.03697285 -0.14251359 -0.08646128 -0.09676763]
 [ 0.08376098 -0.19605236 -0.03285114  0.16838276 -0.09117926]
 [-0.08535226 -0.14517277  0.1861194  -0.16224594  0.08802232]
 [ 0.06046149  0.02778006  0.20381129 -0.00219168 -0.19863513]
 [ 0.03249429  0.11393541  0.03708826 -0.13691509 -0.12910494]
 [ 0.13910034  0.16108185  0.02288209 -0.05193147 -0.05181526]
 [-0.02375491 -0.01449531 -0.06506823  0.15824932  0.05737817]
 [-0.15993921 -0.15391265 -0.00290221 -0.16329236 -0.11534227]
 [-0.152004    0.02057642  0.04729456 -0.15693027 -0.00726774]
 [ 0.03124861 -0.19861938  0.17666292  0.08555436  0.04093698]
 [-0.14260468 -0.2113337   0.1300441   0.04472855  0.20611334]
 [ 0.09716618 -0.20655754  0.16672412 -0.18893832 -0.00610258]
 [-0.01092255 -0.14002511 -0.00033168 -0.17544875 -0.08068506]]: "
2018-04-20 09:30:30,951 (dqn_agent.py:161) DEBUG: "var_name: target_q/fully_connected_1/biases:0, var_value [0. 0. 0. 0. 0.]: "
2018-04-20 09:30:32,395 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:32,395 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:32,395 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:32,395 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:33,005 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:33,006 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:33,006 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:33,006 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:33,474 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:33,474 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:33,474 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:33,474 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:34,153 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:34,154 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:34,154 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:34,154 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:34,874 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:34,874 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:34,874 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:34,874 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:35,585 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:35,585 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:35,585 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:35,585 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:36,437 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:36,437 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:36,437 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:36,437 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:37,128 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:37,129 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:37,129 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:37,129 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:37,705 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:37,706 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:37,706 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:37,706 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:38,575 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:38,575 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:38,576 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:38,576 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:39,387 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:39,388 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:39,388 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:39,388 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:40,112 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:40,112 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:40,112 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:40,112 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:40,838 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:40,838 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:40,838 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:40,838 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:41,566 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:41,567 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:41,567 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:41,567 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:42,182 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:42,182 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:42,183 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:42,183 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:42,810 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:42,810 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:42,810 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:42,810 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:43,573 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:43,573 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:43,573 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:43,573 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:44,113 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:44,113 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:44,113 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:44,113 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:44,923 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:44,923 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:44,923 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:44,923 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:45,612 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:45,612 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:45,612 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:45,612 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:46,313 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:46,313 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:46,313 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:46,313 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:47,058 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:47,059 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:47,059 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:47,059 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:47,977 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:47,977 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:47,977 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:47,977 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:48,768 (dqn_main.py:212) DEBUG: "Episode 0, mean reward over last 10000 episodes: 0"
2018-04-20 09:30:48,769 (dqn_main.py:213) DEBUG: "Epsilon: 0"
2018-04-20 09:30:48,769 (dqn_main.py:214) DEBUG: "RL steps: [], reward: -99.9999999999986, done: False"
2018-04-20 09:30:48,769 (dqn_main.py:215) DEBUG: "Steps: 0, coords: 40"
2018-04-20 09:30:56,144 (dqn_main.py:61) DEBUG: ">>>> RUNNING data_file=7_17.npy,reuse_weights=None,test=True<<<<"
2018-04-20 09:30:56,616 (tf_logging.py:160) Level 1: "Registering Batch (<function _BatchGrad at 0x7f3038cb4378>) in gradient."
2018-04-20 09:30:56,618 (tf_logging.py:160) Level 1: "Registering Unbatch (<function _UnbatchGrad at 0x7f3038cb4e18>) in gradient."
2018-04-20 09:30:56,624 (tf_logging.py:160) Level 1: "Registering ZeroInitializer (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,643 (tf_logging.py:160) Level 1: "Registering SparseFeatureCross (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,646 (tf_logging.py:160) Level 1: "Registering SparseFeatureCrossV2 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,649 (tf_logging.py:160) Level 1: "Registering SparseFeatureCross (None) in gradient."
2018-04-20 09:30:56,650 (tf_logging.py:160) Level 1: "Registering SparseFeatureCrossV2 (None) in gradient."
2018-04-20 09:30:56,654 (tf_logging.py:160) Level 1: "Registering GDNLowerBound (<function GDN._lower_bound_grad at 0x7f30381586a8>) in gradient."
2018-04-20 09:30:56,673 (tf_logging.py:160) Level 1: "Registering ObtainNext (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,684 (tf_logging.py:160) Level 1: "Registering hparams ((<class 'tensorflow.contrib.training.python.training.hparam_pb2.HParamDef'>, <function HParams.to_proto at 0x7f3030240620>, <function HParams.from_proto at 0x7f30302406a8>)) in proto functions."
2018-04-20 09:30:56,691 (tf_logging.py:160) Level 1: "Registering GRUBlockCell (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,693 (tf_logging.py:160) Level 1: "Registering GRUBlockCellGrad (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,695 (tf_logging.py:160) Level 1: "Registering GRUBlockCell (<function _GRUBlockCellGrad at 0x7f30301d9b70>) in gradient."
2018-04-20 09:30:56,697 (tf_logging.py:160) Level 1: "Registering BlockLSTM (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,698 (tf_logging.py:160) Level 1: "Registering BlockLSTMGrad (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,700 (tf_logging.py:160) Level 1: "Registering LSTMBlockCell (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,701 (tf_logging.py:160) Level 1: "Registering LSTMBlockCellGrad (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,704 (tf_logging.py:160) Level 1: "Registering LSTMBlockCell (<function _LSTMBlockCellGrad at 0x7f30301a0d90>) in gradient."
2018-04-20 09:30:56,704 (tf_logging.py:160) Level 1: "Registering BlockLSTM (<function _BlockLSTMGrad at 0x7f30301a0e18>) in gradient."
2018-04-20 09:30:56,709 (tf_logging.py:160) Level 1: "Registering KMC2ChainInitialization (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,710 (tf_logging.py:160) Level 1: "Registering KmeansPlusPlusInitialization (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,711 (tf_logging.py:160) Level 1: "Registering NearestNeighbors (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,714 (tf_logging.py:160) Level 1: "Registering MaskedMatmul (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,716 (tf_logging.py:160) Level 1: "Registering WALSComputePartialLhsAndRhs (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,730 (tf_logging.py:160) Level 1: "Registering ConfigureDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,731 (tf_logging.py:160) Level 1: "Registering CrossReplicaSum (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,732 (tf_logging.py:160) Level 1: "Registering InfeedDequeue (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,733 (tf_logging.py:160) Level 1: "Registering InfeedDequeueTuple (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,733 (tf_logging.py:160) Level 1: "Registering InfeedEnqueue (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,734 (tf_logging.py:160) Level 1: "Registering InfeedEnqueueTuple (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,735 (tf_logging.py:160) Level 1: "Registering OutfeedDequeue (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,735 (tf_logging.py:160) Level 1: "Registering OutfeedDequeueTuple (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,736 (tf_logging.py:160) Level 1: "Registering OutfeedEnqueue (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,736 (tf_logging.py:160) Level 1: "Registering OutfeedEnqueueTuple (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,737 (tf_logging.py:160) Level 1: "Registering ShutdownDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,738 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingActivations (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,738 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingEnqueueSparseBatch (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,739 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingLoadAdagradParameters (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,740 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingLoadGradientDescentParameters (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,740 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingReceiveActivations (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,741 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingRetrieveAdagradParameters (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,742 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingRetrieveGradientDescentParameters (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,743 (tf_logging.py:160) Level 1: "Registering TPUEmbeddingSendGradients (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,743 (tf_logging.py:160) Level 1: "Registering TPUReplicate (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,744 (tf_logging.py:160) Level 1: "Registering TPUReplicateMetadata (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,745 (tf_logging.py:160) Level 1: "Registering TPUReplicatedInput (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,745 (tf_logging.py:160) Level 1: "Registering TPUReplicatedOutput (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,751 (tf_logging.py:160) Level 1: "Registering _ConfigureDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,752 (tf_logging.py:160) Level 1: "Registering _WaitForDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,752 (tf_logging.py:160) Level 1: "Registering _SetGlobalTPUArray (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,753 (tf_logging.py:160) Level 1: "Registering _ShutdownDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,754 (tf_logging.py:160) Level 1: "Registering _InitializeHostForDistributedTPU (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,754 (tf_logging.py:160) Level 1: "Registering _DisconnectHostFromDistributedTPUSystem (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,756 (tf_logging.py:160) Level 1: "Registering CrossReplicaSum (<function _cross_replica_sum_grad at 0x7f3030058400>) in gradient."
2018-04-20 09:30:56,760 (tf_logging.py:160) Level 1: "Registering CloseSummaryWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,762 (tf_logging.py:160) Level 1: "Registering CreateSummaryDbWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,762 (tf_logging.py:160) Level 1: "Registering CreateSummaryFileWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,763 (tf_logging.py:160) Level 1: "Registering FlushSummaryWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,764 (tf_logging.py:160) Level 1: "Registering ImportEvent (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,764 (tf_logging.py:160) Level 1: "Registering SummaryWriter (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,765 (tf_logging.py:160) Level 1: "Registering WriteAudioSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,765 (tf_logging.py:160) Level 1: "Registering WriteGraphSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,766 (tf_logging.py:160) Level 1: "Registering WriteHistogramSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,766 (tf_logging.py:160) Level 1: "Registering WriteImageSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,767 (tf_logging.py:160) Level 1: "Registering WriteScalarSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,767 (tf_logging.py:160) Level 1: "Registering WriteSummary (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,785 (tf_logging.py:160) Level 1: "Registering BigQueryReader (None) in gradient."
2018-04-20 09:30:56,787 (tf_logging.py:160) Level 1: "Registering RangeDecode (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,788 (tf_logging.py:160) Level 1: "Registering RangeEncode (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,829 (tf_logging.py:160) Level 1: "Registering CudnnRNN (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,830 (tf_logging.py:160) Level 1: "Registering CudnnRNNBackprop (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,831 (tf_logging.py:160) Level 1: "Registering CudnnRNNCanonicalToParams (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,831 (tf_logging.py:160) Level 1: "Registering CudnnRNNParamsSize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,832 (tf_logging.py:160) Level 1: "Registering CudnnRNNParamsToCanonical (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,839 (tf_logging.py:160) Level 1: "Registering CudnnRNN (<function _cudnn_rnn_backward at 0x7f2fe316f6a8>) in gradient."
2018-04-20 09:30:56,839 (tf_logging.py:160) Level 1: "Registering CudnnRNNParamsSize (<function call_cpp_shape_fn at 0x7f30a4421840>) in shape functions."
2018-04-20 09:30:56,839 (tf_logging.py:160) Level 1: "Registering CudnnRNNParamsToCanonical (<function call_cpp_shape_fn at 0x7f30a4421840>) in shape functions."
2018-04-20 09:30:56,840 (tf_logging.py:160) Level 1: "Registering CudnnRNNCanonicalToParams (<function call_cpp_shape_fn at 0x7f30a4421840>) in shape functions."
2018-04-20 09:30:56,840 (tf_logging.py:160) Level 1: "Registering CudnnRNN (<function call_cpp_shape_fn at 0x7f30a4421840>) in shape functions."
2018-04-20 09:30:56,840 (tf_logging.py:160) Level 1: "Registering CudnnRNNBackprop (<function call_cpp_shape_fn at 0x7f30a4421840>) in shape functions."
2018-04-20 09:30:56,888 (tf_logging.py:160) Level 1: "Registering AdjustHsvInYiq (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,897 (tf_logging.py:160) Level 1: "Registering BipartiteMatch (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,901 (tf_logging.py:160) Level 1: "Registering ImageConnectedComponents (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,902 (tf_logging.py:160) Level 1: "Registering ImageProjectiveTransform (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,906 (tf_logging.py:160) Level 1: "Registering ImageConnectedComponents (<function call_cpp_shape_fn at 0x7f30a4421840>) in shape functions."
2018-04-20 09:30:56,909 (tf_logging.py:160) Level 1: "Registering ImageProjectiveTransform (<function call_cpp_shape_fn at 0x7f30a4421840>) in shape functions."
2018-04-20 09:30:56,910 (tf_logging.py:160) Level 1: "Registering ImageProjectiveTransform (<function _image_projective_transform_grad at 0x7f2fe2a8fb70>) in gradient."
2018-04-20 09:30:56,911 (tf_logging.py:160) Level 1: "Registering BipartiteMatch (None) in gradient."
2018-04-20 09:30:56,912 (tf_logging.py:160) Level 1: "Registering ImageConnectedComponents (None) in gradient."
2018-04-20 09:30:56,913 (tf_logging.py:160) Level 1: "Registering SingleImageRandomDotStereograms (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,920 (tf_logging.py:160) Level 1: "Registering SingleImageRandomDotStereograms (None) in gradient."
2018-04-20 09:30:56,974 (tf_logging.py:160) Level 1: "Registering BytesInUse (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,974 (tf_logging.py:160) Level 1: "Registering BytesLimit (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,975 (tf_logging.py:160) Level 1: "Registering MaxBytesInUse (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,979 (tf_logging.py:160) Level 1: "Registering NcclAllReduce (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,980 (tf_logging.py:160) Level 1: "Registering NcclBroadcast (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,981 (tf_logging.py:160) Level 1: "Registering NcclReduce (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,983 (tf_logging.py:160) Level 1: "Registering _NcclReduceSend (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,983 (tf_logging.py:160) Level 1: "Registering _NcclReduceRecv (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,984 (tf_logging.py:160) Level 1: "Registering _NcclBroadcastSend (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,984 (tf_logging.py:160) Level 1: "Registering _NcclBroadcastRecv (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,985 (tf_logging.py:160) Level 1: "Registering NcclAllReduce (<function _all_sum_grad at 0x7f2fe2141950>) in gradient."
2018-04-20 09:30:56,985 (tf_logging.py:160) Level 1: "Registering NcclReduce (<function _reduce_sum_grad at 0x7f2fe2141bf8>) in gradient."
2018-04-20 09:30:56,985 (tf_logging.py:160) Level 1: "Registering NcclBroadcast (<function _broadcast_grad at 0x7f2fe2141d90>) in gradient."
2018-04-20 09:30:56,986 (tf_logging.py:160) Level 1: "Registering PeriodicResample (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,992 (tf_logging.py:160) Level 1: "Registering FoldFusedBatchNormGrad (<function _FoldFusedBatchNormGrad at 0x7f2fe0b6a048>) in gradient."
2018-04-20 09:30:56,994 (tf_logging.py:160) Level 1: "Registering Resampler (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,995 (tf_logging.py:160) Level 1: "Registering ResamplerGrad (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:56,997 (tf_logging.py:160) Level 1: "Registering Resampler (<function _resampler_grad at 0x7f2fe0898c80>) in gradient."
2018-04-20 09:30:56,998 (tf_logging.py:160) Level 1: "Registering ResamplerGrad (None) in gradient."
2018-04-20 09:30:57,001 (tf_logging.py:160) Level 1: "Registering GatherTree (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,009 (tf_logging.py:160) Level 1: "Registering StatelessRandomNormal (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,009 (tf_logging.py:160) Level 1: "Registering StatelessRandomUniform (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,010 (tf_logging.py:160) Level 1: "Registering StatelessTruncatedNormal (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,010 (tf_logging.py:160) Level 1: "Registering StatelessRandomNormal (None) in gradient."
2018-04-20 09:30:57,010 (tf_logging.py:160) Level 1: "Registering StatelessRandomUniform (None) in gradient."
2018-04-20 09:30:57,011 (tf_logging.py:160) Level 1: "Registering StatelessTruncatedNormal (None) in gradient."
2018-04-20 09:30:57,015 (tf_logging.py:160) Level 1: "Registering ReinterpretStringToFloat (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,016 (tf_logging.py:160) Level 1: "Registering ScatterAddNdim (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,022 (tf_logging.py:160) Level 1: "Registering CreateTreeVariable (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,022 (tf_logging.py:160) Level 1: "Registering DecisionTreeResourceHandleOp (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,023 (tf_logging.py:160) Level 1: "Registering FeatureUsageCounts (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,023 (tf_logging.py:160) Level 1: "Registering TraverseTreeV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,024 (tf_logging.py:160) Level 1: "Registering TreeDeserialize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,024 (tf_logging.py:160) Level 1: "Registering TreeIsInitializedOp (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,025 (tf_logging.py:160) Level 1: "Registering TreePredictionsV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,026 (tf_logging.py:160) Level 1: "Registering TreeSerialize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,026 (tf_logging.py:160) Level 1: "Registering TreeSize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,027 (tf_logging.py:160) Level 1: "Registering UpdateModelV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,030 (tf_logging.py:160) Level 1: "Registering TreeVariable (None) in gradient."
2018-04-20 09:30:57,030 (tf_logging.py:160) Level 1: "Registering TreeSerialize (None) in gradient."
2018-04-20 09:30:57,030 (tf_logging.py:160) Level 1: "Registering TreeDeserialize (None) in gradient."
2018-04-20 09:30:57,031 (tf_logging.py:160) Level 1: "Registering TreeSize (None) in gradient."
2018-04-20 09:30:57,031 (tf_logging.py:160) Level 1: "Registering TreePredictionsV4 (None) in gradient."
2018-04-20 09:30:57,031 (tf_logging.py:160) Level 1: "Registering FeatureUsageCounts (None) in gradient."
2018-04-20 09:30:57,032 (tf_logging.py:160) Level 1: "Registering CreateFertileStatsVariable (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,033 (tf_logging.py:160) Level 1: "Registering FertileStatsDeserialize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,033 (tf_logging.py:160) Level 1: "Registering FertileStatsIsInitializedOp (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,034 (tf_logging.py:160) Level 1: "Registering FertileStatsResourceHandleOp (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,034 (tf_logging.py:160) Level 1: "Registering FertileStatsSerialize (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,034 (tf_logging.py:160) Level 1: "Registering FinalizeTree (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,035 (tf_logging.py:160) Level 1: "Registering GrowTreeV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,035 (tf_logging.py:160) Level 1: "Registering ProcessInputV4 (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,038 (tf_logging.py:160) Level 1: "Registering FertileStatsVariable (None) in gradient."
2018-04-20 09:30:57,038 (tf_logging.py:160) Level 1: "Registering FertileStatsSerialize (None) in gradient."
2018-04-20 09:30:57,039 (tf_logging.py:160) Level 1: "Registering FertileStatsDeserialize (None) in gradient."
2018-04-20 09:30:57,039 (tf_logging.py:160) Level 1: "Registering GrowTreeV4 (None) in gradient."
2018-04-20 09:30:57,039 (tf_logging.py:160) Level 1: "Registering ProcessInputV4 (None) in gradient."
2018-04-20 09:30:57,054 (tf_logging.py:160) Level 1: "Registering FinalizeTree (None) in gradient."
2018-04-20 09:30:57,102 (tf_logging.py:160) Level 1: "Registering FunctionBufferingResource (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,108 (tf_logging.py:160) Level 1: "Registering FunctionBufferingResourceGetNext (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,121 (tf_logging.py:160) Level 1: "Registering RemoteFusedGraphExecute (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x7f30a4421950>) in default shape functions."
2018-04-20 09:30:57,145 (tf_logging.py:160) Level 1: "Registering RemoteFusedGraphExecute (None) in gradient."
2018-04-20 09:30:57,170 (tf_logging.py:160) Level 1: "Created variable q/Conv/weights:0 with shape (1, 1, 2, 8) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f3038155510>"
2018-04-20 09:30:57,185 (tf_logging.py:160) Level 1: "Created variable q/Conv/biases:0 with shape (8,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f303815a208>"
2018-04-20 09:30:57,193 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/weights:0 with shape (3, 3, 8, 12) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f3038155510>"
2018-04-20 09:30:57,197 (tf_logging.py:160) Level 1: "Created variable q/Conv_1/biases:0 with shape (12,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f303815a208>"
2018-04-20 09:30:57,204 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/weights:0 with shape (3, 3, 12, 16) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f3038155510>"
2018-04-20 09:30:57,207 (tf_logging.py:160) Level 1: "Created variable q/Conv_2/biases:0 with shape (16,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f303815a208>"
2018-04-20 09:30:57,224 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/weights:0 with shape (576, 128) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f30381582f0>"
2018-04-20 09:30:57,228 (tf_logging.py:160) Level 1: "Created variable q/fully_connected/biases:0 with shape (128,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f303815a5f8>"
2018-04-20 09:30:57,235 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/weights:0 with shape (128, 5) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f30381582f0>"
2018-04-20 09:30:57,239 (tf_logging.py:160) Level 1: "Created variable q/fully_connected_1/biases:0 with shape (5,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f303815a5f8>"
2018-04-20 09:30:57,249 (tf_logging.py:160) Level 1: "Created variable target_q/Conv/weights:0 with shape (1, 1, 2, 8) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f3038155510>"
2018-04-20 09:30:57,253 (tf_logging.py:160) Level 1: "Created variable target_q/Conv/biases:0 with shape (8,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f303815a208>"
2018-04-20 09:30:57,261 (tf_logging.py:160) Level 1: "Created variable target_q/Conv_1/weights:0 with shape (3, 3, 8, 12) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f3038155510>"
2018-04-20 09:30:57,265 (tf_logging.py:160) Level 1: "Created variable target_q/Conv_1/biases:0 with shape (12,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f303815a208>"
2018-04-20 09:30:57,273 (tf_logging.py:160) Level 1: "Created variable target_q/Conv_2/weights:0 with shape (3, 3, 12, 16) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f3038155510>"
2018-04-20 09:30:57,276 (tf_logging.py:160) Level 1: "Created variable target_q/Conv_2/biases:0 with shape (16,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f303815a208>"
2018-04-20 09:30:57,288 (tf_logging.py:160) Level 1: "Created variable target_q/fully_connected/weights:0 with shape (576, 128) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f30381582f0>"
2018-04-20 09:30:57,292 (tf_logging.py:160) Level 1: "Created variable target_q/fully_connected/biases:0 with shape (128,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f303815a5f8>"
2018-04-20 09:30:57,299 (tf_logging.py:160) Level 1: "Created variable target_q/fully_connected_1/weights:0 with shape (128, 5) and init <function variance_scaling_initializer.<locals>._initializer at 0x7f30381582f0>"
2018-04-20 09:30:57,302 (tf_logging.py:160) Level 1: "Created variable target_q/fully_connected_1/biases:0 with shape (5,) and init <tensorflow.python.ops.init_ops.Zeros object at 0x7f303815a5f8>"
2018-04-20 09:30:57,329 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/value'"
2018-04-20 09:30:57,330 (tf_logging.py:160) Level 1: "  in  --> gradients/Fill:0"
2018-04-20 09:30:57,330 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/value_grad/tuple/control_dependency:0, gradients/mean_squared_error/value_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,336 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/div'"
2018-04-20 09:30:57,336 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/value_grad/tuple/control_dependency:0"
2018-04-20 09:30:57,336 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/div_grad/tuple/control_dependency:0, gradients/mean_squared_error/div_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,338 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/Sum_1'"
2018-04-20 09:30:57,338 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/div_grad/tuple/control_dependency:0"
2018-04-20 09:30:57,338 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/Sum_1_grad/Tile:0"
2018-04-20 09:30:57,341 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/Select'"
2018-04-20 09:30:57,342 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/div_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,342 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/Select_grad/tuple/control_dependency:0, gradients/mean_squared_error/Select_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,344 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/Sum'"
2018-04-20 09:30:57,344 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/Sum_1_grad/Tile:0"
2018-04-20 09:30:57,344 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/Sum_grad/Tile:0"
2018-04-20 09:30:57,351 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/Mul'"
2018-04-20 09:30:57,351 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/Sum_grad/Tile:0"
2018-04-20 09:30:57,351 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/Mul_grad/tuple/control_dependency:0, gradients/mean_squared_error/Mul_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,353 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/num_present'"
2018-04-20 09:30:57,354 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/Select_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,354 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/num_present_grad/Tile:0"
2018-04-20 09:30:57,359 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/num_present/broadcast_weights'"
2018-04-20 09:30:57,359 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/num_present_grad/Tile:0"
2018-04-20 09:30:57,359 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/num_present/broadcast_weights_grad/tuple/control_dependency:0, gradients/mean_squared_error/num_present/broadcast_weights_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,361 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/num_present/broadcast_weights/ones_like'"
2018-04-20 09:30:57,361 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/num_present/broadcast_weights_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,361 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/num_present/broadcast_weights/ones_like_grad/Sum:0"
2018-04-20 09:30:57,367 (tf_logging.py:160) Level 1: "Gradient for 'mean_squared_error/SquaredDifference'"
2018-04-20 09:30:57,367 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/Mul_grad/tuple/control_dependency:0"
2018-04-20 09:30:57,367 (tf_logging.py:160) Level 1: "  out --> gradients/mean_squared_error/SquaredDifference_grad/tuple/control_dependency:0, gradients/mean_squared_error/SquaredDifference_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,374 (tf_logging.py:160) Level 1: "Gradient for 'Sum'"
2018-04-20 09:30:57,374 (tf_logging.py:160) Level 1: "  in  --> gradients/mean_squared_error/SquaredDifference_grad/tuple/control_dependency:0"
2018-04-20 09:30:57,374 (tf_logging.py:160) Level 1: "  out --> gradients/Sum_grad/Tile:0"
2018-04-20 09:30:57,379 (tf_logging.py:160) Level 1: "Gradient for 'mul'"
2018-04-20 09:30:57,380 (tf_logging.py:160) Level 1: "  in  --> gradients/Sum_grad/Tile:0"
2018-04-20 09:30:57,380 (tf_logging.py:160) Level 1: "  out --> gradients/mul_grad/tuple/control_dependency:0, gradients/mul_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,381 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected_1/BiasAdd'"
2018-04-20 09:30:57,382 (tf_logging.py:160) Level 1: "  in  --> gradients/mul_grad/tuple/control_dependency:0"
2018-04-20 09:30:57,382 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency:0, gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,384 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected_1/MatMul'"
2018-04-20 09:30:57,384 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 09:30:57,384 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency:0, gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,384 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected_1/biases/read'"
2018-04-20 09:30:57,385 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,385 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,385 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/Relu'"
2018-04-20 09:30:57,385 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency:0"
2018-04-20 09:30:57,385 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/Relu_grad/ReluGrad:0"
2018-04-20 09:30:57,386 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected_1/weights/read'"
2018-04-20 09:30:57,386 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,386 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected_1/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,388 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/BiasAdd'"
2018-04-20 09:30:57,388 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/Relu_grad/ReluGrad:0"
2018-04-20 09:30:57,388 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency:0, gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,390 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/MatMul'"
2018-04-20 09:30:57,390 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 09:30:57,390 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/MatMul_grad/tuple/control_dependency:0, gradients/q/fully_connected/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,391 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/biases/read'"
2018-04-20 09:30:57,391 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,391 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,392 (tf_logging.py:160) Level 1: "Gradient for 'q/Flatten/flatten/Reshape'"
2018-04-20 09:30:57,392 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/MatMul_grad/tuple/control_dependency:0"
2018-04-20 09:30:57,392 (tf_logging.py:160) Level 1: "  out --> gradients/q/Flatten/flatten/Reshape_grad/Reshape:0"
2018-04-20 09:30:57,392 (tf_logging.py:160) Level 1: "Gradient for 'q/fully_connected/weights/read'"
2018-04-20 09:30:57,393 (tf_logging.py:160) Level 1: "  in  --> gradients/q/fully_connected/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,393 (tf_logging.py:160) Level 1: "  out --> gradients/q/fully_connected/MatMul_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,393 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/Relu'"
2018-04-20 09:30:57,393 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Flatten/flatten/Reshape_grad/Reshape:0"
2018-04-20 09:30:57,394 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/Relu_grad/ReluGrad:0"
2018-04-20 09:30:57,395 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/BiasAdd'"
2018-04-20 09:30:57,395 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/Relu_grad/ReluGrad:0"
2018-04-20 09:30:57,395 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency:0, gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,399 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/Conv2D'"
2018-04-20 09:30:57,400 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 09:30:57,400 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency:0, gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,400 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/biases/read'"
2018-04-20 09:30:57,400 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,400 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,401 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/Relu'"
2018-04-20 09:30:57,401 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency:0"
2018-04-20 09:30:57,401 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/Relu_grad/ReluGrad:0"
2018-04-20 09:30:57,401 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_2/weights/read'"
2018-04-20 09:30:57,401 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,401 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_2/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,403 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/BiasAdd'"
2018-04-20 09:30:57,403 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/Relu_grad/ReluGrad:0"
2018-04-20 09:30:57,403 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency:0, gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,407 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/Conv2D'"
2018-04-20 09:30:57,407 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 09:30:57,408 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency:0, gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,408 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/biases/read'"
2018-04-20 09:30:57,408 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,408 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,409 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/Relu'"
2018-04-20 09:30:57,409 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency:0"
2018-04-20 09:30:57,409 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/Relu_grad/ReluGrad:0"
2018-04-20 09:30:57,409 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv_1/weights/read'"
2018-04-20 09:30:57,409 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,409 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv_1/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,411 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/BiasAdd'"
2018-04-20 09:30:57,411 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv/Relu_grad/ReluGrad:0"
2018-04-20 09:30:57,411 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/BiasAdd_grad/tuple/control_dependency:0, gradients/q/Conv/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,415 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/Conv2D'"
2018-04-20 09:30:57,416 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv/BiasAdd_grad/tuple/control_dependency:0"
2018-04-20 09:30:57,416 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/Conv2D_grad/tuple/control_dependency:0, gradients/q/Conv/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,416 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/biases/read'"
2018-04-20 09:30:57,416 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,416 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/BiasAdd_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,416 (tf_logging.py:160) Level 1: "Gradient for 'q/Conv/weights/read'"
2018-04-20 09:30:57,416 (tf_logging.py:160) Level 1: "  in  --> gradients/q/Conv/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,417 (tf_logging.py:160) Level 1: "  out --> gradients/q/Conv/Conv2D_grad/tuple/control_dependency_1:0"
2018-04-20 09:30:57,502 (tf_logging.py:126) WARNING: "From /home/syedeqbal/.local/lib/python3.5/site-packages/tensorflow/python/ops/clip_ops.py:113: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead"
